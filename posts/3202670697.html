<!DOCTYPE html><html lang="zh-CN"><head><style type="text/css">.douban-card-block{display:flex;justify-content:center;align-items:center;width:100%;max-height:400px}.douban-card{display:flex;margin:30px 10px;padding:15px;border-radius:15px;position:relative;justify-content:center;align-items:center;overflow:hidden;color:#faebd7;text-decoration:none}.douban-card:hover{text-decoration:none}.douban-card-bgimg{position:absolute;width:115%;height:115%;filter:blur(15px) brightness(.6);background-size:100%;background-position:center;background-repeat:no-repeat}.douban-card-img{position:relative;height:130px;width:80px;background-size:100%;background-position:center;background-repeat:no-repeat}.douban-card-left:hover .douban-card-img{filter:blur(5px) brightness(.6);transform:perspective(800px) rotateX(180deg)}.douban-card-left .douban-card-img{transition:all .5s ease}.douban-card-left{position:relative;display:flex;flex-direction:column;align-items:center}.douban-card-left .douban-card-status{height:130px;width:80px;text-align:center;font-weight:700;position:absolute;left:0;top:30%;transform:rotateX(180deg);backface-visibility:hidden;transition:all .5s ease}.douban-card-left:hover .douban-card-status{transform:perspective(800px) rotateX(0)}.douban-card-right{position:relative;display:flex;flex-direction:column;margin-left:12px;font-size:16px;font-family:"Courier New",Courier,monospace;line-height:1.3;color:#faebd7}.douban-card-item{margin-top:4px}</style><meta charset="UTF-8"><meta name="viewport" content="width=device-width"><meta name="theme-color" content="#222" media="(prefers-color-scheme: light)"><meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 7.3.0"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png"><link rel="mask-icon" href="/images/logo.svg" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:ital,wght@0,300;0,400;0,700;1,300;1,400;1,700&family=Roboto+Mono:ital,wght@0,300;0,400;0,700;1,300;1,400;1,700&family=PT+Mono:ital,wght@0,300;0,400;0,700;1,300;1,400;1,700&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css" integrity="sha256-dABdfBfUoC8vJUBOwGVdm8L9qlMWaHTIfXt+7GnZCIo=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/blue/pace-theme-minimal.css"><script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script><script class="next-config" data-name="main" type="application/json">{"hostname":"www.shaogui.life","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.22.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":true,"style":"flat","show_result":true},"fold":{"enable":true,"height":200},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script><meta name="description" content="本文主要解决如何选择更好的模型问题，通常办法是交叉验证，文章最后也介绍了参数搜索的办法"><meta property="og:type" content="article"><meta property="og:title" content="机器学习的模型选择与评估"><meta property="og:url" content="https://www.shaogui.life/posts/3202670697.html"><meta property="og:site_name" content="年轻人起来冲"><meta property="og:description" content="本文主要解决如何选择更好的模型问题，通常办法是交叉验证，文章最后也介绍了参数搜索的办法"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121807208.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121807209.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121807210.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121807211.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121807212.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121807213.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121807214.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121807216.png"><meta property="article:published_time" content="2021-10-31T16:10:07.000Z"><meta property="article:modified_time" content="2025-01-18T10:36:30.319Z"><meta property="article:author" content="Shaogui"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121807208.png"><link rel="canonical" href="https://www.shaogui.life/posts/3202670697.html"><script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://www.shaogui.life/posts/3202670697.html","path":"posts/3202670697.html","title":"机器学习的模型选择与评估"}</script><script class="next-config" data-name="calendar" type="application/json">""</script><title>机器学习的模型选择与评估 | 年轻人起来冲</title><noscript><link rel="stylesheet" href="/css/noscript.css"></noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css"><link rel="alternate" href="/atom.xml" title="年轻人起来冲" type="application/atom+xml"></head><body itemscope itemtype="http://schema.org/WebPage" class="use-motion"><div class="headband"></div><main class="main"><div class="column"><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏" role="button"><span class="toggle-line"></span> <span class="toggle-line"></span> <span class="toggle-line"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><i class="logo-line"></i><p class="site-title">年轻人起来冲</p><i class="logo-line"></i></a></div><div class="site-nav-right"><div class="toggle popup-trigger" aria-label="搜索" role="button"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">77</span></a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">70</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">544</span></a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"><input autocomplete="off" autocapitalize="off" maxlength="80" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close" role="button"><i class="fa fa-times-circle"></i></span></div><div class="search-result-container"><div class="search-result-icon"><i class="fa fa-spinner fa-pulse fa-5x"></i></div></div></div></div></header><aside class="sidebar"><div class="sidebar-inner sidebar-nav-active sidebar-toc-active"><ul class="sidebar-nav"><li class="sidebar-nav-toc">文章目录</li><li class="sidebar-nav-overview">站点概览</li></ul><div class="sidebar-panel-container"><div class="post-toc-wrap sidebar-panel"><div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9C%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%80%89%E6%8B%A9%E6%8C%87%E7%9A%84%E6%98%AF%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9"><span class="nav-number">1.</span> <span class="nav-text">在机器学习中，模型的选择指的是？如何进行模型选择？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0%E5%92%8C%E8%B6%85%E5%8F%82%E7%9A%84%E5%8C%BA%E5%88%AB%E8%B6%85%E5%8F%82%E7%BB%99%E5%AE%9A%E7%9A%84%E6%96%B9%E5%BC%8F%E6%9C%89%E9%82%A3%E4%BA%9B"><span class="nav-number">2.</span> <span class="nav-text">机器学习中模型参数和超参的区别？超参给定的方式有那些？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E8%AE%AD%E7%BB%83%E9%9B%86-training-set"><span class="nav-number">3.</span> <span class="nav-text">什么是训练集 (training set)?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E6%B5%8B%E8%AF%95%E9%9B%86-testing-set"><span class="nav-number">4.</span> <span class="nav-text">什么是测试集 (testing set)?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E9%AA%8C%E8%AF%81%E9%9B%86-validation-set"><span class="nav-number">5.</span> <span class="nav-text">什么是验证集 (validation set)?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9C%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E6%A0%B7%E6%9C%AC%E5%88%92%E5%88%86%E7%9A%84%E5%8E%9F%E5%88%99"><span class="nav-number">6.</span> <span class="nav-text">在机器学习中，样本划分的原则？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#sklern%E4%B8%AD%E5%A6%82%E4%BD%95%E5%BF%AB%E9%80%9F%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E9%9B%86%E5%88%92%E5%88%86"><span class="nav-number">7.</span> <span class="nav-text">sklern 中，如何快速进行数据集划分？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81"><span class="nav-number">8.</span> <span class="nav-text">什么是交叉验证？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E8%87%AA%E5%8A%A9%E6%B3%95bootstrap%E8%AF%84%E4%BC%B0%E6%A8%A1%E5%9E%8B"><span class="nav-number">9.</span> <span class="nav-text">什么是自助法（Bootstrap）评估模型？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%E5%87%A0%E7%A7%8D%E6%96%B9%E6%B3%95"><span class="nav-number">10.</span> <span class="nav-text">交叉验证几种方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AFk%E6%8A%98%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81"><span class="nav-number">11.</span> <span class="nav-text">什么是 K 折交叉验证？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#k%E6%8A%98%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%E4%B8%ADk%E5%8F%96%E5%80%BC%E5%A4%9A%E5%B0%91%E6%9C%89%E4%BB%80%E4%B9%88%E5%85%B3%E7%B3%BB"><span class="nav-number">12.</span> <span class="nav-text">k 折交叉验证中 k 取值多少有什么关系</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#sklern%E4%B8%AD%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81"><span class="nav-number">13.</span> <span class="nav-text">sklern 中，如何进行交叉验证？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#sklern%E4%B8%AD%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E5%A4%9A%E6%8C%87%E6%A0%87%E8%AF%84%E4%BC%B0"><span class="nav-number">14.</span> <span class="nav-text">sklern 中，如何进行多指标评估？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#sklern%E4%B8%AD%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8Ck%E6%8A%98%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81"><span class="nav-number">15.</span> <span class="nav-text">sklern 中，如何进行 K 折交叉验证？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#sklern%E4%B8%AD%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8Cn%E6%AC%A1k%E6%8A%98%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81"><span class="nav-number">16.</span> <span class="nav-text">sklern 中，如何进行 n 次 K 折交叉验证？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#sklern%E4%B8%AD%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E7%95%99%E4%B8%80%E4%B8%AA-loo-%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81"><span class="nav-number">17.</span> <span class="nav-text">sklern 中，如何进行留一个 (LOO) 交叉验证？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#sklern%E4%B8%AD%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E7%95%99p%E4%B8%AA-lpo-%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81"><span class="nav-number">18.</span> <span class="nav-text">sklern 中，如何进行留 P 个 (LPO) 交叉验证？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#sklern%E4%B8%AD%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E9%9A%8F%E6%9C%BA%E6%8E%92%E5%88%97%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81"><span class="nav-number">19.</span> <span class="nav-text">sklern 中，如何进行随机排列交叉验证？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#sklern%E4%B8%AD%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E5%88%86%E5%B1%82k-flod%E7%9A%84%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81"><span class="nav-number">20.</span> <span class="nav-text">sklern 中，如何进行分层 K-flod 的交叉验证？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#sklern%E4%B8%AD%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E5%88%86%E5%B1%82%E9%9A%8F%E6%9C%BA%E7%9A%84%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81"><span class="nav-number">21.</span> <span class="nav-text">sklern 中，如何进行分层随机的交叉验证？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#sklern%E4%B8%AD%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E5%88%86%E7%BB%84k%E6%8A%98%E7%9A%84%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81"><span class="nav-number">22.</span> <span class="nav-text">sklern 中，如何进行分组 K 折的交叉验证？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#sklern%E4%B8%AD%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E5%88%86%E5%B1%82%E5%88%86%E7%BB%84k%E6%8A%98%E7%9A%84%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81"><span class="nav-number">23.</span> <span class="nav-text">sklern 中，如何进行分层分组 K 折的交叉验证？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#sklern%E4%B8%AD%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E7%95%99%E4%B8%80%E7%BB%84%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81"><span class="nav-number">24.</span> <span class="nav-text">sklern 中，如何进行留一组交叉验证？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#sklern%E4%B8%AD%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E7%95%99p%E7%BB%84%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81"><span class="nav-number">25.</span> <span class="nav-text">sklern 中，如何进行留 P 组交叉验证？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#sklern%E4%B8%AD%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E7%BB%84%E9%9A%8F%E6%9C%BA%E6%8B%86%E5%88%86%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81"><span class="nav-number">26.</span> <span class="nav-text">sklern 中，如何进行组随机拆分交叉验证？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#sklern%E4%B8%AD%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%95%B0%E6%8D%AE%E7%9A%84%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81"><span class="nav-number">27.</span> <span class="nav-text">sklern 中，如何进行时间序列数据的交叉验证？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E7%BD%91%E6%A0%BC%E5%8F%82%E6%95%B0%E6%90%9C%E7%B4%A2gridsearchcv"><span class="nav-number">28.</span> <span class="nav-text">什么是网格参数搜索 (GridSearchCV)？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E9%9A%8F%E6%9C%BA%E5%8F%82%E6%95%B0%E6%90%9C%E7%B4%A2randomizedsearchcv"><span class="nav-number">29.</span> <span class="nav-text">什么是随机参数搜索 (RandomizedSearchCV)？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E8%BF%9E%E7%BB%AD%E5%87%8F%E5%8D%8A%E7%9A%84%E7%BD%91%E6%A0%BC%E5%8F%82%E6%95%B0%E6%90%9C%E7%B4%A2halvinggridsearchcv"><span class="nav-number">30.</span> <span class="nav-text">什么是连续减半的网格参数搜索 (HalvingGridSearchCV)?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E8%BF%9E%E7%BB%AD%E5%87%8F%E5%8D%8A%E7%9A%84%E9%9A%8F%E6%9C%BA%E5%8F%82%E6%95%B0%E6%90%9C%E7%B4%A2halvingrandomsearchcv"><span class="nav-number">31.</span> <span class="nav-text">什么是连续减半的随机参数搜索 (HalvingRandomSearchCV)?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BD%91%E6%A0%BC%E6%90%9C%E7%B4%A2%E4%BC%98%E5%8C%96%E5%8F%82%E6%95%B0-%E9%9A%8F%E6%9C%BA%E6%90%9C%E7%B4%A2%E4%BC%98%E5%8C%96%E5%8F%82%E6%95%B0%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9"><span class="nav-number">32.</span> <span class="nav-text">网格搜索优化参数、随机搜索优化参数如何选择？</span></a></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" alt="Shaogui" src="/images/avatar-2023.png"><p class="site-author-name" itemprop="name">Shaogui</p><div class="site-description" itemprop="description">害怕失败是本能，勇敢面对才是本事</div></div><div class="site-state-wrap animated"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">544</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/"><span class="site-state-item-count">70</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/"><span class="site-state-item-count">77</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="links-of-author animated"><span class="links-of-author-item"><a href="https://github.com/WuShaogui" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;WuShaogui" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a> </span><span class="links-of-author-item"><a href="https://www.zhihu.com/people/mu-zhi-zhi-tian" title="知乎 → https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;mu-zhi-zhi-tian" rel="noopener me" target="_blank"><i class="fab fa-zhihu fa-fw"></i>知乎</a></span></div><div class="cc-license animated" itemprop="license"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh-hans" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a></div></div></div><div class="back-to-top animated" role="button" aria-label="返回顶部"><i class="fa fa-arrow-up"></i> <span>0%</span></div></div><div class="sidebar-inner sidebar-blogroll"><div class="links-of-blogroll animated"><div class="links-of-blogroll-title"><i class="fa fa-globe fa-fw"></i> 链接</div><ul class="links-of-blogroll-list"><li class="links-of-blogroll-item"><a href="http://manaai.cn/" title="http:&#x2F;&#x2F;manaai.cn&#x2F;" rel="noopener" target="_blank">神力AI</a></li></ul></div></div></aside></div><div class="main-inner post posts-expand"><div class="post-block"><article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://www.shaogui.life/posts/3202670697.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar-2023.png"><meta itemprop="name" content="Shaogui"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="年轻人起来冲"><meta itemprop="description" content="害怕失败是本能，勇敢面对才是本事"></span><span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork"><meta itemprop="name" content="机器学习的模型选择与评估 | 年轻人起来冲"><meta itemprop="description" content=""></span><header class="post-header"><h1 class="post-title" itemprop="name headline">机器学习的模型选择与评估</h1><div class="post-meta-container"><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-11-01 00:10:07" itemprop="dateCreated datePublished" datetime="2021-11-01T00:10:07+08:00">2021-11-01</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2025-01-18 18:36:30" itemprop="dateModified" datetime="2025-01-18T18:36:30+08:00">2025-01-18</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/1-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">1-机器学习</span></a> </span></span><span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv"><span class="post-meta-item-icon"><i class="far fa-eye"></i> </span><span class="post-meta-item-text">阅读次数：</span> <span id="busuanzi_value_page_pv"></span> </span><span class="post-meta-break"></span> <span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>13k</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>12 分钟</span></span></div></div></header><div class="post-body" itemprop="articleBody"><p>本文主要解决如何选择更好的模型问题，通常办法是交叉验证，文章最后也介绍了参数搜索的办法</p><span id="more"></span><h3 id="在机器学习中模型的选择指的是如何进行模型选择"><a class="markdownIt-Anchor" href="#在机器学习中模型的选择指的是如何进行模型选择"></a> 在机器学习中，模型的选择指的是？如何进行模型选择？</h3><ul><li>模型选择：就是算法模型及模型参数的选择</li><li>如何进行模型选择：K 折交叉验证</li></ul><h3 id="机器学习中模型参数和超参的区别超参给定的方式有那些"><a class="markdownIt-Anchor" href="#机器学习中模型参数和超参的区别超参给定的方式有那些"></a> 机器学习中模型参数和超参的区别？超参给定的方式有那些？</h3><ul><li>模型参数：模型内部的配置变量，可以用数据估计模型参数的值</li><li>模型超参：是模型外部的配置，必须手动设置参数的值，可以通过网格参数搜索 (GridSearchCV) 来取值，也可以通过经验选定</li></ul><h3 id="什么是训练集-training-set"><a class="markdownIt-Anchor" href="#什么是训练集-training-set"></a> 什么是训练集 (training set)?</h3><ul><li>数据集的子集，用于训练模型</li></ul><h3 id="什么是测试集-testing-set"><a class="markdownIt-Anchor" href="#什么是测试集-testing-set"></a> 什么是测试集 (testing set)?</h3><ul><li>数据集的子集，用于在模型经由验证集的初步验证之后测试模型。与训练集和验证集相对</li><li>与训练集 (training set) 相对</li></ul><h3 id="什么是验证集-validation-set"><a class="markdownIt-Anchor" href="#什么是验证集-validation-set"></a> 什么是验证集 (validation set)?</h3><ul><li>数据集的一个子集，从训练集分离而来，用于调整超参数</li></ul><h3 id="在机器学习中样本划分的原则"><a class="markdownIt-Anchor" href="#在机器学习中样本划分的原则"></a> 在机器学习中，样本划分的原则？</h3><ul><li><strong>在样本量有限的情况下</strong>，有时候会把验证集和测试集合并。实际中，若划分为三类，那么训练集：验证集：测试集 = 6:2:2；若是两类，则训练集：验证集 = 7:3。这里需要主要在数据量不够多的情况，验证集和测试集需要占的数据比例比较多，以充分了解模型的泛化性</li><li><strong>海量样本的情况下</strong>，这种情况在目前深度学习中会比较常见。此时由于数据量巨大，我们不需要将过多的数据用于验证和测试集。例如拥有 1 百万样本时，我们按训练集：验证集：测试集 = 98:1:1 的比例划分，1% 的验证和 1% 的测试集都已经拥有了 1 万个样本。这已足够验证模型性能了</li><li>此外，三个数据集的划分不是一次就可以的，若调试过程中发现，三者得到的性能评价差异很大时，可以重新划分以确定是数据集划分的问题导致还是由模型本身导致的。其次，若评价指标发生变化，而导致模型性能差异在三者上很大时，同样可重新划分确认排除数据问题，以方便进一步的优化</li></ul><h3 id="sklern中如何快速进行数据集划分"><a class="markdownIt-Anchor" href="#sklern中如何快速进行数据集划分"></a> sklern 中，如何快速进行数据集划分？</h3><ul><li><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split"><strong>train_test_split</strong></a> 在 scikit-learn 中，可以使用辅助函数快速计算随机分成训练集 (training set) 和测试集 (testing set)<figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"> &gt;&gt;&gt; import numpy as np</span><br><span class="line"> &gt;&gt;&gt; from sklearn.model_selection import train_test_split</span><br><span class="line"> &gt;&gt;&gt; from sklearn import datasets</span><br><span class="line"> &gt;&gt;&gt; from sklearn import svm</span><br><span class="line"> &gt;&gt;&gt; X, y = datasets.load_iris(return_X_y=True)</span><br><span class="line"> &gt;&gt;&gt; X.shape, y.shape</span><br><span class="line">((<span class="number">150</span>, <span class="number">4</span>), (<span class="number">150</span>,))</span><br><span class="line"> &gt;&gt;&gt; X_train, X_test, y_train, y_test = train_test_split(</span><br><span class="line">...     X, y, test_size=0.4, random_state=0)</span><br><span class="line"> &gt;&gt;&gt; X_train.shape, y_train.shape</span><br><span class="line">((<span class="number">90</span>, <span class="number">4</span>), (<span class="number">90</span>,))</span><br><span class="line"> &gt;&gt;&gt; X_test.shape, y_test.shape</span><br><span class="line">((<span class="number">60</span>, <span class="number">4</span>), (<span class="number">60</span>,))</span><br><span class="line"> &gt;&gt;&gt; clf = svm.SVC(kernel=<span class="string">'linear'</span>, C=1).fit(X_train, y_train)</span><br><span class="line"> &gt;&gt;&gt; clf.score(X_test, y_test)</span><br><span class="line">0.96... </span><br></pre></td></tr></tbody></table></figure></li><li>注意事项：1）训练集的比例要足够多，一般大于一半；2）训练集和测试集要均匀抽样</li></ul><h3 id="什么是交叉验证"><a class="markdownIt-Anchor" href="#什么是交叉验证"></a> 什么是交叉验证？</h3><ul><li>一种检验模型的效果的方法，可用于模型及其参数选择，具有一定的避免过拟合的能力</li></ul><h3 id="什么是自助法bootstrap评估模型"><a class="markdownIt-Anchor" href="#什么是自助法bootstrap评估模型"></a> 什么是自助法（Bootstrap）评估模型？</h3><ul><li>一种有放回的抽样，选择数据中的 63.2% 构建训练集，其余为测试集 (但改变了数据集的分布，会引入估计偏差)</li></ul><h3 id="交叉验证几种方法"><a class="markdownIt-Anchor" href="#交叉验证几种方法"></a> 交叉验证几种方法</h3><ul><li>K 折交叉验证：一般取 5 折交叉验证或者 10 折交叉验证，重复做 p 次</li><li>留 P 法 (LPO) 法：简单地将原始数据集随机划分为训练集，验证集，测试集三个部分.</li><li>留一个 (LOO) 法：每次只留一个样本作为数据的测试集，其余作为训练集（只适用于较少的数据集）</li></ul><h3 id="什么是k折交叉验证"><a class="markdownIt-Anchor" href="#什么是k折交叉验证"></a> 什么是 K 折交叉验证？</h3><ul><li>K 折交叉验证是将原始数据分成 K 组（一般是均分），将每个子集数据分别做一次验证集，其余的 K-1 组子集数据作为训练集，这样会得到 K 个模型，再用这 K 个模型最终的验证集的分类准确率的平均数，作为此 K 折交叉验证下分类器的性能指标</li></ul><h3 id="k折交叉验证中k取值多少有什么关系"><a class="markdownIt-Anchor" href="#k折交叉验证中k取值多少有什么关系"></a> k 折交叉验证中 k 取值多少有什么关系</h3><ul><li>1）K=1，所以数据都被用于训练，模型很容易出现过拟合，因此容易是低偏差、高方差</li><li>2）K=1~n，可以理解为一种方差和偏差妥协的结果，2017 年的一项研究给出了另一种经验式的选择方法，作者建议 k=log (n) 且保证 n/K&gt;3d ，n 代表了数据量，d 代表了特征数</li><li>3）K=n，随着 K 值的不断升高，单一模型评估时的方差逐渐加大而偏差减小。因此容易是高偏差、低方差</li><li>K 值选择： K 一般大于等于 2，实际操作时一般从 3 开始取值，只有在原始数据集和数据量小的时候才会尝试取 2。K 折交叉验证可以有效地避免过学习及欠学习状态的发生，最后得到的结果也比较具有说服力。通常情况下，K 的取值为 3、5、10</li><li>使用交叉验证的根本原因是数据集太小，而较小的 K 值会导致可用于建模的数据量太小，所以小数据集的交叉验证结果需要格外注意。建议选择较大的 K 值，同时也要考虑较大 K 值的计算开销</li></ul><h3 id="sklern中如何进行交叉验证"><a class="markdownIt-Anchor" href="#sklern中如何进行交叉验证"></a> sklern 中，如何进行交叉验证？</h3><ul><li>使用交叉验证最简单的方法是 <a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score"><strong>cross_val_score</strong></a> 在估计器和数据集上调用辅助函数<figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"> &gt;&gt;&gt; from sklearn.model_selection import cross_val_score</span><br><span class="line"> &gt;&gt;&gt; clf = svm.SVC(kernel=<span class="string">'linear'</span>, C=1, random_state=42)</span><br><span class="line"> &gt;&gt;&gt; scores = cross_val_score(clf, X, y, cv=5)</span><br><span class="line"> &gt;&gt;&gt; scores</span><br><span class="line">array([0.96..., 1. , 0.96..., 0.96..., 1. ])</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="sklern中如何进行多指标评估"><a class="markdownIt-Anchor" href="#sklern中如何进行多指标评估"></a> sklern 中，如何进行多指标评估？</h3><ul><li>使用 <a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate"><strong>cross_validate</strong></a> 函数<figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"> &gt;&gt;&gt; from sklearn.model_selection import cross_validate</span><br><span class="line"> &gt;&gt;&gt; from sklearn.metrics import recall_score</span><br><span class="line"> &gt;&gt;&gt; scoring = [<span class="string">'precision_macro'</span>, <span class="string">'recall_macro'</span>]</span><br><span class="line"> &gt;&gt;&gt; clf = svm.SVC(kernel=<span class="string">'linear'</span>, C=1, random_state=0)</span><br><span class="line"> &gt;&gt;&gt; scores = cross_validate(clf, X, y, scoring=scoring)</span><br><span class="line"> &gt;&gt;&gt; sorted(scores.keys())</span><br><span class="line">[<span class="string">'fit_time'</span>, <span class="string">'score_time'</span>, <span class="string">'test_precision_macro'</span>, <span class="string">'test_recall_macro'</span>]</span><br><span class="line"> &gt;&gt;&gt; scores[<span class="string">'test_recall_macro'</span>]</span><br><span class="line">array([0.96..., 1.  ..., 0.96..., 0.96..., 1.        ])</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="sklern中如何进行k折交叉验证"><a class="markdownIt-Anchor" href="#sklern中如何进行k折交叉验证"></a> sklern 中，如何进行 K 折交叉验证？</h3><ul><li><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold"><strong>KFold</strong></a> 将所有样本分成 k 样本组，称为折叠（如果 k=n，这相当于留一出策略），大小相等（如果可能）<figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"> &gt;&gt;&gt; import numpy as np</span><br><span class="line"> &gt;&gt;&gt; from sklearn.model_selection import KFold</span><br><span class="line"> &gt;&gt;&gt; X = [<span class="string">"a"</span>, <span class="string">"b"</span>, <span class="string">"c"</span>, <span class="string">"d"</span>]</span><br><span class="line"> &gt;&gt;&gt; kf = KFold(n_splits=2)</span><br><span class="line"> &gt;&gt;&gt; <span class="keyword">for</span> train, <span class="built_in">test</span> <span class="keyword">in</span> kf.split(X):</span><br><span class="line">...     <span class="built_in">print</span>(<span class="string">"%s %s"</span> % (train, <span class="built_in">test</span>))</span><br><span class="line">[2 3] [0 1]</span><br><span class="line">[0 1] [2 3]</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="sklern中如何进行n次k折交叉验证"><a class="markdownIt-Anchor" href="#sklern中如何进行n次k折交叉验证"></a> sklern 中，如何进行 n 次 K 折交叉验证？</h3><ul><li><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RepeatedKFold.html#sklearn.model_selection.RepeatedKFold"><strong>RepeatedKFold</strong></a> 重复 K 折 n 次。它可以在需要运行 <a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold"><strong>KFold</strong></a>n 次时使用，在每次重复中产生不同的拆分</li><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121807208.png" alt=""><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"> &gt;&gt;&gt; import numpy as np</span><br><span class="line"> &gt;&gt;&gt; from sklearn.model_selection import RepeatedKFold</span><br><span class="line"> &gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])</span><br><span class="line"> &gt;&gt;&gt; random_state = 12883823</span><br><span class="line"> &gt;&gt;&gt; rkf = RepeatedKFold(n_splits=2, n_repeats=2, random_state=random_state)</span><br><span class="line"> &gt;&gt;&gt; <span class="keyword">for</span> train, <span class="built_in">test</span> <span class="keyword">in</span> rkf.split(X):</span><br><span class="line">...     <span class="built_in">print</span>(<span class="string">"%s %s"</span> % (train, <span class="built_in">test</span>))</span><br><span class="line">[2 3] [0 1]</span><br><span class="line">[0 1] [2 3]</span><br><span class="line">[0 2] [1 3]</span><br><span class="line">[1 3] [0 2]</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="sklern中如何进行留一个-loo-交叉验证"><a class="markdownIt-Anchor" href="#sklern中如何进行留一个-loo-交叉验证"></a> sklern 中，如何进行留一<strong>个</strong> (LOO) 交叉验证？</h3><ul><li><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneOut.html#sklearn.model_selection.LeaveOneOut"><strong>LeaveOneOut</strong></a>（或 LOO）是一个简单的交叉验证。每个学习集都是通过获取除一个之外的所有样本创建的，测试集是被遗漏的样本<figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"> &gt;&gt;&gt; from sklearn.model_selection import LeaveOneOut</span><br><span class="line"> &gt;&gt;&gt; X = [1, 2, 3, 4]</span><br><span class="line"> &gt;&gt;&gt; loo = LeaveOneOut()</span><br><span class="line"> &gt;&gt;&gt; <span class="keyword">for</span> train, <span class="built_in">test</span> <span class="keyword">in</span> loo.split(X):</span><br><span class="line">...     <span class="built_in">print</span>(<span class="string">"%s %s"</span> % (train, <span class="built_in">test</span>))</span><br><span class="line">[1 2 3] [0]</span><br><span class="line">[0 2 3] [1]</span><br><span class="line">[0 1 3] [2]</span><br><span class="line">[0 1 2] [3]</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="sklern中如何进行留p个-lpo-交叉验证"><a class="markdownIt-Anchor" href="#sklern中如何进行留p个-lpo-交叉验证"></a> sklern 中，如何进行留 P <strong>个</strong> (LPO) 交叉验证？</h3><ul><li><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeavePOut.html#sklearn.model_selection.LeavePOut"><strong>LeavePOut</strong></a> 非常相似，<a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneOut.html#sklearn.model_selection.LeaveOneOut"><strong>LeaveOneOut</strong></a> 因为它通过删除创建所有可能的训练 / 测试集 p 来自完整集合的样本<figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"> &gt;&gt;&gt; from sklearn.model_selection import LeavePOut</span><br><span class="line"> &gt;&gt;&gt; X = np.ones(4)</span><br><span class="line"> &gt;&gt;&gt; lpo = LeavePOut(p=2)</span><br><span class="line"> &gt;&gt;&gt; <span class="keyword">for</span> train, <span class="built_in">test</span> <span class="keyword">in</span> lpo.split(X):</span><br><span class="line">...     <span class="built_in">print</span>(<span class="string">"%s %s"</span> % (train, <span class="built_in">test</span>))</span><br><span class="line">[2 3] [0 1]</span><br><span class="line">[1 3] [0 2]</span><br><span class="line">[1 2] [0 3]</span><br><span class="line">[0 3] [1 2]</span><br><span class="line">[0 2] [1 3]</span><br><span class="line">[0 1] [2 3]</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="sklern中如何进行随机排列交叉验证"><a class="markdownIt-Anchor" href="#sklern中如何进行随机排列交叉验证"></a> sklern 中，如何进行随机排列交叉验证？</h3><ul><li>迭代器将 <a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit"><strong>ShuffleSplit</strong></a> 生成用户定义数量的独立训练 / 测试数据集拆分。样本首先被打乱，然后分成一对训练集和测试集</li><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121807209.png" alt=""><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"> &gt;&gt;&gt; from sklearn.model_selection import ShuffleSplit</span><br><span class="line"> &gt;&gt;&gt; X = np.arange(10)</span><br><span class="line"> &gt;&gt;&gt; ss = ShuffleSplit(n_splits=5, test_size=0.25, random_state=0)</span><br><span class="line"> &gt;&gt;&gt; <span class="keyword">for</span> train_index, test_index <span class="keyword">in</span> ss.split(X):</span><br><span class="line">...     <span class="built_in">print</span>(<span class="string">"%s %s"</span> % (train_index, test_index))</span><br><span class="line">[9 1 6 7 3 0 5] [2 8 4]</span><br><span class="line">[2 9 8 0 6 7 4] [3 5 1]</span><br><span class="line">[4 5 1 0 6 9 7] [2 3 8]</span><br><span class="line">[2 7 5 8 0 3 4] [6 1 9]</span><br><span class="line">[4 1 0 6 8 9 3] [5 2 7]</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="sklern中如何进行分层k-flod的交叉验证"><a class="markdownIt-Anchor" href="#sklern中如何进行分层k-flod的交叉验证"></a> sklern 中，如何进行分层 K-flod 的交叉验证？</h3><ul><li><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold"><strong>StratifiedKFold</strong></a> 是返回分层折叠的 k-fold 的变体 ：每组包含的每个目标类的样本百分比与完整集大致相同</li><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121807210.png" alt=""><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"> &gt;&gt;&gt; from sklearn.model_selection import StratifiedKFold, KFold</span><br><span class="line"> &gt;&gt;&gt; import numpy as np</span><br><span class="line"> &gt;&gt;&gt; X, y = np.ones((<span class="number">50</span>, <span class="number">1</span>)), np.hstack(([<span class="number">0</span>] * <span class="number">45</span>, [<span class="number">1</span>] * <span class="number">5</span>))</span><br><span class="line"> &gt;&gt;&gt; skf = StratifiedKFold(n_splits=3)</span><br><span class="line"> &gt;&gt;&gt; <span class="keyword">for</span> train, <span class="built_in">test</span> <span class="keyword">in</span> skf.split(X, y):</span><br><span class="line">...     <span class="built_in">print</span>(<span class="string">'train -  {}   |   test -  {}'</span>.format(</span><br><span class="line">...         np.bincount(y[train]), np.bincount(y[<span class="built_in">test</span>])))</span><br><span class="line">train -  [30  3]   |   <span class="built_in">test</span> -  [15  2]</span><br><span class="line">train -  [30  3]   |   <span class="built_in">test</span> -  [15  2]</span><br><span class="line">train -  [30  4]   |   <span class="built_in">test</span> -  [15  1]</span><br><span class="line"> &gt;&gt;&gt; kf = KFold(n_splits=3)</span><br><span class="line"> &gt;&gt;&gt; <span class="keyword">for</span> train, <span class="built_in">test</span> <span class="keyword">in</span> kf.split(X, y):</span><br><span class="line">...     <span class="built_in">print</span>(<span class="string">'train -  {}   |   test -  {}'</span>.format(</span><br><span class="line">...         np.bincount(y[train]), np.bincount(y[<span class="built_in">test</span>])))</span><br><span class="line">train -  [28  5]   |   <span class="built_in">test</span> -  [17]</span><br><span class="line">train -  [28  5]   |   <span class="built_in">test</span> -  [17]</span><br><span class="line">train -  [34]   |   <span class="built_in">test</span> -  [11  5] </span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="sklern中如何进行分层随机的交叉验证"><a class="markdownIt-Anchor" href="#sklern中如何进行分层随机的交叉验证"></a> sklern 中，如何进行分层随机的交叉验证？</h3><ul><li><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html#sklearn.model_selection.StratifiedShuffleSplit"><strong>StratifiedShuffleSplit</strong></a> 是 ShuffleSplit 的变体，它返回分层拆分，即通过为每个目标类保留与完整集合中相同的百分比来创建拆分</li><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121807211.png" alt=""><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"> &gt;&gt;&gt; import numpy as np</span><br><span class="line"> &gt;&gt;&gt; from sklearn.model_selection import StratifiedShuffleSplit</span><br><span class="line"> &gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [1, 2], [3, 4], [1, 2], [3, 4]])</span><br><span class="line"> &gt;&gt;&gt; y = np.array([0, 0, 0, 1, 1, 1])</span><br><span class="line"> &gt;&gt;&gt; sss = StratifiedShuffleSplit(n_splits=5, test_size=0.5, random_state=0)</span><br><span class="line"> &gt;&gt;&gt; sss.get_n_splits(X, y)</span><br><span class="line">5</span><br><span class="line"> &gt;&gt;&gt; <span class="built_in">print</span>(sss)</span><br><span class="line">StratifiedShuffleSplit(n_splits=5, random_state=0, ...)</span><br><span class="line"> &gt;&gt;&gt; <span class="keyword">for</span> train_index, test_index <span class="keyword">in</span> sss.split(X, y):</span><br><span class="line">...     <span class="built_in">print</span>(<span class="string">"TRAIN:"</span>, train_index, <span class="string">"TEST:"</span>, test_index)</span><br><span class="line">...     X_train, X_test = X[train_index], X[test_index]</span><br><span class="line">...     y_train, y_test = y[train_index], y[test_index]</span><br><span class="line">TRAIN: [5 2 3] TEST: [4 1 0]</span><br><span class="line">TRAIN: [5 1 4] TEST: [0 2 3]</span><br><span class="line">TRAIN: [5 0 2] TEST: [4 3 1]</span><br><span class="line">TRAIN: [4 1 0] TEST: [2 3 5]</span><br><span class="line">TRAIN: [0 5 1] TEST: [3 4 2]</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="sklern中如何进行分组k折的交叉验证"><a class="markdownIt-Anchor" href="#sklern中如何进行分组k折的交叉验证"></a> sklern 中，如何进行分组 K 折的交叉验证？</h3><ul><li><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupKFold.html#sklearn.model_selection.GroupKFold"><strong>GroupKFold</strong></a> 是 k-fold 的一种变体，它确保同一组在测试和训练集中都没有出现。例如，如果数据是从每个主题有多个样本的不同主题中获得的，并且如果模型足够灵活，可以从高度个人特定的特征中学习，则它可能无法推广到新主题</li><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121807212.png" alt=""><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"> &gt;&gt;&gt; from sklearn.model_selection import GroupKFold</span><br><span class="line"> &gt;&gt;&gt; X = [0.1, 0.2, 2.2, 2.4, 2.3, 4.55, 5.8, 8.8, 9, 10]</span><br><span class="line"> &gt;&gt;&gt; y = [<span class="string">"a"</span>, <span class="string">"b"</span>, <span class="string">"b"</span>, <span class="string">"b"</span>, <span class="string">"c"</span>, <span class="string">"c"</span>, <span class="string">"c"</span>, <span class="string">"d"</span>, <span class="string">"d"</span>, <span class="string">"d"</span>]</span><br><span class="line"> &gt;&gt;&gt; <span class="built_in">groups</span> = [1, 1, 1, 2, 2, 2, 3, 3, 3, 3]</span><br><span class="line"> &gt;&gt;&gt; gkf = GroupKFold(n_splits=3)</span><br><span class="line"> &gt;&gt;&gt; <span class="keyword">for</span> train, <span class="built_in">test</span> <span class="keyword">in</span> gkf.split(X, y, <span class="built_in">groups</span>=<span class="built_in">groups</span>):</span><br><span class="line">...     <span class="built_in">print</span>(<span class="string">"%s %s"</span> % (train, <span class="built_in">test</span>))</span><br><span class="line">[0 1 2 3 4 5] [6 7 8 9]</span><br><span class="line">[0 1 2 6 7 8 9] [3 4 5]</span><br><span class="line">[3 4 5 6 7 8 9] [0 1 2]</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="sklern中如何进行分层分组k折的交叉验证"><a class="markdownIt-Anchor" href="#sklern中如何进行分层分组k折的交叉验证"></a> sklern 中，如何进行分层分组 K 折的交叉验证？</h3><ul><li><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedGroupKFold.html#sklearn.model_selection.StratifiedGroupKFold"><strong>StratifiedGroupKFold</strong></a><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold"><strong>StratifiedKFold</strong></a> 是一种结合了和的交叉验证方案 <a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupKFold.html#sklearn.model_selection.GroupKFold"><strong>GroupKFold</strong></a>。这个想法是尝试在每个拆分中保留类的分布，同时将每个组保持在一个拆分中。当您有一个不平衡的数据集时，这可能很有用，因此使用 just<a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupKFold.html#sklearn.model_selection.GroupKFold"><strong>GroupKFold</strong></a> 可能会产生倾斜的拆分</li><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121807213.png" alt=""><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"> &gt;&gt;&gt; from sklearn.model_selection import StratifiedGroupKFold</span><br><span class="line"> &gt;&gt;&gt; X = list(range(18))</span><br><span class="line"> &gt;&gt;&gt; y = [1] * 6 + [0] * 12</span><br><span class="line"> &gt;&gt;&gt; <span class="built_in">groups</span> = [1, 2, 3, 3, 4, 4, 1, 1, 2, 2, 3, 4, 5, 5, 5, 6, 6, 6]</span><br><span class="line"> &gt;&gt;&gt; sgkf = StratifiedGroupKFold(n_splits=3)</span><br><span class="line"> &gt;&gt;&gt; <span class="keyword">for</span> train, <span class="built_in">test</span> <span class="keyword">in</span> sgkf.split(X, y, <span class="built_in">groups</span>=<span class="built_in">groups</span>):</span><br><span class="line">...     <span class="built_in">print</span>(<span class="string">"%s %s"</span> % (train, <span class="built_in">test</span>))</span><br><span class="line">[ 0  2  3  4  5  6  7 10 11 15 16 17] [ 1  8  9 12 13 14]</span><br><span class="line">[ 0  1  4  5  6  7  8  9 11 12 13 14] [ 2  3 10 15 16 17]</span><br><span class="line">[ 1  2  3  8  9 10 12 13 14 15 16 17] [ 0  4  5  6  7 11]</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="sklern中如何进行留一组交叉验证"><a class="markdownIt-Anchor" href="#sklern中如何进行留一组交叉验证"></a> sklern 中，如何进行留一<strong>组</strong>交叉验证？</h3><ul><li><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneGroupOut.html#sklearn.model_selection.LeaveOneGroupOut"><strong>LeaveOneGroupOut</strong></a> 是一种交叉验证方案，它根据第三方提供的整数组数组保留样本。该组信息可用于对任意领域特定的预定义交叉验证折叠进行编码<figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"> &gt;&gt;&gt; from sklearn.model_selection import LeaveOneGroupOut</span><br><span class="line"> &gt;&gt;&gt; X = [1, 5, 10, 50, 60, 70, 80]</span><br><span class="line"> &gt;&gt;&gt; y = [0, 1, 1, 2, 2, 2, 2]</span><br><span class="line"> &gt;&gt;&gt; <span class="built_in">groups</span> = [1, 1, 2, 2, 3, 3, 3]</span><br><span class="line"> &gt;&gt;&gt; logo = LeaveOneGroupOut()</span><br><span class="line"> &gt;&gt;&gt; <span class="keyword">for</span> train, <span class="built_in">test</span> <span class="keyword">in</span> logo.split(X, y, <span class="built_in">groups</span>=<span class="built_in">groups</span>):</span><br><span class="line">...     <span class="built_in">print</span>(<span class="string">"%s %s"</span> % (train, <span class="built_in">test</span>))</span><br><span class="line">[2 3 4 5 6] [0 1]</span><br><span class="line">[0 1 4 5 6] [2 3]</span><br><span class="line">[0 1 2 3] [4 5 6]</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="sklern中如何进行留p组交叉验证"><a class="markdownIt-Anchor" href="#sklern中如何进行留p组交叉验证"></a> sklern 中，如何进行留 P <strong>组</strong>交叉验证？</h3><ul><li><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeavePGroupsOut.html#sklearn.model_selection.LeavePGroupsOut"><strong>LeavePGroupsOut</strong></a> 与 类似 <a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneGroupOut.html#sklearn.model_selection.LeaveOneGroupOut"><strong>LeaveOneGroupOut</strong></a>，但删除了与 P 每个训练 / 测试集的组<figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"> &gt;&gt;&gt; from sklearn.model_selection import LeavePGroupsOut</span><br><span class="line"> &gt;&gt;&gt; X = np.arange(6)</span><br><span class="line"> &gt;&gt;&gt; y = [1, 1, 1, 2, 2, 2]</span><br><span class="line"> &gt;&gt;&gt; <span class="built_in">groups</span> = [1, 1, 2, 2, 3, 3]</span><br><span class="line"> &gt;&gt;&gt; lpgo = LeavePGroupsOut(n_groups=2)</span><br><span class="line"> &gt;&gt;&gt; <span class="keyword">for</span> train, <span class="built_in">test</span> <span class="keyword">in</span> lpgo.split(X, y, <span class="built_in">groups</span>=<span class="built_in">groups</span>):</span><br><span class="line">...     <span class="built_in">print</span>(<span class="string">"%s %s"</span> % (train, <span class="built_in">test</span>))</span><br><span class="line">[4 5] [0 1 2 3]</span><br><span class="line">[2 3] [0 1 4 5]</span><br><span class="line">[0 1] [2 3 4 5]</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="sklern中如何进行组随机拆分交叉验证"><a class="markdownIt-Anchor" href="#sklern中如何进行组随机拆分交叉验证"></a> sklern 中，如何进行组随机拆分交叉验证？</h3><ul><li><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupShuffleSplit.html#sklearn.model_selection.GroupShuffleSplit"><strong>GroupShuffleSplit</strong></a> 迭代器表现为 和 的组合 ，<a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit"><strong>ShuffleSplit</strong></a> 并 <a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeavePGroupsOut.html#sklearn.model_selection.LeavePGroupsOut"><strong>LeavePGroupsOut</strong></a> 生成一系列随机分区，其中为每个拆分保留一组组的子集</li><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121807214.png" alt=""><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"> &gt;&gt;&gt; from sklearn.model_selection import GroupShuffleSplit</span><br><span class="line"> &gt;&gt;&gt; X = [0.1, 0.2, 2.2, 2.4, 2.3, 4.55, 5.8, 0.001]</span><br><span class="line"> &gt;&gt;&gt; y = [<span class="string">"a"</span>, <span class="string">"b"</span>, <span class="string">"b"</span>, <span class="string">"b"</span>, <span class="string">"c"</span>, <span class="string">"c"</span>, <span class="string">"c"</span>, <span class="string">"a"</span>]</span><br><span class="line"> &gt;&gt;&gt; <span class="built_in">groups</span> = [1, 1, 2, 2, 3, 3, 4, 4]</span><br><span class="line"> &gt;&gt;&gt; gss = GroupShuffleSplit(n_splits=4, test_size=0.5, random_state=0)</span><br><span class="line"> &gt;&gt;&gt; <span class="keyword">for</span> train, <span class="built_in">test</span> <span class="keyword">in</span> gss.split(X, y, <span class="built_in">groups</span>=<span class="built_in">groups</span>):</span><br><span class="line">...     <span class="built_in">print</span>(<span class="string">"%s %s"</span> % (train, <span class="built_in">test</span>))</span><br><span class="line">...</span><br><span class="line">[0 1 2 3] [4 5 6 7]</span><br><span class="line">[2 3 6 7] [0 1 4 5]</span><br><span class="line">[2 3 4 5] [0 1 6 7]</span><br><span class="line">[4 5 6 7] [0 1 2 3]</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="sklern中如何进行时间序列数据的交叉验证"><a class="markdownIt-Anchor" href="#sklern中如何进行时间序列数据的交叉验证"></a> sklern 中，如何进行时间序列数据的交叉验证？</h3><ul><li><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html#sklearn.model_selection.TimeSeriesSplit"><strong>TimeSeriesSplit</strong></a> 是 k-fold 的一种变体，它首先返回 k 折叠为火车组和 (k+1) 作为测试集折叠。请注意，与标准交叉验证方法不同，连续训练集是之前的训练集的超集。此外，它将所有剩余数据添加到第一个训练分区，该分区始终用于训练模型</li><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121807216.png" alt=""><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"> &gt;&gt;&gt; from sklearn.model_selection import TimeSeriesSplit</span><br><span class="line"> &gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [1, 2], [3, 4], [1, 2], [3, 4]])</span><br><span class="line"> &gt;&gt;&gt; y = np.array([1, 2, 3, 4, 5, 6])</span><br><span class="line"> &gt;&gt;&gt; tscv = TimeSeriesSplit(n_splits=3)</span><br><span class="line"> &gt;&gt;&gt; <span class="built_in">print</span>(tscv)</span><br><span class="line">TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None)</span><br><span class="line"> &gt;&gt;&gt; <span class="keyword">for</span> train, <span class="built_in">test</span> <span class="keyword">in</span> tscv.split(X):</span><br><span class="line">...     <span class="built_in">print</span>(<span class="string">"%s %s"</span> % (train, <span class="built_in">test</span>))</span><br><span class="line">[0 1 2] [3]</span><br><span class="line">[0 1 2 3] [4]</span><br><span class="line">[0 1 2 3 4] [5]</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="什么是网格参数搜索gridsearchcv"><a class="markdownIt-Anchor" href="#什么是网格参数搜索gridsearchcv"></a> 什么是网格参数搜索 (GridSearchCV)？</h3><ul><li><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV"><strong>GridSearchCV</strong></a> 实例实现了通常的估计器 API：当将其 “拟合” 到数据集上时，会评估所有可能的参数值组合，并保留最佳组合</li><li>网格搜索优化参数适用于三四个（或更少）的超参数（当超参数的数量增加时，网格搜索的计算复杂度会呈现指数型增长，这时要换用随机搜索）<figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"> &gt;&gt;&gt; from sklearn import svm, datasets</span><br><span class="line"> &gt;&gt;&gt; from sklearn.model_selection import GridSearchCV</span><br><span class="line"> &gt;&gt;&gt; iris = datasets.load_iris()</span><br><span class="line"> &gt;&gt;&gt; parameters = {<span class="string">'kernel'</span>:(<span class="string">'linear'</span>, <span class="string">'rbf'</span>), <span class="string">'C'</span>:[1, 10]}</span><br><span class="line"> &gt;&gt;&gt; svc = svm.SVC()</span><br><span class="line"> &gt;&gt;&gt; clf = GridSearchCV(svc, parameters)</span><br><span class="line"> &gt;&gt;&gt; clf.fit(iris.data, iris.target)</span><br><span class="line">GridSearchCV(estimator=SVC(),</span><br><span class="line">			 param_grid={<span class="string">'C'</span>: [1, 10], <span class="string">'kernel'</span>: (<span class="string">'linear'</span>, <span class="string">'rbf'</span>)})</span><br><span class="line"> &gt;&gt;&gt; sorted(clf.cv_results_.keys())</span><br><span class="line">[<span class="string">'mean_fit_time'</span>, <span class="string">'mean_score_time'</span>, <span class="string">'mean_test_score'</span>,...</span><br><span class="line"> <span class="string">'param_C'</span>, <span class="string">'param_kernel'</span>, <span class="string">'params'</span>,...</span><br><span class="line"> <span class="string">'rank_test_score'</span>, <span class="string">'split0_test_score'</span>,...</span><br><span class="line"> <span class="string">'split2_test_score'</span>, ...</span><br><span class="line"> <span class="string">'std_fit_time'</span>, <span class="string">'std_score_time'</span>, <span class="string">'std_test_score'</span>]</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="什么是随机参数搜索randomizedsearchcv"><a class="markdownIt-Anchor" href="#什么是随机参数搜索randomizedsearchcv"></a> 什么是随机参数搜索 (RandomizedSearchCV)？</h3><ul><li>目前最广泛使用的参数优化方法，但其他搜索方法具有更有利的特性。 <a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV"><strong>RandomizedSearchCV</strong></a> 实现对参数的随机搜索，其中每个设置都是从​​可能的参数值的分布中采样的</li><li>格搜索优化参数是一种算法参数优化的方法。它是通过遍历已定义参数的列表，来评估算法的参数，从而找到最优参数<figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"> &gt;&gt;&gt; from sklearn.datasets import load_iris</span><br><span class="line"> &gt;&gt;&gt; from sklearn.linear_model import LogisticRegression</span><br><span class="line"> &gt;&gt;&gt; from sklearn.model_selection import RandomizedSearchCV</span><br><span class="line"> &gt;&gt;&gt; from scipy.stats import uniform</span><br><span class="line"> &gt;&gt;&gt; iris = load_iris()</span><br><span class="line"> &gt;&gt;&gt; logistic = LogisticRegression(solver=<span class="string">'saga'</span>, tol=1e-2, max_iter=200,</span><br><span class="line">...                               random_state=0)</span><br><span class="line"> &gt;&gt;&gt; distributions = dict(C=uniform(loc=0, scale=4),</span><br><span class="line">...                      penalty=[<span class="string">'l2'</span>, <span class="string">'l1'</span>])</span><br><span class="line"> &gt;&gt;&gt; clf = RandomizedSearchCV(logistic, distributions, random_state=0)</span><br><span class="line"> &gt;&gt;&gt; search = clf.fit(iris.data, iris.target)</span><br><span class="line"> &gt;&gt;&gt; search.best_params_</span><br><span class="line">{<span class="string">'C'</span>: 2..., <span class="string">'penalty'</span>: <span class="string">'l1'</span>}</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="什么是连续减半的网格参数搜索halvinggridsearchcv"><a class="markdownIt-Anchor" href="#什么是连续减半的网格参数搜索halvinggridsearchcv"></a> 什么是连续减半的网格参数搜索 (HalvingGridSearchCV)?</h3><ul><li>搜索策略开始用少量的资源评估所有的候选人，然后迭代地选择最佳候选人，使用越来越多的资源<figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"> &gt;&gt;&gt; from sklearn.datasets import load_iris</span><br><span class="line"> &gt;&gt;&gt; from sklearn.ensemble import RandomForestClassifier</span><br><span class="line"> &gt;&gt;&gt; from sklearn.experimental import enable_halving_search_cv  <span class="comment"># noqa</span></span><br><span class="line"> &gt;&gt;&gt; from sklearn.model_selection import HalvingGridSearchCV</span><br><span class="line">...</span><br><span class="line"> &gt;&gt;&gt; X, y = load_iris(return_X_y=True)</span><br><span class="line"> &gt;&gt;&gt; clf = RandomForestClassifier(random_state=0)</span><br><span class="line">...</span><br><span class="line"> &gt;&gt;&gt; param_grid = {<span class="string">"max_depth"</span>: [3, None],</span><br><span class="line">...               <span class="string">"min_samples_split"</span>: [5, 10]}</span><br><span class="line"> &gt;&gt;&gt; search = HalvingGridSearchCV(clf, param_grid, resource=<span class="string">'n_estimators'</span>,</span><br><span class="line">...                              max_resources=10,</span><br><span class="line">...                              random_state=0).fit(X, y)</span><br><span class="line"> &gt;&gt;&gt; search.best_params_  </span><br><span class="line">{<span class="string">'max_depth'</span>: None, <span class="string">'min_samples_split'</span>: 10, <span class="string">'n_estimators'</span>: 9}</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="什么是连续减半的随机参数搜索halvingrandomsearchcv"><a class="markdownIt-Anchor" href="#什么是连续减半的随机参数搜索halvingrandomsearchcv"></a> 什么是连续减半的随机参数搜索 (HalvingRandomSearchCV)?</h3><ul><li>搜索策略开始用少量的资源评估所有的候选人，然后迭代地选择最佳候选人，使用越来越多的资源<figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"> &gt;&gt;&gt; from sklearn.datasets import load_iris</span><br><span class="line"> &gt;&gt;&gt; from sklearn.ensemble import RandomForestClassifier</span><br><span class="line"> &gt;&gt;&gt; from sklearn.experimental import enable_halving_search_cv  <span class="comment"># noqa</span></span><br><span class="line"> &gt;&gt;&gt; from sklearn.model_selection import HalvingRandomSearchCV</span><br><span class="line"> &gt;&gt;&gt; from scipy.stats import randint</span><br><span class="line"> &gt;&gt;&gt; import numpy as np</span><br><span class="line">...</span><br><span class="line"> &gt;&gt;&gt; X, y = load_iris(return_X_y=True)</span><br><span class="line"> &gt;&gt;&gt; clf = RandomForestClassifier(random_state=0)</span><br><span class="line"> &gt;&gt;&gt; np.random.seed(0)</span><br><span class="line">...</span><br><span class="line"> &gt;&gt;&gt; param_distributions = {<span class="string">"max_depth"</span>: [3, None],</span><br><span class="line">...                        <span class="string">"min_samples_split"</span>: randint(2, 11)}</span><br><span class="line"> &gt;&gt;&gt; search = HalvingRandomSearchCV(clf, param_distributions,</span><br><span class="line">...                                resource=<span class="string">'n_estimators'</span>,</span><br><span class="line">...                                max_resources=10,</span><br><span class="line">...                                random_state=0).fit(X, y)</span><br><span class="line"> &gt;&gt;&gt; search.best_params_  </span><br><span class="line">{<span class="string">'max_depth'</span>: None, <span class="string">'min_samples_split'</span>: 10, <span class="string">'n_estimators'</span>: 9}</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="网格搜索优化参数-随机搜索优化参数如何选择"><a class="markdownIt-Anchor" href="#网格搜索优化参数-随机搜索优化参数如何选择"></a> 网格搜索优化参数、随机搜索优化参数如何选择？</h3><ul><li>如果算法的参数少于三个，推荐使用网格搜索优化参数</li><li>如果需要优化的参数超过三个，推荐使用随机搜索优化参数</li></ul></div><footer class="post-footer"><div class="reward-container"><div>请我一杯咖啡吧！</div><button>赞赏</button><div class="post-reward"><div><img src="/images/wechatpay.png" alt="Shaogui 微信"> <span>微信</span></div><div><img src="/images/alipay.png" alt="Shaogui 支付宝"> <span>支付宝</span></div></div></div><div class="post-copyright"><ul><li class="post-copyright-author"><strong>本文作者： </strong>Shaogui</li><li class="post-copyright-link"><strong>本文链接：</strong> <a href="https://www.shaogui.life/posts/3202670697.html" title="机器学习的模型选择与评估">https://www.shaogui.life/posts/3202670697.html</a></li><li class="post-copyright-license"><strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh-hans" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><div class="followme"><span>欢迎关注我的其它发布渠道</span><div class="social-list"><div class="social-item"><a target="_blank" class="social-link" href="https://www.zhihu.com/people/mu-zhi-zhi-tian"><span class="icon"><i class="fab fa-zhihu"></i> </span><span class="label">知乎</span></a></div><div class="social-item"><a target="_blank" class="social-link" href="/atom.xml"><span class="icon"><i class="fa fa-rss"></i> </span><span class="label">RSS</span></a></div></div></div><div class="post-nav"><div class="post-nav-item"><a href="/posts/2111258136.html" rel="prev" title="机器学习的模型持久化"><i class="fa fa-angle-left"></i> 机器学习的模型持久化</a></div><div class="post-nav-item"><a href="/posts/284278770.html" rel="next" title="机器学习的正则化方法">机器学习的正则化方法 <i class="fa fa-angle-right"></i></a></div></div></footer></article></div><div class="comments utterances-container"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright">&copy; 2016 – <span itemprop="copyrightYear">2025</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">Shaogui</span></div><div class="wordcount"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-chart-line"></i> </span><span>站点总字数：</span> <span title="站点总字数">1.9m</span> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-coffee"></i> </span><span>站点阅读时长 &asymp;</span> <span title="站点阅读时长">28:48</span></span></div><div class="busuanzi-count"><span class="post-meta-item" id="busuanzi_container_site_uv"><span class="post-meta-item-icon"><i class="fa fa-user"></i> </span><span class="site-uv" title="总访客量"><span id="busuanzi_value_site_uv"></span> </span></span><span class="post-meta-item" id="busuanzi_container_site_pv"><span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="site-pv" title="总访问量"><span id="busuanzi_value_site_pv"></span></span></span></div><div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动</div></div></footer><div class="toggle sidebar-toggle" role="button"><span class="toggle-line"></span> <span class="toggle-line"></span> <span class="toggle-line"></span></div><div class="sidebar-dimmer"></div><div class="reading-progress-bar"></div><a href="https://github.com/WuShaogui" class="github-corner" title="在 GitHub 上关注我" aria-label="在 GitHub 上关注我" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><noscript><div class="noscript-warning">Theme NexT works best with JavaScript enabled</div></noscript><script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/lozad.js/1.16.0/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script><script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script><script src="/js/third-party/search/local-search.js"></script><script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":{"light":"neutral","dark":"dark"},"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mermaid/11.4.0/mermaid.min.js","integrity":"sha256-G8ouPAnw4zzMbnAenHnVz6h9XpKbNdOkrqTh7AadyHs="}}</script><script src="/js/third-party/tags/mermaid.js"></script><script src="/js/third-party/pace.js"></script><script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script><script src="/js/third-party/math/mathjax.js"></script><script class="next-config" data-name="utterances" type="application/json">{"enable":true,"repo":"WuShaogui/wushaogui.github.io","issue_term":"pathname","theme":"github-light"}</script><script src="/js/third-party/comments/utterances.js"></script></body></html>