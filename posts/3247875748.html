<!DOCTYPE html><html lang="zh-CN"><head><style type="text/css">.douban-card-block{display:flex;justify-content:center;align-items:center;width:100%;max-height:400px}.douban-card{display:flex;margin:30px 10px;padding:15px;border-radius:15px;position:relative;justify-content:center;align-items:center;overflow:hidden;color:#faebd7;text-decoration:none}.douban-card:hover{text-decoration:none}.douban-card-bgimg{position:absolute;width:115%;height:115%;filter:blur(15px) brightness(.6);background-size:100%;background-position:center;background-repeat:no-repeat}.douban-card-img{position:relative;height:130px;width:80px;background-size:100%;background-position:center;background-repeat:no-repeat}.douban-card-left:hover .douban-card-img{filter:blur(5px) brightness(.6);transform:perspective(800px) rotateX(180deg)}.douban-card-left .douban-card-img{transition:all .5s ease}.douban-card-left{position:relative;display:flex;flex-direction:column;align-items:center}.douban-card-left .douban-card-status{height:130px;width:80px;text-align:center;font-weight:700;position:absolute;left:0;top:30%;transform:rotateX(180deg);backface-visibility:hidden;transition:all .5s ease}.douban-card-left:hover .douban-card-status{transform:perspective(800px) rotateX(0)}.douban-card-right{position:relative;display:flex;flex-direction:column;margin-left:12px;font-size:16px;font-family:"Courier New",Courier,monospace;line-height:1.3;color:#faebd7}.douban-card-item{margin-top:4px}</style><meta charset="UTF-8"><meta name="viewport" content="width=device-width"><meta name="theme-color" content="#222" media="(prefers-color-scheme: light)"><meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 7.3.0"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png"><link rel="mask-icon" href="/images/logo.svg" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:ital,wght@0,300;0,400;0,700;1,300;1,400;1,700&family=Roboto+Mono:ital,wght@0,300;0,400;0,700;1,300;1,400;1,700&family=PT+Mono:ital,wght@0,300;0,400;0,700;1,300;1,400;1,700&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css" integrity="sha256-dABdfBfUoC8vJUBOwGVdm8L9qlMWaHTIfXt+7GnZCIo=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/blue/pace-theme-minimal.css"><script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script><script class="next-config" data-name="main" type="application/json">{"hostname":"www.shaogui.life","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.22.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":true,"style":"flat","show_result":true},"fold":{"enable":true,"height":200},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script><meta name="description" content="找到图片上目标的轮廓，并对图片进行分割"><meta property="og:type" content="article"><meta property="og:title" content="B09 - 图像处理 - 轮廓"><meta property="og:url" content="https://www.shaogui.life/posts/3247875748.html"><meta property="og:site_name" content="年轻人起来冲"><meta property="og:description" content="找到图片上目标的轮廓，并对图片进行分割"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121424093.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121424481.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121424663.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121424490.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121424069.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121424416.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121424840.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121424624.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121424203.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121424976.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121424248.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121424916.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121425020.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121425992.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121425694.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121425574.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121425566.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121425898.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121425174.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121425470.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121425400.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121425517.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121425958.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121426991.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121425772.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121426057.png"><meta property="article:published_time" content="2022-05-05T04:30:55.000Z"><meta property="article:modified_time" content="2025-01-18T11:05:43.930Z"><meta property="article:author" content="Shaogui"><meta property="article:tag" content="opencv"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121424093.png"><link rel="canonical" href="https://www.shaogui.life/posts/3247875748.html"><script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://www.shaogui.life/posts/3247875748.html","path":"posts/3247875748.html","title":"B09 - 图像处理 - 轮廓"}</script><script class="next-config" data-name="calendar" type="application/json">""</script><title>B09 - 图像处理 - 轮廓 | 年轻人起来冲</title><noscript><link rel="stylesheet" href="/css/noscript.css"></noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css"><link rel="alternate" href="/atom.xml" title="年轻人起来冲" type="application/atom+xml"></head><body itemscope itemtype="http://schema.org/WebPage" class="use-motion"><div class="headband"></div><main class="main"><div class="column"><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏" role="button"><span class="toggle-line"></span> <span class="toggle-line"></span> <span class="toggle-line"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><i class="logo-line"></i><p class="site-title">年轻人起来冲</p><i class="logo-line"></i></a></div><div class="site-nav-right"><div class="toggle popup-trigger" aria-label="搜索" role="button"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">77</span></a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">70</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">544</span></a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"><input autocomplete="off" autocapitalize="off" maxlength="80" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close" role="button"><i class="fa fa-times-circle"></i></span></div><div class="search-result-container"><div class="search-result-icon"><i class="fa fa-spinner fa-pulse fa-5x"></i></div></div></div></div></header><aside class="sidebar"><div class="sidebar-inner sidebar-nav-active sidebar-toc-active"><ul class="sidebar-nav"><li class="sidebar-nav-toc">文章目录</li><li class="sidebar-nav-overview">站点概览</li></ul><div class="sidebar-panel-container"><div class="post-toc-wrap sidebar-panel"><div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E4%B9%8B%E5%8C%BA%E5%9F%9F%E7%94%9F%E9%95%BF"><span class="nav-number">1.</span> <span class="nav-text">图像分割之区域生长？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E4%B9%8B%E5%8C%BA%E5%9F%9F%E5%88%86%E5%89%B2"><span class="nav-number">2.</span> <span class="nav-text">图像分割之区域分割？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E4%B9%8B-k-%E5%9D%87%E5%80%BC%E8%81%9A%E7%B1%BB"><span class="nav-number">3.</span> <span class="nav-text">图像分割之 K 均值聚类？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E4%B9%8B%E7%BA%BF%E6%80%A7%E8%BF%AD%E4%BB%A3%E8%81%9A%E7%B1%BBslic%E8%B6%85%E5%83%8F%E7%B4%A0%E5%88%86%E5%89%B2"><span class="nav-number">4.</span> <span class="nav-text">图像分割之 “线性迭代聚类（SLIC）” 超像素分割？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E4%B9%8Bseeds%E8%B6%85%E5%83%8F%E7%B4%A0%E5%88%86%E5%89%B2"><span class="nav-number">5.</span> <span class="nav-text">图像分割之 “SEEDS” 超像素分割？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E4%B9%8B%E7%BA%BF%E6%80%A7%E8%B0%B1%E8%81%9A%E7%B1%BB-lsc%E8%B6%85%E5%83%8F%E7%B4%A0%E5%88%86%E5%89%B2"><span class="nav-number">6.</span> <span class="nav-text">图像分割之 “线性谱聚类 (LSC)” 超像素分割？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E4%B9%8B%E8%B6%85%E5%83%8F%E7%B4%A0%E5%88%86%E5%89%B2%E5%8C%BA%E5%88%AB"><span class="nav-number">7.</span> <span class="nav-text">图像分割之超像素分割区别？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E4%B9%8B%E5%9D%87%E5%80%BC%E6%BC%82%E7%A7%BB-mean-shift%E7%AE%97%E6%B3%95"><span class="nav-number">8.</span> <span class="nav-text">图像分割之均值漂移 (mean shift) 算法？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E4%B9%8B%E5%9B%BE%E5%89%B2%E6%B3%95-graph-cuts"><span class="nav-number">9.</span> <span class="nav-text">图像分割之图割法 (graph cuts)？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E4%B9%8B%E5%9B%BE%E5%89%B2%E6%B3%95-grab-cut"><span class="nav-number">10.</span> <span class="nav-text">图像分割之图割法 (grab cut)？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E4%B9%8B%E5%88%86%E6%B0%B4%E5%B2%AD%E7%AE%97%E6%B3%95"><span class="nav-number">11.</span> <span class="nav-text">图像分割之分水岭算法？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E4%B9%8B%E5%9F%BA%E4%BA%8E-sobel-%E6%A2%AF%E5%BA%A6%E7%9A%84%E5%88%86%E6%B0%B4%E5%B2%AD%E7%AE%97%E6%B3%95"><span class="nav-number">12.</span> <span class="nav-text">图像分割之基于 Sobel 梯度的分水岭算法？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E4%B9%8B%E5%9F%BA%E4%BA%8E%E5%BD%A2%E6%80%81%E5%AD%A6%E7%9A%84%E5%88%86%E6%B0%B4%E5%B2%AD%E7%AE%97%E6%B3%95"><span class="nav-number">13.</span> <span class="nav-text">图像分割之基于形态学的分水岭算法？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E4%B9%8B%E5%9F%BA%E4%BA%8E%E8%BD%AE%E5%BB%93%E6%A0%87%E8%AE%B0%E7%9A%84%E5%88%86%E6%B0%B4%E5%B2%AD%E7%AE%97%E6%B3%95"><span class="nav-number">14.</span> <span class="nav-text">图像分割之基于轮廓标记的分水岭算法？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#opencv-%E5%AF%BB%E6%89%BE%E5%9B%BE%E5%83%8F%E8%BD%AE%E5%BB%93"><span class="nav-number">15.</span> <span class="nav-text">OpenCV 寻找图像轮廓？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#opencv-%E4%BD%BF%E7%94%A8-findcontours-%E6%89%BE%E8%BE%B9%E7%BC%98%E8%BD%AE%E5%BB%93%E6%97%B6%E5%A6%82%E4%BD%95%E8%A7%A3%E6%9E%90%E8%BD%AE%E5%BB%93%E7%9A%84%E5%B1%82%E7%BA%A7"><span class="nav-number">16.</span> <span class="nav-text">OpenCV 使用 findContours 找边缘轮廓时，如何解析轮廓的层级？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#opencv%E4%BD%BF%E7%94%A8findcontours%E6%89%BE%E8%BE%B9%E7%BC%98%E8%BD%AE%E5%BB%93%E6%97%B6%E8%BF%94%E5%9B%9E%E7%9A%84%E7%82%B9%E6%96%B9%E5%90%91%E5%85%B7%E6%9C%89%E4%B8%80%E8%87%B4%E6%80%A7%E5%90%97"><span class="nav-number">17.</span> <span class="nav-text">OpenCV 使用 findContours 找边缘轮廓时，返回的点方向具有一致性吗？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#opencv%E4%BD%BF%E7%94%A8findcontours%E5%AF%B9%E5%B0%91%E6%95%B0%E5%83%8F%E7%B4%A0%E7%9A%84%E6%9F%A5%E6%89%BE%E8%BE%B9%E7%BC%98%E6%97%B6%E5%85%B6%E8%BF%94%E5%9B%9E%E5%80%BC%E6%98%AF%E5%A4%9A%E5%B0%91"><span class="nav-number">18.</span> <span class="nav-text">OpenCV 使用 findContours 对少数像素的查找边缘时，其返回值是多少？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#opencv-%E5%A6%82%E4%BD%95%E7%BB%98%E5%88%B6%E8%BD%AE%E5%BB%93"><span class="nav-number">19.</span> <span class="nav-text">OpenCV 如何绘制轮廓？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#opencv-%E5%A6%82%E4%BD%95%E7%BB%98%E5%88%B6%E8%BD%AE%E5%BB%93%E7%9A%84%E5%87%B8%E5%8C%85"><span class="nav-number">20.</span> <span class="nav-text">OpenCV 如何绘制轮廓的凸包？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#opencv-%E5%A6%82%E4%BD%95%E7%BB%98%E5%88%B6%E8%BD%AE%E5%BB%93%E7%9A%84%E8%BE%B9%E7%95%8C%E7%9F%A9%E5%BD%A2"><span class="nav-number">21.</span> <span class="nav-text">OpenCV 如何绘制轮廓的边界矩形？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#opencv-%E5%A6%82%E4%BD%95%E7%BB%98%E5%88%B6%E8%BD%AE%E5%BB%93%E7%9A%84%E6%9C%80%E5%B0%8F%E5%A4%96%E6%8E%A5%E5%9C%86"><span class="nav-number">22.</span> <span class="nav-text">OpenCV 如何绘制轮廓的最小外接圆？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#opencv-%E5%A6%82%E4%BD%95%E7%BB%98%E5%88%B6%E8%BD%AE%E5%BB%93%E7%9A%84%E6%8B%9F%E5%90%88%E6%A4%AD%E5%9C%86"><span class="nav-number">23.</span> <span class="nav-text">OpenCV 如何绘制轮廓的拟合椭圆？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#opencv-%E5%A6%82%E4%BD%95%E7%BB%98%E5%88%B6%E8%BD%AE%E5%BB%93%E7%9A%84%E6%8B%9F%E5%90%88%E7%9B%B4%E7%BA%BF"><span class="nav-number">24.</span> <span class="nav-text">OpenCV 如何绘制轮廓的拟合直线？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%BE%E7%89%87%E8%BD%AE%E5%BB%93%E6%9C%89%E5%93%AA%E4%BA%9B%E7%89%B9%E5%BE%81"><span class="nav-number">25.</span> <span class="nav-text">图片轮廓有哪些特征？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E5%9B%BE%E5%83%8F%E7%9F%A9"><span class="nav-number">26.</span> <span class="nav-text">什么是图像矩？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A6%82%E4%BD%95%E5%AE%9A%E4%B9%89%E5%9B%BE%E5%83%8F%E7%9A%84%E5%87%A0%E4%BD%95%E7%9F%A9"><span class="nav-number">27.</span> <span class="nav-text">如何定义图像的 “几何矩”？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A6%82%E4%BD%95%E5%AE%9A%E4%B9%89%E5%9B%BE%E5%83%8F%E7%9A%84%E4%B8%AD%E5%BF%83%E8%B7%9D"><span class="nav-number">28.</span> <span class="nav-text">如何定义图像的 “中心距”？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A6%82%E4%BD%95%E5%AE%9A%E4%B9%89%E5%9B%BE%E5%83%8F%E7%9A%84%E5%BD%92%E4%B8%80%E5%8C%96%E4%B8%AD%E5%BF%83%E7%9F%A9"><span class="nav-number">29.</span> <span class="nav-text">如何定义图像的 “归一化中心矩”？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A6%82%E4%BD%95%E5%AE%9A%E4%B9%89%E5%9B%BE%E5%83%8F%E7%9A%84hu-%E7%9F%A9"><span class="nav-number">30.</span> <span class="nav-text">如何定义图像的 “Hu 矩”？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#opencv-%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8-hu-%E7%9F%A9%E8%BF%9B%E8%A1%8C%E8%BD%AE%E5%BB%93%E5%8C%B9%E9%85%8D"><span class="nav-number">31.</span> <span class="nav-text">OpenCV 如何使用 Hu 矩进行轮廓匹配？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#youcans-%E7%9A%84-opencv-%E4%BE%8B%E7%A8%8B200%E7%AF%87168%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E4%B9%8B%E5%8C%BA%E5%9F%9F%E7%94%9F%E9%95%BF_youcans_%E7%9A%84%E5%8D%9A%E5%AE%A2-csdn%E5%8D%9A%E5%AE%A2"><span class="nav-number">32.</span> <span class="nav-text">【youcans 的 OpenCV 例程 200 篇】168. 图像分割之区域生长_youcans_的博客 - CSDN 博客</span></a></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" alt="Shaogui" src="/images/avatar-2023.png"><p class="site-author-name" itemprop="name">Shaogui</p><div class="site-description" itemprop="description">害怕失败是本能，勇敢面对才是本事</div></div><div class="site-state-wrap animated"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">544</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/"><span class="site-state-item-count">70</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/"><span class="site-state-item-count">77</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="links-of-author animated"><span class="links-of-author-item"><a href="https://github.com/WuShaogui" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;WuShaogui" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a> </span><span class="links-of-author-item"><a href="https://www.zhihu.com/people/mu-zhi-zhi-tian" title="知乎 → https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;mu-zhi-zhi-tian" rel="noopener me" target="_blank"><i class="fab fa-zhihu fa-fw"></i>知乎</a></span></div><div class="cc-license animated" itemprop="license"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh-hans" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a></div></div></div><div class="back-to-top animated" role="button" aria-label="返回顶部"><i class="fa fa-arrow-up"></i> <span>0%</span></div></div><div class="sidebar-inner sidebar-blogroll"><div class="links-of-blogroll animated"><div class="links-of-blogroll-title"><i class="fa fa-globe fa-fw"></i> 链接</div><ul class="links-of-blogroll-list"><li class="links-of-blogroll-item"><a href="http://manaai.cn/" title="http:&#x2F;&#x2F;manaai.cn&#x2F;" rel="noopener" target="_blank">神力AI</a></li></ul></div></div></aside></div><div class="main-inner post posts-expand"><div class="post-block"><article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://www.shaogui.life/posts/3247875748.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar-2023.png"><meta itemprop="name" content="Shaogui"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="年轻人起来冲"><meta itemprop="description" content="害怕失败是本能，勇敢面对才是本事"></span><span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork"><meta itemprop="name" content="B09 - 图像处理 - 轮廓 | 年轻人起来冲"><meta itemprop="description" content=""></span><header class="post-header"><h1 class="post-title" itemprop="name headline">B09 - 图像处理 - 轮廓</h1><div class="post-meta-container"><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2022-05-05 12:30:55" itemprop="dateCreated datePublished" datetime="2022-05-05T12:30:55+08:00">2022-05-05</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2025-01-18 19:05:43" itemprop="dateModified" datetime="2025-01-18T19:05:43+08:00">2025-01-18</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/3-%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B5/" itemprop="url" rel="index"><span itemprop="name">3-编程实践</span></a> </span>， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/3-%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B5/E-OpenCV/" itemprop="url" rel="index"><span itemprop="name">E-OpenCV</span></a> </span>， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/3-%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B5/E-OpenCV/OpenCV%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/" itemprop="url" rel="index"><span itemprop="name">OpenCV使用指南</span></a> </span></span><span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv"><span class="post-meta-item-icon"><i class="far fa-eye"></i> </span><span class="post-meta-item-text">阅读次数：</span> <span id="busuanzi_value_page_pv"></span> </span><span class="post-meta-break"></span> <span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>26k</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>24 分钟</span></span></div></div></header><div class="post-body" itemprop="articleBody"><p>找到图片上目标的轮廓，并对图片进行分割</p><span id="more"></span><h3 id="图像分割之区域生长"><a class="markdownIt-Anchor" href="#图像分割之区域生长"></a> 图像分割之区域生长？</h3><ul><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121424093.png" alt=""></li><li>区域生长的基本方法是，对于一组 “种子” 点，通过把与种子具有相同预定义性质（如灰度或颜色范围）的邻域像素合并到种子像素所在的区域中，再将新像素作为新的种子不断重复这一过程，直到没有满足条件的像素为止</li><li>种子点的选取经常采用人工交互方法实现，也可以寻找目标物体并提取物体内部点，或利用其它算法找到的特征点作为种子点<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">getGrayDiff</span>(<span class="params">image, currentPoint, tmpPoint</span>):  <span class="comment"># 求两个像素的距离</span></span><br><span class="line">	<span class="keyword">return</span> <span class="built_in">abs</span>(<span class="built_in">int</span>(image[currentPoint[<span class="number">0</span>], currentPoint[<span class="number">1</span>]]) - <span class="built_in">int</span>(image[tmpPoint[<span class="number">0</span>], tmpPoint[<span class="number">1</span>]]))</span><br><span class="line"><span class="comment"># 区域生长算法</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">regional_growth</span>(<span class="params">img, seeds, thresh=<span class="number">5</span></span>):</span><br><span class="line">	height, weight = img.shape</span><br><span class="line">	seedMark = np.zeros(img.shape)</span><br><span class="line">	seedList = []</span><br><span class="line">	<span class="keyword">for</span> seed <span class="keyword">in</span> seeds:</span><br><span class="line">		<span class="keyword">if</span> (<span class="number">0</span>&lt;seed[<span class="number">0</span>]&lt;height <span class="keyword">and</span> <span class="number">0</span>&lt;seed[<span class="number">1</span>]&lt;weight): seedList.append(seed)</span><br><span class="line">	label = <span class="number">1</span>  <span class="comment"># 种子位置标记</span></span><br><span class="line">	connects = [(-<span class="number">1</span>,-<span class="number">1</span>), (<span class="number">0</span>,-<span class="number">1</span>), (<span class="number">1</span>,-<span class="number">1</span>), (<span class="number">1</span>,<span class="number">0</span>), (<span class="number">1</span>,<span class="number">1</span>), (<span class="number">0</span>,<span class="number">1</span>), (-<span class="number">1</span>,<span class="number">1</span>), (-<span class="number">1</span>,<span class="number">0</span>)]  <span class="comment"># 8 邻接连通</span></span><br><span class="line">	<span class="keyword">while</span> (<span class="built_in">len</span>(seedList) &gt; <span class="number">0</span>):  <span class="comment"># 如果列表里还存在点</span></span><br><span class="line">		currentPoint = seedList.pop(<span class="number">0</span>)  <span class="comment"># 将最前面的那个抛出</span></span><br><span class="line">		seedMark[currentPoint[<span class="number">0</span>], currentPoint[<span class="number">1</span>]] = label  <span class="comment"># 将对应位置的点标记为 1</span></span><br><span class="line">		<span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">8</span>):  <span class="comment"># 对这个点周围的8个点一次进行相似性判断</span></span><br><span class="line">			tmpX = currentPoint[<span class="number">0</span>] + connects[i][<span class="number">0</span>]</span><br><span class="line">			tmpY = currentPoint[<span class="number">1</span>] + connects[i][<span class="number">1</span>]</span><br><span class="line">			<span class="keyword">if</span> tmpX&lt;<span class="number">0</span> <span class="keyword">or</span> tmpY&lt;<span class="number">0</span> <span class="keyword">or</span> tmpX&gt;=height <span class="keyword">or</span> tmpY&gt;=weight:  <span class="comment"># 是否超出限定阈值</span></span><br><span class="line">				<span class="keyword">continue</span></span><br><span class="line">			grayDiff = getGrayDiff(img, currentPoint, (tmpX, tmpY))  <span class="comment"># 计算灰度差</span></span><br><span class="line">			<span class="keyword">if</span> grayDiff&lt;thresh <span class="keyword">and</span> seedMark[tmpX,tmpY]==<span class="number">0</span>:</span><br><span class="line">				seedMark[tmpX, tmpY] = label</span><br><span class="line">				seedList.append((tmpX, tmpY))</span><br><span class="line">	<span class="keyword">return</span> seedMark</span><br><span class="line"><span class="comment"># 区域生长 主程序</span></span><br><span class="line">img = cv2.imread(<span class="string">"../images/Fig1051a.tif"</span>, flags=<span class="number">0</span>)</span><br><span class="line"><span class="comment"># # 灰度直方图</span></span><br><span class="line"><span class="comment"># histCV = cv2.calcHist([img], [0], None, [256], [0, 256])  # 灰度直方图</span></span><br><span class="line"><span class="comment"># OTSU 全局阈值处理</span></span><br><span class="line">ret, imgOtsu = cv2.threshold(img, <span class="number">127</span>, <span class="number">255</span>, cv2.THRESH_OTSU)  <span class="comment"># 阈值分割, thresh=T</span></span><br><span class="line"><span class="comment"># 自适应局部阈值处理</span></span><br><span class="line">binaryMean = cv2.adaptiveThreshold(img, <span class="number">255</span>, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, <span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line"><span class="comment"># 区域生长图像分割</span></span><br><span class="line"><span class="comment"># seeds = [(10, 10), (82, 150), (20, 300)]  # 直接给定 种子点</span></span><br><span class="line">imgBlur = cv2.blur(img, (<span class="number">3</span>,<span class="number">3</span>))  <span class="comment"># cv2.blur 方法</span></span><br><span class="line">_, imgTop = cv2.threshold(imgBlur, <span class="number">250</span>, <span class="number">255</span>, cv2.THRESH_BINARY)  <span class="comment"># 高百分位阈值产生种子区域</span></span><br><span class="line">nseeds, labels, stats, centroids = cv2.connectedComponentsWithStats(imgTop)  <span class="comment"># 过滤连通域，获得质心点 (x,y)</span></span><br><span class="line">seeds = centroids.astype(<span class="built_in">int</span>)  <span class="comment"># 获得质心像素作为种子点</span></span><br><span class="line">imgGrowth = regional_growth(img, seeds, <span class="number">8</span>)</span><br><span class="line">show_images([img,imgOtsu,binaryMean,imgGrowth])</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="图像分割之区域分割"><a class="markdownIt-Anchor" href="#图像分割之区域分割"></a> 图像分割之区域分割？</h3><ul><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121424481.png" alt=""></li><li>生成是分割的逆过程，都可以完成对图像的分割</li><li>分离过程先判断当前区域是否满足目标的特征测度，如果不满足则将当前区域分离为多个子区域进行判断；不断重复判断、分离，直到拆分到最小区域为止。典型的区域分裂方法，是将区域按照 4 个象限分裂为 4 个子区域，可以简化处理和运算过程<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">SplitMerge</span>(<span class="params">src, dst, h, w, h0, w0, maxMean, minVar, cell=<span class="number">4</span></span>):</span><br><span class="line">	win = src[h0: h0+h, w0: w0+w]</span><br><span class="line">	mean = np.mean(win)  <span class="comment"># 窗口区域的均值</span></span><br><span class="line">	var = np.std(win, ddof=<span class="number">1</span>)  <span class="comment"># 窗口区域的标准差，无偏样本标准差</span></span><br><span class="line">	<span class="keyword">if</span> (mean&lt;maxMean) <span class="keyword">and</span> (var&gt;minVar) <span class="keyword">and</span> (h&lt;<span class="number">2</span>*cell) <span class="keyword">and</span> (w&lt;<span class="number">2</span>*cell):</span><br><span class="line">		<span class="comment"># 该区域满足谓词逻辑条件，判为目标区域，设为白色</span></span><br><span class="line">		dst[h0:h0+h, w0:w0+w] = <span class="number">255</span>  <span class="comment"># 白色</span></span><br><span class="line">		<span class="comment"># print("h0={}, w0={}, h={}, w={}, mean={:.2f}, var={:.2f}".</span></span><br><span class="line">		<span class="comment">#       format(h0, w0, h, w, mean, var))</span></span><br><span class="line">	<span class="keyword">else</span>:  <span class="comment"># 该区域不满足谓词逻辑条件</span></span><br><span class="line">		<span class="keyword">if</span> (h&gt;cell) <span class="keyword">and</span> (w&gt;cell):  <span class="comment"># 区域能否继续分拆？继续拆</span></span><br><span class="line">			SplitMerge(src, dst, (h+<span class="number">1</span>)//<span class="number">2</span>, (w+<span class="number">1</span>)//<span class="number">2</span>, h0, w0, maxMean, minVar, cell)</span><br><span class="line">			SplitMerge(src, dst, (h+<span class="number">1</span>)//<span class="number">2</span>, (w+<span class="number">1</span>)//<span class="number">2</span>, h0, w0+(w+<span class="number">1</span>)//<span class="number">2</span>,  maxMean, minVar, cell)</span><br><span class="line">			SplitMerge(src, dst, (h+<span class="number">1</span>)//<span class="number">2</span>, (w+<span class="number">1</span>)//<span class="number">2</span>, h0+(h+<span class="number">1</span>)//<span class="number">2</span>, w0, maxMean, minVar, cell)</span><br><span class="line">			SplitMerge(src, dst, (h+<span class="number">1</span>)//<span class="number">2</span>, (w+<span class="number">1</span>)//<span class="number">2</span>, h0+(h+<span class="number">1</span>)//<span class="number">2</span>, w0+(w+<span class="number">1</span>)//<span class="number">2</span>, maxMean, minVar, cell)</span><br><span class="line">		<span class="comment"># else:  # 不能再分拆，判为非目标区域，设为黑色</span></span><br><span class="line">		<span class="comment">#     src[h0:h0+h, w0:w0+w] = 0  # 黑色</span></span><br><span class="line">img = cv2.imread(<span class="string">"../images/Fig0938a.tif"</span>, flags=<span class="number">0</span>)</span><br><span class="line">hImg, wImg = img.shape</span><br><span class="line">mean = np.mean(img)  <span class="comment"># 窗口区域的均值</span></span><br><span class="line">var = np.std(img, ddof=<span class="number">1</span>)  <span class="comment"># 窗口区域的标准差，无偏样本标准差</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"h={}, w={}, mean={:.2f}, var={:.2f}"</span>.<span class="built_in">format</span>(hImg, wImg, mean, var))</span><br><span class="line">maxMean = <span class="number">80</span>  <span class="comment"># 均值上界</span></span><br><span class="line">minVar = <span class="number">10</span>  <span class="comment"># 标准差下界</span></span><br><span class="line">src = img.copy()</span><br><span class="line">dst1 = np.zeros_like(img)</span><br><span class="line">dst2 = np.zeros_like(img)</span><br><span class="line">dst3 = np.zeros_like(img)</span><br><span class="line">SplitMerge(src, dst1, hImg, wImg, <span class="number">0</span>, <span class="number">0</span>, maxMean, minVar, cell=<span class="number">32</span>) </span><br><span class="line">SplitMerge(src, dst2, hImg, wImg, <span class="number">0</span>, <span class="number">0</span>, maxMean, minVar, cell=<span class="number">16</span>) </span><br><span class="line">SplitMerge(src, dst3, hImg, wImg, <span class="number">0</span>, <span class="number">0</span>, maxMean, minVar, cell=<span class="number">8</span>) </span><br><span class="line">show_images([img,dst1,dst2,dst3])</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="图像分割之-k-均值聚类"><a class="markdownIt-Anchor" href="#图像分割之-k-均值聚类"></a> 图像分割之 K 均值聚类？</h3><ul><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121424663.png" alt=""></li><li>聚类方法的思想是将样本集合按照其特征的相似性划分为若干类别，使同一类别样本的特征具有较高的相似性，不同类别样本的特征具有较大的差异性</li><li>基于聚类的区域分割，就是基于图像的灰度、颜色、纹理、形状等特征，用聚类算法把图像分成若干类别或区域，使每个点到聚类中心的均值最小<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">img = cv2.imread(<span class="string">"../images/imgB6.jpg"</span>, flags=<span class="number">1</span>)  <span class="comment"># 读取彩色图像(BGR)</span></span><br><span class="line">dataPixel = np.float32(img.reshape((-<span class="number">1</span>, <span class="number">3</span>)))</span><br><span class="line">criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, <span class="number">200</span>, <span class="number">0.1</span>)  <span class="comment"># 终止条件</span></span><br><span class="line">flags = cv2.KMEANS_RANDOM_CENTERS  <span class="comment"># 起始的中心选择</span></span><br><span class="line">K = <span class="number">3</span>  <span class="comment"># 设置聚类数</span></span><br><span class="line">_, labels, center = cv2.kmeans(dataPixel, K, <span class="literal">None</span>, criteria, <span class="number">10</span>, flags)</span><br><span class="line">centerUint = np.uint8(center)</span><br><span class="line">classify = centerUint[labels.flatten()]  <span class="comment"># 将像素标记为聚类中心颜色</span></span><br><span class="line">imgKmean3 = classify.reshape((img.shape))  <span class="comment"># 恢复为二维图像</span></span><br><span class="line">K = <span class="number">4</span>  <span class="comment"># 设置聚类数</span></span><br><span class="line">_, labels, center = cv2.kmeans(dataPixel, K, <span class="literal">None</span>, criteria, <span class="number">10</span>, flags)</span><br><span class="line">centerUint = np.uint8(center)</span><br><span class="line">classify = centerUint[labels.flatten()]  <span class="comment"># 将像素标记为聚类中心颜色</span></span><br><span class="line">imgKmean4 = classify.reshape((img.shape))  <span class="comment"># 恢复为二维图像</span></span><br><span class="line">K = <span class="number">5</span>  <span class="comment"># 设置聚类数</span></span><br><span class="line">_, labels, center = cv2.kmeans(dataPixel, K, <span class="literal">None</span>, criteria, <span class="number">10</span>, flags)</span><br><span class="line">centerUint = np.uint8(center)</span><br><span class="line">classify = centerUint[labels.flatten()]  <span class="comment"># 将像素标记为聚类中心颜色</span></span><br><span class="line">imgKmean5 = classify.reshape((img.shape))  <span class="comment"># 恢复为二维图像</span></span><br><span class="line">show_images([img,imgKmean3,imgKmean4,imgKmean5])</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="图像分割之线性迭代聚类slic超像素分割"><a class="markdownIt-Anchor" href="#图像分割之线性迭代聚类slic超像素分割"></a> 图像分割之 “线性迭代聚类（SLIC）” 超像素分割？</h3><ul><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121424490.png" alt=""></li><li><strong>超像素</strong>：由一系列位置相邻，颜色、亮度、纹理等特征相似的像素点组成的小区域，我们将其视为具有代表性的大 “像素”，称为超像素。超像素技术通过像素的组合得到少量（相对于像素数量）具有感知意义的超像素区域，代替大量原始像素表达图像特征，可以极大地降低图像处理的复杂度、减小计算量</li><li><strong>超像素分割</strong>：基于依赖于图像的颜色信息及空间关系信息，将图像分割为远超于目标个数、远小于像素数量的超像素块，达到尽可能保留图像中所有目标的边缘信息的目的，从而更好的辅助后续视觉任务</li><li><strong>常用的超像素分割方法有</strong>：简单线性迭代聚类（Simple Linear Iterative Clustering，SLIC）、能量驱动采样（Super-pixels Extracted via Energy-Driven Sampling，SEEDS）和线性谱聚类（Linear Spectral Clustering，LSC）<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">img = cv2.imread(<span class="string">"../images/imgLena.tif"</span>, flags=<span class="number">1</span>)  <span class="comment"># 读取彩色图像(BGR)</span></span><br><span class="line">imgHSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV_FULL)  <span class="comment"># BGR-HSV 转换</span></span><br><span class="line"><span class="comment"># SLIC 算法</span></span><br><span class="line">slic = cv2.ximgproc.createSuperpixelSLIC(img, region_size=<span class="number">10</span>, ruler=<span class="number">10.0</span>)  <span class="comment"># 初始化 SLIC</span></span><br><span class="line">slic.iterate(<span class="number">10</span>)  <span class="comment"># 迭代次数，越大效果越好</span></span><br><span class="line">label_slic = slic.getLabels()  <span class="comment"># 获取超像素标签</span></span><br><span class="line">number_slic = slic.getNumberOfSuperpixels()  <span class="comment"># 获取超像素数目</span></span><br><span class="line">mask_slic = slic.getLabelContourMask()  <span class="comment"># 获取 Mask，超像素边缘 Mask==1</span></span><br><span class="line">mask_color = np.array([mask_slic <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>)]).transpose(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>)  <span class="comment"># 转为 3 通道</span></span><br><span class="line"><span class="comment"># mask_color= cv2.COLOR_GRAY2RGB(mask_slic)  # 灰度 Mask 转为 RGB</span></span><br><span class="line">img_slic = cv2.bitwise_and(img, img, mask=cv2.bitwise_not(mask_slic))  <span class="comment"># 在原图上绘制超像素边界</span></span><br><span class="line">imgSlic = cv2.add(img_slic, mask_color)</span><br><span class="line">show_images([img,mask_slic,img_slic,imgSlic])</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="图像分割之seeds超像素分割"><a class="markdownIt-Anchor" href="#图像分割之seeds超像素分割"></a> 图像分割之 “SEEDS” 超像素分割？</h3><ul><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121424069.png" alt=""></li><li>超像素个体应在视觉上一致，特别是颜色应尽可能均匀。SLIC 使用欧几里德距离来度量像素点的相似度，不能反映颜色的方差</li><li>SEEDS 每次迭代只对处于超像素边界的像素点进行更新，通过能量函数的值来决定这个像素点是否转移到相邻的超像素块内<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">img = cv2.imread(<span class="string">"../images/imgLena.tif"</span>, flags=<span class="number">1</span>)  <span class="comment"># 读取彩色图像(BGR)</span></span><br><span class="line">imgHSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV_FULL)  <span class="comment"># BGR-HSV 转换</span></span><br><span class="line"><span class="comment"># SLIC 算法</span></span><br><span class="line">slic = cv2.ximgproc.createSuperpixelSLIC(img, region_size=<span class="number">20</span>, ruler=<span class="number">10.0</span>)  <span class="comment"># 初始化 SLIC</span></span><br><span class="line">slic.iterate(<span class="number">10</span>)  <span class="comment"># 迭代次数，越大效果越好</span></span><br><span class="line">mask_slic = slic.getLabelContourMask()  <span class="comment"># 获取 Mask，超像素边缘 Mask==1</span></span><br><span class="line">img_slic = cv2.bitwise_and(img, img, mask=cv2.bitwise_not(mask_slic))  <span class="comment"># 在原图上绘制超像素边界</span></span><br><span class="line"><span class="comment"># SEEDS 算法，注意图片长宽的顺序为 w, h, c</span></span><br><span class="line">seeds = cv2.ximgproc.createSuperpixelSEEDS(img.shape[<span class="number">1</span>], img.shape[<span class="number">0</span>], img.shape[<span class="number">2</span>], <span class="number">2000</span>, <span class="number">15</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="literal">True</span>)</span><br><span class="line">seeds.iterate(imgHSV, <span class="number">10</span>)  <span class="comment"># 输入图像大小必须与初始化形状相同，迭代次数为10</span></span><br><span class="line">mask_seeds = seeds.getLabelContourMask()  <span class="comment"># 获取 Mask，超像素边缘 Mask==1</span></span><br><span class="line">label_seeds = seeds.getLabels()  <span class="comment"># 获取超像素标签</span></span><br><span class="line">number_seeds = seeds.getNumberOfSuperpixels()  <span class="comment"># 获取超像素数目</span></span><br><span class="line">img_seeds = cv2.bitwise_and(img, img, mask=cv2.bitwise_not(mask_seeds))</span><br><span class="line">show_images([img,mask_seeds,img_slic,img_seeds])</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="图像分割之线性谱聚类-lsc超像素分割"><a class="markdownIt-Anchor" href="#图像分割之线性谱聚类-lsc超像素分割"></a> 图像分割之 “线性谱聚类 (LSC)” 超像素分割？</h3><ul><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121424416.png" alt=""></li><li>线性谱聚类（Linear Spectral Clustering，LSC）是 SLIC 的改进方案，可以生成紧凑且均匀的超像素，将图像分割成大小均匀，边界光滑的小块</li><li>谱聚类是从图论中演化出来的算法，其基本思想是把所有数据看做空间中的点，点之间可以用边连接。距离较远的点之间的边权重值较低，而距离较近的点之间的边权重值较高。通过对所有数据点组成的图进行切图，让切图后不同的子图间边权重和尽可能的低，而子图内的边权重和尽可能的高，从而达到聚类的目的<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">img = cv2.imread(<span class="string">"../images/imgLena.tif"</span>, flags=<span class="number">1</span>)  <span class="comment"># 读取彩色图像(BGR)</span></span><br><span class="line">imgHSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV_FULL)  <span class="comment"># BGR-HSV 转换</span></span><br><span class="line"><span class="comment"># SLIC 算法</span></span><br><span class="line">slic = cv2.ximgproc.createSuperpixelSLIC(img, region_size=<span class="number">20</span>, ruler=<span class="number">10.0</span>)  <span class="comment"># 初始化 SLIC</span></span><br><span class="line">slic.iterate(<span class="number">10</span>)  <span class="comment"># 迭代次数，越大效果越好</span></span><br><span class="line">mask_slic = slic.getLabelContourMask()  <span class="comment"># 获取 Mask，超像素边缘 Mask==1</span></span><br><span class="line">img_slic = cv2.bitwise_and(img, img, mask=cv2.bitwise_not(mask_slic))  <span class="comment"># 在原图上绘制超像素边界</span></span><br><span class="line"><span class="comment"># LSC 算法 (Linear Spectral Clustering)</span></span><br><span class="line">lsc = cv2.ximgproc.createSuperpixelLSC(img)</span><br><span class="line">lsc.iterate(<span class="number">10</span>)</span><br><span class="line">mask_lsc = lsc.getLabelContourMask()</span><br><span class="line">label_lsc = lsc.getLabels()</span><br><span class="line">number_lsc = lsc.getNumberOfSuperpixels()</span><br><span class="line">mask_inv_lsc = cv2.bitwise_not(mask_lsc)</span><br><span class="line">img_lsc = cv2.bitwise_and(img, img, mask=mask_inv_lsc</span><br><span class="line">show_images([img,mask_lsc,img_slic,img_lsc])</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="图像分割之超像素分割区别"><a class="markdownIt-Anchor" href="#图像分割之超像素分割区别"></a> 图像分割之超像素分割区别？</h3><ul><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121424840.png" alt=""></li><li>简单线性迭代聚类、能量驱动采样、线性谱聚类<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">img = cv2.imread(<span class="string">"../images/imgBuilding2.png"</span>, flags=<span class="number">1</span>)  <span class="comment"># 读取彩色图像(BGR)</span></span><br><span class="line">imgHSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV_FULL)  <span class="comment"># BGR-HSV 转换</span></span><br><span class="line"><span class="comment"># SLIC 算法 (Simple Linear Iterative Clustering)</span></span><br><span class="line">slic = cv2.ximgproc.createSuperpixelSLIC(img, region_size=<span class="number">20</span>, ruler=<span class="number">10.0</span>)  <span class="comment"># 初始化 SLIC</span></span><br><span class="line">slic.iterate(<span class="number">10</span>)  <span class="comment"># 迭代次数，越大效果越好</span></span><br><span class="line">mask_slic = slic.getLabelContourMask()  <span class="comment"># 获取 Mask，超像素边缘 Mask==1</span></span><br><span class="line">img_slic = cv2.bitwise_and(img, img, mask=cv2.bitwise_not(mask_slic))  <span class="comment"># 在原图上绘制超像素边界</span></span><br><span class="line"><span class="comment"># SEEDS 算法 (Super-pixels Extracted via Energy-Driven Sampling)</span></span><br><span class="line">seeds = cv2.ximgproc.createSuperpixelSEEDS(img.shape[<span class="number">1</span>], img.shape[<span class="number">0</span>], img.shape[<span class="number">2</span>], <span class="number">2000</span>, <span class="number">15</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="literal">True</span>)</span><br><span class="line">seeds.iterate(img, <span class="number">10</span>)  <span class="comment"># 输入图像大小必须与初始化形状相同，迭代次数为10</span></span><br><span class="line">mask_seeds = seeds.getLabelContourMask()  <span class="comment"># 获取 Mask，超像素边缘 Mask==1</span></span><br><span class="line">label_seeds = seeds.getLabels()  <span class="comment"># 获取超像素标签</span></span><br><span class="line">number_seeds = seeds.getNumberOfSuperpixels()  <span class="comment"># 获取超像素数目</span></span><br><span class="line">img_seeds = cv2.bitwise_and(img, img, mask=cv2.bitwise_not(mask_seeds))</span><br><span class="line"><span class="comment"># LSC 算法 (Linear Spectral Clustering)</span></span><br><span class="line">lsc = cv2.ximgproc.createSuperpixelLSC(img)</span><br><span class="line">lsc.iterate(<span class="number">10</span>)</span><br><span class="line">mask_lsc = lsc.getLabelContourMask()</span><br><span class="line">label_lsc = lsc.getLabels()</span><br><span class="line">number_lsc = lsc.getNumberOfSuperpixels()</span><br><span class="line">mask_inv_lsc = cv2.bitwise_not(mask_lsc)</span><br><span class="line">img_lsc = cv2.bitwise_and(img, img, mask=mask_inv_lsc)</span><br><span class="line">show_images([img,img_slic,img_seeds,img_lsc])</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="图像分割之均值漂移-mean-shift算法"><a class="markdownIt-Anchor" href="#图像分割之均值漂移-mean-shift算法"></a> 图像分割之均值漂移 (mean shift) 算法？</h3><ul><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121424624.png" alt=""></li><li>通过反复迭代搜索特征空间中样本最密集的区域，搜索点沿着样本点密度增加的方向 “漂移” 到局部密度极大值点。采用基于核密度估计的爬山算法，自适应调整步长进行迭代搜索，可以收敛到局部极值</li><li>基于 Mean Shift 的目标跟踪技术采用核概率密度描述目标特征，对于图像分割通常采用直方图对目标建模，然后通过相似性度量搜索目标位置，实现目标的匹配与跟踪<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">meanShiftTracker</span>(<span class="params">src, trackWindow</span>):</span><br><span class="line">	<span class="comment"># meanShift 算法: 在 dst 寻找目标窗口，找到后返回目标窗口位置</span></span><br><span class="line">	hsv = cv2.cvtColor(src, cv2.COLOR_BGR2HSV)  <span class="comment"># BGR-HSV 转换</span></span><br><span class="line">	dst = cv2.calcBackProject([hsv], [<span class="number">0</span>], roiHist, [<span class="number">0</span>, <span class="number">180</span>], <span class="number">1</span>)  <span class="comment"># 计算反向投影</span></span><br><span class="line">	term_crit = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, <span class="number">10</span>, <span class="number">1</span>)</span><br><span class="line">	_, trackWin = cv2.meanShift(dst, trackWindow, term_crit)</span><br><span class="line">	x, y, w, h = trackWin</span><br><span class="line">	imgTrack = src.copy()</span><br><span class="line">	imgTrack = cv2.rectangle(imgTrack, (x, y), (x + w, y + h), <span class="number">255</span>, <span class="number">2</span>)</span><br><span class="line">	<span class="built_in">print</span>(x, y, w, h)</span><br><span class="line">	<span class="keyword">return</span> imgTrack</span><br><span class="line">img = cv2.imread(<span class="string">"../images/FigCross1.png"</span>, flags=<span class="number">1</span>)  <span class="comment"># 基准参考图像</span></span><br><span class="line">imgHSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV_FULL)  <span class="comment"># BGR-HSV 转换</span></span><br><span class="line"><span class="comment"># 设置初始化的窗口位置</span></span><br><span class="line"><span class="comment"># print("Select a ROI and then press SPACE or ENTER button!\n")</span></span><br><span class="line"><span class="comment"># roi = cv2.selectROI(img, showCrosshair=True, fromCenter=False)</span></span><br><span class="line"><span class="comment"># x0, y0, w, h = roi  # 矩形裁剪区域 (ymin:ymin+h, xmin:xmin+w) 的位置参数</span></span><br><span class="line"><span class="comment"># rect = (x0, y0, w, h)  # 边界框矩形的坐标和尺寸  # rect = (990 311 94 72)</span></span><br><span class="line">(x0, y0, w, h) = (<span class="number">990</span>, <span class="number">310</span>, <span class="number">95</span>, <span class="number">72</span>)  <span class="comment"># 直接设置矩形窗口的位置参数，也可以鼠标框选 ROI</span></span><br><span class="line">trackWindow = (x0, y0, w, h)  <span class="comment"># 矩形 ROI</span></span><br><span class="line"><span class="built_in">print</span>(x0, y0, w, h)</span><br><span class="line">imgROI = np.zeros_like(img)  <span class="comment"># 创建与 image 相同形状的黑色图像</span></span><br><span class="line">imgROI[y0:y0+h, x0:x0+w] = img[y0:y0+h, x0:x0+w].copy()</span><br><span class="line">frameROI = imgROI[y0:y0+h, x0:x0+w]  <span class="comment"># 设置追踪的区域</span></span><br><span class="line">roiHSV = cv2.cvtColor(frameROI, cv2.COLOR_BGR2HSV)  <span class="comment"># BGR-HSV 转换</span></span><br><span class="line"><span class="comment"># 取 HSV 在 (0,60,32)~(180,255,255) 之间的部分</span></span><br><span class="line">mask = cv2.inRange(roiHSV, np.array((<span class="number">0.</span>, <span class="number">60.</span>, <span class="number">32.</span>)), np.array((<span class="number">180.</span>, <span class="number">255.</span>, <span class="number">255.</span>)))</span><br><span class="line">roiHist = cv2.calcHist([roiHSV], [<span class="number">0</span>], mask, [<span class="number">180</span>], [<span class="number">0</span>, <span class="number">180</span>])  <span class="comment"># 计算直方图</span></span><br><span class="line">cv2.normalize(roiHist, roiHist, <span class="number">0</span>, <span class="number">255</span>, cv2.NORM_MINMAX)  <span class="comment"># 归一化</span></span><br><span class="line"><span class="comment"># # meanShift 算法: 在 dst 寻找目标窗口，找到后返回目标窗口位置</span></span><br><span class="line">img1 = cv2.imread(<span class="string">"../images/FigCross2.png"</span>, flags=<span class="number">1</span>)  <span class="comment"># 读取彩色图像(BGR)</span></span><br><span class="line">imgTrack1 = meanShiftTracker(img1, trackWindow)</span><br><span class="line">img2 = cv2.imread(<span class="string">"../images/FigCross4.png"</span>, flags=<span class="number">1</span>)  <span class="comment"># 读取彩色图像(BGR)</span></span><br><span class="line">imgTrack2 = meanShiftTracker(img2, trackWindow)</span><br><span class="line">show_images([img,imgROI,img1,imgTrack1,img2,imgTrack2])</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="图像分割之图割法-graph-cuts"><a class="markdownIt-Anchor" href="#图像分割之图割法-graph-cuts"></a> 图像分割之图割法 (graph cuts)？</h3><ul><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121424203.png" alt=""></li><li>将图像映射为带权的无向图，把像素视为节点，两个节点之间的边的权重对应于两个像素之间相似性的度量，割的容量就对应于能量函数；使用最大流最小割算法对图进行切割，得到的最小割就对应于最优图像分割</li><li>GraphCut 算法需要用户在前景和背景处各画几笔作为输入，由此建立各个像素点与前景背景相似度的赋权图，并通过求解最小割进行图像的前景和背景分割</li></ul><h3 id="图像分割之图割法-grab-cut"><a class="markdownIt-Anchor" href="#图像分割之图割法-grab-cut"></a> 图像分割之图割法 (grab cut)？</h3><ul><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121424976.png" alt=""></li><li>GrabCut 算法是对 GraphCut 的改进，使用高斯混合模型（GMM）对背景和目标建立模型，采用迭代方法实现分割能量的最小化，同时支持不完整的标记</li><li>GrabCut 算法有效利用了图像中的纹理（颜色）信息和边界（反差）信息，只需要要少量的人工交互操作就可以对目标实现较好的分割效果<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">image = cv2.imread(<span class="string">"../images/imgGaia.tif"</span>, flags=<span class="number">1</span>)  <span class="comment"># 读取彩色图像(BGR)</span></span><br><span class="line">mask = np.zeros(image.shape[:<span class="number">2</span>], dtype=<span class="string">"uint8"</span>)</span><br><span class="line"><span class="comment"># 定义矩形框，框选目标前景</span></span><br><span class="line"><span class="comment"># rect = (118, 125, 220, 245)  # 直接设置矩形的位置参数，也可以鼠标框选 ROI</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"Select a ROI and then press SPACE or ENTER button!\n"</span>)</span><br><span class="line">roi = cv2.selectROI(image, showCrosshair=<span class="literal">True</span>, fromCenter=<span class="literal">False</span>)</span><br><span class="line">xmin, ymin, w, h = roi  <span class="comment"># 矩形裁剪区域 (ymin:ymin+h, xmin:xmin+w) 的位置参数</span></span><br><span class="line">rect = (xmin, ymin, w, h)  <span class="comment"># 边界框矩形的坐标和尺寸</span></span><br><span class="line">imgROI = np.zeros_like(image)  <span class="comment"># 创建与 image 相同形状的黑色图像</span></span><br><span class="line">imgROI[ymin:ymin + h, xmin:xmin + w] = image[ymin:ymin + h, xmin:xmin + w].copy()</span><br><span class="line"><span class="built_in">print</span>(xmin, ymin, w, h)</span><br><span class="line">fgModel = np.zeros((<span class="number">1</span>, <span class="number">65</span>), dtype=<span class="string">"float"</span>)  <span class="comment"># 前景模型, 13*5</span></span><br><span class="line">bgModel = np.zeros((<span class="number">1</span>, <span class="number">65</span>), dtype=<span class="string">"float"</span>)  <span class="comment"># 背景模型, 13*5</span></span><br><span class="line"><span class="built_in">iter</span> = <span class="number">5</span></span><br><span class="line">(mask, bgModel, fgModel) = cv2.grabCut(image, mask, rect, bgModel, fgModel, <span class="built_in">iter</span>,</span><br><span class="line">									   mode=cv2.GC_INIT_WITH_RECT)  <span class="comment"># 框选前景分割模式</span></span><br><span class="line"><span class="comment"># 将所有确定背景和可能背景像素设置为 0，而确定前景和可能前景像素设置为 1</span></span><br><span class="line">maskOutput = np.where((mask == cv2.GC_BGD) | (mask == cv2.GC_PR_BGD), <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">maskGrabCut = (maskOutput * <span class="number">255</span>).astype(<span class="string">"uint8"</span>)</span><br><span class="line">imgGrabCut = cv2.bitwise_and(image, image, mask=maskGrabCut)</span><br><span class="line">show_images([image,imgROI,maskBGD,maskPBGD,maskGrabCut,imgGrabCut])</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="图像分割之分水岭算法"><a class="markdownIt-Anchor" href="#图像分割之分水岭算法"></a> 图像分割之分水岭算法？</h3><ul><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121424248.png" alt=""></li><li>分水岭算法是一种图像区域分割法，以临近像素间的相似性作为重要特征，从而将空间位置相近且灰度值相近的像素点互相连接起来，构成一个封闭的轮廓</li><li>分水岭方法是一种基于拓扑理论的数学形态学的分割方法，基本思想是把图像看作测地学上的拓扑地貌，将像素点的灰度值视为海拔高度，整个图像就像一张高低起伏的地形图。每个局部极小值及其影响区域称为集水盆，集水盆的边界则形成分水岭<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">img = cv2.imread(<span class="string">"../images/Fig1039a.tif"</span>, flags=<span class="number">1</span>)  <span class="comment"># 读取彩色图像(BGR)</span></span><br><span class="line">gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  <span class="comment"># 转为灰度图像</span></span><br><span class="line"><span class="comment"># 阈值分割，将灰度图像分为黑白二值图像</span></span><br><span class="line">ret, thresh = cv2.threshold(gray, <span class="number">0</span>, <span class="number">255</span>, cv2.THRESH_OTSU)</span><br><span class="line"><span class="comment"># 形态学操作，生成 "确定背景" 区域</span></span><br><span class="line">kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (<span class="number">3</span>, <span class="number">3</span>))  <span class="comment"># 生成 3*3 结构元</span></span><br><span class="line">opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=<span class="number">2</span>)  <span class="comment"># 开运算，消除噪点</span></span><br><span class="line">sure_bg = cv2.dilate(opening, kernel, iterations=<span class="number">3</span>)  <span class="comment"># 膨胀操作，生成 "确定背景" 区域</span></span><br><span class="line"><span class="comment"># 距离变换，生成 "确定前景" 区域</span></span><br><span class="line">distance = cv2.distanceTransform(opening, cv2.DIST_L2, <span class="number">5</span>)  <span class="comment"># DIST_L2: 3/5</span></span><br><span class="line">_, sure_fg = cv2.threshold(distance, <span class="number">0.1</span>*distance.<span class="built_in">max</span>(), <span class="number">255</span>, cv2.THRESH_BINARY)  <span class="comment"># 阈值选择 0.1*max 效果较好</span></span><br><span class="line">sure_fg = np.uint8(sure_fg)</span><br><span class="line"><span class="comment"># 连通域处理</span></span><br><span class="line">ret, component = cv2.connectedComponents(sure_fg, connectivity=<span class="number">8</span>)  <span class="comment"># 对连通区域进行标号，序号为 0-N-1</span></span><br><span class="line">markers = component + <span class="number">1</span>  <span class="comment"># OpenCV 分水岭算法设置标注从 1 开始，而连通域编从 0 开始</span></span><br><span class="line"><span class="comment"># 去除连通域中的背景区域部分</span></span><br><span class="line">unknown = cv2.subtract(sure_bg, sure_fg)  <span class="comment"># 待定区域，前景与背景的重合区域</span></span><br><span class="line">markers[unknown==<span class="number">255</span>] = <span class="number">0</span>  <span class="comment"># 去掉属于背景的区域 (置零)</span></span><br><span class="line"><span class="comment"># 分水岭算法标注目标的轮廓</span></span><br><span class="line">markers = cv2.watershed(img, markers)  <span class="comment"># 分水岭算法，将所有轮廓的像素点标注为 -1</span></span><br><span class="line">kinds = markers.<span class="built_in">max</span>()  <span class="comment"># 标注连通域的数量</span></span><br><span class="line"><span class="comment"># 把轮廓添加到原始图像上</span></span><br><span class="line">imgWatershed = img.copy()</span><br><span class="line">imgWatershed[markers == -<span class="number">1</span>] = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>]  <span class="comment"># 将分水岭算法标注的轮廓点设为红色</span></span><br><span class="line"><span class="built_in">print</span>(img.shape, markers.shape, markers.<span class="built_in">max</span>(), markers.<span class="built_in">min</span>(),ret)</span><br><span class="line">show_images([img,gray,sure_bg,sure_fg,markers,imgWatershed])</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="图像分割之基于-sobel-梯度的分水岭算法"><a class="markdownIt-Anchor" href="#图像分割之基于-sobel-梯度的分水岭算法"></a> 图像分割之基于 Sobel 梯度的分水岭算法？</h3><ul><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121424916.png" alt=""></li><li>在分水岭算法之前通常要对图像进行滤波以消除噪点，但也使弱边缘被平滑，分水岭的峰值弱化。梯度处理可以强化边缘，把梯度图像作为输入图像，可以避免弱边缘在分水岭填充过程中被淹没。可以使用 Sobel、Canny 梯度算子，也可以用形态学梯度操作获得梯度图像</li><li>基于梯度的分水岭算法通过梯度函数使得集水盆只响应想要探测的目标，对微弱边缘也有良好的响应，但图像中的噪声容易导致过分割。对此，在对梯度图像进行阈值分割转换为二值图像后，运用开运算消除噪点非常重要，可以有效地抑制梯度图像的过分割<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">img = cv2.imread(<span class="string">"../images/Fig1039a.tif"</span>, flags=<span class="number">1</span>)  <span class="comment"># 读取彩色图像(BGR)</span></span><br><span class="line">gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  <span class="comment"># 转为灰度图像</span></span><br><span class="line"><span class="comment"># 高斯模糊</span></span><br><span class="line">Gauss = cv2.GaussianBlur(gray, (<span class="number">5</span>,<span class="number">5</span>), sigmaX=<span class="number">10.0</span>)</span><br><span class="line"><span class="comment"># 计算 Sobel 梯度算子</span></span><br><span class="line">SobelX = cv2.Sobel(Gauss, cv2.CV_32F, <span class="number">1</span>, <span class="number">0</span>)  <span class="comment"># 计算 x 轴方向</span></span><br><span class="line">SobelY = cv2.Sobel(Gauss, cv2.CV_32F, <span class="number">0</span>, <span class="number">1</span>)  <span class="comment"># 计算 y 轴方向</span></span><br><span class="line">grad = np.uint8(cv2.normalize(np.sqrt(SobelX**<span class="number">2</span>+SobelY**<span class="number">2</span>), <span class="literal">None</span>, <span class="number">0</span>, <span class="number">255</span>, cv2.NORM_MINMAX))</span><br><span class="line"><span class="comment"># 阈值分割，将灰度图像分为黑白二值图像</span></span><br><span class="line">_, thresh = cv2.threshold(np.uint8(grad), <span class="number">0.2</span>*grad.<span class="built_in">max</span>(), <span class="number">255</span>, cv2.THRESH_BINARY)</span><br><span class="line"><span class="comment"># 形态学操作，生成 "确定背景" 区域</span></span><br><span class="line">kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (<span class="number">3</span>, <span class="number">3</span>))  <span class="comment"># 生成 3*3 结构元</span></span><br><span class="line">opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=<span class="number">2</span>)  <span class="comment"># 开运算，消除噪点</span></span><br><span class="line">sure_bg = cv2.dilate(opening, kernel, iterations=<span class="number">3</span>)  <span class="comment"># 膨胀操作，生成 "确定背景" 区域</span></span><br><span class="line"><span class="comment"># 距离变换，生成 "确定前景" 区域</span></span><br><span class="line">distance = cv2.distanceTransform(opening, cv2.DIST_L2, <span class="number">5</span>)  <span class="comment"># DIST_L2: 3/5</span></span><br><span class="line">_, sure_fg = cv2.threshold(distance, <span class="number">0.1</span> * distance.<span class="built_in">max</span>(), <span class="number">255</span>, <span class="number">0</span>)  <span class="comment"># 阈值选择 0.1*max 效果较好</span></span><br><span class="line">sure_fg = np.uint8(sure_fg)</span><br><span class="line"><span class="comment"># 连通域处理</span></span><br><span class="line">ret, component = cv2.connectedComponents(sure_fg, connectivity=<span class="number">8</span>)  <span class="comment"># 对连通区域进行标号，序号为 0-N-1</span></span><br><span class="line">markers = component + <span class="number">1</span>  <span class="comment"># OpenCV 分水岭算法设置标注从 1 开始，而连通域编从 0 开始</span></span><br><span class="line">kinds = markers.<span class="built_in">max</span>()  <span class="comment"># 标注连通域的数量</span></span><br><span class="line">maxKind = np.argmax(np.bincount(markers.flatten()))  <span class="comment"># 出现最多的序号，所占面积最大，选为底色</span></span><br><span class="line">markersBGR = np.ones_like(img) * <span class="number">255</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(kinds):</span><br><span class="line">	<span class="keyword">if</span> (i!=maxKind):</span><br><span class="line">		colorKind = [np.random.randint(<span class="number">0</span>, <span class="number">255</span>), np.random.randint(<span class="number">0</span>, <span class="number">255</span>), np.random.randint(<span class="number">0</span>, <span class="number">255</span>)]</span><br><span class="line">		markersBGR[markers==i] = colorKind</span><br><span class="line"><span class="comment"># 去除连通域中的背景区域部分</span></span><br><span class="line">unknown = cv2.subtract(sure_bg, sure_fg)  <span class="comment"># 待定区域，前景与背景的重合区域</span></span><br><span class="line">markers[unknown == <span class="number">255</span>] = <span class="number">0</span>  <span class="comment"># 去掉属于背景的区域 (置零)</span></span><br><span class="line"><span class="comment"># 分水岭算法标注目标的轮廓</span></span><br><span class="line">markers = cv2.watershed(img, markers)  <span class="comment"># 分水岭算法，将所有轮廓的像素点标注为 -1</span></span><br><span class="line">kinds = markers.<span class="built_in">max</span>()  <span class="comment"># 标注连通域的数量</span></span><br><span class="line"><span class="comment"># 把轮廓添加到原始图像上</span></span><br><span class="line">imgWatershed = img.copy()</span><br><span class="line">imgWatershed[markers == -<span class="number">1</span>] = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>]  <span class="comment"># 将分水岭算法标注的轮廓点设为红色</span></span><br><span class="line"><span class="built_in">print</span>(img.shape, markers.shape, markers.<span class="built_in">max</span>(), markers.<span class="built_in">min</span>(), ret)</span><br><span class="line">show_images([img,grad,sure_bg,sure_fg,markersBGR,imgWatershed])</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="图像分割之基于形态学的分水岭算法"><a class="markdownIt-Anchor" href="#图像分割之基于形态学的分水岭算法"></a> 图像分割之基于形态学的分水岭算法？</h3><ul><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121425020.png" alt=""></li><li>梯度处理可以使用 Sobel、Canny 梯度算子，也可以用形态学梯度操作获得梯度图像</li><li>基于梯度的分水岭算法对微弱的边缘有着良好的响应，但图像中的噪声容易导致图像的过分割。对此，在对梯度图像进行阈值分割转换为二值图像后，运用开运算消除噪点非常重要，可以有效地抑制梯度图像的过分割<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">img = cv2.imread(<span class="string">"../images/Fig1039a.tif"</span>, flags=<span class="number">1</span>)  <span class="comment"># 读取彩色图像(BGR)</span></span><br><span class="line">gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  <span class="comment"># 转为灰度图像</span></span><br><span class="line"><span class="comment"># 图像的形态学梯度</span></span><br><span class="line">kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (<span class="number">5</span>, <span class="number">5</span>))  <span class="comment"># 生成 5*5 结构元</span></span><br><span class="line">grad = cv2.morphologyEx(gray, cv2.MORPH_GRADIENT, kernel)  <span class="comment"># 形态学梯度</span></span><br><span class="line"><span class="comment"># 阈值分割，将灰度图像分为黑白二值图像</span></span><br><span class="line">_, thresh = cv2.threshold(np.uint8(grad), <span class="number">0.2</span>*grad.<span class="built_in">max</span>(), <span class="number">255</span>, cv2.THRESH_BINARY)</span><br><span class="line"><span class="comment"># 形态学操作，生成 "确定背景" 区域</span></span><br><span class="line">kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (<span class="number">3</span>, <span class="number">3</span>))  <span class="comment"># 生成 3*3 结构元</span></span><br><span class="line">opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=<span class="number">2</span>)  <span class="comment"># 开运算，消除噪点</span></span><br><span class="line">sure_bg = cv2.dilate(opening, kernel, iterations=<span class="number">3</span>)  <span class="comment"># 膨胀操作，生成 "确定背景" 区域</span></span><br><span class="line"><span class="comment"># 距离变换，生成 "确定前景" 区域</span></span><br><span class="line">distance = cv2.distanceTransform(opening, cv2.DIST_L2, <span class="number">5</span>)  <span class="comment"># DIST_L2: 3/5</span></span><br><span class="line">_, sure_fg = cv2.threshold(distance, <span class="number">0.1</span> * distance.<span class="built_in">max</span>(), <span class="number">255</span>, <span class="number">0</span>)  <span class="comment"># 阈值选择 0.1*max 效果较好</span></span><br><span class="line">sure_fg = np.uint8(sure_fg)</span><br><span class="line"><span class="comment"># 连通域处理</span></span><br><span class="line">ret, component = cv2.connectedComponents(sure_fg, connectivity=<span class="number">8</span>)  <span class="comment"># 对连通区域进行标号，序号为 0-N-1</span></span><br><span class="line">markers = component + <span class="number">1</span>  <span class="comment"># OpenCV 分水岭算法设置标注从 1 开始，而连通域编从 0 开始</span></span><br><span class="line">kinds = markers.<span class="built_in">max</span>()  <span class="comment"># 标注连通域的数量</span></span><br><span class="line">maxKind = np.argmax(np.bincount(markers.flatten()))  <span class="comment"># 出现最多的序号，所占面积最大，选为底色</span></span><br><span class="line">markersBGR = np.ones_like(img) * <span class="number">255</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(kinds):</span><br><span class="line">	<span class="keyword">if</span> (i!=maxKind):</span><br><span class="line">		colorKind = [np.random.randint(<span class="number">0</span>, <span class="number">255</span>), np.random.randint(<span class="number">0</span>, <span class="number">255</span>), np.random.randint(<span class="number">0</span>, <span class="number">255</span>)]</span><br><span class="line">		markersBGR[markers==i] = colorKind</span><br><span class="line"><span class="comment"># 去除连通域中的背景区域部分</span></span><br><span class="line">unknown = cv2.subtract(sure_bg, sure_fg)  <span class="comment"># 待定区域，前景与背景的重合区域</span></span><br><span class="line">markers[unknown == <span class="number">255</span>] = <span class="number">0</span>  <span class="comment"># 去掉属于背景的区域 (置零)</span></span><br><span class="line"><span class="comment"># 分水岭算法标注目标的轮廓</span></span><br><span class="line">markers = cv2.watershed(img, markers)  <span class="comment"># 分水岭算法，将所有轮廓的像素点标注为 -1</span></span><br><span class="line">kinds = markers.<span class="built_in">max</span>()  <span class="comment"># 标注连通域的数量</span></span><br><span class="line"><span class="comment"># 把轮廓添加到原始图像上</span></span><br><span class="line">imgWatershed = img.copy()</span><br><span class="line">imgWatershed[markers == -<span class="number">1</span>] = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>]  <span class="comment"># 将分水岭算法标注的轮廓点设为红色</span></span><br><span class="line"><span class="built_in">print</span>(img.shape, markers.shape, markers.<span class="built_in">max</span>(), markers.<span class="built_in">min</span>(), ret)</span><br><span class="line">show_images([img,grad,sure_bg,sure_fg,markersBGR,imgWatershed])</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="图像分割之基于轮廓标记的分水岭算法"><a class="markdownIt-Anchor" href="#图像分割之基于轮廓标记的分水岭算法"></a> 图像分割之基于轮廓标记的分水岭算法？</h3><ul><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121425992.png" alt=""></li><li>基于标记的分水岭算法的思想是利用先验知识来帮助分割。本例程先用梯度算子进行边缘检测，然后通过查找图像轮廓，生成标记图像来引导分割<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">img = cv2.imread(<span class="string">"../images/imgLena.tif"</span>, flags=<span class="number">1</span>)  <span class="comment"># 读取彩色图像(BGR)</span></span><br><span class="line"><span class="comment"># img = cv2.imread("../images/imgTina.png", flags=1)  # 读取彩色图像(BGR)</span></span><br><span class="line">gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  <span class="comment"># 转为灰度图像</span></span><br><span class="line"><span class="comment"># 查找和绘制图像轮廓</span></span><br><span class="line">Gauss = cv2.GaussianBlur(gray, (<span class="number">5</span>,<span class="number">5</span>), sigmaX=<span class="number">4.0</span>)</span><br><span class="line">grad = cv2.Canny(Gauss, <span class="number">50</span>, <span class="number">150</span>)  <span class="comment"># Canny 梯度算子</span></span><br><span class="line"><span class="comment"># grad = cv2.Canny(gray, 80, 150)  # Canny 梯度算子</span></span><br><span class="line">grad, contours, hierarchy = cv2.findContours(grad, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)  <span class="comment"># 查找图像轮廓</span></span><br><span class="line">markers = np.zeros(img.shape[:<span class="number">2</span>], np.int32)  <span class="comment"># 生成标识图像，所有轮廓区域标识为索引号 (index)</span></span><br><span class="line"><span class="keyword">for</span> index <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(contours)):  <span class="comment"># 用轮廓的索引号 index 标识轮廓区域</span></span><br><span class="line">	markers = cv2.drawContours(markers, contours, index, (index, index, index), <span class="number">1</span>, <span class="number">8</span>, hierarchy)</span><br><span class="line">ContoursMarkers = np.zeros(img.shape[:<span class="number">2</span>], np.uint8)</span><br><span class="line">ContoursMarkers[markers&gt;<span class="number">0</span>] = <span class="number">255</span>  <span class="comment"># 轮廓图像，将所有轮廓区域标识为白色 (255)</span></span><br><span class="line"><span class="comment"># 分水岭算法</span></span><br><span class="line">markers = cv2.watershed(img, markers)  <span class="comment"># 分水岭算法，所有轮廓的像素点被标注为 -1</span></span><br><span class="line">WatershedMarkers = cv2.convertScaleAbs(markers)</span><br><span class="line"><span class="comment"># 用随机颜色填充分割图像</span></span><br><span class="line">bgrMarkers = np.zeros_like(img)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(contours)):  <span class="comment"># 用随机颜色进行填充</span></span><br><span class="line">	colorKind = [np.random.randint(<span class="number">0</span>, <span class="number">255</span>), np.random.randint(<span class="number">0</span>, <span class="number">255</span>), np.random.randint(<span class="number">0</span>, <span class="number">255</span>)]</span><br><span class="line">	bgrMarkers[markers==i] = colorKind</span><br><span class="line">bgrFilled = cv2.addWeighted(img, <span class="number">0.67</span>, bgrMarkers, <span class="number">0.33</span>, <span class="number">0</span>)  <span class="comment"># 填充后与原始图像融合</span></span><br><span class="line">show_images([img,grad,ContoursMarkers,WatershedMarkers,bgrMarkers,bgrFilled])</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="opencv-寻找图像轮廓"><a class="markdownIt-Anchor" href="#opencv-寻找图像轮廓"></a> OpenCV 寻找图像轮廓？</h3><ul><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121425694.png" alt=""></li><li>轮廓是一系列相连的像素点组成的曲线，代表了物体的基本外形。轮廓常用于形状分析和物体的检测和识别</li><li><strong>边缘检测</strong>根据灰度的突变检测边界，但检测到的边缘通常还是零散的片段，并未构成整体。从背景中分离目标，就要将边缘像素连接构成<strong>轮廓</strong>。也就是说，轮廓是连续的，边缘不一定都连续。边缘主要是作为图像的特征使用，而轮廓主要用来分析物体的形态</li><li>OpenCV 提供函数&nbsp;<strong>cv. findContours ()</strong>&nbsp;从二值图像中寻找轮廓，函数&nbsp;<strong>cv2. drawContours ()</strong>&nbsp;绘制轮廓<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">img = cv2.imread(<span class="string">"../images/pattern1.png"</span>, flags=<span class="number">1</span>)</span><br><span class="line">gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  <span class="comment"># 灰度图像</span></span><br><span class="line">_, binary = cv2.threshold(gray, <span class="number">127</span>, <span class="number">255</span>, cv2.THRESH_OTSU+cv2.THRESH_BINARY_INV)</span><br><span class="line"><span class="comment"># 寻找二值化图中的轮廓</span></span><br><span class="line">binary, contours, hierarchy = cv2.findContours(binary, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)  <span class="comment"># OpenCV3</span></span><br><span class="line"><span class="comment"># contours, hierarchy = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)  # OpenCV4~</span></span><br><span class="line"><span class="comment"># # 绘制轮廓</span></span><br><span class="line">contourPic = img.copy()  <span class="comment"># OpenCV3.2 之前的早期版本，查找轮廓函数会修改原始图像</span></span><br><span class="line">contourPic = cv2.drawContours(contourPic, contours, -<span class="number">1</span>, (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), <span class="number">2</span>)  <span class="comment"># OpenCV3</span></span><br><span class="line">show_images([img,gray,contourPic])</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="opencv-使用-findcontours-找边缘轮廓时如何解析轮廓的层级"><a class="markdownIt-Anchor" href="#opencv-使用-findcontours-找边缘轮廓时如何解析轮廓的层级"></a> OpenCV 使用 findContours 找边缘轮廓时，如何解析轮廓的层级？</h3><ul><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121425574.png" alt=""></li><li>cv: : findContours 返回轮廓层次关系是 [1, N, 4]，其中 N 是轮廓数量，4 是表示层次关系的四元组：[下一个，上一个，First_Child，父]，元组内存储的是轮廓 Contours 的序号</li><li><strong>RETR_EXTERNAL</strong>： 只寻找最高层级的轮廓<ul><li><strong>RETR_LIST</strong>： 最简单的一种寻找方式，它不建立轮廓间的子属关系，也就是所有轮廓都属于同一层级， hierarchy 中的后两个值 [First Child, Parent] 都为 - 1</li><li><strong>RETR_CCOMP</strong>： 它把所有的轮廓只分为 2 个层级，不是外层的就是里层的</li><li><strong>RETR_TREE</strong>： 完整建立轮廓的层级从属关系</li></ul></li></ul><h3 id="opencv使用findcontours找边缘轮廓时返回的点方向具有一致性吗"><a class="markdownIt-Anchor" href="#opencv使用findcontours找边缘轮廓时返回的点方向具有一致性吗"></a> OpenCV 使用 findContours 找边缘轮廓时，返回的点方向具有一致性吗？</h3><ul><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121425566.png" alt=""></li><li>cv: : findContours 返回的点具有一致的方向，但是<strong>外轮廓应逆时针方向</strong>，<strong>内轮廓顺时针方向</strong><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 模拟数据</span></span><br><span class="line">points=[<span class="number">326</span>,<span class="number">96</span>,<span class="number">255</span>,<span class="number">297</span>,<span class="number">127</span>,<span class="number">297</span>,<span class="number">225</span>,<span class="number">382</span>,<span class="number">141</span>,<span class="number">618</span>,<span class="number">325</span>,<span class="number">470</span>,<span class="number">491</span>,<span class="number">613</span>,<span class="number">421</span>,<span class="number">393</span>,<span class="number">536</span>,<span class="number">300</span>,<span class="number">391</span>,<span class="number">299</span>]</span><br><span class="line"><span class="comment"># points=[325,469,420,393,390,299,255,298,225,380]</span></span><br><span class="line">img=np.zeros((<span class="number">710</span>,<span class="number">710</span>,<span class="number">3</span>),np.uint8)</span><br><span class="line"><span class="comment"># 依次汇出点 </span></span><br><span class="line">LABEL_COLORMAP = imgviz.label_colormap(value=<span class="number">200</span>)</span><br><span class="line">imgs=[]</span><br><span class="line">points_colors=[]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,<span class="built_in">len</span>(points),<span class="number">2</span>):</span><br><span class="line">	x,y=points[i],points[i+<span class="number">1</span>]</span><br><span class="line">	getcolor=<span class="built_in">tuple</span>(LABEL_COLORMAP[(i+<span class="number">1</span>)%<span class="built_in">len</span>(LABEL_COLORMAP)].tolist())</span><br><span class="line">	cv2.circle(img,(x,y),<span class="number">10</span>,getcolor,-<span class="number">1</span>)</span><br><span class="line">	points_colors.append(getcolor)</span><br><span class="line">	imgs.append(copy.deepcopy(img))</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="opencv使用findcontours对少数像素的查找边缘时其返回值是多少"><a class="markdownIt-Anchor" href="#opencv使用findcontours对少数像素的查找边缘时其返回值是多少"></a> OpenCV 使用 findContours 对少数像素的查找边缘时，其返回值是多少？</h3><ul><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121425898.png" alt=""></li><li>对于像素本身就是边缘的来说，<strong>findContours 返回像素自身位置；否则返回边缘</strong>。图示是原图、经过边缘查找后画出的边缘</li></ul><h3 id="opencv-如何绘制轮廓"><a class="markdownIt-Anchor" href="#opencv-如何绘制轮廓"></a> OpenCV 如何绘制轮廓？</h3><ul><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121425174.png" alt=""></li><li>函数&nbsp;<strong>cv2. drawContours ()</strong>&nbsp;绘制轮廓。绘制轮廓并不是绘图显示，而是修改图像添加轮廓线<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">img = cv2.imread(<span class="string">"../images/pattern1.png"</span>, flags=<span class="number">1</span>)</span><br><span class="line">gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  <span class="comment"># 灰度图像</span></span><br><span class="line">_, binary = cv2.threshold(gray, <span class="number">127</span>, <span class="number">255</span>, cv2.THRESH_OTSU+cv2.THRESH_BINARY_INV)</span><br><span class="line"><span class="comment"># 寻找二值化图中的轮廓</span></span><br><span class="line">binary, contours, hierarchy = cv2.findContours(binary, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)  <span class="comment"># OpenCV3</span></span><br><span class="line"><span class="comment">#  绘制最内层轮廓, hierarchy[0][i][2]=-1 表示没有子轮廓，即为最内层轮廓</span></span><br><span class="line">contourEx = img.copy()  <span class="comment"># OpenCV3.2 之前的早期版本，查找轮廓函数会修改原始图像</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(contours)):  <span class="comment"># 绘制第 i 个轮廓</span></span><br><span class="line">	<span class="keyword">if</span> hierarchy[<span class="number">0</span>][i][<span class="number">2</span>]==-<span class="number">1</span>:  <span class="comment"># 最内层轮廓</span></span><br><span class="line">		x, y, w, h = cv2.boundingRect(contours[i])  <span class="comment"># 外接矩形</span></span><br><span class="line">		text = <span class="string">"{}({},{})"</span>.<span class="built_in">format</span>(i, x, y)</span><br><span class="line">		contourEx = cv2.drawContours(contourEx, contours, i, (<span class="number">205</span>, <span class="number">0</span>, <span class="number">0</span>), thickness=-<span class="number">1</span>)  <span class="comment"># 第 i 个轮廓，内部填充</span></span><br><span class="line">		contourEx = cv2.putText(contourEx, text, (x,y), cv2.FONT_HERSHEY_SIMPLEX, <span class="number">0.6</span>, (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>))</span><br><span class="line">		<span class="built_in">print</span>(<span class="string">"i="</span>, i, <span class="string">",contours[i]:"</span>, contours[i].shape, <span class="string">",hierarchy[0][i] ="</span>, hierarchy[<span class="number">0</span>][i], <span class="string">"text="</span>, text)</span><br><span class="line"><span class="comment">#  绘制全部轮廓，contourIdx=-1 绘制全部轮廓</span></span><br><span class="line">contourTree = img.copy()</span><br><span class="line">contourTree = cv2.drawContours(contourTree, contours, -<span class="number">1</span>, (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), <span class="number">2</span>)</span><br><span class="line">show_images([img,contourTree,contourTree])  </span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="opencv-如何绘制轮廓的凸包"><a class="markdownIt-Anchor" href="#opencv-如何绘制轮廓的凸包"></a> OpenCV 如何绘制轮廓的凸包？</h3><ul><li><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hull=cv2.convexHull(cnt)</span><br><span class="line">k=cv2.isContourConvex(cnt)</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="opencv-如何绘制轮廓的边界矩形"><a class="markdownIt-Anchor" href="#opencv-如何绘制轮廓的边界矩形"></a> OpenCV 如何绘制轮廓的边界矩形？</h3><ul><li><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#（x,y）为矩形左上角的坐标，（w,h）是矩形的宽和高</span></span><br><span class="line">x,y,w,h=cv2.boundingRect(cnt)</span><br><span class="line">img=cv2.rectangle(img,(x,y),(x+w,y+h),(<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>),<span class="number">2</span>)</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="opencv-如何绘制轮廓的最小外接圆"><a class="markdownIt-Anchor" href="#opencv-如何绘制轮廓的最小外接圆"></a> OpenCV 如何绘制轮廓的最小外接圆？</h3><ul><li><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(x,y),radius = cv2.minEnclosingCircle(cnt)</span><br><span class="line">center = (<span class="built_in">int</span>(x),<span class="built_in">int</span>(y))</span><br><span class="line">radius = <span class="built_in">int</span>(radius)</span><br><span class="line">img = cv2.circle(img,center,radius,(<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>),<span class="number">2</span>)</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="opencv-如何绘制轮廓的拟合椭圆"><a class="markdownIt-Anchor" href="#opencv-如何绘制轮廓的拟合椭圆"></a> OpenCV 如何绘制轮廓的拟合椭圆？</h3><ul><li><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ellipse = cv2.fitEllipse(cnt)</span><br><span class="line">img = cv2.ellipse(img,ellipse,(<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>),<span class="number">2</span>)</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="opencv-如何绘制轮廓的拟合直线"><a class="markdownIt-Anchor" href="#opencv-如何绘制轮廓的拟合直线"></a> OpenCV 如何绘制轮廓的拟合直线？</h3><ul><li><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">rows,cols = img.shape[:<span class="number">2</span>]</span><br><span class="line">[vx,vy,x,y]=cv2.fitLine(cnt,cv2.DIST_L2,<span class="number">0</span>,<span class="number">0.01</span>,<span class="number">0.01</span>)</span><br><span class="line">lefty=<span class="built_in">int</span>((x*vy/vx)+y)</span><br><span class="line">righty=<span class="built_in">int</span>(((cols-x)*vy/vx)+y)</span><br><span class="line">img = cv2.line(img,(cols-<span class="number">1</span>,righty),(<span class="number">0</span>,lefty),(<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>),<span class="number">2</span>)</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="图片轮廓有哪些特征"><a class="markdownIt-Anchor" href="#图片轮廓有哪些特征"></a> 图片轮廓有哪些特征？</h3><ul><li>轮廓是一系列的座标点，其围绕的内部可以认定是一个区域，可计算其矩特征、重心、面积、周长<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#矩</span></span><br><span class="line">M=cv2.moments(cnt)</span><br><span class="line"><span class="comment">#通过矩特征求重心</span></span><br><span class="line">M=cv2.moments(cnt)</span><br><span class="line">cx=<span class="built_in">int</span>(M[<span class="string">'m10'</span>]/M[<span class="string">'m00'</span>])</span><br><span class="line">cy=<span class="built_in">int</span>(M[<span class="string">'m01'</span>]/M[<span class="string">'m00'</span>])</span><br><span class="line"><span class="comment">#面积</span></span><br><span class="line">area=cv2.contourArea(cnt)</span><br><span class="line"><span class="comment">#周长</span></span><br><span class="line">perimeter = cv2.arcLength(cnt,<span class="literal">True</span>)</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="什么是图像矩"><a class="markdownIt-Anchor" href="#什么是图像矩"></a> 什么是图像矩？</h3><ul><li>矩是统计学和概率论的一个概念，是均值、方差概念的扩展，图像的矩是用来描述图像形状特征的，以及形状的概率分布，被广泛用于图像检索和识别、图像匹配、图像重建、图像压缩以及运动图像序列分析等领域</li><li>opencv 提供两种计算图像矩的方法，cv: : moment 计算包括几何矩 (10)、中心距 (7)、归一化几何矩 (7) 三类共计 24 个矩特征；cv: : HuMoments 计算的 7 个矩特征，这些特征具有旋转、平移和缩放不变性，可用于 cv: : matchShapes 进行形状匹配<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">img = cv2.imread(<span class="string">"../images/pattern1.png"</span>, flags=<span class="number">1</span>)</span><br><span class="line">gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  <span class="comment"># 灰度图像</span></span><br><span class="line">moments = cv2.moments(gray)  <span class="comment"># 几何矩 mpq, 中心矩 mupq 和归一化矩 nupq</span></span><br><span class="line">huM = cv2.HuMoments(moments)  <span class="comment"># 计算 Hu 不变矩</span></span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="如何定义图像的几何矩"><a class="markdownIt-Anchor" href="#如何定义图像的几何矩"></a> 如何定义图像的 “几何矩”？</h3><ul><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121425470.png" alt=""></li><li>图像几何矩的计算方式如下，其中 I (x, y) 是位置 (x, y) 处的像素</li></ul><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>m</mi><mrow><mi>j</mi><mi>i</mi></mrow></msub><mo>=</mo><munder><mo>∑</mo><mrow><mi>x</mi><mo separator="true">,</mo><mi>y</mi></mrow></munder><mi>I</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>∗</mo><msup><mi>x</mi><mi>j</mi></msup><mo>∗</mo><msup><mi>y</mi><mi>i</mi></msup></mrow><annotation encoding="application/x-tex">m_{ji}=\sum_{x,y}I(x,y)*x^j*y^i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.716668em;vertical-align:-.286108em"></span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:2.4361180000000004em;vertical-align:-1.386113em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0500050000000003em"><span style="top:-1.8999949999999999em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:.03588em">y</span></span></span></span><span style="top:-3.050005em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.386113em"><span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal" style="margin-right:.07847em">I</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal" style="margin-right:.03588em">y</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.874664em;vertical-align:0"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.874664em"><span style="top:-3.1130000000000004em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1.0691039999999998em;vertical-align:-.19444em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8746639999999999em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span></span></span></span></span></span></span></span></p><ul><li>x=0, y=0 称为零阶矩，如果是<strong>二进制图像</strong>，该矩特征表示面积，如果是灰度图，该矩特征表示灰度和</li></ul><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mover accent="true"><mi>x</mi><mo>ˉ</mo></mover><mo>=</mo><mfrac><msub><mi>m</mi><mn>10</mn></msub><msub><mi>m</mi><mn>00</mn></msub></mfrac><mo separator="true">,</mo><mover accent="true"><mi>y</mi><mo>ˉ</mo></mover><mo>=</mo><mfrac><msub><mi>m</mi><mn>01</mn></msub><msub><mi>m</mi><mn>00</mn></msub></mfrac></mrow><annotation encoding="application/x-tex">\bar{x}=\frac{m_{10}}{m_{00}},\bar{y}=\frac{m_{01}}{m_{00}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.56778em;vertical-align:0"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.56778em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">x</span></span></span><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-.22222em"><span class="mord">ˉ</span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.94356em;vertical-align:-.8360000000000001em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1075599999999999em"><span style="top:-2.3139999999999996em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0</span><span class="mord mtight">0</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">0</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.8360000000000001em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.56778em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">y</span></span></span><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-.19444em"><span class="mord">ˉ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.19444em"><span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.94356em;vertical-align:-.8360000000000001em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1075599999999999em"><span style="top:-2.3139999999999996em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0</span><span class="mord mtight">0</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.8360000000000001em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><h3 id="如何定义图像的中心距"><a class="markdownIt-Anchor" href="#如何定义图像的中心距"></a> 如何定义图像的 “中心距”？</h3><ul><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121425400.png" alt=""></li><li>中心矩与之前看到的几何矩非常相似，只是从和中减去了质心。图像中心距计算方式如</li></ul><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>m</mi><msub><mi>u</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><munder><mo>∑</mo><mi>x</mi></munder><munder><mo>∑</mo><mi>y</mi></munder><msup><mrow><mo fence="true">(</mo><mi>x</mi><mo>−</mo><mover accent="true"><mi>x</mi><mo>ˉ</mo></mover><mo fence="true">)</mo></mrow><mi>i</mi></msup><msup><mrow><mo fence="true">(</mo><mi>y</mi><mo>−</mo><mover accent="true"><mi>y</mi><mo>ˉ</mo></mover><mo fence="true">)</mo></mrow><mi>j</mi></msup><mi>I</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">mu_{ij}=\sum_x\sum_y\left(x-\bar{x}\right)^i\left(y-\bar{y}\right)^jI(x,y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.716668em;vertical-align:-.286108em"></span><span class="mord mathnormal">m</span><span class="mord"><span class="mord mathnormal">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:2.4361180000000004em;vertical-align:-1.386113em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.050005em"><span style="top:-1.8999949999999999em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span><span style="top:-3.0500049999999996em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.250005em"><span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0500050000000003em"><span style="top:-1.8999949999999999em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.03588em">y</span></span></span><span style="top:-3.050005em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.386113em"><span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner"><span class="minner"><span class="mopen delimcenter" style="top:0">(</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.56778em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">x</span></span></span><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-.22222em"><span class="mord">ˉ</span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0">)</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.964564em"><span style="top:-3.2029em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner"><span class="minner"><span class="mopen delimcenter" style="top:0">(</span><span class="mord mathnormal" style="margin-right:.03588em">y</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.56778em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">y</span></span></span><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-.19444em"><span class="mord">ˉ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.19444em"><span></span></span></span></span></span><span class="mclose delimcenter" style="top:0">)</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.964564em"><span style="top:-3.2029000000000005em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal" style="margin-right:.07847em">I</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal" style="margin-right:.03588em">y</span><span class="mclose">)</span></span></span></span></span></p><ul><li><strong>注意</strong>：中心矩是平移不变的。换句话说，无论斑点在图像中的哪个位置，如果形状相同，则力矩也将相同</li></ul><h3 id="如何定义图像的归一化中心矩"><a class="markdownIt-Anchor" href="#如何定义图像的归一化中心矩"></a> 如何定义图像的 “归一化中心矩”？</h3><ul><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121425517.png" alt=""></li><li>对中心矩进行归一化得到，已知中心矩是平移不变的，那么归一化中心矩既是平移不变的又是尺度不变</li></ul><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.24999999999999992em" columnalign="right" columnspacing=""><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>n</mi><msub><mi>u</mi><mrow><mi>j</mi><mi>i</mi></mrow></msub><mo>=</mo><mfrac><mrow><mi>m</mi><msub><mi>u</mi><mrow><mi>j</mi><mi>i</mi></mrow></msub></mrow><msup><mi>m</mi><mrow><mo stretchy="false">(</mo><mi>i</mi><mo>+</mo><mi>j</mi><mo stretchy="false">)</mo><mi mathvariant="normal">/</mi><mn>2</mn><mo>+</mo><mn>1</mn></mrow></msup></mfrac></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}n u_{j i} =\frac{mu_{ji}}{m^{(i+j)/2+1}} \end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.11156em;vertical-align:-.8057799999999999em"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.30578em"><span style="top:-3.30578em"><span class="pstrut" style="height:3.10756em"></span><span class="mord"><span class="mord mathnormal">n</span><span class="mord"><span class="mord mathnormal">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1075599999999999em"><span style="top:-2.2960000000000003em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.814em"><span style="top:-2.989em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">i</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span><span class="mclose mtight">)</span><span class="mord mtight">/</span><span class="mord mtight">2</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">m</span><span class="mord"><span class="mord mathnormal">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.704em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.8057799999999999em"><span></span></span></span></span></span></span></span></span></span></span></span></p><h3 id="如何定义图像的hu-矩"><a class="markdownIt-Anchor" href="#如何定义图像的hu-矩"></a> 如何定义图像的 “Hu 矩”？</h3><ul><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121425958.png" alt=""></li><li>图像的 “Hu 矩” 和图像中心距的计算方式一</li></ul><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>μ</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><munder><mo>∑</mo><mi>x</mi></munder><munder><mo>∑</mo><mi>y</mi></munder><msup><mrow><mo fence="true">(</mo><mi>x</mi><mo>−</mo><mover accent="true"><mi>x</mi><mo>ˉ</mo></mover><mo fence="true">)</mo></mrow><mi>i</mi></msup><msup><mrow><mo fence="true">(</mo><mi>y</mi><mo>−</mo><mover accent="true"><mi>y</mi><mo>ˉ</mo></mover><mo fence="true">)</mo></mrow><mi>j</mi></msup><mi>I</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mu_{ij}=\sum_x\sum_y\left(x-\bar{x}\right)^i\left(y-\bar{y}\right)^jI(x,y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.716668em;vertical-align:-.286108em"></span><span class="mord"><span class="mord mathnormal">μ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:2.4361180000000004em;vertical-align:-1.386113em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.050005em"><span style="top:-1.8999949999999999em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span><span style="top:-3.0500049999999996em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.250005em"><span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0500050000000003em"><span style="top:-1.8999949999999999em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.03588em">y</span></span></span><span style="top:-3.050005em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.386113em"><span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner"><span class="minner"><span class="mopen delimcenter" style="top:0">(</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.56778em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">x</span></span></span><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-.22222em"><span class="mord">ˉ</span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0">)</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.964564em"><span style="top:-3.2029em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner"><span class="minner"><span class="mopen delimcenter" style="top:0">(</span><span class="mord mathnormal" style="margin-right:.03588em">y</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.56778em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">y</span></span></span><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-.19444em"><span class="mord">ˉ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.19444em"><span></span></span></span></span></span><span class="mclose delimcenter" style="top:0">)</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.964564em"><span style="top:-3.2029000000000005em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal" style="margin-right:.07847em">I</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal" style="margin-right:.03588em">y</span><span class="mclose">)</span></span></span></span></span></p><ul><li>但是其矩特征进一步组合了图像中心距特征<img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121426991.png" alt=""></li></ul><h3 id="opencv-如何使用-hu-矩进行轮廓匹配"><a class="markdownIt-Anchor" href="#opencv-如何使用-hu-矩进行轮廓匹配"></a> OpenCV 如何使用 Hu 矩进行轮廓匹配？</h3><ul><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121425772.png" alt=""></li><li>首先得到待原图和目标的二值化结果，然后提取目标图的所有轮廓，并计算所有轮廓的 Hu 矩，与原图 Hu 矩比较，得到匹配分数，在匹配分数阈值以上的轮廓认定是匹配结果</li><li><strong>Hu 矩是计算图像特征的方法，长度为 7</strong>，matchShapes 提供以下 3 种方式计算匹配分数<img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121426057.png" alt=""><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">image = cv2.imread (<span class="string">'src. jpg'</span>, <span class="number">0</span>)</span><br><span class="line">template = cv2. imread (<span class="string">'template. jpg'</span>, <span class="number">0</span>)</span><br><span class="line">_, thresh = cv2.threshold(image, <span class="number">0</span>, <span class="number">255</span>, cv2.THRESH_BINARY + cv2.THRESH_OTSU)</span><br><span class="line">ret, thresh1 = cv2.threshold(template, <span class="number">0</span>, <span class="number">255</span>, cv2.THRESH_BINARY + cv2.THRESH_OTSU)</span><br><span class="line">contours, _ = cv2.findContours(thresh, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">contours1, _ = cv2.findContours(thresh1, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">cnt2 = contours1[<span class="number">0</span>]</span><br><span class="line"><span class="comment"># 函数 cv2.matchShape() 可以帮我们比 两个形状或 廓的相似度。如果返回值越小， 匹配越好。它是根据 Hu 矩来计算的</span></span><br><span class="line">min_pos = -<span class="number">1</span></span><br><span class="line">min_value = <span class="number">2</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(contours)):</span><br><span class="line">	value = cv2.matchShapes(cnt2,contours[i],<span class="number">1</span>,<span class="number">0.0</span>)</span><br><span class="line">	<span class="keyword">if</span> value &lt; min_value:</span><br><span class="line">		min_value = value</span><br><span class="line">		min_pos = i</span><br><span class="line"><span class="built_in">print</span>(min_pos,min_value)</span><br><span class="line"><span class="comment"># 参数3为0表示绘制本条轮廓contours[min_pos]</span></span><br><span class="line">image_match=image.copy()</span><br><span class="line">cv2.drawContours(image_match,[contours[min_pos]],<span class="number">0</span>,[<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>],<span class="number">3</span>)</span><br></pre></td></tr></tbody></table></figure></li></ul><p>参考：</p><h3 id="youcans-的-opencv-例程200篇168图像分割之区域生长_youcans_的博客-csdn博客"><a class="markdownIt-Anchor" href="#youcans-的-opencv-例程200篇168图像分割之区域生长_youcans_的博客-csdn博客"></a> <a target="_blank" rel="noopener" href="https://blog.csdn.net/youcans/article/details/124472048">【youcans 的 OpenCV 例程 200 篇】168. 图像分割之区域生长_youcans_的博客 - CSDN 博客</a></h3><ul><li><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/youcans/article/details/124496034">【youcans 的 OpenCV 例程 200 篇】169. 图像分割之区域分离_youcans_的博客 - CSDN 博客</a></p></li><li><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/youcans/article/details/124550523">【youcans 的 OpenCV 例程 200 篇】170. 图像分割之 K 均值聚类_图像 k 均值聚类_youcans_的博客 - CSDN 博客</a></p></li><li><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/youcans/article/details/124576469">【youcans 的 OpenCV 例程 200 篇】171.SLIC 超像素区域分割_opencv slic_youcans_的博客 - CSDN 博客</a></p></li><li><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/youcans/article/details/124576598">【youcans 的 OpenCV 例程 200 篇】172.SLIC 超像素区域分割算法比较_opencv 网格化_youcans_的博客 - CSDN 博客</a></p></li><li><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/youcans/article/details/124576698">【youcans 的 OpenCV 例程 200 篇】173.SEEDS 超像素区域分割_youcans_的博客 - CSDN 博客</a></p></li><li><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/youcans/article/details/124643704">【youcans 的 OpenCV 例程 200 篇】174.LSC 超像素区域分割_cv2.ximgproc.supre pixel_youcans_的博客 - CSDN 博客</a></p></li><li><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/youcans/article/details/124643780">【youcans 的 OpenCV 例程 200 篇】175. 超像素区域分割方法比较_opencv 超像素分割_youcans_的博客 - CSDN 博客</a></p></li><li><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/youcans/article/details/124695824">【youcans 的 OpenCV 例程 200 篇】176. 图像分割之均值漂移算法 Mean Shift_youcans_的博客 - CSDN 博客</a></p></li><li><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/youcans/article/details/124723416">【youcans 的 OpenCV 例程 200 篇】177. 图像分割之 GraphCuts 图割法_opencv graphcut_youcans_的博客 - CSDN 博客</a></p></li><li><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/youcans/article/details/124744467">【youcans 的 OpenCV 例程 200 篇】178. 图像分割之 GrabCut 图割法（框选前景）_cv.grabcut_youcans_的博客 - CSDN 博客</a></p></li><li><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/youcans/article/details/124744517">【youcans 的 OpenCV 例程 200 篇】179. 图像分割之 GrabCut 图割法（掩模图像）_如果使用边界图像作为掩膜，可以实现分割_youcans_的博客 - CSDN 博客</a></p></li><li><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/youcans/article/details/124766166">【youcans 的 OpenCV 例程 200 篇】180. 基于距离变换的分水岭算法_youcans_的博客 - CSDN 博客</a></p></li><li><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/youcans/article/details/124766231">【youcans 的 OpenCV 例程 200 篇】181. 基于 Sobel 梯度的分水岭算法_基于梯度的分水岭分割_youcans_的博客 - CSDN 博客</a></p></li><li><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/youcans/article/details/124813539">【youcans 的 OpenCV 例程 200 篇】182. 基于形态学梯度的分水岭算法_基于形态学重建的分水岭算法公式_youcans_的博客 - CSDN 博客</a></p></li><li><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/youcans/article/details/124813571">【youcans 的 OpenCV 例程 200 篇】183. 基于轮廓标记的分水岭算法_基于标记的分水岭算法_youcans_的博客 - CSDN 博客</a></p></li><li><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/youcans/article/details/124813769">【youcans 的 OpenCV 例程 200 篇】184. 鼠标交互标记的分水岭算法_opencv 鼠标点击 分水岭分割_youcans_的博客 - CSDN 博客</a></p></li><li><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/youcans/article/details/124970746">【youcans 的 OpenCV 例程 200 篇】192.Gabor 滤波器组的形状_gabor lambda 取得越小_youcans_的博客 - CSDN 博客</a></p></li><li><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/youcans/article/details/124970610">【youcans 的 OpenCV 例程 200 篇】193. 基于 Gabor 滤波器的特征提取_cv2.getgaborkernel 纹理提取_youcans_的博客 - CSDN 博客</a></p></li><li><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/youcans/article/details/124997075">【youcans 的 OpenCV 例程 200 篇】195. 绘制图像轮廓（cv.drawContours）_opencv drawcontours_youcans_的博客 - CSDN 博客</a></p></li><li><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/youcans/article/details/124998103">【youcans 的 OpenCV 例程 200 篇】196. 图像的矩和不变矩（cv.moments）_cv2.moments_youcans_的博客 - CSDN 博客</a></p></li><li><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/youcans/article/details/125023990">【youcans 的 OpenCV 例程 200 篇】197. 轮廓的基本特征_轮廓特征_youcans_的博客 - CSDN 博客</a></p></li><li><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/youcans/article/details/125090346">【youcans 的 OpenCV 例程 200 篇】198. 基于不变矩的形状相似性检测_形状相似度_youcans_的博客 - CSDN 博客</a></p></li><li><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/youcans/article/details/125024042">【youcans 的 OpenCV 例程 200 篇】199. 轮廓的外接边界框_minenclosingtriangle_youcans_的博客 - CSDN 博客</a></p></li><li><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/youcans/article/details/125112262">【OpenCV 例程 300 篇】200. 轮廓的基本属性_opencv 求轮廓宽度的均值_youcans_的博客 - CSDN 博客</a></p></li></ul></div><footer class="post-footer"><div class="reward-container"><div>请我一杯咖啡吧！</div><button>赞赏</button><div class="post-reward"><div><img src="/images/wechatpay.png" alt="Shaogui 微信"> <span>微信</span></div><div><img src="/images/alipay.png" alt="Shaogui 支付宝"> <span>支付宝</span></div></div></div><div class="post-copyright"><ul><li class="post-copyright-author"><strong>本文作者： </strong>Shaogui</li><li class="post-copyright-link"><strong>本文链接：</strong> <a href="https://www.shaogui.life/posts/3247875748.html" title="B09 - 图像处理 - 轮廓">https://www.shaogui.life/posts/3247875748.html</a></li><li class="post-copyright-license"><strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh-hans" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><div class="followme"><span>欢迎关注我的其它发布渠道</span><div class="social-list"><div class="social-item"><a target="_blank" class="social-link" href="https://www.zhihu.com/people/mu-zhi-zhi-tian"><span class="icon"><i class="fab fa-zhihu"></i> </span><span class="label">知乎</span></a></div><div class="social-item"><a target="_blank" class="social-link" href="/atom.xml"><span class="icon"><i class="fa fa-rss"></i> </span><span class="label">RSS</span></a></div></div></div><div class="post-tags"><a href="/tags/opencv/" rel="tag"><i class="fa fa-tag"></i> opencv</a></div><div class="post-nav"><div class="post-nav-item"><a href="/posts/1914931671.html" rel="prev" title="深度学习的池化操作"><i class="fa fa-angle-left"></i> 深度学习的池化操作</a></div><div class="post-nav-item"><a href="/posts/555294778.html" rel="next" title="深度学习的激活函数">深度学习的激活函数 <i class="fa fa-angle-right"></i></a></div></div></footer></article></div><div class="comments utterances-container"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright">&copy; 2016 – <span itemprop="copyrightYear">2025</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">Shaogui</span></div><div class="wordcount"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-chart-line"></i> </span><span>站点总字数：</span> <span title="站点总字数">1.9m</span> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-coffee"></i> </span><span>站点阅读时长 &asymp;</span> <span title="站点阅读时长">28:48</span></span></div><div class="busuanzi-count"><span class="post-meta-item" id="busuanzi_container_site_uv"><span class="post-meta-item-icon"><i class="fa fa-user"></i> </span><span class="site-uv" title="总访客量"><span id="busuanzi_value_site_uv"></span> </span></span><span class="post-meta-item" id="busuanzi_container_site_pv"><span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="site-pv" title="总访问量"><span id="busuanzi_value_site_pv"></span></span></span></div><div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动</div></div></footer><div class="toggle sidebar-toggle" role="button"><span class="toggle-line"></span> <span class="toggle-line"></span> <span class="toggle-line"></span></div><div class="sidebar-dimmer"></div><div class="reading-progress-bar"></div><a href="https://github.com/WuShaogui" class="github-corner" title="在 GitHub 上关注我" aria-label="在 GitHub 上关注我" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><noscript><div class="noscript-warning">Theme NexT works best with JavaScript enabled</div></noscript><script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/lozad.js/1.16.0/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script><script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script><script src="/js/third-party/search/local-search.js"></script><script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":{"light":"neutral","dark":"dark"},"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mermaid/11.4.0/mermaid.min.js","integrity":"sha256-G8ouPAnw4zzMbnAenHnVz6h9XpKbNdOkrqTh7AadyHs="}}</script><script src="/js/third-party/tags/mermaid.js"></script><script src="/js/third-party/pace.js"></script><script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script><script src="/js/third-party/math/mathjax.js"></script><script class="next-config" data-name="utterances" type="application/json">{"enable":true,"repo":"WuShaogui/wushaogui.github.io","issue_term":"pathname","theme":"github-light"}</script><script src="/js/third-party/comments/utterances.js"></script></body></html>