<!DOCTYPE html><html lang="zh-CN"><head><style type="text/css">.douban-card-block{display:flex;justify-content:center;align-items:center;width:100%;max-height:400px}.douban-card{display:flex;margin:30px 10px;padding:15px;border-radius:15px;position:relative;justify-content:center;align-items:center;overflow:hidden;color:#faebd7;text-decoration:none}.douban-card:hover{text-decoration:none}.douban-card-bgimg{position:absolute;width:115%;height:115%;filter:blur(15px) brightness(.6);background-size:100%;background-position:center;background-repeat:no-repeat}.douban-card-img{position:relative;height:130px;width:80px;background-size:100%;background-position:center;background-repeat:no-repeat}.douban-card-left:hover .douban-card-img{filter:blur(5px) brightness(.6);transform:perspective(800px) rotateX(180deg)}.douban-card-left .douban-card-img{transition:all .5s ease}.douban-card-left{position:relative;display:flex;flex-direction:column;align-items:center}.douban-card-left .douban-card-status{height:130px;width:80px;text-align:center;font-weight:700;position:absolute;left:0;top:30%;transform:rotateX(180deg);backface-visibility:hidden;transition:all .5s ease}.douban-card-left:hover .douban-card-status{transform:perspective(800px) rotateX(0)}.douban-card-right{position:relative;display:flex;flex-direction:column;margin-left:12px;font-size:16px;font-family:"Courier New",Courier,monospace;line-height:1.3;color:#faebd7}.douban-card-item{margin-top:4px}</style><meta charset="UTF-8"><meta name="viewport" content="width=device-width"><meta name="theme-color" content="#222" media="(prefers-color-scheme: light)"><meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 5.4.2"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png"><link rel="mask-icon" href="/images/logo.svg" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Serif+SC:300,300italic,400,400italic,700,700italic%7CRoboto+Mono:300,300italic,400,400italic,700,700italic%7CPT+Mono:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/blue/pace-theme-minimal.css"><script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script><script class="next-config" data-name="main" type="application/json">{"hostname":"www.shaogui.life","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.16.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"width":240,"onmobile":false},"copycode":{"enable":true,"style":"flat","show_result":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script><meta name="description" content="本文介绍 CNN 的基础原理，由此发展出多种概念，包括：1 x 1 卷积、分组卷积、空洞卷积、深度可分离卷积、分解卷积、反卷积、形变卷积等"><meta property="og:type" content="article"><meta property="og:title" content="卷积神经网络-CNN"><meta property="og:url" content="https://www.shaogui.life/posts/2096118350.html"><meta property="og:site_name" content="年轻人起来冲"><meta property="og:description" content="本文介绍 CNN 的基础原理，由此发展出多种概念，包括：1 x 1 卷积、分组卷积、空洞卷积、深度可分离卷积、分解卷积、反卷积、形变卷积等"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212922.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212923.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212924.gif"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212926.gif"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212926-1.gif"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212927.gif"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212927-1.gif"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212928.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212929.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212929-1.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212930.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212930-1.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212931.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212932.gif"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212932-1.gif"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212933.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212933.webp"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212934.gif"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212935.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212935-1.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212936.webp"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212936.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212937.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212937-1.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212938.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212939.gif"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212939.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212940.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212940-1.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212941.gif"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212941.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212942.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212942-1.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212943.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212944.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212942-1.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212943.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704085531.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704085410.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704085421.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704085423.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704085423-1.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704085424.gif"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704085427.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704085428.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704085428-1.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704085429.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704085430.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704085430-1.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704085431.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704085432.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704085432-1.png"><meta property="article:published_time" content="2023-10-27T12:45:42.000Z"><meta property="article:modified_time" content="2023-10-30T10:25:21.545Z"><meta property="article:author" content="Shaogui"><meta property="article:tag" content="卷积神经网络"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212922.png"><link rel="canonical" href="https://www.shaogui.life/posts/2096118350.html"><script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://www.shaogui.life/posts/2096118350.html","path":"posts/2096118350.html","title":"卷积神经网络-CNN"}</script><script class="next-config" data-name="calendar" type="application/json">""</script><title>卷积神经网络-CNN | 年轻人起来冲</title><noscript><link rel="stylesheet" href="/css/noscript.css"></noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css"><link rel="alternate" href="/atom.xml" title="年轻人起来冲" type="application/atom+xml"></head><body itemscope itemtype="http://schema.org/WebPage" class="use-motion"><div class="headband"></div><main class="main"><div class="column"><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏" role="button"><span class="toggle-line"></span> <span class="toggle-line"></span> <span class="toggle-line"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><i class="logo-line"></i><p class="site-title">年轻人起来冲</p><i class="logo-line"></i></a></div><div class="site-nav-right"><div class="toggle popup-trigger" aria-label="搜索" role="button"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"><input autocomplete="off" autocapitalize="off" maxlength="80" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close" role="button"><i class="fa fa-times-circle"></i></span></div><div class="search-result-container no-result"><div class="search-result-icon"><i class="fa fa-spinner fa-pulse fa-5x"></i></div></div></div></div></header><aside class="sidebar"><div class="sidebar-inner sidebar-nav-active sidebar-toc-active"><ul class="sidebar-nav"><li class="sidebar-nav-toc">文章目录</li><li class="sidebar-nav-overview">站点概览</li></ul><div class="sidebar-panel-container"><div class="post-toc-wrap sidebar-panel"><div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E5%8D%B7%E7%A7%AF-convolution"><span class="nav-number">1.</span> <span class="nav-text">什么是卷积 (Convolution)？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E7%89%B9%E6%80%A7"><span class="nav-number">2.</span> <span class="nav-text">卷积神经网络的特性？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%A6%82%E4%BD%95%E8%AE%A4%E8%AF%86%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E7%A8%80%E7%96%8F%E8%BF%9E%E6%8E%A5-sparse-connectivity"><span class="nav-number">3.</span> <span class="nav-text">如何认识卷积神经网络的稀疏连接 (sparse connectivity)？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%A6%82%E4%BD%95%E8%AE%A4%E8%AF%86%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E6%9D%83%E9%87%8D%E5%85%B1%E4%BA%ABshared-weights"><span class="nav-number">4.</span> <span class="nav-text">如何认识卷积神经网络的权重共享(shared weights)？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E5%8D%B7%E7%A7%AF%E8%BF%87%E6%BB%A4%E5%99%A8%E5%8D%B7%E7%A7%AF%E6%A0%B8convolutional-filter"><span class="nav-number">5.</span> <span class="nav-text">什么是卷积过滤器&#x2F;卷积核(convolutional filter)?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%AF%B9%E5%9B%BE%E7%89%87%E6%95%B0%E6%8D%AE%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E5%B1%95%E5%B9%B3%E4%BD%BF%E7%94%A8%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82%E5%8E%BB%E5%AD%A6%E4%B9%A0%E8%80%8C%E6%98%AF%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF"><span class="nav-number">6.</span> <span class="nav-text">对图片数据，为什么不展平使用全连接层去学习，而是使用卷积？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%A6%82%E4%BD%95%E4%BB%8E%E5%8D%B7%E7%A7%AF%E8%BE%93%E5%85%A5%E8%AE%A1%E7%AE%97%E8%BE%93%E5%87%BA%E5%A4%A7%E5%B0%8F"><span class="nav-number">7.</span> <span class="nav-text">如何从卷积输入计算输出大小？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%8D%95%E9%80%9A%E9%81%93%E8%BE%93%E5%85%A5%E6%97%B6%E5%A6%82%E4%BD%95%E8%AE%A1%E7%AE%97%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%BE%93%E5%87%BA%E5%80%BC"><span class="nav-number">8.</span> <span class="nav-text">单通道输入时，如何计算卷积神经网络输出值？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%A4%9A%E9%80%9A%E9%81%93%E8%BE%93%E5%85%A5%E6%97%B6%E5%A6%82%E4%BD%95%E8%AE%A1%E7%AE%97%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%BE%93%E5%87%BA%E5%80%BC"><span class="nav-number">9.</span> <span class="nav-text">多通道输入时，如何计算卷积神经网络输出值？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%9C%A8%E5%8D%B7%E7%A7%AF%E8%BF%87%E7%A8%8B%E4%B8%AD%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3%E5%A1%AB%E5%85%85padding"><span class="nav-number">10.</span> <span class="nav-text">在卷积过程中，如何理解填充(Padding)?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%9C%A8%E5%8D%B7%E7%A7%AF%E8%BF%87%E7%A8%8B%E4%B8%AD%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3%E6%AD%A5%E9%95%BFstride"><span class="nav-number">11.</span> <span class="nav-text">在卷积过程中，如何理解步长(Stride)?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%8D%B7%E7%A7%AF%E5%B1%82%E7%9A%84%E5%8F%82%E6%95%B0%E9%87%8F%E5%8F%8A%E8%AE%A1%E7%AE%97%E9%87%8Fflops"><span class="nav-number">12.</span> <span class="nav-text">卷积层的参数量及计算量(FLOPs)？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%8D%B7%E7%A7%AF%E6%A0%B8%E4%B8%80%E8%88%AC%E4%B8%BA%E5%A5%87%E6%95%B0"><span class="nav-number">13.</span> <span class="nav-text">卷积核一般为奇数？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%8D%B7%E7%A7%AF%E6%A0%B8%E6%98%AF%E4%B8%8D%E6%98%AF%E8%B6%8A%E5%A4%A7%E8%B6%8A%E5%A5%BD"><span class="nav-number">14.</span> <span class="nav-text">卷积核是不是越大越好？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%B8%8D%E5%90%8C%E5%8D%B7%E7%A7%AF%E6%A0%B8%E4%BD%9C%E7%94%A8%E5%9B%BE%E5%83%8F%E7%9A%84%E6%95%88%E6%9E%9C"><span class="nav-number">15.</span> <span class="nav-text">不同卷积核作用图像的效果?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AE%BD%E5%BA%A6"><span class="nav-number">16.</span> <span class="nav-text">什么是卷积神经网络的宽度？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E7%89%B9%E5%BE%81%E5%9B%BEfeatrue-map"><span class="nav-number">17.</span> <span class="nav-text">什么是特征图(featrue map)？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E6%84%9F%E5%8F%97%E9%87%8Ereceptive-field"><span class="nav-number">18.</span> <span class="nav-text">什么是感受野(receptive field)？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%A2%9E%E5%A4%A7%E6%84%9F%E5%8F%97%E9%87%8E%E7%9A%84%E6%96%B9%E5%BC%8F"><span class="nav-number">19.</span> <span class="nav-text">增大感受野的方式？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF1x1%E5%8D%B7%E7%A7%AF"><span class="nav-number">20.</span> <span class="nav-text">什么是1x1卷积？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#1-x-1-%E5%8D%B7%E7%A7%AF%E7%9A%84%E4%BD%9C%E7%94%A8"><span class="nav-number">21.</span> <span class="nav-text">1 x 1 卷积的作用？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E5%8F%8D%E5%8D%B7%E7%A7%AFdeconvolution"><span class="nav-number">22.</span> <span class="nav-text">什么是反卷积(deconvolution)?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E5%8F%8D%E5%8D%B7%E7%A7%AF-deconvolution"><span class="nav-number">23.</span> <span class="nav-text">如何进行反卷积 (deconvolution)?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%8F%8D%E5%8D%B7%E7%A7%AF%E7%9A%84%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E5%A4%A7%E5%B0%8F%E8%AE%A1%E7%AE%97"><span class="nav-number">24.</span> <span class="nav-text">反卷积的输入输出大小计算？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%8D%B7%E7%A7%AF%E4%B8%8E%E5%8F%8D%E5%8D%B7%E7%A7%AF%E7%9A%84%E5%85%B3%E7%B3%BB"><span class="nav-number">25.</span> <span class="nav-text">卷积与反卷积的关系？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E5%8F%8D%E5%8D%B7%E7%A7%AFdeconvolution%E7%9A%84%E6%A3%8B%E7%9B%98%E6%95%88%E5%BA%94"><span class="nav-number">26.</span> <span class="nav-text">什么是反卷积(deconvolution)的棋盘效应？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E5%8F%8D%E5%8D%B7%E7%A7%AF%E4%BC%9A%E5%87%BA%E7%8E%B0%E6%A3%8B%E7%9B%98%E6%95%88%E5%BA%94"><span class="nav-number">27.</span> <span class="nav-text">为什么反卷积会出现棋盘效应？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%A6%82%E4%BD%95%E6%8A%91%E5%88%B6%E5%8F%8D%E5%8D%B7%E7%A7%AF%E8%BD%AC%E7%BD%AE%E5%8D%B7%E7%A7%AF%E7%9A%84%E6%A3%8B%E7%9B%98%E6%95%88%E5%BA%94"><span class="nav-number">28.</span> <span class="nav-text">如何抑制反卷积(转置卷积)的棋盘效应？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E7%A9%BA%E6%B4%9E%E5%8D%B7%E7%A7%AFatrous-convolution"><span class="nav-number">29.</span> <span class="nav-text">什么是空洞卷积(Atrous convolution)？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%A9%BA%E6%B4%9E%E5%8D%B7%E7%A7%AF%E7%9A%84%E4%BD%9C%E7%94%A8"><span class="nav-number">30.</span> <span class="nav-text">空洞卷积的作用？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%A9%BA%E6%B4%9E%E5%8D%B7%E7%A7%AF%E7%9A%842%E7%A7%8D%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F"><span class="nav-number">31.</span> <span class="nav-text">空洞卷积的2种实现方式？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%A9%BA%E6%B4%9E%E5%8D%B7%E7%A7%AF%E6%9C%89%E4%BB%80%E4%B9%88%E7%BC%BA%E7%82%B9"><span class="nav-number">32.</span> <span class="nav-text">空洞卷积有什么缺点？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E5%88%86%E7%BB%84%E5%8D%B7%E7%A7%AFgroup-convolution"><span class="nav-number">33.</span> <span class="nav-text">什么是分组卷积(Group Convolution) ?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%88%86%E7%BB%84%E5%8D%B7%E7%A7%AF%E7%9A%84%E4%BD%9C%E7%94%A8"><span class="nav-number">34.</span> <span class="nav-text">分组卷积的作用？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E5%88%86%E7%BB%84%E5%8D%B7%E7%A7%AF%E6%9C%89%E7%94%A8"><span class="nav-number">35.</span> <span class="nav-text">为什么分组卷积有用？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%88%86%E7%BB%84%E5%8D%B7%E7%A7%AF%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%8F%AF%E5%88%86%E7%A6%BB%E5%8D%B7%E7%A7%AF%E7%9A%84%E5%85%B3%E7%B3%BB"><span class="nav-number">36.</span> <span class="nav-text">分组卷积与深度可分离卷积的关系？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%88%86%E7%BB%84%E5%8D%B7%E7%A7%AF%E4%B8%8E%E5%85%A8%E5%B1%80%E6%B7%B1%E5%BA%A6%E5%8D%B7%E7%A7%AFgdc%E7%9A%84%E5%85%B3%E7%B3%BB"><span class="nav-number">37.</span> <span class="nav-text">分组卷积与全局深度卷积(GDC)的关系？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%88%86%E7%BB%84%E5%8D%B7%E7%A7%AF%E7%9A%84%E5%B1%80%E9%99%90%E6%80%A7"><span class="nav-number">38.</span> <span class="nav-text">分组卷积的局限性？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E6%B7%B1%E5%BA%A6%E5%8F%AF%E5%88%86%E7%A6%BB%E5%8D%B7%E7%A7%AF"><span class="nav-number">39.</span> <span class="nav-text">什么是深度可分离卷积?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%B7%B1%E5%BA%A6%E5%8F%AF%E5%88%86%E7%A6%BB%E5%8D%B7%E7%A7%AF%E7%9A%84%E4%BD%9C%E7%94%A8"><span class="nav-number">40.</span> <span class="nav-text">深度可分离卷积的作用？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%B7%B1%E5%BA%A6%E5%88%86%E7%A6%BB%E5%8D%B7%E7%A7%AF%E4%B8%8E%E6%A0%87%E5%87%86%E5%8D%B7%E7%A7%AF%E5%8F%82%E6%95%B0%E9%87%8F-%E8%AE%A1%E7%AE%97%E9%87%8Fflops%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="nav-number">41.</span> <span class="nav-text">深度分离卷积与标准卷积参数量、计算量(FLOPs)的区别？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E7%A9%BA%E9%97%B4%E5%8F%AF%E5%88%86%E7%A6%BB%E5%8D%B7%E7%A7%AF"><span class="nav-number">42.</span> <span class="nav-text">什么是空间可分离卷积？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E5%8F%AF%E5%8F%98%E5%BD%A2%E5%8D%B7%E7%A7%AF-deformable-convolution"><span class="nav-number">43.</span> <span class="nav-text">什么是可变形卷积 (Deformable Convolution)?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%8F%AF%E5%8F%98%E5%BD%A2%E5%8D%B7%E7%A7%AF%E7%9A%84%E4%BD%9C%E7%94%A8"><span class="nav-number">44.</span> <span class="nav-text">可变形卷积的作用？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E5%BB%B6%E8%BF%9F%E5%8D%B7%E7%A7%AFlazyconv2d"><span class="nav-number">45.</span> <span class="nav-text">什么是延迟卷积（LazyConv2d）</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF3d-%E5%8D%B7%E7%A7%AF"><span class="nav-number">46.</span> <span class="nav-text">什么是3D 卷积？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E5%BA%A7%E6%A0%87%E5%8D%B7%E7%A7%AF-coordconv"><span class="nav-number">47.</span> <span class="nav-text">什么是座标卷积 (CoordConv)?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%8D%B7%E7%A7%AF%E5%B1%82%E5%92%8C%E6%B1%A0%E5%8C%96%E5%B1%82%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB"><span class="nav-number">48.</span> <span class="nav-text">卷积层和池化层有什么区别？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%AF%8F%E5%B1%82%E5%8D%B7%E7%A7%AF%E6%98%AF%E5%90%A6%E5%8F%AA%E8%83%BD%E7%94%A8%E4%B8%80%E7%A7%8D%E5%B0%BA%E5%AF%B8%E7%9A%84%E5%8D%B7%E7%A7%AF%E6%A0%B8"><span class="nav-number">49.</span> <span class="nav-text">每层卷积是否只能用一种尺寸的卷积核？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%80%8E%E6%A0%B7%E6%89%8D%E8%83%BD%E5%87%8F%E5%B0%91%E5%8D%B7%E7%A7%AF%E5%B1%82%E5%8F%82%E6%95%B0%E9%87%8F"><span class="nav-number">50.</span> <span class="nav-text">怎样才能减少卷积层参数量？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E9%87%87%E7%94%A8%E5%AE%BD%E5%8D%B7%E7%A7%AF%E7%9A%84%E5%A5%BD%E5%A4%84%E6%9C%89%E4%BB%80%E4%B9%88"><span class="nav-number">51.</span> <span class="nav-text">采用宽卷积的好处有什么？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%85%A8%E8%BF%9E%E6%8E%A5-%E5%B1%80%E9%83%A8%E8%BF%9E%E6%8E%A5-%E5%85%A8%E5%8D%B7%E7%A7%AF%E4%B8%8E%E5%B1%80%E9%83%A8%E5%8D%B7%E7%A7%AF"><span class="nav-number">52.</span> <span class="nav-text">全连接、局部连接、全卷积与局部卷积？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%B1%80%E9%83%A8%E5%8D%B7%E7%A7%AF%E7%9A%84%E5%BA%94%E7%94%A8"><span class="nav-number">53.</span> <span class="nav-text">局部卷积的应用?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%B8%BA%E6%8D%95%E8%8E%B7-featrue-map-%E4%B8%8A%E9%95%BF%E8%B7%9D%E7%A6%BB%E7%9A%84%E4%BE%9D%E8%B5%96cnn-%E6%9C%89%E5%93%AA%E4%BA%9B%E6%96%B9%E6%B3%95"><span class="nav-number">54.</span> <span class="nav-text">为捕获 featrue map 上长距离的依赖，CNN 有哪些方法？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%9C%A8-cnn-%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E4%B8%8A%E7%BB%8F%E5%B8%B8%E4%BF%AE%E6%94%B9%E5%93%AA%E4%BA%9B%E6%8C%87%E6%A0%87%E5%8E%BB%E6%8F%90%E5%8D%87%E7%BD%91%E7%BB%9C%E6%80%A7%E8%83%BD"><span class="nav-number">55.</span> <span class="nav-text">在 CNN 架构设计上，经常修改哪些指标去提升网络性能？</span></a></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" alt="Shaogui" src="/images/avatar-2023.png"><p class="site-author-name" itemprop="name">Shaogui</p><div class="site-description" itemprop="description">害怕失败是本能，勇敢面对才是本事</div></div><div class="site-state-wrap animated"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">231</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/"><span class="site-state-item-count">33</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/"><span class="site-state-item-count">90</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="sidebar-button animated"><button><i class="fa fa-comment"></i> 聊天</button></div><div class="links-of-author animated"><span class="links-of-author-item"><a href="https://github.com/WuShaogui" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;WuShaogui" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a> </span><span class="links-of-author-item"><a href="/wshglearn@163.com" title="E-Mail → wshglearn@163.com" rel="noopener me"><i class="fa fa-envelope fa-fw"></i>E-Mail</a></span></div></div></div><div class="back-to-top animated" role="button" aria-label="返回顶部"><i class="fa fa-arrow-up"></i> <span>0%</span></div></div><div class="sidebar-inner sidebar-blogroll"><div class="links-of-blogroll animated"><div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i> 链接</div><ul class="links-of-blogroll-list"><li class="links-of-blogroll-item"><a href="http://manaai.cn/" title="http:&#x2F;&#x2F;manaai.cn&#x2F;" rel="noopener" target="_blank">神力AI</a></li></ul></div></div></aside></div><div class="main-inner post posts-expand"><div class="post-block"><article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://www.shaogui.life/posts/2096118350.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar-2023.png"><meta itemprop="name" content="Shaogui"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="年轻人起来冲"><meta itemprop="description" content="害怕失败是本能，勇敢面对才是本事"></span><span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork"><meta itemprop="name" content="卷积神经网络-CNN | 年轻人起来冲"><meta itemprop="description" content=""></span><header class="post-header"><h1 class="post-title" itemprop="name headline">卷积神经网络-CNN</h1><div class="post-meta-container"><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2023-10-27 20:45:42" itemprop="dateCreated datePublished" datetime="2023-10-27T20:45:42+08:00">2023-10-27</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2023-10-30 18:25:21" itemprop="dateModified" datetime="2023-10-30T18:25:21+08:00">2023-10-30</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">2-深度学习</span></a> </span>， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/A-%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/" itemprop="url" rel="index"><span itemprop="name">A-基础知识</span></a> </span></span><span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv"><span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">阅读次数：</span> <span id="busuanzi_value_page_pv"></span> </span><span class="post-meta-break"></span> <span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>13k</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>12 分钟</span></span></div></div></header><div class="post-body" itemprop="articleBody"><p>本文介绍 CNN 的基础原理，由此发展出多种概念，包括：1 x 1 卷积、分组卷积、空洞卷积、深度可分离卷积、分解卷积、反卷积、形变卷积等</p><span id="more"></span><h1 id="什么是卷积-convolution"><a class="markdownIt-Anchor" href="#什么是卷积-convolution"></a> 什么是卷积 (Convolution)？</h1><ul><li><img src="/images/loading.gif" data-original="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212922.png" alt=""></li><li>使用卷积过滤器 (convolutional filter) 扫描<strong>图像矩阵</strong>的过程，对感受野(receptivefield) 内的元素之间作哈达玛积，然后将结果矩阵相加，得到本次的扫描值</li><li>在传统图像处理中，人们通过设定不同的算子来提取诸如边缘、水平、垂直等固定的特征。而在卷积神经网络中，仅需要随机初始化一个固定卷积核大小的滤波器，并通过诸如反向传播的技术来实现卷积核参数的自动更新即可。其中，浅层的滤波器对诸如点、线、面等底层特征比较敏感，深层的滤波器则可以用于提取更加抽象的高级语义特征，以完成从低级特征到高级特征的映射</li></ul><h1 id="卷积神经网络的特性"><a class="markdownIt-Anchor" href="#卷积神经网络的特性"></a> 卷积神经网络的特性？</h1><ul><li>稀疏连接(sparseconnectivity)：传统的神经网络层每个输出单元与每个输入单元进行密集交互；卷积网络只与当前卷积核窗口内的输入交互，因此其连接是稀疏的。在 VGG中，全连接层可以转换为卷积层，<strong>但是转换后的卷积核非常多，远大于实际使用的卷积核个数</strong><img src="/images/loading.gif" data-original="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212923.png" alt="卷积神经网络-CNN-20230704212923"></li><li>权重共享(shared weights)：在传统的神经网络中，任意输出单元与任意输入单元都有一个唯一权重描述，而 CNN 只使用卷积核大小的权重描述输入与输出的关系，因此权重被多个输入区域共享</li><li>平移不变性(translationalinvariance)：指当图像中的目标发生偏移时网络仍然能够输出同源图像一致的结果。对于图像分类任务来说，我们希望 CNNs 具备平移不变性，因为当图像中目标发生位置偏移时其输出结果应该保持一致</li><li><strong>平移等变性 (translation equivalence)</strong>：指的是当输入发生偏移时网络的输出结果也应该发生相应的偏移。这种特性比较适用于目标检测和语义分割等任务</li><li>大小不变性(sizeinvariance)：指当图像中的目标发生缩放时网络仍然能够输出同源图像一致的结果</li><li>旋转不变性(rotationalinvariance)：指当图像中的目标发生旋转时网络仍然能够输出同源图像一致的结果，旋转不变性是相对的，得看实际的目标是否是旋转对称的</li></ul><h1 id="如何认识卷积神经网络的稀疏连接-sparse-connectivity"><a class="markdownIt-Anchor" href="#如何认识卷积神经网络的稀疏连接-sparse-connectivity"></a> 如何认识卷积神经网络的稀疏连接 (sparse connectivity)？</h1><ul><li>相比较全连接层，卷积层的节点仅仅和其前一层的部分节点相连接，只用来学习局部特征</li><li><img src="/images/loading.gif" data-original="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212924.gif" alt=""></li></ul><h1 id="如何认识卷积神经网络的权重共享shared-weights"><a class="markdownIt-Anchor" href="#如何认识卷积神经网络的权重共享shared-weights"></a> 如何认识卷积神经网络的权重共享(shared weights)？</h1><ul><li><strong>权值共享就是滤波器共享</strong>，滤波器的参数是固定的，即是用相同的滤波器去扫一遍图像，提取一次特征特征，得到feature map</li><li><img src="/images/loading.gif" data-original="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212926.gif" alt=""></li></ul><h1 id="什么是卷积过滤器卷积核convolutional-filter"><a class="markdownIt-Anchor" href="#什么是卷积过滤器卷积核convolutional-filter"></a> 什么是卷积过滤器/卷积核(convolutional filter)?</h1><ul><li><img src="/images/loading.gif" data-original="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212926-1.gif" alt=""></li><li>也称卷积核，是一种矩阵，与输入矩阵相比，其形状小很多</li></ul><h1 id="对图片数据为什么不展平使用全连接层去学习而是使用卷积"><a class="markdownIt-Anchor" href="#对图片数据为什么不展平使用全连接层去学习而是使用卷积"></a> 对图片数据，为什么不展平使用全连接层去学习，而是使用卷积？</h1><ul><li><strong>输入数据的空间信息被丢失：</strong> 空间上相邻的像素点往往具有相似的RGB值，各个通道之间的数据通常密切相关，但是转化成1维向量时，这些信息被丢失</li><li><strong>模型参数过多，容易发生过拟合 (overfitting)</strong>： 每个像素点都要跟所有输出的神经元相连接。当图片尺寸变大时，输入神经元的个数会按图片尺寸的平方增大，导致模型参数过多，容易发生过拟合</li></ul><h1 id="如何从卷积输入计算输出大小"><a class="markdownIt-Anchor" href="#如何从卷积输入计算输出大小"></a> 如何从卷积输入计算输出大小？</h1><ul><li><img src="/images/loading.gif" data-original="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212927.gif" alt=""></li><li>根据输入 i、卷积核大小 k、是否填充 p、步幅长度 s 计算输出大小<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>o</mi><mo>=</mo><mrow><mo fence="true">⌊</mo><mfrac><mrow><mi>i</mi><mo>+</mo><mn>2</mn><mi>p</mi><mo>−</mo><mi>k</mi></mrow><mi>s</mi></mfrac><mo fence="true">⌋</mo></mrow><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">o=\left\lfloor\frac{i+2 p-k}{s}\right\rfloor+1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathnormal">o</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:2.40003em;vertical-align:-.95003em"></span><span class="minner"><span class="mopen delimcenter" style="top:0"><span class="delimsizing size3">⌊</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714399999999998em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">s</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord">2</span><span class="mord mathnormal">p</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord mathnormal" style="margin-right:.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0"><span class="delimsizing size3">⌋</span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">1</span></span></span></span></span></p></li></ul><h1 id="单通道输入时如何计算卷积神经网络输出值"><a class="markdownIt-Anchor" href="#单通道输入时如何计算卷积神经网络输出值"></a> 单通道输入时，如何计算卷积神经网络输出值？</h1><ul><li><img src="/images/loading.gif" data-original="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212927-1.gif" alt=""></li><li>假设有一个 5x5 的图像，使用一个 3x3 的 filter 进行卷积，想得到一个 3x3 的 Feature Map，如图所示</li></ul><h1 id="多通道输入时如何计算卷积神经网络输出值"><a class="markdownIt-Anchor" href="#多通道输入时如何计算卷积神经网络输出值"></a> 多通道输入时，如何计算卷积神经网络输出值？</h1><ul><li><img src="/images/loading.gif" data-original="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212928.png" alt=""></li><li>现有 7 x7 x3 输入，假设使用卷积 kernel_size=3x3，pad=1，output_channel=2 对右下角区域 (3 x 3)进行卷积，得到输出为 3x3x2，如果对整个输入进行卷积，将得到 6 x 6 x 2 的输出</li><li>根据输出特征的数量 n，使用 n 批卷积核，每批卷积核使用 m 个卷积核去提取特征，上图使用 2 批，每批 3 个卷积核提取特征</li></ul><h1 id="在卷积过程中如何理解填充padding"><a class="markdownIt-Anchor" href="#在卷积过程中如何理解填充padding"></a> 在卷积过程中，如何理解填充(Padding)?</h1><ul><li><img src="/images/loading.gif" data-original="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212929.png" alt=""></li><li>正常卷积过程中，输入图像的边缘像素无法参与卷积计算，为了使边缘像素也参与卷积滤波，填充技术应运而生。填充是指在边缘像素点周围填充“0”（即0填充），使得输入图像的边缘像素也可以参与卷积计算</li></ul><h1 id="在卷积过程中如何理解步长stride"><a class="markdownIt-Anchor" href="#在卷积过程中如何理解步长stride"></a> 在卷积过程中，如何理解步长(Stride)?</h1><ul><li><img src="/images/loading.gif" data-original="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212929-1.png" alt=""></li><li>在卷积操作时，通常希望输出图像分辨率与输入图像分辨率相比会逐渐减少，即图像被约减。因此，可以通过改变卷积核在输入图像中移动步长大小来跳过一些像素，进行卷积滤波</li><li>当Stride=1时，卷积核滑动跳过1个像素，这是最基本的单步滑动，也是标准的卷积模式。Stride=k表示卷积核移动跳过的步长是k，如图是步长为2的卷积过程</li></ul><h1 id="卷积层的参数量及计算量flops"><a class="markdownIt-Anchor" href="#卷积层的参数量及计算量flops"></a> 卷积层的参数量及计算量(FLOPs)？</h1><ul><li><strong>参数量</strong>：以2D 卷积为例，卷积核的参数是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>C</mi><mtext>in </mtext></msub><mo>∗</mo><msub><mi>C</mi><mtext>out </mtext></msub><mo>∗</mo><msub><mi>K</mi><mi>h</mi></msub><mo>∗</mo><msub><mi>K</mi><mi>w</mi></msub></mrow><annotation encoding="application/x-tex">C_{\text {in }} * C_{\text {out }} * K_{h} * K_{w}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.83333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31750199999999995em"><span style="top:-2.5500000000000003em;margin-left:-.07153em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">in </span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.83333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.2805559999999999em"><span style="top:-2.5500000000000003em;margin-left:-.07153em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">out </span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.83333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07153em">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.33610799999999996em"><span style="top:-2.5500000000000003em;margin-left:-.07153em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">h</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.83333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07153em">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.151392em"><span style="top:-2.5500000000000003em;margin-left:-.07153em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.02691em">w</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span>，每个输出通道有1个 bias，所以卷积的参数量为：<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mtext> Param </mtext><mtext>conv2d </mtext></msub><mo>=</mo><msub><mi>C</mi><mtext>in </mtext></msub><mo>∗</mo><msub><mi>C</mi><mtext>out </mtext></msub><mo>∗</mo><msub><mi>K</mi><mi>h</mi></msub><mo>∗</mo><msub><mi>K</mi><mi>w</mi></msub><mo>+</mo><msub><mi>C</mi><mtext>out </mtext></msub></mrow><annotation encoding="application/x-tex">\text { Param }_{\text {conv2d }}=C_{\text {in }} * C_{\text {out }} * K_{h} * K_{w}+C_{\text {out }}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.83333em;vertical-align:-.15em"></span><span class="mord"><span class="mord text"><span class="mord"> Param </span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.33610799999999996em"><span style="top:-2.5500000000000003em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">conv2d </span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.83333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31750199999999995em"><span style="top:-2.5500000000000003em;margin-left:-.07153em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">in </span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.83333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.2805559999999999em"><span style="top:-2.5500000000000003em;margin-left:-.07153em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">out </span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.83333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07153em">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.33610799999999996em"><span style="top:-2.5500000000000003em;margin-left:-.07153em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">h</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.83333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07153em">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.151392em"><span style="top:-2.5500000000000003em;margin-left:-.07153em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.02691em">w</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.83333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.2805559999999999em"><span style="top:-2.5500000000000003em;margin-left:-.07153em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">out </span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span></span></p></li><li><strong>计算量</strong>：以2D 卷积为例，计算输出 featrue map 的每个点时，所有的参数均参与（不考虑 bias，需要减1），所以卷积的 FLOPs 如下，其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>H</mi><mi>W</mi><msub><mi>C</mi><mrow><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">HWC_{out}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.83333em;vertical-align:-.15em"></span><span class="mord mathnormal" style="margin-right:.08125em">H</span><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="mord"><span class="mord mathnormal" style="margin-right:.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.2805559999999999em"><span style="top:-2.5500000000000003em;margin-left:-.07153em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 表示输出特征图有多少个元素，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mo>×</mo><msub><mi>C</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub><msup><mi>K</mi><mn>2</mn></msup><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">2\times C_{in}K^2-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.72777em;vertical-align:-.08333em"></span><span class="mord">2</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.964108em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:-.07153em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07153em">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8141079999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">1</span></span></span></span> 表示原特征图需要计算多少次得到输出特征图上的一个点，需要 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>C</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub><msup><mi>K</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">C_{in}K^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.964108em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:-.07153em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07153em">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8141079999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span> 个乘法和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>C</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub><msup><mi>K</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">C_{in}K^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.964108em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:-.07153em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07153em">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8141079999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span> 个加法：<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>F</mi><mi>L</mi><mi>O</mi><mi>P</mi><mi>s</mi><mo>=</mo><mi>B</mi><mo>×</mo><munder><mrow><mi>H</mi><mi>W</mi><msub><mi>C</mi><mrow><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub></mrow><mo stretchy="true">⏟</mo></munder><mo>×</mo><mover><mrow><mo stretchy="false">(</mo><mn>2</mn><mo>⋅</mo><msub><mi>C</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub><msup><mi>K</mi><mn>2</mn></msup><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><mo stretchy="true">⏞</mo></mover></mrow><annotation encoding="application/x-tex">FLOPs =B\times\underbrace{HWC_{out}}\times\overbrace{(2\cdot C_{in}K^2-1)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.13889em">F</span><span class="mord mathnormal">L</span><span class="mord mathnormal" style="margin-right:.02778em">O</span><span class="mord mathnormal" style="margin-right:.13889em">P</span><span class="mord mathnormal">s</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.76666em;vertical-align:-.08333em"></span><span class="mord mathnormal" style="margin-right:.05017em">B</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1.48133em;vertical-align:-.798em"></span><span class="mord munder"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.68333em"><span class="svg-align" style="top:-2.202em"><span class="pstrut" style="height:3em"></span><span class="stretchy" style="height:.548em;min-width:1.6em"><span class="brace-left" style="height:.548em"><svg width="400em" height="0.548em" viewBox="0 0 400000 548" preserveAspectRatio="xMinYMin slice"><path d="M0 6l6-6h17c12.688 0 19.313.3 20 1 4 4 7.313 8.3 10 13
 35.313 51.3 80.813 93.8 136.5 127.5 55.688 33.7 117.188 55.8 184.5 66.5.688
 0 2 .3 4 1 18.688 2.7 76 4.3 172 5h399450v120H429l-6-1c-124.688-8-235-61.7
-331-161C60.687 138.7 32.312 99.3 7 54L0 41V6z"/></svg></span><span class="brace-center" style="height:.548em"><svg width="400em" height="0.548em" viewBox="0 0 400000 548" preserveAspectRatio="xMidYMin slice"><path d="M199572 214
c100.7 8.3 195.3 44 280 108 55.3 42 101.7 93 139 153l9 14c2.7-4 5.7-8.7 9-14
 53.3-86.7 123.7-153 211-199 66.7-36 137.3-56.3 212-62h199568v120H200432c-178.3
 11.7-311.7 78.3-403 201-6 8-9.7 12-11 12-.7.7-6.7 1-18 1s-17.3-.3-18-1c-1.3 0
-5-4-11-12-44.7-59.3-101.3-106.3-170-141s-145.3-54.3-229-60H0V214z"/></svg></span><span class="brace-right" style="height:.548em"><svg width="400em" height="0.548em" viewBox="0 0 400000 548" preserveAspectRatio="xMaxYMin slice"><path d="M399994 0l6 6v35l-6 11c-56 104-135.3 181.3-238 232-57.3
 28.7-117 45-179 50H-300V214h399897c43.3-7 81-15 113-26 100.7-33 179.7-91 237
-174 2.7-5 6-9 10-13 .7-1 7.3-1 20-1h17z"/></svg></span></span></span><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.08125em">H</span><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="mord"><span class="mord mathnormal" style="margin-right:.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.2805559999999999em"><span style="top:-2.5500000000000003em;margin-left:-.07153em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.798em"><span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1.762108em;vertical-align:-.25em"></span><span class="mord mover"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.512108em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mopen">(</span><span class="mord">2</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:-.07153em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07153em">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8641079999999999em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord">1</span><span class="mclose">)</span></span></span><span class="svg-align" style="top:-3.964108em"><span class="pstrut" style="height:3em"></span><span class="stretchy" style="height:.548em;min-width:1.6em"><span class="brace-left" style="height:.548em"><svg width="400em" height="0.548em" viewBox="0 0 400000 548" preserveAspectRatio="xMinYMin slice"><path d="M6 548l-6-6v-35l6-11c56-104 135.3-181.3 238-232 57.3-28.7 117
-45 179-50h399577v120H403c-43.3 7-81 15-113 26-100.7 33-179.7 91-237 174-2.7
 5-6 9-10 13-.7 1-7.3 1-20 1H6z"/></svg></span><span class="brace-center" style="height:.548em"><svg width="400em" height="0.548em" viewBox="0 0 400000 548" preserveAspectRatio="xMidYMin slice"><path d="M200428 334
c-100.7-8.3-195.3-44-280-108-55.3-42-101.7-93-139-153l-9-14c-2.7 4-5.7 8.7-9 14
-53.3 86.7-123.7 153-211 199-66.7 36-137.3 56.3-212 62H0V214h199568c178.3-11.7
 311.7-78.3 403-201 6-8 9.7-12 11-12 .7-.7 6.7-1 18-1s17.3.3 18 1c1.3 0 5 4 11
 12 44.7 59.3 101.3 106.3 170 141s145.3 54.3 229 60h199572v120z"/></svg></span><span class="brace-right" style="height:.548em"><svg width="400em" height="0.548em" viewBox="0 0 400000 548" preserveAspectRatio="xMaxYMin slice"><path d="M400000 542l
-6 6h-17c-12.7 0-19.3-.3-20-1-4-4-7.3-8.3-10-13-35.3-51.3-80.8-93.8-136.5-127.5
s-117.2-55.8-184.5-66.5c-.7 0-2-.3-4-1-18.7-2.7-76-4.3-172-5H0V214h399571l6 1
c124.7 8 235 61.7 331 161 31.3 33.3 59.7 72.7 85 118l7 13v35z"/></svg></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.25em"><span></span></span></span></span></span></span></span></span></span></p></li></ul><h1 id="卷积核一般为奇数"><a class="markdownIt-Anchor" href="#卷积核一般为奇数"></a> 卷积核一般为奇数？</h1><ul><li>保证锚点刚好在中间，方便以 central pixel为标准进行滑动卷积，避免了位置信息发生偏移</li><li>保证在填充（Padding）时，在图像之间添加额外的零层，图像的两边仍然对称</li></ul><h1 id="卷积核是不是越大越好"><a class="markdownIt-Anchor" href="#卷积核是不是越大越好"></a> 卷积核是不是越大越好？</h1><ul><li>AlexNet中用到了一些非常大的卷积核，比如11×11、5×5卷积核，之前人们的观念是，卷积核越大，感受野越大，看到的图片信息越多，因此获得的特征越好。但是大的卷积核会导致计算量的暴增，不利于模型深度的增加，计算性能也会降低</li><li>在 VGG、Inception 网络中，利用2个3×3卷积核的组合比1个5×5卷积核的效果更佳，同时参数量（3×3×2+1=19&lt;26=5×5×1+1）被降低，因此后来3×3卷积核被广泛应用在各种模型中</li><li>总结：增加核函数的大小不一定会提高性能。这个问题在很大程度上取决于数据集</li></ul><h1 id="不同卷积核作用图像的效果"><a class="markdownIt-Anchor" href="#不同卷积核作用图像的效果"></a> 不同卷积核作用图像的效果?</h1><ul><li><img src="/images/loading.gif" data-original="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212930.png" alt=""></li></ul><h1 id="什么是卷积神经网络的宽度"><a class="markdownIt-Anchor" href="#什么是卷积神经网络的宽度"></a> 什么是卷积神经网络的宽度？</h1><ul><li>所谓宽度，卷积神经网络中的通道数，通道数越多越宽</li></ul><h1 id="什么是特征图featrue-map"><a class="markdownIt-Anchor" href="#什么是特征图featrue-map"></a> 什么是特征图(featrue map)？</h1><ul><li>任意大小、任意维度信息矩阵的统称，指在卷积神经网络中卷积滤波结果矩阵</li></ul><h1 id="什么是感受野receptive-field"><a class="markdownIt-Anchor" href="#什么是感受野receptive-field"></a> 什么是感受野(receptive field)？</h1><ul><li><img src="/images/loading.gif" data-original="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212930-1.png" alt=""></li><li>指的是<strong>卷积神经网络每一层输出的</strong>特征图(featrue map)<strong>上的像素点在原始图像上映射的区域大小</strong></li><li>上图是2个3x3卷积(stride=1)，layer2上绿色点的layer1感受野为绿色区域， layer3上黄色点的layer2感受野为黄色区域， 同时在layer1上感受野是黄色区域</li><li>第一层卷积层的输出特征图像素的感受野的大小等于滤波器的大小；深层卷积层的感受野大小和它之前所有层的滤波器大小和步长有关系</li></ul><h1 id="增大感受野的方式"><a class="markdownIt-Anchor" href="#增大感受野的方式"></a> 增大感受野的方式？</h1><ul><li>加深网络，如 VGGNet</li><li>使用空洞卷积(Atrous convolution)</li></ul><h1 id="什么是1x1卷积"><a class="markdownIt-Anchor" href="#什么是1x1卷积"></a> 什么是1x1卷积？</h1><ul><li>在一个维度为 H x W x D 的输入层上的操作方式。经过大小为 1 x 1 x D 的filters的 1 x 1 卷积，输出通道的维度为 H x W x 1 <img src="/images/loading.gif" data-original="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212931.png" alt=""></li><li>NIN是第一篇探索1x1卷积核的论文，这篇论文通过在卷积层中使用MLP替代传统线性的卷积核，使单层卷积层内具有非线性映射的能力</li><li>GoogleNetv1 使用1x1卷积核减少模型参数量。在原始版本的Inception block中，由于每一层网络采用了更多的卷积核，大大增加了模型的参数量。此时在每一个较大卷积核的卷积层前引入1x1卷积，可以通过分离通道与宽高卷积来减少模型参数量</li></ul><h1 id="1-x-1-卷积的作用"><a class="markdownIt-Anchor" href="#1-x-1-卷积的作用"></a> 1 x 1 卷积的作用？</h1><ul><li><strong>增强特征表达能力</strong>：1×1卷积本质上也是一个带参数的滤波器，在不改变特征图本身尺寸的情况下，能够增加网络深度。通过在卷积后通过非线性激活函数可以有效的增强网络的表达能力</li><li><strong>升维和降维</strong>：1×1卷积可以通过增加或减少滤波器的数量来实现升维或降维的目的。与全连接层不同，由于卷积是基于权值共享，因此能够有效的降低网络的参数量和计算量</li><li><strong>跨通道的信息交互</strong>：类似于多层感知机，1×1卷积本质上就是多个特征图之间的线性组合。因此，通过1×1卷积操作可以轻松实现跨通道的信息交互和整合</li></ul><h1 id="什么是反卷积deconvolution"><a class="markdownIt-Anchor" href="#什么是反卷积deconvolution"></a> 什么是反卷积(deconvolution)?</h1><ul><li><img src="/images/loading.gif" data-original="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212932.gif" alt=""></li><li>反卷积也被称为转置卷积，反卷积其实就是标准卷积(Convolution)的逆过程，是一种上采样技术</li><li>反卷积操作并不能还原出卷积之前的图片，只能还原出卷积之前图片的尺寸</li></ul><h1 id="如何进行反卷积-deconvolution"><a class="markdownIt-Anchor" href="#如何进行反卷积-deconvolution"></a> 如何进行反卷积 (deconvolution)?</h1><ul><li><img src="/images/loading.gif" data-original="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212932-1.gif" alt=""></li><li>通过<strong>对原始特征矩阵进行填充</strong>使其维度扩大，然后进行普通卷积的过程</li></ul><h1 id="反卷积的输入输出大小计算"><a class="markdownIt-Anchor" href="#反卷积的输入输出大小计算"></a> 反卷积的输入输出大小计算？</h1><ul><li>假设输入矩阵大小为 i，填充为 p，步幅为 s，卷积核为 i<img src="/images/loading.gif" data-original="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212933.png" alt=""></li><li><strong>第一步</strong>：对输入进行 stride 变换，<strong>stride 可理解为为在输入的相邻元素之间添加 s−1 个零元素</strong>。变换后的尺寸为<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>i</mi><mi>s</mi></msub><mo>=</mo><mi>i</mi><mo>+</mo><mo stretchy="false">(</mo><mi>s</mi><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mi>i</mi><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">i_s=i+(s-1)(i-1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.80952em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.151392em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.74285em;vertical-align:-.08333em"></span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord">1</span><span class="mclose">)</span><span class="mopen">(</span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord">1</span><span class="mclose">)</span></span></span></span></span></p></li><li><strong>第二步</strong>：对 stride 变换后的图片按照卷积形式求解输出尺寸<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>o</mi><mo>=</mo><mi>s</mi><mo stretchy="false">(</mo><mi>i</mi><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo><mo>+</mo><mn>2</mn><mi>p</mi><mo>−</mo><mi>k</mi><mo>+</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">o=s(i-1)+2p-k+2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathnormal">o</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal">s</span><span class="mopen">(</span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord">1</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.8388800000000001em;vertical-align:-.19444em"></span><span class="mord">2</span><span class="mord mathnormal">p</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.77777em;vertical-align:-.08333em"></span><span class="mord mathnormal" style="margin-right:.03148em">k</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">2</span></span></span></span></span></p></li></ul><h1 id="卷积与反卷积的关系"><a class="markdownIt-Anchor" href="#卷积与反卷积的关系"></a> 卷积与反卷积的关系？</h1><ul><li>卷积：stride=1<br><img src="/images/loading.gif" data-original="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212933.webp" alt=""></li><li>反卷积：padding=1， stride=1<br><img src="/images/loading.gif" data-original="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212934.gif" alt=""></li><li>反卷积的本质还是卷积 ，他们并不是互为逆运算的，仅仅是在形状上存在互逆的关系</li></ul><h1 id="什么是反卷积deconvolution的棋盘效应"><a class="markdownIt-Anchor" href="#什么是反卷积deconvolution的棋盘效应"></a> 什么是反卷积(deconvolution)的棋盘效应？</h1><ul><li><img src="/images/loading.gif" data-original="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212935.png" alt=""></li><li>在使用转置卷积时观察到一个棘手的现象（尤其是深色部分常出现）就是&quot;棋盘格子状伪影&quot;，被命名为棋盘效应（Checkboard artifacts）</li></ul><h1 id="为什么反卷积会出现棋盘效应"><a class="markdownIt-Anchor" href="#为什么反卷积会出现棋盘效应"></a> 为什么反卷积会出现棋盘效应？</h1><ul><li>当内核大小（输出窗口大小）不能被步幅整除时，反卷积具有<strong>不均匀的重叠</strong> <img src="/images/loading.gif" data-original="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212935-1.png" alt=""></li><li>重叠图案也以二维形式形成。两个轴上的不均匀重叠相乘在一起，形成了不同大小的典型棋盘状图案 <img src="/images/loading.gif" data-original="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212936.webp" alt=""></li><li>神经网络在创建图像时通常使用多层反卷积，从一系列较低分辨率的描述中迭代构建更大的图像。虽然这些堆叠的反卷积可以消除伪影，但它们通常会复合，在各种尺度上产生伪影 <img src="/images/loading.gif" data-original="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212936.png" alt=""></li></ul><h1 id="如何抑制反卷积转置卷积的棋盘效应"><a class="markdownIt-Anchor" href="#如何抑制反卷积转置卷积的棋盘效应"></a> 如何抑制反卷积(转置卷积)的棋盘效应？</h1><ul><li><strong>方法一： 确保使用整除步幅的内核大小，避免重叠问题。</strong> 这相当于“亚像素卷积”。然而虽然这种方法有帮助，但反卷积仍然很容易陷入创建伪影 <img src="/images/loading.gif" data-original="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212937.png" alt=""></li><li><strong>方法二：将上采样到更高分辨率从卷积中分离出来以计算特征。</strong> 例如，可以调整图像大小（使用最近邻插值或双线性插值），然后进行卷积层 <img src="/images/loading.gif" data-original="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212937-1.png" alt=""></li></ul><h1 id="什么是空洞卷积atrous-convolution"><a class="markdownIt-Anchor" href="#什么是空洞卷积atrous-convolution"></a> 什么是空洞卷积(Atrous convolution)？</h1><ul><li><img src="/images/loading.gif" data-original="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212938.png" alt="卷积神经网络-CNN-20230704212938"></li><li>也称为扩张卷积 (Dilated Convolution)，是DeepLabv1在标准卷积的基础上引入扩张率 r (Dilation) 参数，在卷积核之间插入 r-1 个 0，将 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>∗</mo><mi>k</mi></mrow><annotation encoding="application/x-tex">k*k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.03148em">k</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.03148em">k</span></span></span></span> 的卷积核扩展为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>+</mo><mo stretchy="false">(</mo><mi>k</mi><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo><mo>∗</mo><mo stretchy="false">(</mo><mi>r</mi><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">k+(k-1)*(r-1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.77777em;vertical-align:-.08333em"></span><span class="mord mathnormal" style="margin-right:.03148em">k</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:.03148em">k</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord">1</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:.02778em">r</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord">1</span><span class="mclose">)</span></span></span></span>，此时卷积核的感受野出现空洞</li><li>相同尺寸的空洞卷积拥有更大的感受视野，相同视野情况下比普通卷积更少的参数，如图同样是<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><mo>×</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">3\times3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.72777em;vertical-align:-.08333em"></span><span class="mord">3</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">3</span></span></span></span>的卷积核尺寸，空洞卷积可以提取<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>5</mn><mo>×</mo><mn>5</mn></mrow><annotation encoding="application/x-tex">5\times5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.72777em;vertical-align:-.08333em"></span><span class="mord">5</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">5</span></span></span></span>范围的区域特征 <img src="/images/loading.gif" data-original="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212939.gif" alt=""></li><li>根据卷积的输出计算公式 torch. Nn. Conv 2 d，卷积核为 3 x 3 的空洞卷积，只要其 padding=dilation，卷积层输出的大小保持不变。空洞卷积金字塔池化 (Atrous Spatial Pyramid Pooling，ASPP) 正是利用这一点进行多路的空洞卷积<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; input = torch.randn(5, 8, 56, 128)</span><br><span class="line">&gt;&gt;&gt; m = torch.nn.Conv2d(8, 33, (3, 3), padding=(4, 4), dilation=(4, 4));m(input).shape</span><br><span class="line">torch.Size([5, 33, 56, 128])</span><br><span class="line">&gt;&gt;&gt; m = torch.nn.Conv2d(8, 33, (3, 3), padding=(24, 24), dilation=(24, 24));m(input).shape</span><br><span class="line">torch.Size([5, 33, 56, 128])</span><br></pre></td></tr></table></figure></li></ul><h1 id="空洞卷积的作用"><a class="markdownIt-Anchor" href="#空洞卷积的作用"></a> 空洞卷积的作用？</h1><ul><li><strong>增大感受野</strong>：空洞卷积可以在同等卷积核参数下获得更大的感受野。对于需要较为全局的语义信息或类似于语音文本需要较长的序列信息依赖的任务中，都可以尝试应用空洞卷积</li><li><strong>表征多尺度信息</strong>：利用带有不同空洞率的卷积，还可以捕捉到多尺度的上下文语义信息。不同的空洞率代表着不同的感受野，意味着网络能够感知到不同尺寸的目标，例如 DeepLabv3 、DeepLabv3+</li></ul><h1 id="空洞卷积的2种实现方式"><a class="markdownIt-Anchor" href="#空洞卷积的2种实现方式"></a> 空洞卷积的2种实现方式？</h1><ul><li><strong>从kernel角度</strong>：相当于在标准kernel的相邻点之间添加r-1个0</li><li><strong>从原图角度</strong>：使用标准kernel，在原图每隔r-1行进行卷积采样(DeepLabv2用的这一种)</li></ul><h1 id="空洞卷积有什么缺点"><a class="markdownIt-Anchor" href="#空洞卷积有什么缺点"></a> 空洞卷积有什么缺点？</h1><ul><li><strong>不好优化</strong>：虽然引入空洞卷积可以在参数不变的情况增大感受野，但是由于空间分辨率的增大，所以在实际中常常会不好优化，速度方面是一个诟病，因此在工业上对实时性有要求的应用更多的还是类FCN结构</li><li><strong>网格效应</strong>：多次叠加r=2 的 3 x 3kernel，发现 kernel 并不连续，也就是并不是所有的 pixel 都用来计算了，因此这里将信息看做 checker-board 的方式会损失信息的连续性。这对 pixel-level dense prediction 的任务来说是致命的 <img src="/images/loading.gif" data-original="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212939.png" alt=""></li><li><strong>长空洞对小物体不友好：</strong> 采用大 dilation rate 的信息或许只对一些大物体分割有效果，而对小物体来说可能则有弊无利了，HDC 可以解决该问题<br><img src="/images/loading.gif" data-original="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212940.png" alt=""></li></ul><h1 id="什么是分组卷积group-convolution"><a class="markdownIt-Anchor" href="#什么是分组卷积group-convolution"></a> 什么是分组卷积(Group Convolution) ?</h1><ul><li><img src="/images/loading.gif" data-original="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212940-1.png" alt=""></li><li>AlexNet为了使得大卷积层能在小GPU上训练，将卷积层的filter分组到2个GPU上训练，这是最早的分组卷积，ResNeXt 则将分组卷积系统地提出，并说明分组卷积<strong>类似给模型加上正则化一样，使得模型学习更准确</strong></li><li>现有输入特征 CxHxW，N 个 KxK 卷积核，以下是标准卷积和分组卷积（G 组）的参数量比较，可以发现分组卷积的参数量是标准卷积的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mi>G</mi></mfrac></mrow><annotation encoding="application/x-tex">\frac 1 G</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.190108em;vertical-align:-.345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.845108em"><span style="top:-2.6550000000000002em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">G</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.15999999999999992em" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mi>C</mi><mn>0</mn></msub><mo>×</mo><mi>K</mi><mo>×</mo><mi>K</mi><mo>×</mo><msub><mi>C</mi><mn>1</mn></msub></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mfrac><msub><mi>C</mi><mn>0</mn></msub><mi>G</mi></mfrac><mo>×</mo><mi>K</mi><mo>×</mo><mi>K</mi><mo>×</mo><mfrac><msub><mi>C</mi><mn>1</mn></msub><mi>G</mi></mfrac><mo>×</mo><mi>G</mi></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{array}{}{C_0}\times K \times K \times C_1 \\ \frac{C_0}{G}\times K\times K\times \frac{C_1}{G} \times G \end{array}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.4484310000000002em;vertical-align:-.9742155000000003em"></span><span class="mord"><span class="mtable"><span class="arraycolsep" style="width:.5em"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.4742155em"><span style="top:-3.6342155em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.07153em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord mathnormal" style="margin-right:.07153em">K</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord mathnormal" style="margin-right:.07153em">K</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.07153em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span><span style="top:-2.3857844999999993em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8884309999999999em"><span style="top:-2.6550000000000002em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">G</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.4101em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31731428571428577em"><span style="top:-2.357em;margin-left:-.07153em;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord mathnormal" style="margin-right:.07153em">K</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord mathnormal" style="margin-right:.07153em">K</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8884309999999999em"><span style="top:-2.6550000000000002em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">G</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.4101em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31731428571428577em"><span style="top:-2.357em;margin-left:-.07153em;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord mathnormal">G</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.9742155000000003em"><span></span></span></span></span></span><span class="arraycolsep" style="width:.5em"></span></span></span></span></span></span></span></p></li></ul><h1 id="分组卷积的作用"><a class="markdownIt-Anchor" href="#分组卷积的作用"></a> 分组卷积的作用？</h1><ul><li><strong>减少参数量</strong>：分为 G 组后，分组卷积 (Group Convolution) 的参数量减少为标准卷积 (Convolution) 的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mi>G</mi></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{G}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.190108em;vertical-align:-.345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.845108em"><span style="top:-2.6550000000000002em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">G</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></li><li><strong>提高训练效率</strong>：通过将卷积运算按通道划分为多个路径，可以尽可能地利用分布式的计算资源进行并行运算，有利于大规模深度神经网络的训练</li><li><strong>提高泛化性能</strong>： 组卷积可以看成是对原始卷积操作的一种解耦，改善原始卷积操作中滤波器之间的稀疏性，在一定程度上起到正则化的作用，即由标准卷积的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo>∗</mo><mi>K</mi><mo>∗</mo><mi>K</mi></mrow><annotation encoding="application/x-tex">C*K*K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.07153em">C</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.07153em">K</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.07153em">K</span></span></span></span> 卷积核变为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mi>C</mi><mi>G</mi></mfrac><mo>∗</mo><mi>K</mi><mo>∗</mo><mi>K</mi></mrow><annotation encoding="application/x-tex">\frac{C} {G}*K*K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.217331em;vertical-align:-.345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.872331em"><span style="top:-2.6550000000000002em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">G</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.07153em">C</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.07153em">K</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.07153em">K</span></span></span></span> ，相当于其他 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>C</mi><mo>−</mo><mfrac><mi>C</mi><mi>G</mi></mfrac><mo stretchy="false">)</mo><mo>∗</mo><mi>K</mi><mo>∗</mo><mi>K</mi><mo>∗</mo><mi>N</mi></mrow><annotation encoding="application/x-tex">(C-\frac{C}{G}) *K*K*N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:.07153em">C</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1.217331em;vertical-align:-.345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.872331em"><span style="top:-2.6550000000000002em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">G</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.07153em">C</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.07153em">K</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.07153em">K</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.10903em">N</span></span></span></span> 个卷积核的参数为 0</li></ul><h1 id="为什么分组卷积有用"><a class="markdownIt-Anchor" href="#为什么分组卷积有用"></a> 为什么分组卷积有用？</h1><ul><li><img src="/images/loading.gif" data-original="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212941.gif" alt=""></li><li>其实就是对卷积过滤器进行稀疏。如图是在CIFAR10上训练的NIN模型中，相邻层filters之间的相关矩阵（越亮相关性越高），当使用1、2、4、8和16个<strong>filters组</strong>训练时，在CIFAR10上训练的NIN模型中相邻层filters之间的相关性</li><li>分组后的filters同组的filter的相似性更高，类似给filters加上强制化的“结构”约束信息，即对模型进行了正则化处理，使得模型学习更准确</li><li>正如通过分组在不同GPU训练的AlexNet那样，它的filters组似乎将学习到的filters分为两个不同的组，即黑白filter和彩色filter，第一组学习纹理信息，第二组学习颜色信息，其学习的重点不同分组不同<img src="/images/loading.gif" data-original="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212941.png" alt="卷积神经网络-CNN-20230704212941"></li></ul><h1 id="分组卷积与深度可分离卷积的关系"><a class="markdownIt-Anchor" href="#分组卷积与深度可分离卷积的关系"></a> 分组卷积与深度可分离卷积的关系？</h1><ul><li>在分组卷积(Group Convolution) 中，如果输入特征图数量、输出特征图数量、分组数量都相等，即C=N=G，此时，卷积核大小为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mi>C</mi><mi>G</mi></mfrac><mo>∗</mo><mi>K</mi><mo>∗</mo><mi>K</mi><mo>=</mo><mn>1</mn><mo>∗</mo><mi>K</mi><mo>∗</mo><mi>K</mi></mrow><annotation encoding="application/x-tex">\frac{C} {G}*K*K=1*K*K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.217331em;vertical-align:-.345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.872331em"><span style="top:-2.6550000000000002em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">G</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.07153em">C</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.07153em">K</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.07153em">K</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">1</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.07153em">K</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.07153em">K</span></span></span></span> ，这和深度可分离卷积(depthwise separable convolution) 的<strong>通道卷积</strong>一致</li><li>由此可知，分组卷机是标准卷积(Convolution)和深度可分离卷积的一个折中方案</li></ul><h1 id="分组卷积与全局深度卷积gdc的关系"><a class="markdownIt-Anchor" href="#分组卷积与全局深度卷积gdc的关系"></a> 分组卷积与全局深度卷积(GDC)的关系？</h1><ul><li>在分组卷积中，如果输入特征图数量、输出特征图数量、分组数量都相等，即 C=N=G，在进一步，如果卷积核尺寸等于输入特征图尺寸，即 K=H=W，那么输出是 Cx1x1长度为 C 的向量，此时称为 Global Depthwise Convolution (GDC)</li><li>与全局池化(Global Pooling) 不同的是，GDC 给每个位置赋予了可学习的权重（对于已对齐的图像这很有效，比如人脸，中心位置和边界位置的权重自然应该不同），而GAP每个位置的权重相同，全局取个平均</li></ul><h1 id="分组卷积的局限性"><a class="markdownIt-Anchor" href="#分组卷积的局限性"></a> 分组卷积的局限性？</h1><ul><li>分组卷积将输入层的不同特征图进行分组，然后采用不同的卷积核再对各个组进行卷积，这样会降低卷积的计算量。因为一般的卷积都是在所有的输入特征图上做卷积，可以说是<strong>全通道卷积</strong>，这是一种<strong>通道密集连接方式</strong>，而分组卷积相比则是一种<strong>通道稀疏连接方式</strong></li><li><strong>1)计算量矛盾：</strong> 分组卷积在输入特征图数量、输出特征图数量、分组数量都相等的情况下，退变为深度可分离卷积(depthwise separable convolution) ，此时存在大量的1x1卷积</li><li><strong>2)特征通信矛盾：</strong> 分组后的卷积不同组之间的不会进行通信，会降低网络的特征提取能力，所以 Xception，MobileNet 通过密集的1x1卷积，保证不同组的特征的交流，为了让不同组的特征进行交流，除了使用1x1卷积，ShuffleNetv1 还提出将不同组的特征混淆来实现特征重组</li></ul><h1 id="什么是深度可分离卷积"><a class="markdownIt-Anchor" href="#什么是深度可分离卷积"></a> 什么是深度可分离卷积?</h1><ul><li>深度可分离卷积(depthwise separable convolution)分为depthwise(深度计算，逐通道卷积)和pointwise(点计算，逐点卷积)组成， 用来提取特征feature map，与标准卷积相比，其参数数量和运算成本比较低</li><li><strong>标准卷积</strong>：输入5x5x3图像，经过3x3卷积（输出通道为4） <img src="/images/loading.gif" data-original="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212942.png" alt=""></li><li><strong>深度可分离卷积：depthwise (深度计算，逐通道卷积)</strong> 输入图像，经过3x3深度可分离卷积（<strong>输出通道一定为3，因为卷积核的数量与上一层的通道数相同</strong> ） <img src="/images/loading.gif" data-original="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212942-1.png" alt=""></li><li><strong>深度可分离卷积：pointwise (点计算，逐点卷积)</strong> ，输入图像，经过 Mx1x1xN 的点卷积，M 为上一层通道，N 为输出通道 <img src="/images/loading.gif" data-original="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212943.png" alt=""></li><li><strong>depthwise(深度计算，逐通道卷积)</strong> 只在某个固定特征图上扫描，提取的是空间特征，<strong>pointwise(点计算，逐点卷积)</strong> 使用1x1卷积，此时与周围特征无关，只整合通道间的特征</li><li>可分离卷积(Seperable Convolution)通常应用在模型压缩或一些轻量的卷积神经网络中，如MobileNet、Xception等</li></ul><h1 id="深度可分离卷积的作用"><a class="markdownIt-Anchor" href="#深度可分离卷积的作用"></a> 深度可分离卷积的作用？</h1><ul><li><strong>降低参数量和计算量</strong>：深度可分离卷积将原始的卷积运算分为两层，一层用于滤波（深度卷积），一层用于组合（逐点卷积）。这种分解过程能极大减少模型的参数量和计算量</li><li><strong>降低模型容量</strong>：深度可分离卷积在应用时并没有使用激活函数。此外，虽然深度可分离卷积可以显著的降低模型的计算量，但同时也会导致模型的容量显著降低，从而导致模型精度的下降</li></ul><h1 id="深度分离卷积与标准卷积参数量-计算量flops的区别"><a class="markdownIt-Anchor" href="#深度分离卷积与标准卷积参数量-计算量flops的区别"></a> 深度分离卷积与标准卷积参数量、计算量(FLOPs)的区别？</h1><ul><li>标准卷积的计算原理 <img src="/images/loading.gif" data-original="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212944.png" alt=""></li><li>深度可分离卷积(depthwise separable convolution) 将空间卷积和时间卷积(通道卷积)分离，先进行时间卷积(通道卷积)，再进行空间卷积 <img src="/images/loading.gif" data-original="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212942-1.png" alt=""> <img src="/images/loading.gif" data-original="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704212943.png" alt=""></li><li><strong>参数量比较</strong>：所谓参数量，指的是卷积核的大小，标准卷积和深度可分离卷积的参数量计算如下，较少的参数意味较少的乘法，也就意味着卷积实现过程通用矩阵乘法(General Matrix Multiply Functions,GEMM)实现 执行更快$$\left{\begin{array}{l} D_{kernel} \times D_{kernel}\times M \times N\ D_{kernel} \times D_{kernel}\times M + 1\times 1 \times M \times N \end{array}\right.$$</li><li><strong>计算量比较：</strong> 参数量乘上特征图尺寸为计算量大小，标准卷积和深度可分离卷积的计算量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo fence="true">{</mo><mtable rowspacing="0.15999999999999992em" columnalign="left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mi>D</mi><mrow><mi>k</mi><mi>e</mi><mi>r</mi><mi>n</mi><mi>e</mi><mi>l</mi></mrow></msub><mo>×</mo><msub><mi>D</mi><mrow><mi>k</mi><mi>e</mi><mi>r</mi><mi>n</mi><mi>e</mi><mi>l</mi></mrow></msub><mo>×</mo><mi>M</mi><mo>×</mo><mi>N</mi><mo>×</mo><msub><mi>D</mi><mrow><mi>f</mi><mi>e</mi><mi>a</mi><mi>t</mi><mi>r</mi><mi>u</mi><mi>e</mi></mrow></msub><mo>×</mo><msub><mi>D</mi><mrow><mi>f</mi><mi>e</mi><mi>a</mi><mi>t</mi><mi>r</mi><mi>u</mi><mi>e</mi></mrow></msub></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mi>D</mi><mrow><mi>k</mi><mi>e</mi><mi>r</mi><mi>n</mi><mi>e</mi><mi>l</mi></mrow></msub><mo>×</mo><msub><mi>D</mi><mrow><mi>k</mi><mi>e</mi><mi>r</mi><mi>n</mi><mi>e</mi><mi>l</mi></mrow></msub><mo>×</mo><mi>M</mi><mo>×</mo><msub><mi>D</mi><mrow><mi>f</mi><mi>e</mi><mi>a</mi><mi>t</mi><mi>r</mi><mi>u</mi><mi>e</mi></mrow></msub><mo>×</mo><msub><mi>D</mi><mrow><mi>f</mi><mi>e</mi><mi>a</mi><mi>t</mi><mi>r</mi><mi>u</mi><mi>e</mi></mrow></msub><mo>+</mo><mi>M</mi><mo>×</mo><mi>N</mi><mo>×</mo><msub><mi>D</mi><mrow><mi>f</mi><mi>e</mi><mi>a</mi><mi>t</mi><mi>r</mi><mi>u</mi><mi>e</mi></mrow></msub><mo>×</mo><msub><mi>D</mi><mrow><mi>f</mi><mi>e</mi><mi>a</mi><mi>t</mi><mi>r</mi><mi>u</mi><mi>e</mi></mrow></msub></mrow></mstyle></mtd></mtr></mtable></mrow><annotation encoding="application/x-tex">\left\{\begin{array}{l} D_{kernel} \times D_{kernel}\times M \times N\times D_{featrue}\times D_{featrue}\\ D_{kernel} \times D_{kernel}\times M \times D_{featrue}\times D_{featrue} + M \times N \times D_{featrue} \times D_{featrue} \end{array}\right.</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.40003em;vertical-align:-.95003em"></span><span class="minner"><span class="mopen delimcenter" style="top:0"><span class="delimsizing size3">{</span></span><span class="mord"><span class="mtable"><span class="arraycolsep" style="width:.5em"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.45em"><span style="top:-3.61em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:.02778em">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.33610799999999996em"><span style="top:-2.5500000000000003em;margin-left:-.02778em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:.02778em">r</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:.01968em">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02778em">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.33610799999999996em"><span style="top:-2.5500000000000003em;margin-left:-.02778em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:.02778em">r</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:.01968em">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord mathnormal" style="margin-right:.10903em">M</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord mathnormal" style="margin-right:.10903em">N</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02778em">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3361079999999999em"><span style="top:-2.5500000000000003em;margin-left:-.02778em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.10764em">f</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight" style="margin-right:.02778em">r</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02778em">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3361079999999999em"><span style="top:-2.5500000000000003em;margin-left:-.02778em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.10764em">f</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight" style="margin-right:.02778em">r</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span></span></span><span style="top:-2.4099999999999997em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:.02778em">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.33610799999999996em"><span style="top:-2.5500000000000003em;margin-left:-.02778em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:.02778em">r</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:.01968em">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02778em">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.33610799999999996em"><span style="top:-2.5500000000000003em;margin-left:-.02778em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:.02778em">r</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:.01968em">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord mathnormal" style="margin-right:.10903em">M</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02778em">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3361079999999999em"><span style="top:-2.5500000000000003em;margin-left:-.02778em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.10764em">f</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight" style="margin-right:.02778em">r</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02778em">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3361079999999999em"><span style="top:-2.5500000000000003em;margin-left:-.02778em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.10764em">f</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight" style="margin-right:.02778em">r</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord mathnormal" style="margin-right:.10903em">M</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord mathnormal" style="margin-right:.10903em">N</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02778em">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3361079999999999em"><span style="top:-2.5500000000000003em;margin-left:-.02778em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.10764em">f</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight" style="margin-right:.02778em">r</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02778em">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3361079999999999em"><span style="top:-2.5500000000000003em;margin-left:-.02778em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.10764em">f</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight" style="margin-right:.02778em">r</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.9500000000000004em"><span></span></span></span></span></span><span class="arraycolsep" style="width:.5em"></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></li><li>对于卷积核为3的卷积，参数量或计算量为标准卷积的1/9 <img src="/images/loading.gif" data-original="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704085531.png" alt=""></li></ul><h1 id="什么是空间可分离卷积"><a class="markdownIt-Anchor" href="#什么是空间可分离卷积"></a> 什么是空间可分离卷积？</h1><ul><li>又称分解卷积(Spatial Separable Convolutions)，在空间维度将标准卷积运算进行拆分，将标准卷积核拆分成多个小卷积核，如3x3的卷积，可分解为3x1的卷积，接上1x3卷积，在执行相同操作时，空间可分离卷积只需要6个参数而不是9个参数</li><li>单通道标准卷积<img src="/images/loading.gif" data-original="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704085410.png" alt=""></li><li>单通道的空间分离卷积<img src="/images/loading.gif" data-original="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704085421.png" alt=""></li><li>尽管空间可分离卷积节省了成本，但很少在深度学习中使用它。主要原因之一是并非所有kennels都可以分为两个较小的kennels。如果用空间可分离卷积代替所有传统的卷积，在训练过程中，我们将限制卷积核的类型，训练结果可能不是最佳的</li></ul><h1 id="什么是可变形卷积-deformable-convolution"><a class="markdownIt-Anchor" href="#什么是可变形卷积-deformable-convolution"></a> 什么是可变形卷积 (Deformable Convolution)?</h1><ul><li><img src="/images/loading.gif" data-original="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704085423.png" alt=""></li><li><strong>固定视野的窗口无法适应目标尺寸</strong>：传统 CNN 模块，卷积单元在固定位置对输入特征图进行采样，即<strong>同一 CNN 层中所有激活单元的感受野大小是相同的</strong>，这对于具有精细定位的视觉识别（语义分割）是有害的，因为不同的位置可能对应于具有不同尺度或变形的对象</li><li>可变形卷积就是卷积的位置是可变形的，在传统的N×N卷积基础上，通过在每一个卷积采样点加上了一个偏移量实现<img src="/images/loading.gif" data-original="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704085423-1.png" alt=""></li></ul><h1 id="可变形卷积的作用"><a class="markdownIt-Anchor" href="#可变形卷积的作用"></a> 可变形卷积的作用？</h1><ul><li><strong>自适应感受野</strong>：传统的卷积核由于尺寸形状固定，其激活单元的感受野也相对固定。但实际上同一个物体由于在不同位置上可能对应着不同的尺度或者变形，因此自适应感受野是进行精确定位所需要的，特别是对于密集型预测任务来说。可变形卷积基于一个平行的网络来学习偏移，让卷积核在输入特征图能够发散采样，使网络能够聚焦目标中心，从而提高对物体形变的建模能力</li><li><strong>难以部署</strong>：DCN虽然可以带来高精度，但是仍然存在一个缺陷，即当卷积核过大时，会占用非常大的内存空间，因此在落地部署方面的应用很受限制。不过对于参加竞赛而言倒不失为一种提分的trick</li></ul><h1 id="什么是延迟卷积lazyconv2d"><a class="markdownIt-Anchor" href="#什么是延迟卷积lazyconv2d"></a> 什么是延迟卷积（LazyConv2d）</h1><ul><li>延迟卷积应用于那些输入通道 (in_channel)未知的卷积，实际执行时才知道，才去对卷积参数初始化。所以定义该层不需要像 torch. nn. Conv2d 提供 in_channel 参数</li><li>LazyConv2d能够更高效地利用计算资源，因为它只会在需要时才计算</li></ul><h1 id="什么是3d-卷积"><a class="markdownIt-Anchor" href="#什么是3d-卷积"></a> 什么是3D 卷积？</h1><ul><li><img src="/images/loading.gif" data-original="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704085424.gif" alt=""></li><li>2D-卷积和3D-卷积的主要区别为filters滑动的空间维度，3D-卷积的优势在于描述3D空间中的对象关系。3D关系在某一些应用中十分重要，如3D-对象的分割以及医学图像的重构等</li></ul><h1 id="什么是座标卷积-coordconv"><a class="markdownIt-Anchor" href="#什么是座标卷积-coordconv"></a> 什么是座标卷积 (CoordConv)?</h1><ul><li><img src="/images/loading.gif" data-original="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704085427.png" alt=""></li><li>传统卷积具备平移不变性，这使得其在应对分类等任务时可以更好的学习本质特征。不过当需要感知位置信息时，传统卷积就有点力不从心了。为了使得卷积能够感知空间信息，在输入 feature map 后面增加了两个 coordinate 通道，分别表示原始输入的 x 和 y 坐标，然后再进行传统卷积，从而使得卷积过程可以感知 feature map 的空间信息</li><li>在训练神经网络时，没有直接在后向传播中使用，只是训练时输入该座标信息，使得网络可以根据不同任务需求学习平移不变性或者一定程度的平移依赖性<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">ins_feat = x <span class="comment"># 当前实例特征tensor</span></span><br><span class="line"><span class="comment"># 生成从-1到1的线性值</span></span><br><span class="line">x_range = torch.linspace(-<span class="number">1</span>, <span class="number">1</span>, ins_feat.shape[-<span class="number">1</span>], device=ins_feat.device)</span><br><span class="line">y_range = torch.linspace(-<span class="number">1</span>, <span class="number">1</span>, ins_feat.shape[-<span class="number">2</span>], device=ins_feat.device)</span><br><span class="line">y, x = torch.meshgrid(y_range, x_range) <span class="comment"># 生成二维坐标网格</span></span><br><span class="line">y = y.expand([ins_feat.shape[<span class="number">0</span>], <span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>]) <span class="comment"># 扩充到和ins_feat相同维度</span></span><br><span class="line">x = x.expand([ins_feat.shape[<span class="number">0</span>], <span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>])</span><br><span class="line">coord_feat = torch.cat([x, y], <span class="number">1</span>) <span class="comment"># 位置特征</span></span><br><span class="line">ins_feat = torch.cat([ins_feat, coord_feat], <span class="number">1</span>) <span class="comment"># concatnate一起作为下一个卷积的输入</span></span><br></pre></td></tr></table></figure></li></ul><h1 id="卷积层和池化层有什么区别"><a class="markdownIt-Anchor" href="#卷积层和池化层有什么区别"></a> 卷积层和池化层有什么区别？</h1><ul><li><img src="/images/loading.gif" data-original="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704085428.png" alt=""></li><li>卷积层核池化层在结构上具有一定的相似性，都是对感受域内的特征进行提取，并且根据步长设置获取到不同维度的输出，但是其内在操作是有本质区别的</li></ul><h1 id="每层卷积是否只能用一种尺寸的卷积核"><a class="markdownIt-Anchor" href="#每层卷积是否只能用一种尺寸的卷积核"></a> 每层卷积是否只能用一种尺寸的卷积核？</h1><ul><li><img src="/images/loading.gif" data-original="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704085428-1.png" alt=""></li><li>经典的神经网络一般都属于层叠式网络，每层仅用一个尺寸的卷积核，如VGG结构中使用了大量的3×3卷积层。事实上，同一层特征图可以分别使用多个不同尺寸的卷积核，以获得不同尺度的特征，再把这些特征结合起来，得到的特征往往比使用单一卷积核的要好</li><li>如GoogLeNet、Inception系列的网络，均是每层使用了多个卷积核结构。如图所示，输入的特征在同一层分别经过1×1、3×3和5×5三种不同尺寸的卷积核，再将分别得到的特征进行整合，得到的新特征可以看作不同感受域提取的特征组合，相比于单一卷积核会有更强的表达能力</li></ul><h1 id="怎样才能减少卷积层参数量"><a class="markdownIt-Anchor" href="#怎样才能减少卷积层参数量"></a> 怎样才能减少卷积层参数量？</h1><ul><li><strong>使用堆叠小卷积核代替大卷积核</strong>：VGG网络中2个3x3的卷积核可以代替1个5x5的卷积核</li><li><strong>使用分解卷积操作</strong>：将原本 KxKxC 的卷积操作分离为 KxKx1和1x1xC 的两部分操作</li><li><strong>添加1x1的卷积操作</strong>：与分离卷积类似，但是通道数可变，在KxKxC_1卷积前添加1x1xC_2的卷积核（满足C_2</li><li><strong>在卷积层前使用池化操作</strong>：池化可以降低卷积层的输入特征维度</li></ul><h1 id="采用宽卷积的好处有什么"><a class="markdownIt-Anchor" href="#采用宽卷积的好处有什么"></a> 采用宽卷积的好处有什么？</h1><ul><li><img src="/images/loading.gif" data-original="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704085429.png" alt=""></li><li>宽卷积对应的是窄卷积，实际上并不是卷积操作的类型，指的是卷积过程中的填充方法，对应的是’SAME’填充和’VALID’填充。</li><li><strong>SAME填充</strong>：采用零填充的方式对卷积核不满足整除条件的输入特征进行补全，以使卷积层的输出维度保持与输入特征维度一致；</li><li><strong>VALID填充</strong>：实际并不进行任何填充，在输入特征边缘位置若不足以进行卷积操作，则对边缘信息进行舍弃，因此在步长为1的情况下该填充方式的卷积层输出特征维度可能会略小于输入特征的维度</li><li>左部分为窄卷积。注意到越在边缘的位置被卷积的次数越少。宽卷积可以看作在卷积之前在边缘用0补充，常见有两种情况，一个是全补充，如图右部分，这样输出大于输入的维度</li></ul><h1 id="全连接-局部连接-全卷积与局部卷积"><a class="markdownIt-Anchor" href="#全连接-局部连接-全卷积与局部卷积"></a> 全连接、局部连接、全卷积与局部卷积？</h1><ul><li><strong>全连接：</strong> 层间神经元完全连接，每个输出神经元可以获取到所有输入神经元的信息，有利于信息汇总，常置于网络末层；连接与连接之间独立参数，大量的连接大大增加模型的参数规模 <img src="/images/loading.gif" data-original="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704085430.png" alt=""></li><li><strong>局部连接：</strong> 层间神经元只有局部范围内的连接，在这个范围内采用全连接的方式，超过这个范围的神经元则没有连接；连接与连接之间独立参数，相比于全连接减少了感受域外的连接，有效减少参数规模<img src="/images/loading.gif" data-original="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704085430-1.png" alt=""></li><li><strong>全卷积：</strong> 层间神经元只有局部范围内的连接，在这个范围内采用全连接的方式，连接所采用的参数在不同感受域之间共享，有利于提取特定模式的特征；相比于局部连接，共用感受域之间的参数可以进一步减少参数量<img src="/images/loading.gif" data-original="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704085431.png" alt=""></li><li><strong>局部卷积：</strong> 层间神经元只有局部范围内的连接，感受域内采用全连接的方式，而感受域之间间隔采用局部连接与全卷积的连接方式；相比与全卷积成倍引入额外参数，但有更强的灵活性和表达能力；相比于局部连接，可以有效控制参数量<img src="/images/loading.gif" data-original="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704085432.png" alt=""></li></ul><h1 id="局部卷积的应用"><a class="markdownIt-Anchor" href="#局部卷积的应用"></a> 局部卷积的应用?</h1><ul><li>并不是所有的卷积都会进行权重共享，在某些特定任务中，会使用不权重共享的卷积。下面通过人脸这一任务来进行讲解。在读人脸方向的一些paper时，会发现很多都会在最后加入一个Local Connected Conv，也就是不进行权重共享的卷积层<img src="/images/loading.gif" data-original="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN-20230704085432-1.png" alt=""></li><li>参数不共享原因： （1）对齐的人脸图片中，不同的区域会有不同的统计特征，因此并不存在特征的局部稳定性，所以使用相同的卷积核会导致信息的丢失； （2）不共享的卷积核并不增加 inference 时特征的计算量，仅会增加训练时的计算量。使用不共享的卷积核，由于需要训练的参数量大大增加，因此往往需要通过其他方法增加数据量</li></ul><h1 id="为捕获-featrue-map-上长距离的依赖cnn-有哪些方法"><a class="markdownIt-Anchor" href="#为捕获-featrue-map-上长距离的依赖cnn-有哪些方法"></a> 为捕获 featrue map 上长距离的依赖，CNN 有哪些方法？</h1><ul><li>CNN 设计特性导致其天然视野受限，这对复杂场景的识别带来困难，常常通过其他方法显式构建像素之间的依赖关系，避免这个问题。目前为之，一共有 3 个方法可以做到</li><li><strong>Query 依赖 (自注意力机制)</strong>：对于 HxW 大小的特征，构建 HWxHW 的自注意力矩阵，Non-local、transformer 等模型使用该方法</li><li><strong>无 Query 依赖（上下文依赖）</strong>: 在 CNN 使用全局池化生成通道注意力、使用 1 x 1 卷积生成空间注意力，然后使用网络去学习这种依赖</li><li><strong>CRF</strong>：deeplabv1、deeplabv2 使用该方法后处理模型输出，迭代构建像素之间的远程依赖</li></ul><h1 id="在-cnn-架构设计上经常修改哪些指标去提升网络性能"><a class="markdownIt-Anchor" href="#在-cnn-架构设计上经常修改哪些指标去提升网络性能"></a> 在 CNN 架构设计上，经常修改哪些指标去提升网络性能？</h1><ul><li><strong>网络的宽度 width</strong>：每层卷积的输出通道数</li><li><strong>网络的深度 depth</strong>：网络的层数</li><li><strong>网络的分辨率 resolution</strong>：输入图像的分辨率大小</li><li><strong>网络的增长率 growth</strong>：随着层数的增加，每层卷积输出通道数的增长比例</li><li><strong>网络的特征复用</strong>：如 DenseNet 可以使用更浅的网络，更少的参数，提升特征复用，达到与深度网络相当的性能</li><li><strong>高效特征融合</strong>：InceptionNet的split-transforms-merge模式，将输入分别使用不同的转换分支提取特征，然后将多个分支的结果进行合并实现特征融合</li></ul></div><footer class="post-footer"><div class="reward-container"><div>请我一杯咖啡吧！</div><button>赞赏</button><div class="post-reward"><div><img src="/images/loading.gif" data-original="/images/wechatpay.png" alt="Shaogui 微信"> <span>微信</span></div><div><img src="/images/loading.gif" data-original="/images/alipay.png" alt="Shaogui 支付宝"> <span>支付宝</span></div></div></div><div class="followme"><span>欢迎关注我的其它发布渠道</span><div class="social-list"><div class="social-item"><span class="social-link"><span class="icon"><i class="fab fa-weixin"></i> </span><span class="label">WeChat</span> </span><img class="social-item-img" src="/images/loading.gif" data-original="/images/wechat_channel.jpg"></div><div class="social-item"><a target="_blank" class="social-link" href="/atom.xml"><span class="icon"><i class="fa fa-rss"></i> </span><span class="label">RSS</span></a></div></div></div><div class="post-tags"><a href="/tags/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" rel="tag"><i class="fa fa-tag"></i> 卷积神经网络</a></div><div class="post-nav"><div class="post-nav-item"><a href="/posts/1586568861.html" rel="prev" title="统计推断之分布拟合检验"><i class="fa fa-chevron-left"></i> 统计推断之分布拟合检验</a></div><div class="post-nav-item"><a href="/posts/2123358141.html" rel="next" title="递归神经网络-RNN">递归神经网络-RNN <i class="fa fa-chevron-right"></i></a></div></div></footer></article></div><div class="comments utterances-container"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright">&copy; 2016 – <span itemprop="copyrightYear">2023</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">Shaogui</span></div><div class="wordcount"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-chart-line"></i> </span><span>站点总字数：</span> <span title="站点总字数">658k</span> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-coffee"></i> </span><span>站点阅读时长 &asymp;</span> <span title="站点阅读时长">9:58</span></span></div><div class="busuanzi-count"><span class="post-meta-item" id="busuanzi_container_site_uv"><span class="post-meta-item-icon"><i class="fa fa-user"></i> </span><span class="site-uv" title="总访客量"><span id="busuanzi_value_site_uv"></span> </span></span><span class="post-meta-item" id="busuanzi_container_site_pv"><span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="site-pv" title="总访问量"><span id="busuanzi_value_site_pv"></span></span></span></div><div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动</div></div></footer><a href="https://github.com/WuShaogui" class="github-corner" title="在 GitHub 上关注我" aria-label="在 GitHub 上关注我" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><noscript><div class="noscript-warning">Theme NexT works best with JavaScript enabled</div></noscript><script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script><script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script><script src="/js/third-party/search/local-search.js"></script><script class="next-config" data-name="chatra" type="application/json">{"enable":true,"async":true,"id":"ZcbPEF2yS5LbSrg3P"}</script><script src="/js/third-party/chat/chatra.js"></script><script async src="https://call.chatra.io/chatra.js"></script><script src="/js/third-party/pace.js"></script><script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script class="next-config" data-name="enableMath" type="application/json">false</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script><script src="/js/third-party/math/mathjax.js"></script><script class="next-config" data-name="utterances" type="application/json">{"enable":true,"repo":"WuShaogui/wushaogui.github.io","issue_term":"pathname","theme":"github-light"}</script><script src="/js/third-party/comments/utterances.js"></script><style>[bg-lazy]{background-image:none!important;background-color:#eee!important}</style><script>window.imageLazyLoadSetting={isSPA:!1,preloadRatio:1,processImages:null}</script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(e.href.match(t)||e.href.match(r))&&(e.href=a.dataset.original)})})</script><script>!function(r){r.imageLazyLoadSetting.processImages=t;var e=r.imageLazyLoadSetting.isSPA,n=r.imageLazyLoadSetting.preloadRatio||1,c=a();function a(){var t=Array.prototype.slice.call(document.querySelectorAll("img[data-original]")),e=Array.prototype.slice.call(document.querySelectorAll("[bg-lazy]"));return t.concat(e)}function t(){e&&(c=a());for(var t,o=0;o<c.length;o++)0<=(t=(t=c[o]).getBoundingClientRect()).bottom&&0<=t.left&&t.top<=(r.innerHeight*n||document.documentElement.clientHeight*n)&&function(){var t,e,n,a=c[o],i=function(){c=c.filter(function(t){return a!==t}),r.imageLazyLoadSetting.onImageLoaded&&r.imageLazyLoadSetting.onImageLoaded(a)};(t=a).hasAttribute("bg-lazy")?(t.removeAttribute("bg-lazy"),i()):(e=new Image,n=t.getAttribute("data-original"),e.onload=function(){t.src=n,t.removeAttribute("data-original"),i()},t.src!==n&&(e.src=n))}()}function i(){clearTimeout(t.tId),t.tId=setTimeout(t,500)}t(),document.addEventListener("scroll",i),r.addEventListener("resize",i),r.addEventListener("orientationchange",i)}(this)</script></body></html>