<!DOCTYPE html><html lang="zh-CN"><head><style type="text/css">.douban-card-block{display:flex;justify-content:center;align-items:center;width:100%;max-height:400px}.douban-card{display:flex;margin:30px 10px;padding:15px;border-radius:15px;position:relative;justify-content:center;align-items:center;overflow:hidden;color:#faebd7;text-decoration:none}.douban-card:hover{text-decoration:none}.douban-card-bgimg{position:absolute;width:115%;height:115%;filter:blur(15px) brightness(.6);background-size:100%;background-position:center;background-repeat:no-repeat}.douban-card-img{position:relative;height:130px;width:80px;background-size:100%;background-position:center;background-repeat:no-repeat}.douban-card-left:hover .douban-card-img{filter:blur(5px) brightness(.6);transform:perspective(800px) rotateX(180deg)}.douban-card-left .douban-card-img{transition:all .5s ease}.douban-card-left{position:relative;display:flex;flex-direction:column;align-items:center}.douban-card-left .douban-card-status{height:130px;width:80px;text-align:center;font-weight:700;position:absolute;left:0;top:30%;transform:rotateX(180deg);backface-visibility:hidden;transition:all .5s ease}.douban-card-left:hover .douban-card-status{transform:perspective(800px) rotateX(0)}.douban-card-right{position:relative;display:flex;flex-direction:column;margin-left:12px;font-size:16px;font-family:"Courier New",Courier,monospace;line-height:1.3;color:#faebd7}.douban-card-item{margin-top:4px}</style><meta charset="UTF-8"><meta name="viewport" content="width=device-width"><meta name="theme-color" content="#222" media="(prefers-color-scheme: light)"><meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 7.3.0"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png"><link rel="mask-icon" href="/images/logo.svg" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:ital,wght@0,300;0,400;0,700;1,300;1,400;1,700&family=Roboto+Mono:ital,wght@0,300;0,400;0,700;1,300;1,400;1,700&family=PT+Mono:ital,wght@0,300;0,400;0,700;1,300;1,400;1,700&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css" integrity="sha256-dABdfBfUoC8vJUBOwGVdm8L9qlMWaHTIfXt+7GnZCIo=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/blue/pace-theme-minimal.css"><script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script><script class="next-config" data-name="main" type="application/json">{"hostname":"www.shaogui.life","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.22.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":true,"style":"flat","show_result":true},"fold":{"enable":true,"height":200},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script><meta name="description" content="介绍图像的目标特征及其计算方法"><meta property="og:type" content="article"><meta property="og:title" content="C01 - 图像特征提取与检测"><meta property="og:url" content="https://www.shaogui.life/posts/346787849.html"><meta property="og:site_name" content="年轻人起来冲"><meta property="og:description" content="介绍图像的目标特征及其计算方法"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121415507.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121415383.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121415506.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121415823.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121415726.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121415090.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121415948.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121415948.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121415948.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121416592.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121416195.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121416491.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121417695.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121416811.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121416278.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121416811.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121416025.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121416003.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121416024.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121416928.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121416003.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121416191.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121417991.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121417170.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121417949.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121417736.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121417192.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121417734.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121417768.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121417696.png"><meta property="og:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121417671.png"><meta property="article:published_time" content="2022-06-02T14:51:20.000Z"><meta property="article:modified_time" content="2025-01-18T11:05:43.933Z"><meta property="article:author" content="Shaogui"><meta property="article:tag" content="opencv"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121415507.png"><link rel="canonical" href="https://www.shaogui.life/posts/346787849.html"><script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://www.shaogui.life/posts/346787849.html","path":"posts/346787849.html","title":"C01 - 图像特征提取与检测"}</script><script class="next-config" data-name="calendar" type="application/json">""</script><title>C01 - 图像特征提取与检测 | 年轻人起来冲</title><noscript><link rel="stylesheet" href="/css/noscript.css"></noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css"><link rel="alternate" href="/atom.xml" title="年轻人起来冲" type="application/atom+xml"></head><body itemscope itemtype="http://schema.org/WebPage" class="use-motion"><div class="headband"></div><main class="main"><div class="column"><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏" role="button"><span class="toggle-line"></span> <span class="toggle-line"></span> <span class="toggle-line"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><i class="logo-line"></i><p class="site-title">年轻人起来冲</p><i class="logo-line"></i></a></div><div class="site-nav-right"><div class="toggle popup-trigger" aria-label="搜索" role="button"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">77</span></a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">70</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">544</span></a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"><input autocomplete="off" autocapitalize="off" maxlength="80" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close" role="button"><i class="fa fa-times-circle"></i></span></div><div class="search-result-container"><div class="search-result-icon"><i class="fa fa-spinner fa-pulse fa-5x"></i></div></div></div></div></header><aside class="sidebar"><div class="sidebar-inner sidebar-nav-active sidebar-toc-active"><ul class="sidebar-nav"><li class="sidebar-nav-toc">文章目录</li><li class="sidebar-nav-overview">站点概览</li></ul><div class="sidebar-panel-container"><div class="post-toc-wrap sidebar-panel"><div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%BE%E5%83%8F%E4%B8%8A%E7%9A%84%E7%9B%AE%E6%A0%87%E7%89%B9%E5%BE%81"><span class="nav-number">1.</span> <span class="nav-text">图像上的目标特征？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%BE%E5%83%8F%E4%B8%8A%E7%9B%AE%E6%A0%87%E7%89%B9%E5%BE%81%E6%9C%89%E5%93%AA%E4%BA%9B"><span class="nav-number">2.</span> <span class="nav-text">图像上目标特征有哪些？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%BE%E5%83%8F%E7%9A%84%E7%89%B9%E5%BE%81%E6%A3%80%E6%B5%8B%E4%B8%8E%E5%8C%B9%E9%85%8D"><span class="nav-number">3.</span> <span class="nav-text">图像的特征检测与匹配？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%9B%AE%E6%A0%87%E7%9A%84%E8%BE%B9%E7%95%8C%E7%89%B9%E5%BE%81%E6%8F%8F%E8%BF%B0%E5%AD%90"><span class="nav-number">4.</span> <span class="nav-text">目标的 “边界特征” 描述子？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%9B%AE%E6%A0%87%E8%BD%AE%E5%BB%93%E7%9A%84%E9%97%AD%E5%90%88%E6%9B%B2%E7%BA%BF%E5%BC%97%E9%87%8C%E6%9B%BC%E9%93%BE%E7%A0%81freeman-chain-code"><span class="nav-number">5.</span> <span class="nav-text">目标轮廓的闭合曲线弗里曼链码（Freeman chain code）？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%9B%AE%E6%A0%87%E8%BD%AE%E5%BB%93%E7%9A%84%E5%A4%9A%E8%BE%B9%E5%BD%A2%E6%8B%9F%E5%90%88"><span class="nav-number">6.</span> <span class="nav-text">目标轮廓的多边形拟合？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%9B%AE%E6%A0%87%E8%BD%AE%E5%BB%93%E7%9A%84%E9%AA%A8%E6%9E%B6%E6%8F%90%E5%8F%96"><span class="nav-number">7.</span> <span class="nav-text">目标轮廓的骨架提取？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%9B%AE%E6%A0%87%E8%BD%AE%E5%BB%93%E7%9A%84%E5%82%85%E9%87%8C%E5%8F%B6%E6%8F%8F%E8%BF%B0%E5%AD%90"><span class="nav-number">8.</span> <span class="nav-text">目标轮廓的傅里叶描述子？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%9B%AE%E6%A0%87%E8%BD%AE%E5%BB%93%E7%9A%84%E7%B4%A7%E8%87%B4%E5%BA%A6"><span class="nav-number">9.</span> <span class="nav-text">目标轮廓的紧致度？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%9B%AE%E6%A0%87%E8%BD%AE%E5%BB%93%E7%9A%84%E5%9C%86%E5%BA%A6"><span class="nav-number">10.</span> <span class="nav-text">目标轮廓的圆度？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%9B%AE%E6%A0%87%E8%BD%AE%E5%BB%93%E7%9A%84%E5%81%8F%E5%BF%83%E7%8E%87"><span class="nav-number">11.</span> <span class="nav-text">目标轮廓的偏心率？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%9B%AE%E6%A0%87%E5%8C%BA%E5%9F%9F%E5%8C%BA%E5%9F%9F%E7%89%B9%E5%BE%81"><span class="nav-number">12.</span> <span class="nav-text">目标区域 “区域特征”？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%9B%AE%E6%A0%87%E5%8C%BA%E5%9F%9F%E7%9A%84%E7%BA%B9%E7%90%86%E7%89%B9%E5%BE%81"><span class="nav-number">13.</span> <span class="nav-text">目标区域的 “纹理特征”？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%9B%AE%E6%A0%87%E5%8C%BA%E5%9F%9F%E7%9A%84lbp-%E7%BA%B9%E7%90%86%E7%89%B9%E5%BE%81%E7%AE%97%E5%AD%90"><span class="nav-number">14.</span> <span class="nav-text">目标区域的 “LBP 纹理特征算子”？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%9B%AE%E6%A0%87%E5%8C%BA%E5%9F%9F%E7%9A%84extendlbp-%E7%BA%B9%E7%90%86%E7%89%B9%E5%BE%81%E7%AE%97%E5%AD%90"><span class="nav-number">15.</span> <span class="nav-text">目标区域的 “extendLBP 纹理特征算子”？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%9B%AE%E6%A0%87%E5%8C%BA%E5%9F%9F%E7%9A%84lbp-%E7%9B%B4%E6%96%B9%E5%9B%BE"><span class="nav-number">16.</span> <span class="nav-text">目标区域的 “LBP 直方图”？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%9B%AE%E6%A0%87%E5%8C%BA%E5%9F%9F%E7%9A%84%E7%81%B0%E5%BA%A6%E5%85%B1%E7%94%9F%E7%9F%A9%E9%98%B5-glcm"><span class="nav-number">17.</span> <span class="nav-text">目标区域的灰度共生矩阵 (GLCM)?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%9B%AE%E6%A0%87%E5%8C%BA%E5%9F%9F%E7%BA%B9%E7%90%86%E7%89%B9%E5%BE%81%E7%9A%84%E9%A2%91%E8%B0%B1%E6%96%B9%E6%B3%95"><span class="nav-number">18.</span> <span class="nav-text">目标区域纹理特征的频谱方法？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%9B%AE%E6%A0%87%E5%8C%BA%E5%9F%9F%E7%89%B9%E5%BE%81%E7%9A%84%E7%9F%A9%E4%B8%8D%E5%8F%98%E9%87%8F"><span class="nav-number">19.</span> <span class="nav-text">目标区域特征的矩不变量？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E8%A7%92%E7%82%B9"><span class="nav-number">20.</span> <span class="nav-text">什么是角点？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#opencv-%E7%9A%84-harris-%E8%A7%92%E7%82%B9%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95"><span class="nav-number">21.</span> <span class="nav-text">OpenCV 的 Harris 角点检测算法？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#opencv-%E7%9A%84-harris-%E8%A7%92%E7%82%B9%E6%A3%80%E6%B5%8B%E4%B9%8B%E7%B2%BE%E7%A1%AE%E5%AE%9A%E4%BD%8D"><span class="nav-number">22.</span> <span class="nav-text">OpenCV 的 Harris 角点检测之精确定位？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#opencv-%E7%9A%84-shi-tomasi-%E8%A7%92%E7%82%B9%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95"><span class="nav-number">23.</span> <span class="nav-text">OpenCV 的 Shi-Tomasi 角点检测算法？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B0%BA%E5%BA%A6%E4%B8%8D%E5%8F%98%E7%89%B9%E5%BE%81%E8%BD%AC%E6%8D%A2%E7%AE%97%E6%B3%95sift%E7%89%B9%E5%BE%81%E7%82%B9%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95"><span class="nav-number">24.</span> <span class="nav-text">尺度不变特征转换算法（SIFT）特征点检测算法？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8E-sifi-%E7%89%B9%E5%BE%81%E5%9B%BE%E5%83%8F%E5%8C%B9%E9%85%8D%E7%AE%97%E6%B3%95"><span class="nav-number">25.</span> <span class="nav-text">基于 SIFI 特征图像匹配算法？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#surf-%E7%89%B9%E5%BE%81%E7%82%B9%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95"><span class="nav-number">26.</span> <span class="nav-text">SURF 特征点检测算法？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#fast-%E7%89%B9%E5%BE%81%E7%82%B9%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95"><span class="nav-number">27.</span> <span class="nav-text">FAST 特征点检测算法？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#brief-%E7%89%B9%E5%BE%81%E7%82%B9%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95"><span class="nav-number">28.</span> <span class="nav-text">BRIEF 特征点检测算法？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#brisk-%E7%89%B9%E5%BE%81%E7%82%B9%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95"><span class="nav-number">29.</span> <span class="nav-text">BRISK 特征点检测算法？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#orb-%E7%89%B9%E5%BE%81%E7%82%B9%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95"><span class="nav-number">30.</span> <span class="nav-text">ORB 特征点检测算法？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#censure-%E7%89%B9%E5%BE%81%E7%82%B9%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95"><span class="nav-number">31.</span> <span class="nav-text">CenSurE 特征点检测算法？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%89%B9%E5%BE%81%E6%A3%80%E6%B5%8B%E4%B9%8B%E6%9C%80%E5%A4%A7%E7%A8%B3%E5%AE%9A%E6%9E%81%E5%80%BC%E5%8C%BA%E5%9F%9Fmser"><span class="nav-number">32.</span> <span class="nav-text">特征检测之最大稳定极值区域（MSER）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%89%B9%E5%BE%81%E6%8F%8F%E8%BF%B0%E4%B9%8B-hog-%E6%8F%8F%E8%BF%B0%E7%AC%A6"><span class="nav-number">33.</span> <span class="nav-text">特征描述之 HOG 描述符？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%89%B9%E5%BE%81%E6%A3%80%E6%B5%8B%E4%B9%8B%E8%A7%86%E7%BD%91%E8%86%9C%E7%AE%97%E6%B3%95freak"><span class="nav-number">34.</span> <span class="nav-text">特征检测之视网膜算法（FREAK）？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%89%B9%E5%BE%81%E5%8C%B9%E9%85%8D%E4%B9%8B%E6%9A%B4%E5%8A%9B%E5%8C%B9%E9%85%8D"><span class="nav-number">35.</span> <span class="nav-text">特征匹配之暴力匹配？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8E%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E6%A0%B8%E7%9A%84%E5%9B%BE%E5%83%8F%E5%AD%A4%E7%AB%8B%E7%82%B9%E6%A3%80%E6%B5%8B"><span class="nav-number">36.</span> <span class="nav-text">基于拉普拉斯核的图像 “孤立点” 检测？</span></a></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" alt="Shaogui" src="/images/avatar-2023.png"><p class="site-author-name" itemprop="name">Shaogui</p><div class="site-description" itemprop="description">害怕失败是本能，勇敢面对才是本事</div></div><div class="site-state-wrap animated"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">544</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/"><span class="site-state-item-count">70</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/"><span class="site-state-item-count">77</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="links-of-author animated"><span class="links-of-author-item"><a href="https://github.com/WuShaogui" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;WuShaogui" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a> </span><span class="links-of-author-item"><a href="https://www.zhihu.com/people/mu-zhi-zhi-tian" title="知乎 → https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;mu-zhi-zhi-tian" rel="noopener me" target="_blank"><i class="fab fa-zhihu fa-fw"></i>知乎</a></span></div><div class="cc-license animated" itemprop="license"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh-hans" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a></div></div></div><div class="back-to-top animated" role="button" aria-label="返回顶部"><i class="fa fa-arrow-up"></i> <span>0%</span></div></div><div class="sidebar-inner sidebar-blogroll"><div class="links-of-blogroll animated"><div class="links-of-blogroll-title"><i class="fa fa-globe fa-fw"></i> 链接</div><ul class="links-of-blogroll-list"><li class="links-of-blogroll-item"><a href="http://manaai.cn/" title="http:&#x2F;&#x2F;manaai.cn&#x2F;" rel="noopener" target="_blank">神力AI</a></li></ul></div></div></aside></div><div class="main-inner post posts-expand"><div class="post-block"><article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://www.shaogui.life/posts/346787849.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar-2023.png"><meta itemprop="name" content="Shaogui"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="年轻人起来冲"><meta itemprop="description" content="害怕失败是本能，勇敢面对才是本事"></span><span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork"><meta itemprop="name" content="C01 - 图像特征提取与检测 | 年轻人起来冲"><meta itemprop="description" content=""></span><header class="post-header"><h1 class="post-title" itemprop="name headline">C01 - 图像特征提取与检测</h1><div class="post-meta-container"><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2022-06-02 22:51:20" itemprop="dateCreated datePublished" datetime="2022-06-02T22:51:20+08:00">2022-06-02</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2025-01-18 19:05:43" itemprop="dateModified" datetime="2025-01-18T19:05:43+08:00">2025-01-18</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/3-%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B5/" itemprop="url" rel="index"><span itemprop="name">3-编程实践</span></a> </span>， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/3-%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B5/E-OpenCV/" itemprop="url" rel="index"><span itemprop="name">E-OpenCV</span></a> </span>， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/3-%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B5/E-OpenCV/OpenCV%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/" itemprop="url" rel="index"><span itemprop="name">OpenCV使用指南</span></a> </span></span><span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv"><span class="post-meta-item-icon"><i class="far fa-eye"></i> </span><span class="post-meta-item-text">阅读次数：</span> <span id="busuanzi_value_page_pv"></span> </span><span class="post-meta-break"></span> <span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>45k</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>41 分钟</span></span></div></div></header><div class="post-body" itemprop="articleBody"><p>介绍图像的目标特征及其计算方法</p><span id="more"></span><h3 id="图像上的目标特征"><a class="markdownIt-Anchor" href="#图像上的目标特征"></a> 图像上的目标特征？</h3><ul><li><strong>目标</strong>：通过图像分割获得多个区域，得到区域内的像素集合或区域边界像素集合。我们把感兴趣的人或物称为目标，目标所处的区域就是目标区域</li><li><strong>目标特征</strong>：针对于图像中的某个目标而言的。图像分割之后，还要对目标区域进行适当的表示和描述，以便下一步处理。“<strong>表示</strong>” 是直接具体地表示目标，以节省存储空间、方便特征计算。目标的表示方法，有链码、多边形逼近、斜率标记图、边界分段、区域骨架；“<strong>描述</strong>” 是对目标的抽象表达，在区别不同目标的基础上，尽可能对目标的尺度、平移、旋转变化不敏感</li></ul><h3 id="图像上目标特征有哪些"><a class="markdownIt-Anchor" href="#图像上目标特征有哪些"></a> 图像上目标特征有哪些？</h3><ul><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121415507.png" alt=""></li><li>在图像处理和计算机视觉领域，图像特征可以用来解决目标识别、图像匹配、视觉跟踪、三维重建等一系列问题。图像特征主要包括三种类型：(1) 角点 (Corner)；(2) 边缘 (Edge)；(3) 区域 (Blob)；(4) 山脊 (Ridge)，其实就是点、线、面、曲线</li><li><strong>角点</strong>：应用最为广泛，因为角点在任意方向的一个微小变动都会引起图像灰度的很大变化。“角点”(conrner) 也称之为 “兴趣点”(interest point) 或 “关键点”(key point) 或 “特征点”（feature）</li><li><strong>孤立的点</strong>：与角点不同，孤立的点是一个被背景像素围绕的前景像素，或一个被前景像素围绕的背景像素</li><li><strong>线与曲线</strong>：是一条细边缘线段，其两侧的背景灰度与线段的像素灰度存在显著差异</li><li><strong>边缘</strong>：区别于线，一般指局部不连续的的图像特征，边缘点是灰度阶跃变化的像素点，即灰度值变化显著，导数较大或极大的地方</li><li><strong>面</strong>：图片上的一个区域</li></ul><h3 id="图像的特征检测与匹配"><a class="markdownIt-Anchor" href="#图像的特征检测与匹配"></a> 图像的特征检测与匹配？</h3><ul><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121415383.png" alt=""></li><li><strong>特征检测</strong>：特征检测的结果是把图像上的点分为不同的子集，这些子集往往属于孤立的点、连续的曲线或者连续的区域</li><li><strong>特征点</strong>：由关键点（key point）和描述子（Descriptor）组成，其中，描述子通常是一个向量，描述了该关键点周围的像素信息。只要两个特征点的描述子在向量空间上的距离相近，就可以认为它们是相同的特征点</li></ul><h3 id="目标的边界特征描述子"><a class="markdownIt-Anchor" href="#目标的边界特征描述子"></a> 目标的 “边界特征” 描述子？</h3><ul><li>目标的边界描述符（Boundary descriptors），也称为边界描述子。轮廓就是对目标边界的描述，轮廓属性是基本的边界描述子，例如：</li><li><strong>边界的长度</strong>：轮廓线的像素数量是边界周长的近似估计</li><li><strong>边界的直径</strong>：边界长轴的长度，等于轮廓最小矩形边界框的长边长度</li><li><strong>边界的偏心率</strong>：边界长轴与短轴之比，等于轮廓最小矩形边界框的长宽比</li><li><strong>边界的曲率</strong>：相邻边界线段的斜率差</li><li><strong>链码</strong>：通过规定长度和方向的直线段来表示边界</li><li><strong>傅里叶描述符</strong>：对二维边界点进行离散傅里叶变换得到的傅里叶系数，对旋转、平移、缩放和起点不敏感</li><li><strong>统计矩</strong>：把边界视为直方图函数，用图像矩对边界特征进行描述，具有平移、灰度、尺度、旋转不变性</li></ul><h3 id="目标轮廓的闭合曲线弗里曼链码freeman-chain-code"><a class="markdownIt-Anchor" href="#目标轮廓的闭合曲线弗里曼链码freeman-chain-code"></a> 目标轮廓的闭合曲线弗里曼链码（Freeman chain code）？</h3><ul><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121415506.png" alt=""></li><li>链码表示基于线段的 4 连通或 8 连通（参考：如何认识 OpenCV 的线型 lineType）。弗里曼链码使用一种编号方案来对每个线段的方向进行编号<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">FreemanChainCode</span>(<span class="params">cLoop, gridsep=<span class="number">1</span></span>):  <span class="comment"># 由闭合边界点集生成弗里曼链码</span></span><br><span class="line">	<span class="comment"># Freeman 8 方向链码的方向数</span></span><br><span class="line">	dictFreeman = {(<span class="number">1</span>, <span class="number">0</span>): <span class="number">0</span>, (<span class="number">1</span>, <span class="number">1</span>): <span class="number">1</span>, (<span class="number">0</span>, <span class="number">1</span>): <span class="number">2</span>, (-<span class="number">1</span>, <span class="number">1</span>): <span class="number">3</span>, (-<span class="number">1</span>, <span class="number">0</span>): <span class="number">4</span>, (-<span class="number">1</span>, -<span class="number">1</span>): <span class="number">5</span>, (<span class="number">0</span>, -<span class="number">1</span>): <span class="number">6</span>, (<span class="number">1</span>, -<span class="number">1</span>): <span class="number">7</span>}</span><br><span class="line">	diff_cLoop = np.diff(cLoop, axis=<span class="number">0</span>) // gridsep  <span class="comment"># cLoop 的一阶差分码</span></span><br><span class="line">	direction = [<span class="built_in">tuple</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> diff_cLoop.tolist()]</span><br><span class="line">	codeList = <span class="built_in">list</span>(<span class="built_in">map</span>(dictFreeman.get, direction))  <span class="comment"># 查字典获得链码</span></span><br><span class="line">	code = np.array(codeList)  <span class="comment"># 转回 Numpy 数组</span></span><br><span class="line">	<span class="keyword">return</span> code</span><br><span class="line"><span class="comment"># 计算目标轮廓曲线的弗里曼链码</span></span><br><span class="line">img = cv2.imread(<span class="string">"../images/Fig1105.tif"</span>, flags=<span class="number">1</span>)</span><br><span class="line">gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  <span class="comment"># 灰度图像</span></span><br><span class="line">blur = cv2.boxFilter(gray, -<span class="number">1</span>, (<span class="number">5</span>, <span class="number">5</span>))  <span class="comment"># 盒式滤波器，9*9 平滑核</span></span><br><span class="line">_, binary = cv2.threshold(blur, <span class="number">200</span>, <span class="number">255</span>, cv2.THRESH_OTSU + cv2.THRESH_BINARY)</span><br><span class="line"><span class="comment"># 寻找二值化图中的轮廓，method=cv2.CHAIN_APPROX_NONE 输出轮廓的每个像素点</span></span><br><span class="line">contours, hierarchy = cv2.findContours(binary, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)  <span class="comment"># OpenCV4~</span></span><br><span class="line"><span class="comment"># 绘制全部轮廓，contourIdx=-1 绘制全部轮廓</span></span><br><span class="line">imgCnts = np.zeros(gray.shape[:<span class="number">2</span>], np.uint8)  <span class="comment"># 绘制轮廓函数会修改原始图像</span></span><br><span class="line">imgCnts = cv2.drawContours(imgCnts, contours, -<span class="number">1</span>, (<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>), thickness=<span class="number">2</span>)  <span class="comment"># 绘制全部轮廓</span></span><br><span class="line"><span class="comment"># 获取最大轮廓</span></span><br><span class="line">cnts = <span class="built_in">sorted</span>(contours, key=cv2.contourArea, reverse=<span class="literal">True</span>)  <span class="comment"># 所有轮廓按面积排序</span></span><br><span class="line">cnt = cnts[<span class="number">0</span>]  <span class="comment"># 第 0 个轮廓，面积最大的轮廓，(1361, 1, 2)</span></span><br><span class="line">maxContour = np.zeros(gray.shape[:<span class="number">2</span>], np.uint8)  <span class="comment"># 初始化最大轮廓图像</span></span><br><span class="line">cv2.drawContours(maxContour, cnt, -<span class="number">1</span>, (<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>), thickness=<span class="number">2</span>)  <span class="comment"># 绘制轮廓 cnt</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"len(contours) ="</span>, <span class="built_in">len</span>(contours))  <span class="comment"># 所有轮廓的列表 24</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"area of max contour: "</span>, cv2.contourArea(cnt))  <span class="comment"># 轮廓面积 152294.5</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"perimeter of max contour: {:.1f}"</span>.<span class="built_in">format</span>(cv2.arcLength(cnt, <span class="literal">True</span>)))  <span class="comment"># 轮廓周长 1525.4</span></span><br><span class="line"><span class="comment"># 向下降采样，简化轮廓的边界</span></span><br><span class="line">gridsep = <span class="number">50</span>  <span class="comment"># 采样间隔</span></span><br><span class="line">cntPoints = np.squeeze(cnt)  <span class="comment"># 删除维度为1的数组维度，(1361,1,2)-&gt;(1361,2)</span></span><br><span class="line">subPoints = boundarySubsample(cntPoints, gridsep)  <span class="comment"># 自定义函数，通过向下采样简化轮廓</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"points of contour:"</span>, cntPoints.shape[<span class="number">0</span>])  <span class="comment"># 原始轮廓点数     1361</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"points of subsample:"</span>, subPoints.shape[<span class="number">0</span>])  <span class="comment"># 降采样轮廓点数 34</span></span><br><span class="line"><span class="comment"># 绘制简化轮廓图像</span></span><br><span class="line">subContour = np.zeros(gray.shape[:<span class="number">2</span>], np.uint8)  <span class="comment"># 初始化简化轮廓图像</span></span><br><span class="line">[cv2.circle(subContour, point, <span class="number">1</span>, <span class="number">160</span>, -<span class="number">1</span>) <span class="keyword">for</span> point <span class="keyword">in</span> cntPoints]  <span class="comment"># 绘制初始轮廓的采样点</span></span><br><span class="line">[cv2.circle(subContour, point, <span class="number">4</span>, <span class="number">255</span>, -<span class="number">1</span>) <span class="keyword">for</span> point <span class="keyword">in</span> subPoints]  <span class="comment"># 绘制降采样轮廓的采样点</span></span><br><span class="line">cv2.polylines(subContour, [subPoints], <span class="literal">True</span>, <span class="number">255</span>, thickness=<span class="number">2</span>)  <span class="comment"># 绘制多边形，闭合曲线</span></span><br><span class="line"><span class="comment"># 生成 Freeman 链码</span></span><br><span class="line">cntPoints = np.squeeze(cnt)  <span class="comment"># 删除维度为1 的数组维度，(1361,1,2)-&gt;(1361,2)</span></span><br><span class="line">pointsLoop = np.append(cntPoints, [cntPoints[<span class="number">0</span>]], axis=<span class="number">0</span>)  <span class="comment"># 首尾循环，结尾添加 cntPoints[0]</span></span><br><span class="line">chainCode = FreemanChainCode(pointsLoop, gridsep=<span class="number">1</span>)  <span class="comment"># 自定义函数，生成链码 (1361,)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"Freeman chain code:"</span>, chainCode.shape)  <span class="comment"># 链码长度为轮廓长度 1361</span></span><br><span class="line">subPointsLoop = np.append(subPoints, [subPoints[<span class="number">0</span>]], axis=<span class="number">0</span>)  <span class="comment"># 首尾循环，(34,2)-&gt;(35,2)</span></span><br><span class="line">subChainCode = FreemanChainCode(subPointsLoop, gridsep=<span class="number">50</span>)  <span class="comment"># 自定义函数，生成链码 (34,)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"Down-sampling Freeman chain code:"</span>, subChainCode.shape)  <span class="comment"># 链码长度为简化轮廓程度 34</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"youcans code:"</span>, subChainCode) <span class="comment"># [4 2 4 2 2 4 2 2 2 2 2 0 2 0 0 0 2 0 0 6 0 6 6 6 6 6 6 6 6 4 6 4 4 4]</span></span><br><span class="line">show_images([img,blur,binary,imgCnts,maxContour,subContour])</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="目标轮廓的多边形拟合"><a class="markdownIt-Anchor" href="#目标轮廓的多边形拟合"></a> 目标轮廓的多边形拟合？</h3><ul><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121415823.png" alt=""></li><li><strong>原理</strong>：1）在曲线的起点 A 和终点 B 之间做一条直线 AB，是曲线的弦；2）寻找曲线上离该直线段距离最大的点 C，计算其与 AB 的距离 d；3）比较距离 d 与设定的阈值 threshold，如果小于设定阈值则该直线段作为曲线的近似；4）如果距离 d 大于设定阈值，则以 C 点将曲线 AB 分为两段 AC 和 BC，并分别对这两段进行以上步骤的处理；5）当所有曲线都处理完毕时，依次连接所有分割点形成的折线，作为曲线的近似</li><li>OpenCV 中的函数&nbsp;<strong>cv.approxPolyDP ()</strong>&nbsp;可以用于对图像轮廓点进行多边形拟合<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">img = cv2.imread(<span class="string">"../images/Fig1105.tif"</span>, flags=<span class="number">1</span>)</span><br><span class="line">gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  <span class="comment"># 灰度图像</span></span><br><span class="line">blur = cv2.boxFilter(gray, -<span class="number">1</span>, (<span class="number">5</span>, <span class="number">5</span>))  <span class="comment"># 盒式滤波器，9*9 平滑核</span></span><br><span class="line">_, binary = cv2.threshold(blur, <span class="number">205</span>, <span class="number">255</span>, cv2.THRESH_OTSU + cv2.THRESH_BINARY)</span><br><span class="line"><span class="comment"># 寻找二值化图中的轮廓</span></span><br><span class="line">contours, hierarchy = cv2.findContours(binary, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)  <span class="comment"># OpenCV4~</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">'len:'</span>, <span class="built_in">len</span>(contours))</span><br><span class="line"><span class="comment"># 绘制全部轮廓，contourIdx=-1 绘制全部轮廓</span></span><br><span class="line">imgCnts = np.zeros(gray.shape[:<span class="number">2</span>], np.uint8)  <span class="comment"># 绘制轮廓函数会修改原始图像</span></span><br><span class="line">imgCnts = cv2.drawContours(imgCnts, contours, -<span class="number">1</span>, (<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>), thickness=<span class="number">2</span>)  <span class="comment"># 绘制全部轮廓</span></span><br><span class="line">show_images([img,binary,imgCnts])</span><br><span class="line">cnts = <span class="built_in">sorted</span>(contours, key=cv2.contourArea, reverse=<span class="literal">True</span>)  <span class="comment"># 所有轮廓按面积排序</span></span><br><span class="line">cnt = cnts[<span class="number">0</span>]  <span class="comment"># 第 0 个轮廓，面积最大的轮廓，(664, 1, 2)</span></span><br><span class="line">eps = [<span class="number">50</span>, <span class="number">30</span>, <span class="number">10</span>]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(eps)):</span><br><span class="line">	polyFit = cv2.approxPolyDP(cnt, eps[i], <span class="literal">True</span>)</span><br><span class="line">	<span class="built_in">print</span>(<span class="string">"eps={}, shape of fitting polygon:{}"</span>.<span class="built_in">format</span>(eps[i], polyFit.shape[<span class="number">0</span>]))</span><br><span class="line">	fitContour = np.zeros(gray.shape[:<span class="number">2</span>], np.uint8)  <span class="comment"># 初始化最大轮廓图像</span></span><br><span class="line">	cv2.polylines(fitContour, [cnt], <span class="literal">True</span>, <span class="number">205</span>, thickness=<span class="number">2</span>)  <span class="comment"># 绘制最大轮廓，多边形曲线</span></span><br><span class="line">	cv2.polylines(fitContour, [polyFit], <span class="literal">True</span>, <span class="number">255</span>, <span class="number">3</span>)</span><br><span class="line">	show_images([fitContour])</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="目标轮廓的骨架提取"><a class="markdownIt-Anchor" href="#目标轮廓的骨架提取"></a> 目标轮廓的骨架提取？</h3><ul><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121415726.png" alt=""></li><li>骨架可以由区域的边界计算。提取骨架的常用方法是用重建开运算来实现，在保持端点和线的连通性的同时持续<strong>细化</strong>目标区域<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">img = cv2.imread(<span class="string">"../images/bloodvessels.tif"</span>, flags=<span class="number">1</span>)</span><br><span class="line">gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  <span class="comment"># 灰度图像</span></span><br><span class="line">_, binary = cv2.threshold(gray, <span class="number">127</span>, <span class="number">255</span>, cv2.THRESH_OTSU + cv2.THRESH_BINARY)</span><br><span class="line">dst = binary.copy()</span><br><span class="line">skeleton = np.zeros(gray.shape, np.uint8)  <span class="comment"># 创建空骨架图</span></span><br><span class="line">kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (<span class="number">5</span>, <span class="number">5</span>))</span><br><span class="line"><span class="keyword">while</span> (<span class="literal">True</span>):</span><br><span class="line">	dst = cv2.erode(dst, kernel, <span class="literal">None</span>, <span class="literal">None</span>, <span class="number">1</span>)  <span class="comment"># 腐蚀</span></span><br><span class="line">	opening = cv2.morphologyEx(dst, cv2.MORPH_OPEN, kernel)  <span class="comment"># 开运算</span></span><br><span class="line">	subSkeleton = cv2.subtract(dst, opening)  <span class="comment"># 获得骨架子集</span></span><br><span class="line">	skeleton = cv2.bitwise_or(skeleton, subSkeleton)  <span class="comment"># 将删除的像素添加到骨架图</span></span><br><span class="line">	<span class="keyword">if</span> cv2.countNonZero(dst) == <span class="number">0</span>:</span><br><span class="line">		<span class="keyword">break</span></span><br><span class="line">show_images([img,skeleton,result])</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="目标轮廓的傅里叶描述子"><a class="markdownIt-Anchor" href="#目标轮廓的傅里叶描述子"></a> 目标轮廓的傅里叶描述子？</h3><ul><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121415090.png" alt=""></li><li>傅里叶描述子的基本思想是用目标边界曲线的傅里叶变换来描述目标区域的形状，将二维描述问题简化为一维描述问题。傅里叶描述子具有旋转、平移和尺度不变性</li><li>由于傅里叶变换的低频分量决定整体形状，高频分量决定形状的细节。因此，仅取前 P 个系数相当于保留低频系数、删除高频系数的理想低通滤波器进行滤波。用少量低频的傅里叶描述子就可以描述目标边界曲线形状的基本特征。下面的例程表明，使用约 1% 的傅里叶描述子，就可以较好地描述边界曲线的基本形状<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">truncFFT</span>(<span class="params">fftCnt, pLowF=<span class="number">64</span></span>):  <span class="comment"># 截短傅里叶描述子</span></span><br><span class="line">	fftShift = np.fft.fftshift(fftCnt)  <span class="comment"># 中心化，将低频分量移动到频域中心</span></span><br><span class="line">	center = <span class="built_in">int</span>(<span class="built_in">len</span>(fftShift)/<span class="number">2</span>)</span><br><span class="line">	low, high = center - <span class="built_in">int</span>(pLowF/<span class="number">2</span>), center + <span class="built_in">int</span>(pLowF/<span class="number">2</span>)</span><br><span class="line">	fftshiftLow = fftShift[low:high]</span><br><span class="line">	fftLow = np.fft.ifftshift(fftshiftLow)  <span class="comment"># 逆中心化</span></span><br><span class="line">	<span class="keyword">return</span> fftLow</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">reconstruct</span>(<span class="params">img, fftCnt, scale, ratio=<span class="number">1.0</span></span>):  <span class="comment"># 由傅里叶描述子重建轮廓图</span></span><br><span class="line">	pLowF = <span class="built_in">int</span>(fftCnt.shape[<span class="number">0</span>] * ratio)  <span class="comment"># 截短长度 P&lt;=K</span></span><br><span class="line">	fftLow = truncFFT(fftCnt, pLowF)  <span class="comment"># 截短傅里叶描述子，删除高频系数</span></span><br><span class="line">	ifft = np.fft.ifft(fftLow)  <span class="comment"># 傅里叶逆变换 (P,)</span></span><br><span class="line">	cntRebuild = np.stack((ifft.real, ifft.imag), axis=-<span class="number">1</span>)  <span class="comment"># 复数转为数组 (P, 2)</span></span><br><span class="line">	<span class="keyword">if</span> cntRebuild.<span class="built_in">min</span>() &lt; <span class="number">0</span>:</span><br><span class="line">		cntRebuild -= cntRebuild.<span class="built_in">min</span>()</span><br><span class="line">	cntRebuild *= scale / cntRebuild.<span class="built_in">max</span>()</span><br><span class="line">	cntRebuild = cntRebuild.astype(np.int32)</span><br><span class="line">	<span class="built_in">print</span>(<span class="string">"ratio={}, fftCNT:{}, fftLow:{}"</span>.<span class="built_in">format</span>(ratio, fftCnt.shape, fftLow.shape))</span><br><span class="line">	rebuild = np.ones(img.shape, np.uint8)*<span class="number">255</span>  <span class="comment"># 创建空白图像</span></span><br><span class="line">	cv2.rectangle(rebuild, (<span class="number">2</span>,<span class="number">3</span>), (<span class="number">568</span>,<span class="number">725</span>), (<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>), )  <span class="comment"># 绘制边框</span></span><br><span class="line">	cv2.polylines(rebuild, [cntRebuild], <span class="literal">True</span>, <span class="number">0</span>, thickness=<span class="number">2</span>)  <span class="comment"># 绘制多边形，闭合曲线</span></span><br><span class="line">	<span class="keyword">return</span> rebuild</span><br><span class="line"><span class="comment"># 特征提取之傅里叶描述子</span></span><br><span class="line">img = cv2.imread(<span class="string">"../images/chromosome.tif"</span>, flags=<span class="number">1</span>)</span><br><span class="line">gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  <span class="comment"># 灰度图像</span></span><br><span class="line">_, binary = cv2.threshold(gray, <span class="number">127</span>, <span class="number">255</span>, cv2.THRESH_OTSU + cv2.THRESH_BINARY)</span><br><span class="line"><span class="comment"># 寻找二值化图中的轮廓，method=cv2.CHAIN_APPROX_NONE 输出轮廓的每个像素点</span></span><br><span class="line">contours, hierarchy = cv2.findContours(binary, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)  <span class="comment"># OpenCV4~</span></span><br><span class="line">cnts = <span class="built_in">sorted</span>(contours, key=cv2.contourArea, reverse=<span class="literal">True</span>)  <span class="comment"># 所有轮廓按面积排序</span></span><br><span class="line">cnt = cnts[<span class="number">0</span>]  <span class="comment"># 第 0 个轮廓，面积最大的轮廓，(664, 1, 2)</span></span><br><span class="line">cntPoints = np.squeeze(cnt)  <span class="comment"># 删除维度为 1 的数组维度，(2867, 1, 2)-&gt;(2867,2)</span></span><br><span class="line">lenCnt = cnt.shape[<span class="number">0</span>]  <span class="comment"># 轮廓点的数量</span></span><br><span class="line">imgCnts = np.zeros(gray.shape[:<span class="number">2</span>], np.uint8)  <span class="comment"># 创建空白图像</span></span><br><span class="line">cv2.drawContours(imgCnts, cnt, -<span class="number">1</span>, (<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>), <span class="number">2</span>)  <span class="comment"># 绘制轮廓</span></span><br><span class="line"><span class="comment"># 离散傅里叶变换，生成傅里叶描述子 fftCnt</span></span><br><span class="line">cntComplex = np.empty(cntPoints.shape[<span class="number">0</span>], dtype=<span class="built_in">complex</span>)  <span class="comment"># 声明复数数组 (2867,)</span></span><br><span class="line">cntComplex = cntPoints[:,<span class="number">0</span>] + <span class="number">1j</span> * cntPoints[:,<span class="number">1</span>]  <span class="comment"># (xk,yk)-&gt;xk+j*yk</span></span><br><span class="line">fftCnt = np.fft.fft(cntComplex)  <span class="comment"># 离散傅里叶变换，生成傅里叶描述子</span></span><br><span class="line"><span class="comment"># 由全部傅里叶描述子重建轮廓曲线</span></span><br><span class="line">scale = cntPoints.<span class="built_in">max</span>()  <span class="comment"># 尺度系数</span></span><br><span class="line">rebuild = reconstruct(img, fftCnt, scale)  <span class="comment"># 傅里叶逆变换重建轮廓曲线，傅里叶描述子 (2866,)</span></span><br><span class="line"><span class="comment"># 由截短傅里叶系数重建轮廓曲线</span></span><br><span class="line">rebuild1 = reconstruct(img, fftCnt, scale, ratio=<span class="number">0.2</span>)  <span class="comment"># 截短比例 20%，傅里叶描述子 (572,)</span></span><br><span class="line">rebuild2 = reconstruct(img, fftCnt, scale, ratio=<span class="number">0.05</span>)  <span class="comment"># 截短比例 5%，傅里叶描述子 (142,)</span></span><br><span class="line">rebuild3 = reconstruct(img, fftCnt, scale, ratio=<span class="number">0.02</span>)  <span class="comment"># 截短比例 2%，傅里叶描述子 (56,)</span></span><br><span class="line">show_images([img,imgCnts,rebuild,rebuild1,rebuild2,rebuild3])</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="目标轮廓的紧致度"><a class="markdownIt-Anchor" href="#目标轮廓的紧致度"></a> 目标轮廓的紧致度？</h3><ul><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121415948.png" alt=""></li><li>紧致度（Compactness），周长的平方与面积之比，具有平移、尺度、旋转不变性<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">n = <span class="number">4</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,n+<span class="number">1</span>):</span><br><span class="line">	path = <span class="string">"../images/wingding{}.tif"</span>.<span class="built_in">format</span>(<span class="built_in">str</span>(i))</span><br><span class="line">	gray = cv2.imread(path, flags=<span class="number">0</span>)</span><br><span class="line">	_, binary = cv2.threshold(gray, <span class="number">127</span>, <span class="number">255</span>, cv2.THRESH_BINARY)</span><br><span class="line">	contours, hierarchy = cv2.findContours(binary, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)  <span class="comment"># OpenCV4~</span></span><br><span class="line">	cnts = <span class="built_in">sorted</span>(contours, key=cv2.contourArea, reverse=<span class="literal">True</span>)  <span class="comment"># 所有轮廓按面积排序</span></span><br><span class="line">	cnt = cnts[<span class="number">0</span>]  <span class="comment"># 第 0 个轮廓，面积最大的轮廓，(2867, 1, 2)</span></span><br><span class="line">	<span class="built_in">print</span>(<span class="string">"{}, path:{}, shape:{}"</span>.<span class="built_in">format</span>(i, path, gray.shape))</span><br><span class="line">	area = cv2.contourArea(cnt)  <span class="comment"># 轮廓面积 (area)</span></span><br><span class="line">	<span class="built_in">print</span>(<span class="string">"\tarea of contour: "</span>, area)</span><br><span class="line">	perimeter = cv2.arcLength(cnt, <span class="literal">True</span>)  <span class="comment"># 轮廓周长 (perimeter)</span></span><br><span class="line">	<span class="built_in">print</span>(<span class="string">"\tperimeter of contour: {:.1f}"</span>.<span class="built_in">format</span>(perimeter))</span><br><span class="line">	compact = perimeter ** <span class="number">2</span> / area  <span class="comment"># 轮廓的紧致度 (compactness)</span></span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="目标轮廓的圆度"><a class="markdownIt-Anchor" href="#目标轮廓的圆度"></a> 目标轮廓的圆度？</h3><ul><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121415948.png" alt=""></li><li>圆度（circularity），面积与周长的平方之比，具有平移、尺度、旋转不变性<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">n = <span class="number">4</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,n+<span class="number">1</span>):</span><br><span class="line">	path = <span class="string">"../images/wingding{}.tif"</span>.<span class="built_in">format</span>(<span class="built_in">str</span>(i))</span><br><span class="line">	gray = cv2.imread(path, flags=<span class="number">0</span>)</span><br><span class="line">	_, binary = cv2.threshold(gray, <span class="number">127</span>, <span class="number">255</span>, cv2.THRESH_BINARY)</span><br><span class="line">	contours, hierarchy = cv2.findContours(binary, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)  <span class="comment"># OpenCV4~</span></span><br><span class="line">	cnts = <span class="built_in">sorted</span>(contours, key=cv2.contourArea, reverse=<span class="literal">True</span>)  <span class="comment"># 所有轮廓按面积排序</span></span><br><span class="line">	cnt = cnts[<span class="number">0</span>]  <span class="comment"># 第 0 个轮廓，面积最大的轮廓，(2867, 1, 2)</span></span><br><span class="line">	area = cv2.contourArea(cnt)  <span class="comment"># 轮廓面积 (area)</span></span><br><span class="line">	<span class="built_in">print</span>(<span class="string">"\tarea of contour: "</span>, area)</span><br><span class="line">	perimeter = cv2.arcLength(cnt, <span class="literal">True</span>)  <span class="comment"># 轮廓周长 (perimeter)</span></span><br><span class="line">	<span class="built_in">print</span>(<span class="string">"\tperimeter of contour: {:.1f}"</span>.<span class="built_in">format</span>(perimeter))</span><br><span class="line">	circular = <span class="number">4</span> * np.pi * area / perimeter ** <span class="number">2</span>  <span class="comment"># 轮廓的圆度 (circularity)</span></span><br><span class="line">	<span class="built_in">print</span>(<span class="string">"\tcircularity of contour: {:.2f}"</span>.<span class="built_in">format</span>(circular))</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="目标轮廓的偏心率"><a class="markdownIt-Anchor" href="#目标轮廓的偏心率"></a> 目标轮廓的偏心率？</h3><ul><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121415948.png" alt=""></li><li>偏心率（Eccentricity），椭圆的偏心率定义为焦距与椭圆长轴的长度之比<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">n = <span class="number">4</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,n+<span class="number">1</span>):</span><br><span class="line">	path = <span class="string">"../images/wingding{}.tif"</span>.<span class="built_in">format</span>(<span class="built_in">str</span>(i))</span><br><span class="line">	gray = cv2.imread(path, flags=<span class="number">0</span>)</span><br><span class="line">	_, binary = cv2.threshold(gray, <span class="number">127</span>, <span class="number">255</span>, cv2.THRESH_BINARY)</span><br><span class="line">	contours, hierarchy = cv2.findContours(binary, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)  <span class="comment"># OpenCV4~</span></span><br><span class="line">	cnts = <span class="built_in">sorted</span>(contours, key=cv2.contourArea, reverse=<span class="literal">True</span>)  <span class="comment"># 所有轮廓按面积排序</span></span><br><span class="line">	cnt = cnts[<span class="number">0</span>]  <span class="comment"># 第 0 个轮廓，面积最大的轮廓，(2867, 1, 2)</span></span><br><span class="line">	ellipse = cv2.fitEllipse(cnt)  <span class="comment"># 轮廓的拟合椭圆</span></span><br><span class="line">	<span class="comment"># 椭圆中心点 (x,y), 长轴短轴长度 (a,b), 旋转角度 ang</span></span><br><span class="line">	(x, y), (a, b), ang = np.int32(ellipse[<span class="number">0</span>]), np.int32(ellipse[<span class="number">1</span>]), <span class="built_in">round</span>(ellipse[<span class="number">2</span>], <span class="number">1</span>)</span><br><span class="line">	<span class="comment"># print("Fitted ellipse: (Cx,Cy)={}, (a,b)={}, ang={})".format((x, y), (a, b), ang))</span></span><br><span class="line">	<span class="comment"># 轮廓的偏心率 (eccentricity)</span></span><br><span class="line">	<span class="keyword">if</span> (a &gt; b):</span><br><span class="line">		eccentric = np.sqrt(<span class="number">1.0</span> - (b / a) ** <span class="number">2</span>)  <span class="comment"># a 为长轴</span></span><br><span class="line">	<span class="keyword">else</span>:</span><br><span class="line">		eccentric = np.sqrt(<span class="number">1.0</span> - (a / b) ** <span class="number">2</span>)</span><br><span class="line">	<span class="built_in">print</span>(<span class="string">"\teccentricity of contour: {:.2f}"</span>.<span class="built_in">format</span>(eccentric))</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="目标区域区域特征"><a class="markdownIt-Anchor" href="#目标区域区域特征"></a> 目标区域 “区域特征”？</h3><ul><li>针对目标所在区域的特征描述符（Region descriptors），称为区域特征描述子</li></ul><h3 id="目标区域的纹理特征"><a class="markdownIt-Anchor" href="#目标区域的纹理特征"></a> 目标区域的 “纹理特征”？</h3><ul><li>纹理体现了物体表面的具有缓慢变化或者周期性变化的表面结构组织排列属性。纹理特征描述了图像或图像区域所对应景物的表面性质</li><li>纹理与尺度密切相关，一般仅呈现在特定尺度上，对纹理的识别要在恰当的尺度上进行。纹理特征不是基于像素点的特征，而是一种基于像素区域的统计特性。因此，纹理能用来描述不同的图像区域</li><li>纹理特征通常具有旋转不变性，在模式匹配中对噪声有较强的抵抗能力。描述图像中的纹理区域，要基于区域尺度、可分辨灰度元素的数目以及这些灰度元素的相互关系等。</li></ul><h3 id="目标区域的lbp-纹理特征算子"><a class="markdownIt-Anchor" href="#目标区域的lbp-纹理特征算子"></a> 目标区域的 “LBP 纹理特征算子”？</h3><ul><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121416592.png" alt=""></li><li>局部二值模式是一种用来描述图像局部纹理特征的算子，它具有旋转不变性和灰度不变性的优点。LBP 算子利用了邻域点的量化关系，可以有效地消除光照对图像的影响。只要光照变化不足以改变相邻像素点的像素值的大小关系，LBP 算子的值就不会发生变化</li><li>原始的 LBP 算子定义在 3×3 的窗口内，以窗口中心像素为阈值，与相邻的 8 个像素的灰度值比较，大于阈值则标记为 1，否则标记为 0。从右上角开始顺时针旋转，排列 8 个 0/1 标记值，得到一个 8 位二进制数，就是窗口中心像素点的 LBP 值<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">getLBP1</span>(<span class="params">gray</span>):</span><br><span class="line">	height, width = gray.shape</span><br><span class="line">	dst = np.zeros((height, width), np.uint8)</span><br><span class="line">	kernel = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">128</span>, <span class="number">0</span>, <span class="number">8</span>, <span class="number">64</span>, <span class="number">32</span>, <span class="number">16</span>]).reshape(<span class="number">3</span>,<span class="number">3</span>)  <span class="comment"># 从左上角开始顺时针旋转</span></span><br><span class="line">	<span class="comment"># kernel = np.array([64,128,1,32,0,2,16,8,4]).reshape(3,3)  # 从右上角开始顺时针旋转</span></span><br><span class="line">	<span class="keyword">for</span> h <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, height-<span class="number">1</span>):</span><br><span class="line">		<span class="keyword">for</span> w <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, width-<span class="number">1</span>):</span><br><span class="line">			LBPMat = (gray[h-<span class="number">1</span>:h+<span class="number">2</span>, w-<span class="number">1</span>:w+<span class="number">2</span>] &gt;= gray[h, w])  <span class="comment"># 阈值比较</span></span><br><span class="line">			dst[h, w] = np.<span class="built_in">sum</span>(LBPMat * kernel)  <span class="comment"># 二维矩阵相乘</span></span><br><span class="line">	<span class="keyword">return</span> dst</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getLBP2</span>(<span class="params">gray</span>):</span><br><span class="line">	height, width = gray.shape</span><br><span class="line">	dst = np.zeros((height, width), np.uint8)</span><br><span class="line">	<span class="comment"># kernelFlatten = np.array([1, 2, 4, 128, 0, 8, 64, 32, 16])  # 从左上角开始顺时针旋转</span></span><br><span class="line">	kernelFlatten = np.array([<span class="number">64</span>,<span class="number">128</span>,<span class="number">1</span>,<span class="number">32</span>,<span class="number">0</span>,<span class="number">2</span>,<span class="number">16</span>,<span class="number">8</span>,<span class="number">4</span>])  <span class="comment"># 从右上角开始顺时针旋转</span></span><br><span class="line">	<span class="keyword">for</span> h <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, height-<span class="number">1</span>):</span><br><span class="line">		<span class="keyword">for</span> w <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, width-<span class="number">1</span>):</span><br><span class="line">			LBPFlatten = (gray[h-<span class="number">1</span>:h+<span class="number">2</span>, w-<span class="number">1</span>:w+<span class="number">2</span>] &gt;= gray[h, w]).flatten()  <span class="comment"># 展平为一维向量, (9,)</span></span><br><span class="line">			dst[h, w] = np.vdot(LBPFlatten, kernelFlatten)  <span class="comment"># 一维向量的内积</span></span><br><span class="line">	<span class="keyword">return</span> dst</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getLBP3</span>(<span class="params">gray</span>):</span><br><span class="line">	height, width = gray.shape</span><br><span class="line">	dst = np.zeros((height, width), np.uint8)</span><br><span class="line">	<span class="keyword">for</span> h <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, height-<span class="number">1</span>):</span><br><span class="line">		<span class="keyword">for</span> w <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, width-<span class="number">1</span>):</span><br><span class="line">			center = gray[h, w]</span><br><span class="line">			code = <span class="number">0</span>  <span class="comment"># 从左上角开始顺时针旋转</span></span><br><span class="line">			code |= (gray[h-<span class="number">1</span>, w-<span class="number">1</span>] &gt;= center) &lt;&lt; (np.uint8)(<span class="number">7</span>)</span><br><span class="line">			code |= (gray[h-<span class="number">1</span>, w  ] &gt;= center) &lt;&lt; (np.uint8)(<span class="number">6</span>)</span><br><span class="line">			code |= (gray[h-<span class="number">1</span>, w+<span class="number">1</span>] &gt;= center) &lt;&lt; (np.uint8)(<span class="number">5</span>)</span><br><span class="line">			code |= (gray[h  , w+<span class="number">1</span>] &gt;= center) &lt;&lt; (np.uint8)(<span class="number">4</span>)</span><br><span class="line">			code |= (gray[h+<span class="number">1</span>, w+<span class="number">1</span>] &gt;= center) &lt;&lt; (np.uint8)(<span class="number">3</span>)</span><br><span class="line">			code |= (gray[h+<span class="number">1</span>, w  ] &gt;= center) &lt;&lt; (np.uint8)(<span class="number">2</span>)</span><br><span class="line">			code |= (gray[h+<span class="number">1</span>, w-<span class="number">1</span>] &gt;= center) &lt;&lt; (np.uint8)(<span class="number">1</span>)</span><br><span class="line">			code |= (gray[h  , w-<span class="number">1</span>] &gt;= center) &lt;&lt; (np.uint8)(<span class="number">0</span>)</span><br><span class="line">			dst[h, w] = code</span><br><span class="line">	<span class="keyword">return</span> dst</span><br><span class="line"><span class="comment"># 原始 LBP 算法：选取中心点周围的 8个像素点，阈值处理后标记为 8位二进制数</span></span><br><span class="line">img = cv2.imread(<span class="string">"../images/fabric1.png"</span>, flags=<span class="number">1</span>)</span><br><span class="line">gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  <span class="comment"># 灰度图像</span></span><br><span class="line"><span class="comment"># 1) 二重循环, 二维矩阵相乘</span></span><br><span class="line">timeBegin = cv2.getTickCount()</span><br><span class="line">imgLBP1 = getLBP1(gray)  <span class="comment"># # 从左上角开始顺时针旋转</span></span><br><span class="line">timeEnd = cv2.getTickCount()</span><br><span class="line">time = (timeEnd-timeBegin)/cv2.getTickFrequency()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"1) 二重循环, 二维矩阵相乘:"</span>, <span class="built_in">round</span>(time, <span class="number">4</span>))</span><br><span class="line"><span class="comment"># 2) 二重循环, 一维向量的内积</span></span><br><span class="line">timeBegin = cv2.getTickCount()</span><br><span class="line">imgLBP2 = getLBP2(gray)  <span class="comment"># 从右上角开始顺时针旋转</span></span><br><span class="line">timeEnd = cv2.getTickCount()</span><br><span class="line">time = (timeEnd-timeBegin)/cv2.getTickFrequency()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"2) 二重循环, 一维向量的内积:"</span>, <span class="built_in">round</span>(time, <span class="number">4</span>))</span><br><span class="line"><span class="comment"># 3) 二重循环, 按位操作</span></span><br><span class="line">timeBegin = cv2.getTickCount()</span><br><span class="line">imgLBP3 = getLBP3(gray)  <span class="comment"># 从右上角开始顺时针旋转</span></span><br><span class="line">timeEnd = cv2.getTickCount()</span><br><span class="line">time = (timeEnd-timeBegin)/cv2.getTickFrequency()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"3) 二重循环, 按位操作:"</span>, <span class="built_in">round</span>(time, <span class="number">4</span>))</span><br><span class="line"><span class="comment"># 4) skimage 特征检测</span></span><br><span class="line"><span class="keyword">from</span> skimage.feature <span class="keyword">import</span> local_binary_pattern</span><br><span class="line">timeBegin = cv2.getTickCount()</span><br><span class="line">lbpSKimage = local_binary_pattern(gray, <span class="number">8</span>, <span class="number">1</span>)</span><br><span class="line">timeEnd = cv2.getTickCount()</span><br><span class="line">time = (timeEnd-timeBegin)/cv2.getTickFrequency()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"4) skimage.feature 封装:"</span>, <span class="built_in">round</span>(time, <span class="number">4</span>))</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="目标区域的extendlbp-纹理特征算子"><a class="markdownIt-Anchor" href="#目标区域的extendlbp-纹理特征算子"></a> 目标区域的 “extendLBP 纹理特征算子”？</h3><ul><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121416195.png" alt=""></li><li>基本的 LBP 纹理特征描述子只覆盖了一个固定半径范围内的小区域。这种特征描述方法是随尺度变化的，当图像尺度变化时 LBP 特征编码也会发生变化，因此在大尺寸图像时就不能准确提取到所需的纹理特征，不能反映所描述的纹理信息</li><li>为了满足尺度、灰度和旋转不变性的要求，Ojala 等对 LBP 算子进行了改进，将 3×3 邻域扩展到任意邻域，并用圆形邻域代替了方形邻域。改进算子允许在半径为 R 的圆形邻域内有 P 个采样点，称为扩展 LBP 算子（Extended LBP）<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">basicLBP</span>(<span class="params">gray</span>):</span><br><span class="line">	height, width = gray.shape</span><br><span class="line">	dst = np.zeros((height, width), np.uint8)</span><br><span class="line">	kernelFlatten = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">128</span>, <span class="number">0</span>, <span class="number">8</span>, <span class="number">64</span>, <span class="number">32</span>, <span class="number">16</span>])  <span class="comment"># 从左上角开始顺时针旋转</span></span><br><span class="line">	<span class="keyword">for</span> h <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, height-<span class="number">1</span>):</span><br><span class="line">		<span class="keyword">for</span> w <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, width-<span class="number">1</span>):</span><br><span class="line">			LBPFlatten = (gray[h-<span class="number">1</span>:h+<span class="number">2</span>, w-<span class="number">1</span>:w+<span class="number">2</span>] &gt;= gray[h, w]).flatten()  <span class="comment"># 展平为一维向量, (9,)</span></span><br><span class="line">			dst[h, w] = np.vdot(LBPFlatten, kernelFlatten)  <span class="comment"># 一维向量的内积</span></span><br><span class="line">	<span class="keyword">return</span> dst</span><br><span class="line"><span class="comment"># extend LBP，在半径为 R 的圆形邻域内有 N 个采样点</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">extendLBP</span>(<span class="params">gray, r=<span class="number">3</span>, n=<span class="number">8</span></span>):</span><br><span class="line">	height, width = gray.shape</span><br><span class="line">	ww = np.empty((n, <span class="number">4</span>), np.<span class="built_in">float</span>)  <span class="comment"># (8,4)</span></span><br><span class="line">	p = np.empty((n, <span class="number">4</span>), np.<span class="built_in">int</span>)  <span class="comment"># [x1, y1, x2, y2]</span></span><br><span class="line">	<span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(n):  <span class="comment"># 双线性插值估计坐标偏移量和权值</span></span><br><span class="line">		<span class="comment"># 计算坐标偏移量 rx，ry</span></span><br><span class="line">		rx = r * np.cos(<span class="number">2.0</span> * np.pi * k / n)</span><br><span class="line">		ry = -(r * np.sin(<span class="number">2.0</span> * np.pi * k / n))</span><br><span class="line">		<span class="comment"># 对采样点分别进行上下取整</span></span><br><span class="line">		x1, y1 = <span class="built_in">int</span>(np.floor(rx)), <span class="built_in">int</span>(np.floor(ry))</span><br><span class="line">		x2, y2 = <span class="built_in">int</span>(np.ceil(rx)), <span class="built_in">int</span>(np.ceil(ry))</span><br><span class="line">		<span class="comment"># 将坐标偏移量映射到 0-1</span></span><br><span class="line">		tx = rx - x1</span><br><span class="line">		ty = ry - y1</span><br><span class="line">		<span class="comment"># 计算插值的权重</span></span><br><span class="line">		ww[k, <span class="number">0</span>] = (<span class="number">1</span> - tx) * (<span class="number">1</span> - ty)</span><br><span class="line">		ww[k, <span class="number">1</span>] = tx * (<span class="number">1</span> - ty)</span><br><span class="line">		ww[k, <span class="number">2</span>] = (<span class="number">1</span> - tx) * ty</span><br><span class="line">		ww[k, <span class="number">3</span>] = tx * ty</span><br><span class="line">		p[k, <span class="number">0</span>], p[k, <span class="number">1</span>], p[k, <span class="number">2</span>], p[k, <span class="number">3</span>] = x1, y1, x2, y2</span><br><span class="line">	dst = np.zeros((height-<span class="number">2</span>*r, width-<span class="number">2</span>*r), np.uint8)</span><br><span class="line">	<span class="keyword">for</span> h <span class="keyword">in</span> <span class="built_in">range</span>(r, height-r):</span><br><span class="line">		<span class="keyword">for</span> w <span class="keyword">in</span> <span class="built_in">range</span>(r, width-r):</span><br><span class="line">			center = gray[h, w]  <span class="comment"># 中心像素点的灰度值</span></span><br><span class="line">			<span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">				<span class="comment"># 双线性插值估计采样点 k 的灰度值</span></span><br><span class="line">				<span class="comment"># neighbor = gray[i+y1,j+x1]*w1 + gray[i+y2,j+x1]*w2 + gray[i+y1,j+x2]*w3 + gray[i+y2,j+x2]*w4</span></span><br><span class="line">				x1, y1, x2, y2 = p[k,<span class="number">0</span>], p[k,<span class="number">1</span>], p[k,<span class="number">2</span>], p[k,<span class="number">3</span>]</span><br><span class="line">				gInterp = np.array([gray[h+y1,w+x1], gray[h+y2,w+x1], gray[h+y1,w+x2], gray[h+y2,w+x2]])</span><br><span class="line">				wFlatten = ww[k,:]</span><br><span class="line">				grayNeighbor = np.vdot(gInterp, wFlatten)  <span class="comment"># 一维向量的内积</span></span><br><span class="line">				<span class="comment"># 由 N 个采样点与中心像素点的灰度值比较，构造 LBP 特征编码</span></span><br><span class="line">				dst[h-r, w-r] |= (grayNeighbor &gt; center) &lt;&lt; (np.uint8)(n-k-<span class="number">1</span>)</span><br><span class="line">	<span class="keyword">return</span> dst</span><br><span class="line"><span class="comment"># 特征描述之 extendLBP 改进算子</span></span><br><span class="line">img = cv2.imread(<span class="string">"../images/fabric1.png"</span>, flags=<span class="number">1</span>)</span><br><span class="line">gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  <span class="comment"># 灰度图像</span></span><br><span class="line"><span class="comment"># 1) skimage 特征检测</span></span><br><span class="line"><span class="keyword">from</span> skimage.feature <span class="keyword">import</span> local_binary_pattern</span><br><span class="line">timeBegin = cv2.getTickCount()</span><br><span class="line">lbpSKimage = local_binary_pattern(gray, <span class="number">8</span>, <span class="number">1</span>)</span><br><span class="line">imgLBP1 = basicLBP(gray)  <span class="comment"># 从右上角开始顺时针旋转</span></span><br><span class="line">r1, n1 = <span class="number">3</span>, <span class="number">8</span></span><br><span class="line">imgLBP2 = extendLBP(gray, r1, n1)</span><br><span class="line">r2, n2 = <span class="number">5</span>, <span class="number">8</span></span><br><span class="line">imgLBP3 = extendLBP(gray, r2, n2)</span><br><span class="line">show_images([img,gray,lbpSKimage,imgLBP1,imgLBP2,imgLBP3])</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="目标区域的lbp-直方图"><a class="markdownIt-Anchor" href="#目标区域的lbp-直方图"></a> 目标区域的 “LBP 直方图”？</h3><ul><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121416491.png" alt=""></li><li>图像可以用 LBP 特征向量来表示，但在应用中一般并不是直接使用 LBP 图谱进行分类识别，而是使用 LBP 特征谱的统计直方图进行分类识别。因为 LBP 特征是与图像中的位置紧密相关的，直接对两幅图片提取 LBP 特征进行判别分析，会由于位置没有对准而带来很大的误差</li><li>为了解决这个问题，可以将图像划分为若干子区域，对每个子区域内提取 LBP 特征后在子区域内建立 LBP 特征的统计直方图。图片的每个子区域可以用一个统计直方图来描述，整个图片就由若干个统计直方图组成，称为 LBP 特征的统计直方图<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">basicLBP</span>(<span class="params">gray</span>):</span><br><span class="line">	height, width = gray.shape</span><br><span class="line">	dst = np.zeros((height, width), np.uint8)</span><br><span class="line">	kernelFlatten = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">128</span>, <span class="number">0</span>, <span class="number">8</span>, <span class="number">64</span>, <span class="number">32</span>, <span class="number">16</span>])  <span class="comment"># 从左上角开始顺时针旋转</span></span><br><span class="line">	<span class="keyword">for</span> h <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, height-<span class="number">1</span>):</span><br><span class="line">		<span class="keyword">for</span> w <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, width-<span class="number">1</span>):</span><br><span class="line">			LBPFlatten = (gray[h-<span class="number">1</span>:h+<span class="number">2</span>, w-<span class="number">1</span>:w+<span class="number">2</span>] &gt;= gray[h, w]).flatten()  <span class="comment"># 展平为一维向量, (9,)</span></span><br><span class="line">			dst[h, w] = np.vdot(LBPFlatten, kernelFlatten)  <span class="comment"># 一维向量的内积</span></span><br><span class="line">	<span class="keyword">return</span> dst</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calLBPHistogram</span>(<span class="params">imgLBP, nCellX, nCellY</span>):  <span class="comment"># 计算 LBP 直方图</span></span><br><span class="line">	height, width = gray.shape</span><br><span class="line">	<span class="comment"># nCellX, nCellY = 4, 4  # 将图像划分为 nCellX*nCellY 个子区域</span></span><br><span class="line">	hCell, wCell = height//nCellY, width//nCellX  <span class="comment"># 子区域的高度与宽度 (150,120)</span></span><br><span class="line">	LBPHistogram = np.zeros((nCellX*nCellY, <span class="number">256</span>), np.<span class="built_in">int</span>)</span><br><span class="line">	<span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(nCellY):</span><br><span class="line">		<span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(nCellX):</span><br><span class="line">			cell = imgLBP[j * hCell:(j + <span class="number">1</span>) * hCell, i * wCell:(i + <span class="number">1</span>) * wCell].copy()  <span class="comment"># 子区域 cell LBP</span></span><br><span class="line">			<span class="built_in">print</span>(<span class="string">"{}, Cell({}{}): [{}:{}, {}:{}]"</span>.<span class="built_in">format</span></span><br><span class="line">				  (j*nCellX+i+<span class="number">1</span>, j+<span class="number">1</span>, i+<span class="number">1</span>, j*hCell, (j+<span class="number">1</span>)*hCell, i*wCell, (i+<span class="number">1</span>)*wCell))</span><br><span class="line">			histCell = cv2.calcHist([cell], [<span class="number">0</span>], <span class="literal">None</span>, [<span class="number">256</span>], [<span class="number">0</span>, <span class="number">256</span>])  <span class="comment"># 子区域 LBP 直方图</span></span><br><span class="line">			LBPHistogram[(i+<span class="number">1</span>)*(j+<span class="number">1</span>)-<span class="number">1</span>, :] = histCell.flatten()</span><br><span class="line">	<span class="built_in">print</span>(LBPHistogram.shape)</span><br><span class="line">	<span class="keyword">return</span> LBPHistogram</span><br><span class="line"><span class="comment"># 特征描述之 LBP 直方图</span></span><br><span class="line">img = cv2.imread(<span class="string">"../images/fabric2.png"</span>, flags=<span class="number">1</span>)</span><br><span class="line">gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  <span class="comment"># 灰度图像</span></span><br><span class="line">height, width = gray.shape</span><br><span class="line">nCellX, nCellY = <span class="number">4</span>, <span class="number">4</span>  <span class="comment"># 将图像划分为 nCellX*nCellY 个子区域</span></span><br><span class="line">hCell, wCell = height//nCellY, width//nCellX  <span class="comment"># 子区域的高度与宽度 (150,120)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"img: h={},w={}, cell: h={},w={}"</span>.<span class="built_in">format</span>(height, width, hCell, wCell))</span><br><span class="line">basicLBP = basicLBP(gray)  <span class="comment"># 计算 basicLBP 特征算子</span></span><br><span class="line"><span class="comment"># LBPHistogram = calLBPHistogram(basicLBP, nCellX, nCellY)  # 计算 LBP 直方图 (16, 256)</span></span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(nCellY):</span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(nCellX):</span><br><span class="line">		cell = basicLBP[j*hCell:(j+<span class="number">1</span>)*hCell, i*wCell:(i+<span class="number">1</span>)*wCell].copy()  <span class="comment"># 子区域 cell LBP</span></span><br><span class="line">		histCV = cv2.calcHist([cell], [<span class="number">0</span>], <span class="literal">None</span>, [<span class="number">256</span>], [<span class="number">0</span>, <span class="number">256</span>])  <span class="comment"># 子区域 cell LBP 直方图</span></span><br><span class="line">		ax1 = fig1.add_subplot(nCellY, nCellX, j * nCellX + i + <span class="number">1</span>)</span><br><span class="line">		ax1.set_xticks([]), ax1.set_yticks([])</span><br><span class="line">		ax1.imshow(cell, <span class="string">'gray'</span>)  <span class="comment"># 绘制子区域 LBP  </span></span><br><span class="line">		ax2 = fig2.add_subplot(nCellY,nCellX,j*nCellX+i+<span class="number">1</span>)</span><br><span class="line">		ax2.set_xticks([]), ax2.set_yticks([])</span><br><span class="line">		ax2.bar(<span class="built_in">range</span>(<span class="number">256</span>), histCV[:, <span class="number">0</span>])  <span class="comment"># 绘制子区域 LBP 直方图</span></span><br><span class="line">		<span class="built_in">print</span>(<span class="string">"{}, Cell({}{}): [{}:{}, {}:{}]"</span>.<span class="built_in">format</span></span><br><span class="line">			  (j * nCellX + i + <span class="number">1</span>, j + <span class="number">1</span>, i + <span class="number">1</span>, j * hCell, (j + <span class="number">1</span>) * hCell, i * wCell, (i + <span class="number">1</span>) * wCell))</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="目标区域的灰度共生矩阵-glcm"><a class="markdownIt-Anchor" href="#目标区域的灰度共生矩阵-glcm"></a> 目标区域的灰度共生矩阵 (GLCM)?</h3><ul><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121417695.png" alt=""></li><li>灰度共生矩阵（Gray level co-occurrence matrix，<a target="_blank" rel="noopener" href="https://so.csdn.net/so/search?q=GLCM&amp;spm=1001.2101.3001.7020">GLCM</a>）是特征检测与分析的重要方法，在纹理分析、特征分类、图像质量评价中应用广泛</li><li>图像的像素具有不同的灰度级，灰度共生矩阵表示不同灰度组合同时出现的频率。简单地说，灰度共生矩阵反映灰度图像中<strong>某种形状的像素对</strong>在整个图像中<strong>出现的次数</strong></li><li>灰度共生矩阵的数据量很大，一般不直接用它来描述纹理特征，而是构建一些统计量作为纹理分类特征。例如，能量、熵、对比度、均匀性、相关性、方差等<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> skimage.feature <span class="keyword">import</span> greycomatrix, greycoprops</span><br><span class="line">img = cv2.imread(<span class="string">"../images/fabric1.png"</span>, flags=<span class="number">1</span>)</span><br><span class="line">gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  <span class="comment"># 灰度图像</span></span><br><span class="line">height, width = gray.shape</span><br><span class="line">table16 = np.array([(i//<span class="number">16</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">256</span>)]).astype(<span class="string">"uint8"</span>)  <span class="comment"># 16 levels</span></span><br><span class="line">gray16 = cv2.LUT(gray, table16)  <span class="comment"># 灰度级压缩为 [0,15]</span></span><br><span class="line"><span class="comment"># 计算灰度共生矩阵 GLCM</span></span><br><span class="line">dist = [<span class="number">1</span>, <span class="number">4</span>]  <span class="comment"># 计算 2 个距离偏移量 [1, 2]</span></span><br><span class="line">degree = [<span class="number">0</span>, np.pi/<span class="number">4</span>, np.pi/<span class="number">2</span>, np.pi*<span class="number">3</span>/<span class="number">4</span>]  <span class="comment"># 计算 4 个方向</span></span><br><span class="line">glcm = greycomatrix(gray16, dist, degree, levels=<span class="number">16</span>)  <span class="comment"># 灰度级 L=16</span></span><br><span class="line"><span class="built_in">print</span>(glcm.shape)  <span class="comment"># (16,16,2,4)</span></span><br><span class="line"><span class="comment"># 由灰度共生矩阵 GLCM 计算特征统计量</span></span><br><span class="line"><span class="keyword">for</span> prop <span class="keyword">in</span> [<span class="string">'contrast'</span>, <span class="string">'dissimilarity'</span>,<span class="string">'homogeneity'</span>, <span class="string">'energy'</span>, <span class="string">'correlation'</span>, <span class="string">'ASM'</span>]:</span><br><span class="line">	feature= greycoprops(glcm, prop).<span class="built_in">round</span>(<span class="number">4</span>)  <span class="comment"># (2,4)</span></span><br><span class="line">	<span class="built_in">print</span>(<span class="string">"{}: {}"</span>.<span class="built_in">format</span>(prop, feature))</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="目标区域纹理特征的频谱方法"><a class="markdownIt-Anchor" href="#目标区域纹理特征的频谱方法"></a> 目标区域纹理特征的频谱方法？</h3><ul><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121416811.png" alt=""></li><li>傅里叶谱可以描述图像中的周期性或半周期性二维模式的方向性，因此可以基于傅里叶变换对纹理进行频谱分析</li><li>纹理与图像频谱中的高频分量密切相关，纹理模式在频谱图表现为高能量的爆发</li></ul><h3 id="目标区域特征的矩不变量"><a class="markdownIt-Anchor" href="#目标区域特征的矩不变量"></a> 目标区域特征的矩不变量？</h3><ul><li>图像矩是对特征进行参数描述的一种算法，通常描述了图像形状的全局特征，并提供了大量的关于该图像不同类型的几何特性信息，比如大小、位置、方向及形状等</li><li>Hu 利用二阶和三阶归一化中心距构造了 7 个不变矩 M1~M7，在连续图像下具有平移、灰度、尺度、旋转不变性，是高度浓缩的图像特征。不变矩能够描述图像的整体性质，从而在边缘提取、图像匹配及目标识别中得到了广泛的应用<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">gray = cv2.imread(<span class="string">"../images/Fig1137.tif"</span>, flags=<span class="number">0</span>)  <span class="comment"># 灰度图像</span></span><br><span class="line">height, width = gray.shape  <span class="comment"># (568, 568)</span></span><br><span class="line"><span class="comment"># 图像的平移，缩放，旋转和镜像</span></span><br><span class="line">grayList = []</span><br><span class="line">grayList.append(gray)  <span class="comment"># [0]，原始图像</span></span><br><span class="line">mat = np.float32([[<span class="number">1</span>, <span class="number">0</span>, <span class="number">50</span>], [<span class="number">0</span>, <span class="number">1</span>, <span class="number">50</span>]])</span><br><span class="line">grayList.append(cv2.warpAffine(gray, mat, (height, width)))  <span class="comment"># [1]，图像平移</span></span><br><span class="line">top, bottom, left, right = height//<span class="number">4</span>, height//<span class="number">4</span>, width//<span class="number">4</span>, width//<span class="number">4</span></span><br><span class="line">grayResize = cv2.resize(gray, (width//<span class="number">2</span>, height//<span class="number">2</span>))  <span class="comment"># 图像缩放 (284, 284)</span></span><br><span class="line">replicate = cv2.copyMakeBorder(grayResize, top, bottom, left, right, cv2.BORDER_CONSTANT, value=<span class="number">0</span>)</span><br><span class="line">grayList.append(replicate)  <span class="comment"># [2]，图像缩放并填充至原来尺寸 (568, 568)</span></span><br><span class="line">grayList.append(cv2.flip(gray, <span class="number">1</span>))  <span class="comment"># [3]，图像镜像，水平翻转</span></span><br><span class="line">mar = cv2.getRotationMatrix2D((width//<span class="number">2</span>, height//<span class="number">2</span>), angle=<span class="number">45</span>, scale=<span class="number">1</span>)  <span class="comment"># 图像中心作为旋转中心</span></span><br><span class="line">rotate = cv2.warpAffine(gray, mar, (height, width))  <span class="comment"># 旋转变换，默认为黑色填充</span></span><br><span class="line">grayList.append(rotate)  <span class="comment"># [4]，图像旋转 45度</span></span><br><span class="line">grayList.append(cv2.rotate(gray, cv2.ROTATE_90_COUNTERCLOCKWISE))  <span class="comment"># [5]，图像逆时针旋转90度</span></span><br><span class="line">plt.figure(figsize=(<span class="number">9</span>, <span class="number">6</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(grayList)):</span><br><span class="line">	moments = cv2.moments(grayList[i])  <span class="comment"># 返回几何矩 mpq, 中心矩 mupq 和归一化矩 nupq</span></span><br><span class="line">	huM = cv2.HuMoments(moments)  <span class="comment"># 计算 Hu 不变矩</span></span><br><span class="line">	plt.subplot(<span class="number">2</span>,<span class="number">3</span>,i+<span class="number">1</span>), plt.axis(<span class="string">'off'</span>), plt.imshow(grayList[i], <span class="string">'gray'</span>)</span><br><span class="line">	<span class="comment"># print("Moments of gray:\n", moments)</span></span><br><span class="line">	<span class="built_in">print</span>(<span class="string">"HuMoments of gray:\n"</span>, np.log10(np.<span class="built_in">abs</span>(huM.T)).<span class="built_in">round</span>(<span class="number">4</span>))</span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="什么是角点"><a class="markdownIt-Anchor" href="#什么是角点"></a> 什么是角点？</h3><ul><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121416278.png" alt=""></li><li>角点的定义很多，可以指一阶导数 (即灰度的梯度) 的局部最大所对应的像素点，也可以指两条及两条以上边缘的交点</li><li>角点检测算法基本思想是使用一个固定窗口（取某个像素的一个邻域窗口）在图像上进行<strong>任意方向</strong>上的滑动，比较滑动前与滑动后两种情况，窗口中的像素灰度变化程度，<strong>如果存在任意方向上的滑动，都有着较大灰度变化，那么我们可以认为该窗口中存在角点</strong></li><li>角点可以应用<strong>三维场景重建运动估计</strong>，目标跟踪、目标识别、<strong>图像配准与匹配</strong>等计算机视觉领域</li></ul><h3 id="opencv-的-harris-角点检测算法"><a class="markdownIt-Anchor" href="#opencv-的-harris-角点检测算法"></a> OpenCV 的 Harris 角点检测算法？</h3><ul><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121416811.png" alt=""></li><li>在基于灰度变换的角点检测算法中，Harris 算法重复性良好、检测效率较高，应用较为广泛。Harris 的原理是，通过检测窗口在图像上移动，计算移动前后窗口中像素的灰度变化。角点是两条边的交点，其特征是检测窗口沿任意方向移动都会导致灰度的显著变化<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">img = cv2.imread(<span class="string">"../images/Chess01.png"</span>, flags=<span class="number">1</span>)</span><br><span class="line">gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  <span class="comment"># (600, 540)</span></span><br><span class="line">blockSize = [<span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>]  <span class="comment"># 滑动窗口大小</span></span><br><span class="line">ksize = [<span class="number">3</span>, <span class="number">5</span>, <span class="number">9</span>]  <span class="comment"># Sobel 核函数大小</span></span><br><span class="line">plt.figure(figsize=(<span class="number">9</span>, <span class="number">9</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(blockSize)):</span><br><span class="line">	<span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(ksize)):</span><br><span class="line">		dst = cv2.cornerHarris(gray, blockSize[i], ksize[j], k=<span class="number">0.04</span>)</span><br><span class="line">		imgCorner = np.copy(img)</span><br><span class="line">		imgCorner[dst &gt; <span class="number">0.01</span>*dst.<span class="built_in">max</span>()] = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>]  <span class="comment"># 筛选角点，红色标记</span></span><br><span class="line">		show_images([imgCorner])</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="opencv-的-harris-角点检测之精确定位"><a class="markdownIt-Anchor" href="#opencv-的-harris-角点检测之精确定位"></a> OpenCV 的 Harris 角点检测之精确定位？</h3><ul><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121416025.png" alt=""></li><li>OpenCV 提供了函数 cv.cornerSubPix () 用于细化角点位置，细化了以亚像素精度检测到的角点位置<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">img = cv2.imread(<span class="string">"../images/sign01.png"</span>, flags=<span class="number">1</span>)</span><br><span class="line">gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  <span class="comment"># (600, 540)</span></span><br><span class="line"><span class="built_in">print</span>(img.shape)  <span class="comment"># (600, 836, 3)</span></span><br><span class="line"><span class="comment"># 角点检测</span></span><br><span class="line">gray = np.float32(gray)    <span class="comment"># uint8，float32 都支持</span></span><br><span class="line">dst = cv2.cornerHarris(gray, <span class="number">2</span>, <span class="number">3</span>, <span class="number">0.04</span>)  <span class="comment"># Harris 角点检测</span></span><br><span class="line">_, dst = cv2.threshold(dst, <span class="number">0.01</span> * dst.<span class="built_in">max</span>(), <span class="number">255</span>, <span class="number">0</span>)  <span class="comment"># 提取角点</span></span><br><span class="line">dst = np.uint8(dst)  <span class="comment"># (600, 836)</span></span><br><span class="line"><span class="comment"># 角点检测结果图像</span></span><br><span class="line">imgCorner = np.copy(img)</span><br><span class="line">imgCorner[:,:,<span class="number">2</span>] = cv2.bitwise_or(imgCorner[:,:,<span class="number">2</span>], dst)  <span class="comment"># 筛选角点，红色标记</span></span><br><span class="line"><span class="comment"># 对检测角点进行精细定位</span></span><br><span class="line">ret, labels, stats, centroids = cv2.connectedComponentsWithStats(dst)  <span class="comment"># 检测连通区域</span></span><br><span class="line">criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, <span class="number">100</span>, <span class="number">0.001</span>)  <span class="comment"># 终止判据</span></span><br><span class="line">fineCorners = cv2.cornerSubPix(gray, np.float32(centroids), (<span class="number">5</span>,<span class="number">5</span>), (-<span class="number">1</span>,-<span class="number">1</span>), criteria)  <span class="comment"># (144, 2)</span></span><br><span class="line"><span class="comment"># 精细定位检测图像</span></span><br><span class="line">imgFineCorners = np.copy(img)</span><br><span class="line">centroids = centroids.astype(np.<span class="built_in">int</span>)  <span class="comment"># 连通区域的质心 (x,y)</span></span><br><span class="line">fineCorners = fineCorners.astype(np.<span class="built_in">int</span>)  <span class="comment"># 精细定位的角点 (x,y)</span></span><br><span class="line">imgFineCorners[centroids[:, <span class="number">1</span>], centroids[:, <span class="number">0</span>]] = [<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>]  <span class="comment"># Harris 检测位置，绿色</span></span><br><span class="line">imgFineCorners[fineCorners[:, <span class="number">1</span>], fineCorners[:, <span class="number">0</span>]] = [<span class="number">0</span>,<span class="number">0</span>,<span class="number">255</span>]  <span class="comment"># 精细检测位置，红色</span></span><br><span class="line">show_images([img,imgCorner,imgFineCorners])</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="opencv-的-shi-tomasi-角点检测算法"><a class="markdownIt-Anchor" href="#opencv-的-shi-tomasi-角点检测算法"></a> OpenCV 的 Shi-Tomasi 角点检测算法？</h3><ul><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121416003.png" alt=""></li><li>Shi-Tomas 算法是对 Harris 角点检测算法的改进，一般会比 Harris 算法得到更好的角点</li><li>函数 cv. goodFeaturesToTrack 通过 Shi-Tomasi 方法找出图像中最突出的 N 个角点<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">img = cv2.imread(<span class="string">"../images/sign04.png"</span>, flags=<span class="number">1</span>)  <span class="comment"># (300, 300, 3)</span></span><br><span class="line">gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span><br><span class="line"><span class="comment"># Harris 检测角点</span></span><br><span class="line">dst = cv2.cornerHarris(gray, <span class="number">2</span>, <span class="number">3</span>, k=<span class="number">0.04</span>)</span><br><span class="line"><span class="comment"># Harris[dst &gt; 0.01*dst.max()] = [0, 0, 255]  # 筛选角点，红色标记</span></span><br><span class="line">corners = np.column_stack(np.where(dst&gt;<span class="number">0.1</span>*dst.<span class="built_in">max</span>()))  <span class="comment"># 筛选并返回角点坐标 (y,x)</span></span><br><span class="line">corners = corners.astype(np.<span class="built_in">int</span>)  <span class="comment"># 检测到的角点的点集 (y,x), (92, 2)</span></span><br><span class="line">imgHarris = np.copy(img)</span><br><span class="line"><span class="keyword">for</span> point <span class="keyword">in</span> corners:  <span class="comment"># 注意坐标次序</span></span><br><span class="line">	cv2.circle(imgHarris, (point[<span class="number">1</span>], point, <span class="number">4</span>, (<span class="number">0</span>,<span class="number">0</span>,<span class="number">255</span>), <span class="number">2</span>)  <span class="comment"># # 在点 (x,y) 处画圆</span></span><br><span class="line"><span class="comment"># Shi-tomas 检测角点</span></span><br><span class="line">corners = cv2.goodFeaturesToTrack(gray, <span class="number">30</span>, <span class="number">0.3</span>, <span class="number">5</span>)  <span class="comment"># (30, 1, 2)</span></span><br><span class="line">corners = np.squeeze(corners).astype(np.<span class="built_in">int</span>)  <span class="comment"># (30, 1, 2)-&gt;(30,2)  角点坐标 (x,y)</span></span><br><span class="line">imgShiTomas = np.copy(img)</span><br><span class="line"><span class="keyword">for</span> point <span class="keyword">in</span> corners:</span><br><span class="line">	cv2.circle(imgShiTomas, point, <span class="number">4</span>, (<span class="number">0</span>,<span class="number">0</span>,<span class="number">255</span>), <span class="number">2</span>)  <span class="comment"># # 在点 (x,y) 处画圆</span></span><br><span class="line">show_images([img,imgHarris,imgShiTomas])</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="尺度不变特征转换算法sift特征点检测算法"><a class="markdownIt-Anchor" href="#尺度不变特征转换算法sift特征点检测算法"></a> 尺度不变特征转换算法（SIFT）特征点检测算法？</h3><ul><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121416024.png" alt=""></li><li><strong>SIFT 算法的实质是在不同的尺度空间上查找关键点（特征点）</strong>，<strong>计算特征点的大小、方向、尺度信息，利用这些信息组成关键点对特征点进行描述的问题</strong>。SIFT 算法查找的关键点都是高度显著且容易获取的 “稳定” 特征点，如角点、边缘点、暗区的亮点以及亮区的暗点等，这些特征与大小、旋转无关，对于光线、噪声、视角改变的鲁棒性也很高</li><li>（1）<strong>尺度空间极值检测</strong>：通过高斯差分金字塔识别潜在的对于尺度和旋转不变的兴趣点</li><li>（2）<strong>关键点的精确定位</strong>：通过模型拟合确定关键点位置和尺度</li><li>（3）<strong>确定关键点的方向</strong>：基于图像局部的梯度方向，确定每个关键点的一个或多个方向</li><li>（4）<strong>关键点描述</strong>：在关键点的邻域内，在选定的尺度上测量图像局部的梯度。计算关键点周围 16 x 16 区域的梯度，分为 4 x 4 个子 grid 处理，每个 grid 计算 8 个方向的梯度，最终得到 4 x 4 x 8=128</li></ul><h3 id="基于-sifi-特征图像匹配算法"><a class="markdownIt-Anchor" href="#基于-sifi-特征图像匹配算法"></a> 基于 SIFI 特征图像匹配算法？</h3><ul><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121416928.png" alt=""></li><li>获取图像的尺度不变特征的关键点信息，每个关键由 128 维长度的特征描述，通过计算所有关键点的距离，完成关键点的匹配。上图是完成关键点匹配后，拿出 4 对匹配的关键点进行透视变换<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">im_src = cv2.imread(<span class="string">'book2.jpg'</span>)</span><br><span class="line">pts_src = np.array([[<span class="number">141</span>, <span class="number">131</span>], [<span class="number">480</span>, <span class="number">159</span>], [<span class="number">493</span>, <span class="number">630</span>],[<span class="number">64</span>, <span class="number">601</span>]])</span><br><span class="line">im_dst = cv2.imread(<span class="string">'book1.jpg'</span>)</span><br><span class="line">pts_dst = np.array([[<span class="number">318</span>, <span class="number">256</span>],[<span class="number">534</span>, <span class="number">372</span>],[<span class="number">316</span>, <span class="number">670</span>],[<span class="number">73</span>, <span class="number">473</span>]])</span><br><span class="line"><span class="comment">#自定义画一个多边形 测试投影关系</span></span><br><span class="line">polyline=[[<span class="number">329</span>,<span class="number">110</span>],[<span class="number">435</span>,<span class="number">110</span>],[<span class="number">389</span>,<span class="number">131</span>]]</span><br><span class="line">im_dstDraw= cv2.polylines(im_src,[np.int32(polyline)] ,<span class="literal">True</span>,<span class="number">255</span>,<span class="number">3</span>, cv2.LINE_AA)</span><br><span class="line">cv2.imshow(<span class="string">"im_dstDraw"</span>, im_dstDraw)</span><br><span class="line"><span class="comment"># 计算单应性矩阵 这个是重点</span></span><br><span class="line">h1, status = cv2.findHomography(pts_src, pts_dst)</span><br><span class="line"><span class="comment">#对图像进行透视变换，就是变形 把book1变形匹配book2</span></span><br><span class="line">im_out = cv2.warpPerspective(im_dst, h1, (im_dst.shape[<span class="number">1</span>],im_dst.shape[<span class="number">0</span>]))</span><br><span class="line">cv2.imshow(<span class="string">"im_out"</span>, im_out)</span><br><span class="line"><span class="comment">#取图片高宽</span></span><br><span class="line">h,w = im_dst.shape[<span class="number">1</span>],im_dst.shape[<span class="number">0</span>]</span><br><span class="line">pts = np.float32(polyline).reshape(-<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line"><span class="comment">#透视变换  是将图片投影到一个新的视平面</span></span><br><span class="line">dst = cv2.perspectiveTransform(pts,h1)</span><br><span class="line"><span class="comment">#绘制变换关系</span></span><br><span class="line">img2 = cv2.polylines(im_dst,[np.int32(dst)],<span class="literal">True</span>,<span class="number">55</span>,<span class="number">3</span>, cv2.LINE_AA)</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="surf-特征点检测算法"><a class="markdownIt-Anchor" href="#surf-特征点检测算法"></a> SURF 特征点检测算法？</h3><ul><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121416003.png" alt=""></li><li>SURF 算法的结构框架与 SIFT 类似，基本步骤包括：构造尺度空间、检测关键点、选取主方向和特征描述</li><li>（1）<strong>基于均值滤波器实现 Hessian 矩阵</strong>：SIFT 算法先构造尺度空间检测极值点，再通过 Hessian 矩阵判别并消除不稳定的边缘效应</li><li>（2）<strong>构造尺度空间</strong>：为了获取特征点的尺度参数，可以通过建立图像金字塔构造尺度空间</li><li>（3）<strong>特征点定位</strong>：特征点定位的方法与 SIFT 算法类似</li><li>（4）<strong>选取关键点的主方向</strong>：为了保证特征矢量具有旋转不变形，需要对于每一个特征点分配一个主要方向</li><li>（5）<strong>构造关键点的特征描述子</strong>：SIFT 把关键点的邻域划分为 4x4=16 个子块，每个子块统计 8 个方向的梯度，得到 4x4x8=128 维向量量作为 SIFT 描述子；通过主方向旋转矫正后，SURF 将关键点周围 20s×20s 的邻域划分为 4×4=16 个子块，每个子块 5s×5s 个像素。对每个子块，用尺度为 2S 的 Haar 小波计算水平方向和垂直方向（相对于主方向）的小波响应值，构造 4 维特征向量。<strong>将 4×4 个子块的 4 维特征向量 v 组合，形成 64 位的特征向量</strong>，就是 SURF 的特征描述符<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">img = cv.imread(<span class="string">"../images/Circuit04.png"</span>, flags=<span class="number">1</span>)</span><br><span class="line">gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)  <span class="comment"># (425, 558)</span></span><br><span class="line">height, width = gray.shape[:<span class="number">2</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"shape of image: "</span>, height, width)</span><br><span class="line"><span class="comment"># 比较：SIFT 关键点检测</span></span><br><span class="line"><span class="comment"># sift = cv.xfeatures2d.SIFT_create()  # OpenCV 早期版本</span></span><br><span class="line">sift = cv.SIFT.create()  <span class="comment"># sift 实例化对象</span></span><br><span class="line">kpSift = sift.detect(gray, <span class="literal">None</span>)  <span class="comment"># 关键点检测，kp 为关键点信息（包括方向）</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"shape of keypoints: "</span>, <span class="built_in">len</span>(kpSift))  <span class="comment"># 775</span></span><br><span class="line">imgSift1 = cv.drawKeypoints(img, kpSift, <span class="literal">None</span>)  <span class="comment"># 只绘制关键点位置</span></span><br><span class="line">imgSift2 = cv.drawKeypoints(img, kpSift, <span class="literal">None</span>, flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)  <span class="comment"># 绘制关键点大小和方向</span></span><br><span class="line"><span class="comment"># 比较：SURF 关键点检测</span></span><br><span class="line">surf = cv.xfeatures2d.SURF.create(<span class="number">1000</span>)  <span class="comment"># surf 实例化对象</span></span><br><span class="line">kpSurf, desSurf = surf.detect(gray, <span class="literal">None</span>)  <span class="comment"># 关键点检测，kp 为关键点信息（包括方向）</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"shape of keypoints: "</span>, <span class="built_in">len</span>(kpSurf))  <span class="comment"># 775</span></span><br><span class="line">imgSurf1 = cv.drawKeypoints(img, kpSurf, <span class="literal">None</span>)  <span class="comment"># 只绘制关键点位置</span></span><br><span class="line">imgSurf2 = cv.drawKeypoints(img, kpSurf, <span class="literal">None</span>, flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)  <span class="comment"># 绘制关键点大小和方向</span></span><br><span class="line">show_images([imgSift1,imgSift2,imgSurf1,imgSurf2])</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="fast-特征点检测算法"><a class="markdownIt-Anchor" href="#fast-特征点检测算法"></a> FAST 特征点检测算法？</h3><ul><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121416191.png" alt=""></li><li>一种特征点检测算法，用于特征提取但不涉及特征描述。SIFT、SURF 的计算量很大，难以满足实时性的要求。Edward Rosten 在 2006 年提出了 FAST 特征检测算法。FAST 算法通过与圆周像素的比较结果判别特征点，计算速度快、可重复性高，非常适合实时视频的处理</li><li><strong>FAST 算法逻辑</strong>：如果像素点与其周围邻域内多个像素相差较大，则该像素点可能是角点。因此，在以像素点为中心的圆周上均匀地取 16 个像素点，如果其中连续 N 个像素点与中心点的像素值之差都大于设置的阈值，则中心像素被判定为角点。具体有两种情况，一是连续 N 个像素点都比中心点更亮，二是连续 N 个像素点都比中心点更暗，且亮度差都大于设置的阈值 t<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">img = cv.imread(<span class="string">"../images/Circuit04.png"</span>, flags=<span class="number">1</span>)  <span class="comment"># 基准图像</span></span><br><span class="line">gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)  <span class="comment"># (425, 558)</span></span><br><span class="line">height, width = gray.shape[:<span class="number">2</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"shape of image: "</span>, height, width)</span><br><span class="line">fast = cv.FastFeatureDetector_create()  <span class="comment"># 初始化 FAST 对象</span></span><br><span class="line"><span class="comment"># 默认值：threshold=10, nonmaxSuppression=true, type=FastFeatureDetector::TYPE_9_16</span></span><br><span class="line">kpNMS1 = fast.detect(img, <span class="literal">None</span>)  <span class="comment"># 检测关键点</span></span><br><span class="line">imgFASTnms1 = cv.drawKeypoints(img, kpNMS1, <span class="literal">None</span>, color=(<span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span>))</span><br><span class="line"><span class="comment"># 关闭非极大抑制</span></span><br><span class="line">fast.setNonmaxSuppression(<span class="number">0</span>)  <span class="comment"># nonmaxSuppression=false</span></span><br><span class="line">kp1 = fast.detect(img, <span class="literal">None</span>)</span><br><span class="line">imgFAST1 = cv.drawKeypoints(img, kp1, <span class="literal">None</span>, color=(<span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"\nthreshold: {}"</span>.<span class="built_in">format</span>(fast.getThreshold()))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"num of Keypoints without NMS: {}"</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(kp1)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"num of Keypoints with NMS: {}"</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(kpNMS1)))</span><br><span class="line">fastT2 = cv.FastFeatureDetector_create(threshold=<span class="number">20</span>)  <span class="comment"># 设置差分阈值为 20</span></span><br><span class="line">kpNMS2 = fastT2.detect(img, <span class="literal">None</span>)  <span class="comment"># 检测关键点</span></span><br><span class="line">imgFASTnms2 = cv.drawKeypoints(img, kpNMS2, <span class="literal">None</span>, color=(<span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span>))</span><br><span class="line"><span class="comment"># 关闭非极大抑制</span></span><br><span class="line">fastT2.setNonmaxSuppression(<span class="number">0</span>)  <span class="comment"># nonmaxSuppression=false</span></span><br><span class="line">kp2 = fastT2.detect(img, <span class="literal">None</span>)</span><br><span class="line">imgFAST2 = cv.drawKeypoints(img, kp2, <span class="literal">None</span>, color=(<span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"\nthreshold: {}"</span>.<span class="built_in">format</span>(fastT2.getThreshold()))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"num of Keypoints without NMS: {}"</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(kp2)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"num of Keypoints with NMS: {}"</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(kpNMS2)))</span><br><span class="line">fastT3 = cv.FastFeatureDetector_create(threshold=<span class="number">40</span>)  <span class="comment"># 设置差分阈值为 40</span></span><br><span class="line">kpNMS3 = fastT3.detect(img, <span class="literal">None</span>)  <span class="comment"># 检测关键点</span></span><br><span class="line">imgFASTnms3 = cv.drawKeypoints(img, kpNMS3, <span class="literal">None</span>, color=(<span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span>))</span><br><span class="line"><span class="comment"># 关闭非极大抑制</span></span><br><span class="line">fastT3.setNonmaxSuppression(<span class="number">0</span>)  <span class="comment"># nonmaxSuppression=false</span></span><br><span class="line">kp3 = fastT3.detect(img, <span class="literal">None</span>)</span><br><span class="line">imgFAST3 = cv.drawKeypoints(img, kp3, <span class="literal">None</span>, color=(<span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"\nthreshold: {}"</span>.<span class="built_in">format</span>(fastT3.getThreshold()))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"num of Keypoints without NMS: {}"</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(kp3)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"num of Keypoints with NMS: {}"</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(kpNMS3)))</span><br><span class="line">show_images([imgFAST1,imgFAST2,imgFAST3])</span><br><span class="line">show_images([imgFAST1,imgFAST2,imgFAST3])</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="brief-特征点检测算法"><a class="markdownIt-Anchor" href="#brief-特征点检测算法"></a> BRIEF 特征点检测算法？</h3><ul><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121417991.png" alt=""></li><li>二进制鲁棒独立的特征描述 BRIEF （Binary Robust Independent Elementary Features），对检测到的特征点构造特征描述子，其特点是直接生成二进制字符串作为特征描述符，效率很高</li><li>SIFT 使用 128 维的浮点数作为特征描述符，共有 512 个字节；SURF 使用 64/128 维特征描述符，共有 256/512 个字节。由于特征点常常高达数千个，这些特征描述向量所占用的内存很大，而且特征点匹配所需的时间也很长。这些特征描述符往往存在大量的数据冗余，可以进行数据压缩或转换为二进制字符串，以减少内存和加快匹配</li><li>BRIEF 描述子提供了一种直接生成二进制字符串的特征描述方法，加快了建立特征描述符的速度，也极大的降低了特征描述符的内存占用和特征匹配的时间。因此，BRIEF 算子是一种对特征点描述符计算和匹配的快速方法</li><li>BRIEF 描述子的思想是在关键点 P 的周围以一定模式选取 N 个点对，将 N 个点对的比较结果组合起来作为描述子。为了保持选点的一致性，工程上采用特殊设计的固定模式<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">img = cv.imread(<span class="string">"../images/book01.jpg"</span>, flags=<span class="number">1</span>)  <span class="comment"># 基准图像</span></span><br><span class="line">gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)  <span class="comment"># (425, 558)</span></span><br><span class="line">height, width = gray.shape[:<span class="number">2</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"shape of image: "</span>, height, width)</span><br><span class="line"><span class="comment"># SIFT 关键点检测 + SIFT 特征描述</span></span><br><span class="line"><span class="comment"># sift = cv.xfeatures2d.SIFT_create()  # OpenCV 早期版本</span></span><br><span class="line">sift = cv.SIFT.create()  <span class="comment"># sift 实例化对象</span></span><br><span class="line">kpSift = sift.detect(gray, <span class="literal">None</span>)  <span class="comment"># 关键点检测，kp 为关键点信息（包括方向）</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"shape of keypoints: "</span>, <span class="built_in">len</span>(kpSift))  <span class="comment"># 775</span></span><br><span class="line">imgSift1 = cv.drawKeypoints(img, kpSift, <span class="literal">None</span>)  <span class="comment"># 只绘制关键点位置</span></span><br><span class="line">imgSift2 = cv.drawKeypoints(img, kpSift, <span class="literal">None</span>, flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)  <span class="comment"># 绘制关键点大小和方向</span></span><br><span class="line"><span class="comment"># SIFT 关键点检测 + BRIEF 特征描述</span></span><br><span class="line">brief = cv.xfeatures2d.BriefDescriptorExtractor_create()  <span class="comment"># BRIEF 特征描述</span></span><br><span class="line">kpBrief, des = brief.compute(img, kpSift)  <span class="comment"># 对 SIFT 检测的关键点，通过 BRIEF 计算描述子</span></span><br><span class="line">imgBrief1 = cv.drawKeypoints(img, kpBrief, <span class="literal">None</span>)</span><br><span class="line">imgBrief2 = cv.drawKeypoints(img, kpBrief, <span class="literal">None</span>, flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)</span><br><span class="line"><span class="comment"># STAR 关键点检测 + BRIEF 特征描述</span></span><br><span class="line">star = cv.xfeatures2d.StarDetector_create()  <span class="comment"># STAR 特征检测</span></span><br><span class="line">brief2 = cv.xfeatures2d.BriefDescriptorExtractor_create()  <span class="comment"># BRIEF 特征描述</span></span><br><span class="line">kpStar = star.detect(img, <span class="literal">None</span>)  <span class="comment"># STAR 特征检测</span></span><br><span class="line">kpBriefStar, des = brief.compute(img, kpStar)  <span class="comment"># 通过 BRIEF 计算描述子</span></span><br><span class="line">imgBriefS1 = cv.drawKeypoints(img, kpBriefStar, <span class="literal">None</span>)</span><br><span class="line">imgBriefS2 = cv.drawKeypoints(img, kpBriefStar, <span class="literal">None</span>, flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)</span><br><span class="line">show_images([imgSift1,imgSift2,imgBrief1])</span><br><span class="line">show_images([imgBrief2,imgBriefS1,imgBriefS2])</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="brisk-特征点检测算法"><a class="markdownIt-Anchor" href="#brisk-特征点检测算法"></a> BRISK 特征点检测算法？</h3><ul><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121417170.png" alt=""></li><li>尺度不变的二进制特征描述 BRISK （Binary Robust Invariant Scalable Kepoints），是改进的 BRIEF 算法，也是二进制特征描述符。具有高计算效率和旋转不变性、尺度不变性，对噪声也有一定的鲁棒性<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">imgRef = cv.imread(<span class="string">"../images/Circuit04.png"</span>, flags=<span class="number">1</span>)  <span class="comment"># (480, 600, 3)</span></span><br><span class="line">refer = cv.cvtColor(imgRef, cv.COLOR_BGR2GRAY)  <span class="comment"># 基准图像</span></span><br><span class="line">height, width = imgRef.shape[:<span class="number">2</span>]  <span class="comment"># 图片的高度和宽度</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"shape of image: "</span>, height, width)</span><br><span class="line"><span class="comment"># 读取或构造目标图像</span></span><br><span class="line">top, left = <span class="built_in">int</span>(<span class="number">0.1</span>*height), <span class="built_in">int</span>(<span class="number">0.1</span>*width)</span><br><span class="line">border = cv.copyMakeBorder(imgRef, top, top, left, top, borderType=cv.BORDER_CONSTANT, value=(<span class="number">32</span>,<span class="number">32</span>,<span class="number">32</span>))</span><br><span class="line">zoom = cv.resize(border, (width, height), interpolation=cv.INTER_AREA)</span><br><span class="line">theta= <span class="number">15</span>  <span class="comment"># 顺时针旋转角度，单位为角度</span></span><br><span class="line">x0, y0 = width//<span class="number">2</span>, height//<span class="number">2</span>  <span class="comment"># 以图像中心作为旋转中心</span></span><br><span class="line">MAR = cv.getRotationMatrix2D((x0,y0), theta, <span class="number">1.0</span>)</span><br><span class="line">imgObj = cv.warpAffine(zoom, MAR, (width, height))  <span class="comment"># 旋转变换，默认为黑色填充</span></span><br><span class="line"><span class="comment"># imgObj = cv.imread("../images/Circuit04B.png", flags=1)  # (480, 600, 3)</span></span><br><span class="line"><span class="built_in">object</span> = cv.cvtColor(imgObj, cv.COLOR_BGR2GRAY)  <span class="comment"># 目标图像</span></span><br><span class="line"><span class="comment"># 构造 BRISK 对象，检测关键点，计算特征描述向量</span></span><br><span class="line">brisk = cv.BRISK_create()  <span class="comment"># 创建 BRISK 检测器</span></span><br><span class="line">kpRef, desRef = brisk.detectAndCompute(refer, <span class="literal">None</span>)  <span class="comment"># 基准图像关键点检测</span></span><br><span class="line">kpObj, desObj = brisk.detectAndCompute(<span class="built_in">object</span>, <span class="literal">None</span>)  <span class="comment"># 目标图像关键点检测</span></span><br><span class="line">imgRefBrisk = cv.drawKeypoints(imgRef, kpRef, <span class="literal">None</span>, flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)  <span class="comment"># 绘制关键点大小和方向</span></span><br><span class="line">imgObjBrisk = cv.drawKeypoints(imgObj, kpObj, <span class="literal">None</span>, flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)  <span class="comment"># 绘制关键点大小和方向</span></span><br><span class="line"><span class="built_in">print</span>(desRef.shape, desObj.shape)</span><br><span class="line"><span class="comment"># 特征点匹配，Brute-force matcher</span></span><br><span class="line">matcher = cv.BFMatcher()  <span class="comment"># 构造 BFmatcher 对象</span></span><br><span class="line">matches = matcher.<span class="keyword">match</span>(desRef, desObj)  <span class="comment"># 对描述子 des1, des2 进行匹配</span></span><br><span class="line">matches = <span class="built_in">sorted</span>(matches, key=<span class="keyword">lambda</span> x: x.distance)</span><br><span class="line">matches1 = cv.drawMatches(imgRef, kpRef, imgObj, kpObj, matches[:<span class="number">100</span>], <span class="literal">None</span>, flags=<span class="number">2</span>)</span><br><span class="line">show_images([matches1,imgRefBrisk,imgObjBrisk])</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="orb-特征点检测算法"><a class="markdownIt-Anchor" href="#orb-特征点检测算法"></a> ORB 特征点检测算法？</h3><ul><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121417949.png" alt=""></li><li>ORB（Oriented FAST and Rotated BRIEF）是一种快速特征点提取和描述的算法，采用改进的 FAST 关键点检测方法，使其具有方向性，并采用具有旋转不变性的 BRIEF 特征描述子。FAST 和 BRIEF 都是非常快速的特征计算方法，因此 ORB 具有非同一般的性能优势。关键过程有两个，一是如何确定关键点；二是如何为关键点生成描述子</li><li><strong>FAST 关键点</strong>：要想判断一个像素点 p 是不是 FAST 关键点，只需要判断其周围的 16 个像素点中是否有连续 N 个点的灰度值与 p 的差超出阈值</li><li><strong>BRIEF 描述子</strong>：一种二进制描述子，通常为 128 位的二进制串。它的计算方法是从关键点 p 周围随机挑选 128 个点对，对于每个点对中的两个点，如果前一个点的灰度值大于后一个点，则取 1，反之取 0<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">img = cv.imread(<span class="string">"../images/Fig1701.png"</span>, flags=<span class="number">1</span>)</span><br><span class="line">gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"shape of image: "</span>, gray.shape)</span><br><span class="line"><span class="comment"># Initiate ORB detector</span></span><br><span class="line">orb = cv.ORB_create()  <span class="comment"># 实例化 ORB 类</span></span><br><span class="line"><span class="comment"># kp, descriptors = orb.detectAndCompute(gray)  # 检测关键点和生成描述符</span></span><br><span class="line">kp = orb.detect(img, <span class="literal">None</span>)  <span class="comment"># 关键点检测，kp 为元组</span></span><br><span class="line">kp, des = orb.compute(img, kp)  <span class="comment"># 生成描述符</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"Num of keypoints: "</span>, <span class="built_in">len</span>(kp))  <span class="comment"># 500</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"Shape of kp descriptors: "</span>, des.shape)  <span class="comment"># (500,32)</span></span><br><span class="line">imgS = cv.convertScaleAbs(img, alpha=<span class="number">0.5</span>, beta=<span class="number">128</span>)</span><br><span class="line">imgKp1 = cv.drawKeypoints(imgS, kp, <span class="literal">None</span>)  <span class="comment"># 只绘制关键点位置</span></span><br><span class="line">imgKp2 = cv.drawKeypoints(imgS, kp, <span class="literal">None</span>, flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)  <span class="comment"># 绘制关键点大小和方向</span></span><br><span class="line">show_images([img,imgKp1,imgKp2])</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="censure-特征点检测算法"><a class="markdownIt-Anchor" href="#censure-特征点检测算法"></a> CenSurE 特征点检测算法？</h3><ul><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121417736.png" alt=""></li><li>在 CenSurE 算法中，在所有位置和所有尺度计算简化的中心环绕滤波器，并在局部邻域中找到极值<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">imgRef = cv.imread(<span class="string">"../images/Circuit04.png"</span>, flags=<span class="number">1</span>)  <span class="comment"># (480, 600, 3)</span></span><br><span class="line">refer = cv.cvtColor(imgRef, cv.COLOR_BGR2GRAY)  <span class="comment"># 基准图像</span></span><br><span class="line">height, width = imgRef.shape[:<span class="number">2</span>]  <span class="comment"># 图片的高度和宽度</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"shape of image: "</span>, height, width)  <span class="comment"># 480 600</span></span><br><span class="line"><span class="comment"># 读取或构造目标图像</span></span><br><span class="line">top, left = <span class="built_in">int</span>(<span class="number">0.1</span>*height), <span class="built_in">int</span>(<span class="number">0.1</span>*width)</span><br><span class="line">border = cv.copyMakeBorder(imgRef, top, top, left, top, borderType=cv.BORDER_CONSTANT, value=(<span class="number">32</span>,<span class="number">32</span>,<span class="number">32</span>))</span><br><span class="line">zoom = cv.resize(border, (width, height), interpolation=cv.INTER_AREA)</span><br><span class="line">theta= <span class="number">10</span>  <span class="comment"># 顺时针旋转角度，单位为角度</span></span><br><span class="line">x0, y0 = width//<span class="number">2</span>, height//<span class="number">2</span>  <span class="comment"># 以图像中心作为旋转中心</span></span><br><span class="line">MAR = cv.getRotationMatrix2D((x0,y0), theta, <span class="number">1.0</span>)</span><br><span class="line">imgObj = cv.warpAffine(zoom, MAR, (width, height))  <span class="comment"># 旋转变换，默认为黑色填充</span></span><br><span class="line"><span class="comment"># imgObj = cv.imread("../images/Circuit04B.png", flags=1)  # (480, 600, 3)</span></span><br><span class="line"><span class="built_in">object</span> = cv.cvtColor(imgObj, cv.COLOR_BGR2GRAY)  <span class="comment"># 目标图像</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"shape of image: "</span>, imgObj.shape)  <span class="comment"># (480, 600, 3)</span></span><br><span class="line"><span class="comment"># STAR 关键点检测</span></span><br><span class="line">star = cv.xfeatures2d.StarDetector_create()  <span class="comment"># STAR 特征检测</span></span><br><span class="line">brief = cv.xfeatures2d.BriefDescriptorExtractor_create()  <span class="comment"># BRIEF 特征描述</span></span><br><span class="line">kpStarRef = star.detect(imgRef, <span class="literal">None</span>)  <span class="comment"># STAR 基准图像关键点检测</span></span><br><span class="line">kpStarObj = star.detect(imgObj, <span class="literal">None</span>)  <span class="comment"># STAR 目标图像关键点检测</span></span><br><span class="line"><span class="comment"># BRIEF 特征描述</span></span><br><span class="line">kpStarRef, desBriefRef = brief.compute(imgRef, kpStarRef)  <span class="comment"># 通过 BRIEF 计算描述子</span></span><br><span class="line">kpStarObj, desBriefObj = brief.compute(imgObj, kpStarObj)  <span class="comment"># 通过 BRIEF 计算描述子</span></span><br><span class="line"><span class="comment"># 特征点匹配，Brute-force matcher</span></span><br><span class="line">matcher = cv.BFMatcher()  <span class="comment"># 构造 BFmatcher 对象</span></span><br><span class="line">matches = matcher.<span class="keyword">match</span>(desBriefRef, desBriefObj)  <span class="comment"># 对描述子 des1, des2 进行匹配</span></span><br><span class="line">matches = <span class="built_in">sorted</span>(matches, key=<span class="keyword">lambda</span> x: x.distance)</span><br><span class="line">matches1 = cv.drawMatches(imgRef, kpStarRef, imgObj, kpStarObj, matches[:<span class="number">100</span>], <span class="literal">None</span>, flags=<span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">'queryIdx=%d'</span> % matches[<span class="number">0</span>].queryIdx)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">'trainIdx=%d'</span> % matches[<span class="number">0</span>].trainIdx)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">'distance=%d'</span> % matches[<span class="number">0</span>].distance)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"bf.match:{}"</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(matches)))</span><br><span class="line">imgRefStar = cv.drawKeypoints(imgRef, kpStarRef, <span class="literal">None</span>, flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)  <span class="comment"># 绘制关键点大小和方向</span></span><br><span class="line">imgObjStar = cv.drawKeypoints(imgObj, kpStarObj, <span class="literal">None</span>, flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)  <span class="comment"># 绘制关键点大小和方向</span></span><br><span class="line">show_images([matches1,imgRefStar,imgObjStar])</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="特征检测之最大稳定极值区域mser"><a class="markdownIt-Anchor" href="#特征检测之最大稳定极值区域mser"></a> 特征检测之最大稳定极值区域（MSER）</h3><ul><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121417192.png" alt=""></li><li>最大稳定极值区域（MSER-Maximally Stable Extremal Regions），是一种检测图像文本区域的算法，基于分水岭的思想对图像进行斑点区域检测。MSER 算法具有仿射不变性，对灰度的变化具有较强的鲁棒性，但检测准确率低于深度学习方法，主要用于自然场景的文本检测的前期阶段</li><li>SER 算法对灰度图像进行阈值处理，阈值从 0 到 255 依次递增，类似于分水岭算法中的水平面的上升。最低点首先被淹没，随着水面的上升逐渐淹没整个山谷，直到所有的点全部被淹没。在不同阈值下，如果某些连通区域不变或变化很小，则该区域称为最大稳定极值区域<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">NonMaxSuppression</span>(<span class="params">boxes, thresh=<span class="number">0.5</span></span>):</span><br><span class="line">	x1, y1 = boxes[:,<span class="number">0</span>], boxes[:,<span class="number">1</span>]</span><br><span class="line">	x2, y2 = boxes[:,<span class="number">0</span>]+boxes[:,<span class="number">2</span>], boxes[:,<span class="number">1</span>]+boxes[:,<span class="number">3</span>]</span><br><span class="line">	area = boxes[:,<span class="number">2</span>] * boxes[:,<span class="number">3</span>]  <span class="comment"># 计算面积</span></span><br><span class="line">	<span class="comment"># 删除重复的矩形框</span></span><br><span class="line">	pick = []</span><br><span class="line">	idxs = np.argsort(y2)  <span class="comment"># 返回的是右下角坐标从小到大的索引值</span></span><br><span class="line">	<span class="keyword">while</span> <span class="built_in">len</span>(idxs) &gt; <span class="number">0</span>:        </span><br><span class="line">		last = <span class="built_in">len</span>(idxs) - <span class="number">1</span>  <span class="comment"># 将最右下方的框放入pick 数组</span></span><br><span class="line">		i = idxs[last]</span><br><span class="line">		pick.append(i)</span><br><span class="line">		<span class="comment"># 剩下框中最大的坐标(x1Max,y1Max)和最小的坐标(x2Min,y2Min)</span></span><br><span class="line">		x1Max = np.maximum(x1[i], x1[idxs[:last]])</span><br><span class="line">		y1Max = np.maximum(y1[i], y1[idxs[:last]])</span><br><span class="line">		x2Min = np.minimum(x2[i], x2[idxs[:last]])</span><br><span class="line">		y2Min = np.minimum(y2[i], y2[idxs[:last]])</span><br><span class="line">		<span class="comment"># 重叠面积的占比</span></span><br><span class="line">		w = np.maximum(<span class="number">0</span>, x2Min-x1Max+<span class="number">1</span>)</span><br><span class="line">		h = np.maximum(<span class="number">0</span>, y2Min-y1Max+<span class="number">1</span>)</span><br><span class="line">		overlap = (w * h) / area[idxs[:last]]</span><br><span class="line">		<span class="comment"># 根据重叠占比的阈值删除重复的矩形框</span></span><br><span class="line">		idxs = np.delete(idxs, np.concatenate(([last], np.where(overlap &gt; thresh)[<span class="number">0</span>])))</span><br><span class="line">	<span class="keyword">return</span> boxes[pick]  <span class="comment"># x, y, w, h</span></span><br><span class="line">img = cv.imread(<span class="string">"../images/Fig0944a.tif"</span>, flags=<span class="number">1</span>)</span><br><span class="line">gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)</span><br><span class="line">height, width = gray.shape[:<span class="number">2</span>]</span><br><span class="line"><span class="comment"># 创建 MSER 对象，检测 MSER 区域</span></span><br><span class="line"><span class="comment"># mser = cv.MSER_create(_min_area=500, _max_area=20000)</span></span><br><span class="line">mser = cv.MSER.create(_min_area=<span class="number">306</span>, _max_area=<span class="number">20000</span>)  <span class="comment"># 实例化 MSER</span></span><br><span class="line">regions, boxes = mser.detectRegions(gray)  <span class="comment"># 检测并返回找到的 MSER</span></span><br><span class="line">lenMSER = <span class="built_in">len</span>(regions)  <span class="comment"># 4082</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"Number of detected MSER: "</span>, lenMSER) <span class="comment"># 4082</span></span><br><span class="line">imgMser1 = img.copy()</span><br><span class="line">imgMser2 = img.copy()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(lenMSER):</span><br><span class="line">	<span class="comment"># 绘制 MSER 凸壳</span></span><br><span class="line">	points = regions[i].reshape(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>)  <span class="comment"># (k,2) -&gt; (k,1,2)</span></span><br><span class="line">	hulls = cv.convexHull(points)</span><br><span class="line">	cv.polylines(imgMser1, [hulls], <span class="number">1</span>, (<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>), <span class="number">2</span>)  <span class="comment"># 绘制凸壳 (x,y)</span></span><br><span class="line">	<span class="comment">#　绘制 MSER 矩形框</span></span><br><span class="line">	x, y, w, h = boxes[i]  <span class="comment"># 区域的垂直矩形边界框</span></span><br><span class="line">	cv.rectangle(imgMser2, (x,y), (x+w,y+h), (<span class="number">0</span>,<span class="number">0</span>,<span class="number">255</span>), <span class="number">2</span>)</span><br><span class="line"><span class="comment"># 非最大值抑制 (NMS)</span></span><br><span class="line">imgMser3 = img.copy()</span><br><span class="line">nmsBoxes = NonMaxSuppression(boxes, <span class="number">0.6</span>)</span><br><span class="line">lenNMS = <span class="built_in">len</span>(nmsBoxes)  <span class="comment"># 149</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"Number of NMS-MSER: "</span>, lenNMS) <span class="comment">#149</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(lenNMS):</span><br><span class="line">	<span class="comment">#　绘制 NMS-MSER 矩形框</span></span><br><span class="line">	x, y, w, h = nmsBoxes[i]  <span class="comment"># NMS 矩形框</span></span><br><span class="line">	cv.rectangle(imgMser3, (x,y), (x+w,y+h), (<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>), <span class="number">2</span>)</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="特征描述之-hog-描述符"><a class="markdownIt-Anchor" href="#特征描述之-hog-描述符"></a> 特征描述之 HOG 描述符？</h3><ul><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121417734.png" alt=""></li><li>方向梯度直方图（Histogram of Oriented Gradient, HOG）使用梯度方向的分布作为特征来构造描述符，应用非常广泛</li><li>梯度的幅值是边缘和角点检测的基础，梯度的方向也包含着丰富的图像特征。HOG 的基本思想，就是图像的局部特征可以用梯度幅值和方向的分布描述。HOG 的基本方法是，将图像划分成多个单元格，计算单元格的方向梯度直方图，把每个单元格的直方图连接起来构造为 HOG 特征向量</li><li>HOG 描述符的向量维数不是固定不变的，取决于检测图像大小和单元格的大小。HOG 描述符不具有尺度和旋转不变性，但具有有良好的几何和光学不变性，特别适合人体检测<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">drawHOG</span>(<span class="params">image, descriptors, cx, cy, rad</span>):</span><br><span class="line">	angles = np.arange(<span class="number">0</span>, <span class="number">180</span>, <span class="number">22.5</span>).astype(np.float32)  <span class="comment"># start, stop, step</span></span><br><span class="line">	normGrad = descriptors/np.<span class="built_in">max</span>(descriptors).astype(np.float32)</span><br><span class="line">	gx, gy = cv.polarToCart(normGrad*rad, angles, angleInDegrees=<span class="literal">True</span>)</span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(angles.shape[<span class="number">0</span>]):</span><br><span class="line">		px, py = <span class="built_in">int</span>(cx+gx[i]), <span class="built_in">int</span>(cy+gy[i])</span><br><span class="line">		cv.arrowedLine(image, (cx,cy), (px, py), <span class="number">0</span>, tipLength=<span class="number">0.1</span>)  <span class="comment"># 黑色</span></span><br><span class="line">	<span class="keyword">return</span> image</span><br><span class="line"><span class="comment"># (1) 读取样本图像，构造样本图像集合</span></span><br><span class="line">img = cv.imread(<span class="string">"../images/Fig1101.png"</span>, flags=<span class="number">0</span>)  <span class="comment"># 灰度图像</span></span><br><span class="line">height, width, wCell, d = <span class="number">200</span>, <span class="number">200</span>, <span class="number">20</span>, <span class="number">10</span></span><br><span class="line">img = cv.resize(img, (width, height))  <span class="comment"># 调整为统一尺寸</span></span><br><span class="line"><span class="comment"># (2) 构造 HOG 检测器</span></span><br><span class="line">winSize = (<span class="number">20</span>, <span class="number">20</span>)</span><br><span class="line">blockSize = (<span class="number">20</span>, <span class="number">20</span>)</span><br><span class="line">blockStride = (<span class="number">20</span>, <span class="number">20</span>)</span><br><span class="line">cellSize = (<span class="number">20</span>, <span class="number">20</span>)</span><br><span class="line">nbins = <span class="number">8</span></span><br><span class="line">hog = cv.HOGDescriptor(winSize, blockSize, blockStride, cellSize, nbins)</span><br><span class="line">lenHOG = nbins * (blockSize[<span class="number">0</span>]/cellSize[<span class="number">0</span>]) * (blockSize[<span class="number">1</span>]/cellSize[<span class="number">1</span>]) \</span><br><span class="line">		* ((winSize[<span class="number">0</span>]-blockSize[<span class="number">0</span>])/blockStride[<span class="number">0</span>] + <span class="number">1</span>) \</span><br><span class="line">		* ((winSize[<span class="number">1</span>]-blockSize[<span class="number">1</span>])/blockStride[<span class="number">1</span>] + <span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"length of descriptors:"</span>, lenHOG)</span><br><span class="line"><span class="comment"># (3) 计算检测区域的 HOG 描述符</span></span><br><span class="line">xt, yt = <span class="number">80</span>, <span class="number">80</span>  <span class="comment"># 检测区域位置</span></span><br><span class="line">cell = img[xt:xt+wCell, yt:yt+wCell]</span><br><span class="line">cellDes = hog.compute(cell)  <span class="comment"># HOG 描述符，(8,)</span></span><br><span class="line">normGrad = cellDes/np.<span class="built_in">max</span>(cellDes).astype(np.float32)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"shape of descriptors:{}"</span>.<span class="built_in">format</span>(cellDes.shape))</span><br><span class="line"><span class="built_in">print</span>(cellDes)</span><br><span class="line"><span class="comment"># (4) 绘制方向梯度示意图</span></span><br><span class="line">imgGrad = cv.resize(cell, (wCell*<span class="number">10</span>, wCell*<span class="number">10</span>), interpolation=cv.INTER_AREA)</span><br><span class="line">Gx = cv.Sobel(img, cv.CV_32F, <span class="number">1</span>, <span class="number">0</span>, ksize=<span class="number">5</span>)  <span class="comment"># X 轴梯度 Gx</span></span><br><span class="line">Gy = cv.Sobel(img, cv.CV_32F, <span class="number">0</span>, <span class="number">1</span>, ksize=<span class="number">5</span>)  <span class="comment"># Y 轴梯度 Gy</span></span><br><span class="line">magG, angG = cv.cartToPolar(Gx, Gy, angleInDegrees=<span class="literal">True</span>)  <span class="comment"># 极坐标求幅值与方向 (0~360)</span></span><br><span class="line"><span class="built_in">print</span>(magG.<span class="built_in">min</span>(), magG.<span class="built_in">max</span>(), angG.<span class="built_in">min</span>(), angG.<span class="built_in">max</span>())</span><br><span class="line">angCell = angG[xt:xt+wCell, yt:yt+wCell]</span><br><span class="line">box = np.zeros((<span class="number">4</span>, <span class="number">2</span>), np.int32)  <span class="comment"># 计算旋转矩形的顶点, (4, 2)</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(wCell):</span><br><span class="line">	<span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(wCell):</span><br><span class="line">		cx, cy = i*<span class="number">10</span>+d, j*<span class="number">10</span>+d</span><br><span class="line">		rect = ((cx,cy), (<span class="number">8</span>,<span class="number">1</span>), angCell[i,j])  <span class="comment"># 旋转矩形类</span></span><br><span class="line">		box = np.int32(cv.boxPoints(rect))  <span class="comment"># 计算旋转矩形的顶点, (4, 2)</span></span><br><span class="line">		cv.drawContours(imgGrad, [box], <span class="number">0</span>, (<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line"><span class="comment"># (5) 绘制检测区域的方向梯度直方图</span></span><br><span class="line">cellHOG = np.ones((<span class="number">201</span>,<span class="number">201</span>), np.uint8)  <span class="comment"># 白色</span></span><br><span class="line">cellHOG = drawHOG(cellHOG, cellDes, xt+d, yt+d, <span class="number">40</span>)</span><br><span class="line"><span class="comment"># (6) 绘制图像的方向梯度直方图</span></span><br><span class="line">imgHOG = np.ones(img.shape, np.uint8)*<span class="number">255</span>  <span class="comment"># 白色</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">	<span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">		xc, yc = <span class="number">20</span>*i, <span class="number">20</span>*j</span><br><span class="line">		cell = img[xc:xc+wCell, yc:yc+wCell]</span><br><span class="line">		descriptors = hog.compute(cell)  <span class="comment"># HOG 描述符，(8,)</span></span><br><span class="line">		imgHOG = drawHOG(imgHOG, descriptors, xc+d, yc+d, <span class="number">8</span>)</span><br><span class="line">imgWeight = cv.addWeighted(img, <span class="number">0.5</span>, imgHOG, <span class="number">0.5</span>, <span class="number">0</span>)</span><br><span class="line">show_images([img,angNorm,imgWeight,imgGrad,cellHOG])</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="特征检测之视网膜算法freak"><a class="markdownIt-Anchor" href="#特征检测之视网膜算法freak"></a> 特征检测之视网膜算法（FREAK）？</h3><ul><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121417768.png" alt=""></li><li>快速视网膜关键点描述（FREAK，Fast Retina Keypoint）模拟人类视网膜的拓扑结构设计关键点的采样模式，构造二进制编码串珠外关键点的特征描述符，具有速度快、内存占用小和鲁棒性强的优点</li><li>BRISK 算法的采样模式是均匀采样模式（在同一圆上等间隔的进行采样），FREAK 算法采取了更为接近于人眼视网膜接收图像信息的采样模型<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">img = cv.imread(<span class="string">"../images/Fig1701.png"</span>, flags=<span class="number">1</span>)  <span class="comment"># 基准图像</span></span><br><span class="line">height, width = img.shape[:<span class="number">2</span>]  <span class="comment"># (500, 500)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"shape of image: ({},{})"</span>.<span class="built_in">format</span>(height, width))</span><br><span class="line"><span class="comment"># BRISK 检测关键点</span></span><br><span class="line">brisk = cv.BRISK_create()  <span class="comment"># 创建 BRISK 检测器</span></span><br><span class="line">kp = brisk.detect(img)  <span class="comment"># 关键点检测，kp 为元组</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"Num of keypoints: "</span>, <span class="built_in">len</span>(kp))  <span class="comment"># 271</span></span><br><span class="line"><span class="comment"># BRIEF 特征描述</span></span><br><span class="line">brief = cv.xfeatures2d.BriefDescriptorExtractor_create()  <span class="comment"># 实例化 BRIEF 类</span></span><br><span class="line">kpBrief, desBrief = brief.compute(img, kp)  <span class="comment"># 计算 BRIEF 描述符</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"BRIEF descriptors: "</span>, desBrief.shape)  <span class="comment"># (270, 32)</span></span><br><span class="line"><span class="comment"># FREAK 特征描述</span></span><br><span class="line">freak = cv.xfeatures2d.FREAK_create()  <span class="comment"># 实例化 FREAK 类</span></span><br><span class="line">kpFreak, desFreak = freak.compute(img, kp)  <span class="comment"># 生成描述符</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"FREAK descriptors: "</span>, desFreak.shape)  <span class="comment"># (196, 64)</span></span><br><span class="line">imgS = cv.convertScaleAbs(img, alpha=<span class="number">0.5</span>, beta=<span class="number">128</span>)</span><br><span class="line">imgKp1 = cv.drawKeypoints(imgS, kpBrief, <span class="literal">None</span>, flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)</span><br><span class="line">imgKp2 = cv.drawKeypoints(imgS, kpFreak, <span class="literal">None</span>, flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)</span><br><span class="line">show_images([img,imgKp1,imgKp2])</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="特征匹配之暴力匹配"><a class="markdownIt-Anchor" href="#特征匹配之暴力匹配"></a> 特征匹配之暴力匹配？</h3><ul><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121417696.png" alt=""></li><li>基于特征描述符的特征点匹配是通过对两幅图像的特征点集合内的关键点描述符的相似性比对来实现的。分别对参考图像（Reference image）和检测图像（Observation image）建立关键点描述符集合，采用某种距离测度作为关键点描述向量的相似性度量</li><li>暴力匹配（Brute-force matcher）是最简单的二维特征点匹配方法。对于从两幅图像中提取的两个特征描述符集合，对第一个集合中的每个描述符 Ri，从第二个集合中找出与其距离最小的描述符 Sj 作为匹配点<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">imgRef = cv.imread(<span class="string">"../images/Fig1703a.png"</span>, flags=<span class="number">1</span>)</span><br><span class="line">refer = cv.cvtColor(imgRef, cv.COLOR_BGR2GRAY)  <span class="comment"># 参考图像</span></span><br><span class="line">height, width = imgRef.shape[:<span class="number">2</span>]  <span class="comment"># 图片的高度和宽度</span></span><br><span class="line"><span class="comment"># 读取或构造检测图像</span></span><br><span class="line">imgObj = cv.imread(<span class="string">"../images/Fig1703b.png"</span>, flags=<span class="number">1</span>)</span><br><span class="line"><span class="built_in">object</span> = cv.cvtColor(imgObj, cv.COLOR_BGR2GRAY)  <span class="comment"># 目标图像</span></span><br><span class="line"><span class="comment"># (2) 构造 SIFT 对象，检测关键点，计算特征描述向量</span></span><br><span class="line">sift = cv.SIFT.create()  <span class="comment"># sift 实例化对象</span></span><br><span class="line">kpRef, desRef = sift.detectAndCompute(refer, <span class="literal">None</span>)  <span class="comment"># 参考图像关键点检测</span></span><br><span class="line">kpObj, desObj = sift.detectAndCompute(<span class="built_in">object</span>, <span class="literal">None</span>)  <span class="comment"># 检测图像关键点检测</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"Keypoints: RefImg {}, ObjImg {}"</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(kpRef), <span class="built_in">len</span>(kpObj)))  <span class="comment"># 2238/1675</span></span><br><span class="line"><span class="comment"># (3) 特征点匹配，暴力匹配+交叉匹配筛选，返回最优匹配结果</span></span><br><span class="line">bf1 = cv.BFMatcher(crossCheck=<span class="literal">True</span>)  <span class="comment"># 构造 BFmatcher 对象，设置交叉匹配</span></span><br><span class="line">matches = bf1.<span class="keyword">match</span>(desRef, desObj)  <span class="comment"># 对描述子 desRef, desObj 进行匹配</span></span><br><span class="line"><span class="comment"># matches = sorted(matches, key=lambda x: x.distance)</span></span><br><span class="line">imgMatches1 = cv.drawMatches(imgRef, kpRef, imgObj, kpObj, matches[:<span class="number">300</span>], <span class="literal">None</span>, matchColor=(<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"(1) bf.match with crossCheck: {}"</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(matches)))</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(matches), <span class="built_in">type</span>(matches[<span class="number">0</span>]))</span><br><span class="line"><span class="built_in">print</span>(matches[<span class="number">0</span>].queryIdx, matches[<span class="number">0</span>].trainIdx, matches[<span class="number">0</span>].distance)  <span class="comment"># DMatch 的结构和用法</span></span><br><span class="line"><span class="comment"># (4) 特征点匹配，KNN匹配+比较阈值筛选</span></span><br><span class="line">bf2 = cv.BFMatcher()  <span class="comment"># 构造 BFmatcher 对象</span></span><br><span class="line">matches = bf2.knnMatch(desRef, desObj, k=<span class="number">2</span>)  <span class="comment"># KNN匹配，返回最优点和次优点 2个结果</span></span><br><span class="line">goodMatches = []  <span class="comment"># 筛选匹配结果</span></span><br><span class="line"><span class="keyword">for</span> m, n <span class="keyword">in</span> matches:  <span class="comment"># matches 是元组</span></span><br><span class="line">	<span class="keyword">if</span> m.distance &lt; <span class="number">0.7</span> * n.distance:  <span class="comment"># 最优点距离/次优点距离 之比小于阈值0.7</span></span><br><span class="line">		goodMatches.append([m])  <span class="comment"># 保留显著性高度匹配结果</span></span><br><span class="line"><span class="comment"># good = [[m] for m, n in matches if m.distance&lt;0.7*n.distance]  # 单行嵌套循环遍历</span></span><br><span class="line">imgMatches2 = cv.drawMatchesKnn(imgRef, kpRef, imgObj, kpObj, goodMatches, <span class="literal">None</span>, matchColor=(<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"(2) bf.knnMatch:{}, goodMatch:{}"</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(matches), <span class="built_in">len</span>(goodMatches))) <span class="comment"># 1058 1015</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(matches), <span class="built_in">type</span>(matches[<span class="number">0</span>]), <span class="built_in">type</span>(matches[<span class="number">0</span>][<span class="number">0</span>])) <span class="comment"># 363</span></span><br><span class="line"><span class="built_in">print</span>(matches[<span class="number">0</span>][<span class="number">0</span>].distance) <span class="comment"># 1058 123</span></span><br><span class="line">show_images([imgMatches1,imgMatches2])</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="基于拉普拉斯核的图像孤立点检测"><a class="markdownIt-Anchor" href="#基于拉普拉斯核的图像孤立点检测"></a> 基于拉普拉斯核的图像 “孤立点” 检测？</h3><ul><li><img data-src="https://picgo-1304919305.cos.ap-guangzhou.myqcloud.com/picGo/202501121417671.png" alt=""></li><li>孤立点的检测，是检测嵌在一幅图像的恒定区域或亮度几乎不变的区域里的孤立点。孤立点的检测以二阶导数为基础</li><li><strong>注意</strong>：这里孤立点检测，是绝对意义上的孤立点，即一个孤立的像素。人眼所能感知、识别的孤立点，通常来说其实是一个微小的区域，而不是孤立的一个像素，因此并不能用这种方法检测<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">imgGray = cv2.imread(<span class="string">"../images/Fig1004.tif"</span>, flags=<span class="number">0</span>)</span><br><span class="line">hImg, wImg = imgGray.shape</span><br><span class="line"><span class="comment"># scipy.signal 实现卷积运算 (注意：不能用 cv2.filter2D 处理)</span></span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> signal</span><br><span class="line">kernelLaplace = np.array([[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, -<span class="number">8</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]])  <span class="comment"># Laplacian kernel</span></span><br><span class="line">imgLaplace = signal.convolve2d(imgGray, kernelLaplace, boundary=<span class="string">'symm'</span>, mode=<span class="string">'same'</span>)  <span class="comment"># same 卷积</span></span><br><span class="line"><span class="comment"># 在原图上用半径为 5 的圆圈标记角点</span></span><br><span class="line">T = <span class="number">0.9</span> * <span class="built_in">max</span>(imgLaplace.<span class="built_in">max</span>(), -imgLaplace.<span class="built_in">min</span>())</span><br><span class="line">imgPoint = np.zeros((hImg, wImg), np.uint8)  <span class="comment"># 创建黑色图像</span></span><br><span class="line"><span class="keyword">for</span> h <span class="keyword">in</span> <span class="built_in">range</span>(hImg):</span><br><span class="line">	<span class="keyword">for</span> w <span class="keyword">in</span> <span class="built_in">range</span>(wImg):</span><br><span class="line">		<span class="keyword">if</span> (imgLaplace[h, w] &gt; T) <span class="keyword">or</span> (imgLaplace[h, w] &lt; -T):</span><br><span class="line">			imgPoint[h, w] = <span class="number">255</span>  <span class="comment"># 二值处理</span></span><br><span class="line">			cv2.circle(imgPoint, (w, h), <span class="number">10</span>, <span class="number">255</span>)</span><br></pre></td></tr></tbody></table></figure></li></ul><p>参考：</p><ol><li><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Feature_" title="computer_vision">Feature (computer vision) - Wikipedia</a></li><li><a target="_blank" rel="noopener" href="https://www.cs.rice.edu/~vo9/vision/slides/lecture07.pdf">https://www.cs.rice.edu/~vo9/vision/slides/lecture07.pdf</a></li><li><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1901.09723.pdf">1901.09723.pdf</a></li><li><a target="_blank" rel="noopener" href="https://blog.csdn.net/ChenLuLiang/article/details/108375174">python-opencv 手动标记 4 点 利用 findHomography 投影坐标_手动实现 findhomography__陈陆亮的博客 - CSDN 博客</a></li><li><a target="_blank" rel="noopener" href="https://blog.csdn.net/huang98778/article/details/89567885">SIFT 的详细解析_sift 插值方法 v_程序猿 - 猩球崛起的博客 - CSDN 博客</a></li><li><a target="_blank" rel="noopener" href="https://juejin.cn/post/7023698517327609887">Python，OpenCV 中的 SURF（加速健壮功能） - 掘金</a></li><li><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/420f8211d1cb">OpenCV 提取 ORB 特征并匹配 - 简书</a></li><li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/MfBLRmB7SQfACY27TI4Uug">微信公众平台</a></li><li><a target="_blank" rel="noopener" href="https://blog.csdn.net/youcans/article/details/124005009">【youcans 的 OpenCV 例程 200 篇】147. 图像分割之孤立点检测_opencv 孤立点检测_youcans_的博客 - CSDN 博客</a></li><li><ul><li><a target="_blank" rel="noopener" href="https://blog.csdn.net/youcans/article/details/125598167">【OpenCV 例程 300 篇】223. 特征提取之多边形拟合（cv.approxPolyDP）_opencv approxpolydp_youcans_的博客 - CSDN 博客</a></li></ul></li><li><a target="_blank" rel="noopener" href="https://blog.csdn.net/youcans/article/details/125600888">【OpenCV 例程 300 篇】224. 特征提取之提取骨架_opencv 骨架提取_youcans_的博客 - CSDN 博客</a></li><li><a target="_blank" rel="noopener" href="https://blog.csdn.net/youcans/article/details/125634022">【OpenCV 例程 300 篇】225. 特征提取之傅里叶描述子_youcans_的博客 - CSDN 博客</a></li><li><a target="_blank" rel="noopener" href="https://blog.csdn.net/youcans/article/details/125652989">【OpenCV 例程 300 篇】226. 区域特征之紧致度 / 圆度 / 偏心率_opencv 圆度_youcans_的博客 - CSDN 博客</a></li><li><a target="_blank" rel="noopener" href="https://blog.csdn.net/youcans/article/details/125670942">【OpenCV 例程 300 篇】227. 特征描述之 LBP 纹理特征算子_opencv 图像纹理_youcans_的博客 - CSDN 博客</a></li><li><a target="_blank" rel="noopener" href="https://blog.csdn.net/youcans/article/details/125671009">【OpenCV 例程 200 篇】228. 特征描述之 extendLBP 改进算子_youcans_的博客 - CSDN 博客</a></li><li><a target="_blank" rel="noopener" href="https://blog.csdn.net/youcans/article/details/125672432">【OpenCV 例程 300 篇】229. 特征描述之 LBP 算子比较（skimage）_skimage lbp_youcans_的博客 - CSDN 博客</a></li><li><a target="_blank" rel="noopener" href="https://blog.csdn.net/youcans/article/details/125681261">【OpenCV 例程 300 篇】230. 特征描述之 LBP 统计直方图_lbp 直方图_youcans_的博客 - CSDN 博客</a></li><li><a target="_blank" rel="noopener" href="https://blog.csdn.net/youcans/article/details/125693533">【OpenCV 例程 300 篇】231. 特征描述之灰度共生矩阵（GLCM）_opencv 灰度共生矩阵_youcans_的博客 - CSDN 博客</a></li><li><a target="_blank" rel="noopener" href="https://blog.csdn.net/youcans/article/details/125704655">【OpenCV 例程 300 篇】232. 特征描述之频谱方法_高频图像特征描述方法_youcans_的博客 - CSDN 博客</a></li><li><a target="_blank" rel="noopener" href="https://blog.csdn.net/youcans/article/details/125704724">【OpenCV 例程 300 篇】233. 区域特征之矩不变量_youcans_的博客 - CSDN 博客</a></li><li><a target="_blank" rel="noopener" href="https://blog.csdn.net/youcans/article/details/125534118">【OpenCV 例程 300 篇】222. 特征提取之弗里曼链码（Freeman chain code）_youcans_的博客 - CSDN 博客</a></li><li><a target="_blank" rel="noopener" href="https://blog.csdn.net/youcans/article/details/125820758">【OpenCV 例程 300 篇】238. OpenCV 中的 Harris 角点检测_youcans_的博客 - CSDN 博客</a></li><li><a target="_blank" rel="noopener" href="https://blog.csdn.net/youcans/article/details/125821029">【OpenCV 例程 300 篇】239. Harris 角点检测之精确定位（cornerSubPix）_cv.cornersubpix_youcans_的博客 - CSDN 博客</a></li><li><a target="_blank" rel="noopener" href="https://blog.csdn.net/youcans/article/details/125828053">【OpenCV 例程 300 篇】240. OpenCV 中的 Shi-Tomas 角点检测_opencv shi-tomas_youcans_的博客 - CSDN 博客</a></li><li><a target="_blank" rel="noopener" href="https://blog.csdn.net/youcans/article/details/126018654">【OpenCV 例程 300 篇】241. 尺度不变特征变换（SIFT）_youcans_的博客 - CSDN 博客</a></li><li><a target="_blank" rel="noopener" href="https://blog.csdn.net/youcans/article/details/127133693">【OpenCV 例程 300 篇】242. 加速稳健特征检测算法（SURF）_youcans_的博客 - CSDN 博客</a></li><li><a target="_blank" rel="noopener" href="https://blog.csdn.net/youcans/article/details/127333535">【OpenCV 例程 300 篇】243. 特征检测之 FAST 算法_opencv fast_youcans_的博客 - CSDN 博客</a></li><li><a target="_blank" rel="noopener" href="https://blog.csdn.net/youcans/article/details/127352928">【OpenCV 例程 300 篇】244. 特征检测之 BRIEF 特征描述_brief opencv 例程_youcans_的博客 - CSDN 博客</a></li><li><a target="_blank" rel="noopener" href="https://blog.csdn.net/youcans/article/details/127415464">【OpenCV 例程 300 篇】245. 特征检测之 BRISK 算子_opencv brisk_youcans_的博客 - CSDN 博客</a></li><li><a target="_blank" rel="noopener" href="https://blog.csdn.net/youcans/article/details/128033070">【OpenCV 例程 300 篇】246. 特征检测之 ORB 算法_opencv orb_youcans_的博客 - CSDN 博客</a></li><li><a target="_blank" rel="noopener" href="https://blog.csdn.net/youcans/article/details/128565226">【OpenCV 例程 300 篇】256. 特征检测之 CenSurE（StarDetector）算法_youcans_的博客 - CSDN 博客</a></li><li><a target="_blank" rel="noopener" href="https://blog.csdn.net/youcans/article/details/125724395">【OpenCV 例程 300 篇】247. 特征检测之最大稳定极值区域（MSER）_mser 区域检测_youcans_的博客 - CSDN 博客</a></li><li><a target="_blank" rel="noopener" href="https://blog.csdn.net/youcans/article/details/127970587">【OpenCV 例程 300 篇】248. 特征描述之 HOG 描述符_youcans_的博客 - CSDN 博客</a></li><li><a target="_blank" rel="noopener" href="https://blog.csdn.net/youcans/article/details/128169703">【OpenCV 例程 300 篇】249. 特征描述之视网膜算法（FREAK）_opencv freak_youcans_的博客 - CSDN 博客</a></li><li><a target="_blank" rel="noopener" href="https://blog.csdn.net/youcans/article/details/128253435">【OpenCV 例程 300 篇】251. 特征匹配之暴力匹配_youcans_的博客 - CSDN 博客</a></li></ol></div><footer class="post-footer"><div class="reward-container"><div>请我一杯咖啡吧！</div><button>赞赏</button><div class="post-reward"><div><img src="/images/wechatpay.png" alt="Shaogui 微信"> <span>微信</span></div><div><img src="/images/alipay.png" alt="Shaogui 支付宝"> <span>支付宝</span></div></div></div><div class="post-copyright"><ul><li class="post-copyright-author"><strong>本文作者： </strong>Shaogui</li><li class="post-copyright-link"><strong>本文链接：</strong> <a href="https://www.shaogui.life/posts/346787849.html" title="C01 - 图像特征提取与检测">https://www.shaogui.life/posts/346787849.html</a></li><li class="post-copyright-license"><strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh-hans" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><div class="followme"><span>欢迎关注我的其它发布渠道</span><div class="social-list"><div class="social-item"><a target="_blank" class="social-link" href="https://www.zhihu.com/people/mu-zhi-zhi-tian"><span class="icon"><i class="fab fa-zhihu"></i> </span><span class="label">知乎</span></a></div><div class="social-item"><a target="_blank" class="social-link" href="/atom.xml"><span class="icon"><i class="fa fa-rss"></i> </span><span class="label">RSS</span></a></div></div></div><div class="post-tags"><a href="/tags/opencv/" rel="tag"><i class="fa fa-tag"></i> opencv</a></div><div class="post-nav"><div class="post-nav-item"><a href="/posts/1820958548.html" rel="prev" title="C++ 的数据类型转换"><i class="fa fa-angle-left"></i> C++ 的数据类型转换</a></div><div class="post-nav-item"><a href="/posts/3490990429.html" rel="next" title="C++ 编译原理及优化编译">C++ 编译原理及优化编译 <i class="fa fa-angle-right"></i></a></div></div></footer></article></div><div class="comments utterances-container"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright">&copy; 2016 – <span itemprop="copyrightYear">2025</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">Shaogui</span></div><div class="wordcount"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-chart-line"></i> </span><span>站点总字数：</span> <span title="站点总字数">1.9m</span> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-coffee"></i> </span><span>站点阅读时长 &asymp;</span> <span title="站点阅读时长">28:48</span></span></div><div class="busuanzi-count"><span class="post-meta-item" id="busuanzi_container_site_uv"><span class="post-meta-item-icon"><i class="fa fa-user"></i> </span><span class="site-uv" title="总访客量"><span id="busuanzi_value_site_uv"></span> </span></span><span class="post-meta-item" id="busuanzi_container_site_pv"><span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="site-pv" title="总访问量"><span id="busuanzi_value_site_pv"></span></span></span></div><div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动</div></div></footer><div class="toggle sidebar-toggle" role="button"><span class="toggle-line"></span> <span class="toggle-line"></span> <span class="toggle-line"></span></div><div class="sidebar-dimmer"></div><div class="reading-progress-bar"></div><a href="https://github.com/WuShaogui" class="github-corner" title="在 GitHub 上关注我" aria-label="在 GitHub 上关注我" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><noscript><div class="noscript-warning">Theme NexT works best with JavaScript enabled</div></noscript><script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/lozad.js/1.16.0/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script><script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script><script src="/js/third-party/search/local-search.js"></script><script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":{"light":"neutral","dark":"dark"},"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mermaid/11.4.0/mermaid.min.js","integrity":"sha256-G8ouPAnw4zzMbnAenHnVz6h9XpKbNdOkrqTh7AadyHs="}}</script><script src="/js/third-party/tags/mermaid.js"></script><script src="/js/third-party/pace.js"></script><script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script><script src="/js/third-party/math/mathjax.js"></script><script class="next-config" data-name="utterances" type="application/json">{"enable":true,"repo":"WuShaogui/wushaogui.github.io","issue_term":"pathname","theme":"github-light"}</script><script src="/js/third-party/comments/utterances.js"></script></body></html>