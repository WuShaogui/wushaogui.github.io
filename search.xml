<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>404</title>
    <url>/2021/02/15/404/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>Gluon学习02-使用GPU</title>
    <url>/2017/09/22/Gluon%E5%AD%A6%E4%B9%A002-%E4%BD%BF%E7%94%A8GPU/</url>
    <content><![CDATA[<p>本文介绍Mxnet如何使用GPU的过程</p>
<a id="more"></a>
<p>本机环境介绍:</p>
<blockquote>
<p>系统:Linuxmint<br />
Python版本:Python3</p>
</blockquote>
<h1 id="1安装cuda与cudnn"><a class="markdownIt-Anchor" href="#1安装cuda与cudnn"></a> 1.安装cuda与cudnn</h1>
<p><strong>(0)定义</strong></p>
<p>CUDA(Compute Unified Device Architecture)，是英伟达公司推出的一种基于新的并行编程模型和指令集架构的通用计算架构，它能利用英伟达GPU的并行计算引擎，比CPU更高效的解决许多复杂计算任务。</p>
<blockquote>
<p>摘自:<a href="https://blog.csdn.net/fangjin_kl/article/details/53906874">CPU、GPU、CUDA，CuDNN 简介</a></p>
</blockquote>
<p>cuDNN（CUDA Deep Neural Network library）：是NVIDIA打造的针对深度神经网络的加速库，是一个用于深层神经网络的GPU加速库。如果你要用GPU训练模型，cuDNN不是必须的，但是一般会采用这个加速库。</p>
<blockquote>
<p>摘自:<a href="https://blog.csdn.net/u014380165/article/details/77340765">GPU，CUDA，cuDNN的理解</a></p>
</blockquote>
<p><strong>(1)下载</strong></p>
<p>选择合适版本下载cuda:<br />
网址:<a href="https://developer.nvidia.com/cuda-downloads">https://developer.nvidia.com/cuda-downloads</a></p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613540535696.png" alt="选择合适版本" /></p>
<p>配合前面的cuda版本,下载相应的cudnn:<br />
网址:<a href="https://developer.nvidia.com/rdp/cudnn-archive">https://developer.nvidia.com/rdp/cudnn-archive</a><br />
注:这里需要注册账号才可以下,有时收不到激活邮件,可以多试试不同放入邮箱,不行就出去一下.</p>
<p><strong>(2)安装</strong></p>
<p>下载完成以上两个文件后,首先安装cuda,使用以下命令安装:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo dpkg -i cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64.deb</span><br><span class="line">sudo apt-key add /var/cuda-repo-9-0-local/7fa2af80.pub</span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install cuda</span><br></pre></td></tr></table></figure>
<p>然后,解压cudnn,将相应文件拷贝的cuda的安装目录上,使用以下命令:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tar xvzf cudnn-8.0-linux-x64-v5.1-ga.tgz </span><br><span class="line">sudo cp cuda/include/cudnn.h /usr/<span class="built_in">local</span>/cuda/include</span><br><span class="line">sudo cp cuda/lib64/libcudnn* /usr/<span class="built_in">local</span>/cuda/lib64</span><br><span class="line">sudo chmod a+r /usr/<span class="built_in">local</span>/cuda/include/cudnn.h /usr/<span class="built_in">local</span>/cuda/lib64/libcudnn*</span><br></pre></td></tr></table></figure>
<p><strong>(3)配置</strong></p>
<p>将cuda安装路径配置到系统路径下:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> LD_LIBRARY_PATH=<span class="string">&quot;<span class="variable">$LD_LIBRARY_PATH</span>:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64&quot;</span></span><br><span class="line"><span class="built_in">export</span> CUDA_HOME=/usr/<span class="built_in">local</span>/cuda</span><br></pre></td></tr></table></figure>
<p>根据自己环境将该信息添加到相应文件,我的是<code>~/.zshrc</code>,如果终端是bash,则是<code>~/.bashrc</code>.</p>
<h1 id="2安装mxnet-gpu"><a class="markdownIt-Anchor" href="#2安装mxnet-gpu"></a> 2.安装mxnet-gpu</h1>
<p><strong>(1)卸载以前安装的CPU版本的mxnet</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pip uninstall mxnet</span><br></pre></td></tr></table></figure>
<p><strong>(2)安装mxnet-gpu</strong></p>
<p>根据前面安装的cuda 版本,安装相应的mxnet-gpu</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pip install --pre mxnet-cu75 <span class="comment"># CUDA 7.5</span></span><br><span class="line">pip install --pre mxnet-cu80 <span class="comment"># CUDA 8.0</span></span><br><span class="line">pip install --pre mxnet-cu90 <span class="comment"># CUDA 9.0</span></span><br></pre></td></tr></table></figure>
<p>注:如果安装过程过慢,可以更换pip的源,更换方法是可以看这篇博客<a href="https://blog.csdn.net/chenghuikai/article/details/55258957">更换pip源到国内镜像</a></p>
<p><strong>参考:</strong><br />
<a href="http://zh.gluon.ai/chapter_crashcourse/install.html">Gluon动手学深度学习</a></p>
]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>Gluon</tag>
        <tag>cuda</tag>
      </tags>
  </entry>
  <entry>
    <title>Calibre中使用DeDRM插件进行Kindle电子书解锁</title>
    <url>/2016/06/01/Calibre%E4%B8%AD%E4%BD%BF%E7%94%A8DeDRM%E6%8F%92%E4%BB%B6%E8%BF%9B%E8%A1%8CKindle%E7%94%B5%E5%AD%90%E4%B9%A6%E8%A7%A3%E9%94%81/</url>
    <content><![CDATA[<p>本文利用calire的DeDRM插件解锁kindle的加密电子书，文中需要使用kindle的设备号，意味着待解锁的电子书必须是已经购买的</p>
<a id="more"></a>
<p>废话不多说，下面是Calibre和DeDRM插件的下载地址：</p>
<blockquote>
<p><a href="https://calibre-ebook.com/download">https://calibre-ebook.com/download</a><br />
<a href="https://github.com/apprenticeharper/DeDRM_tools/releases/tag/v6.5.5">https://github.com/apprenticeharper/DeDRM_tools/releases/tag/v6.5.5</a></p>
</blockquote>
<p>假设你已经安装好Calibre，并下载好DeDRM插件，只需走以下三个步骤即可完成解锁。</p>
<h1 id="1在calibre上安装dedrm插件"><a class="markdownIt-Anchor" href="#1在calibre上安装dedrm插件"></a> 1.在Calibre上安装DEDRM插件</h1>
<p>将下载的DeDRM插件进行解压，需要强调的是：插件文件在下面图示路径中。</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613525776830.png" alt="图2-插件文件路径" /></p>
<p>在Calibre中点击<code>首选项</code>进入设置界面，点击<code>插件</code>按钮进入插件管理界面。</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613525776966.png" alt="图3-插件管理界面" /></p>
<p>点击<code>从文件中加载插件</code>，然后选择上图2红框的文件，完成插件的安装，安装完成可以在<em>文件类型</em>中找到插件。</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613525776981.png" alt="图4-安装插件" /></p>
<h1 id="2配置dedrm插件"><a class="markdownIt-Anchor" href="#2配置dedrm插件"></a> 2.配置DeDRM插件</h1>
<p>双击进入插件配置界面，填入<strong>Kindle设备序列号</strong>，即完成配置，步骤如下：</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613525776982.png" alt="图5-配置插件" /></p>
<p><strong>Kindle设备序列号</strong>通过登录自己的亚马逊帐号找到，步骤如下：</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613525776983.png" alt="图6-查找Kindle设备序列号" /></p>
<p>注意：填入序列号不能包含空格</p>
<h1 id="3添加书籍"><a class="markdownIt-Anchor" href="#3添加书籍"></a> 3.添加书籍</h1>
<p>使用Calibre添加书籍或者将书籍直接拖入，即可完成解锁，书籍不在有DRM保护。</p>
]]></content>
      <categories>
        <category>软件工具</category>
      </categories>
      <tags>
        <tag>Calibre</tag>
      </tags>
  </entry>
  <entry>
    <title>Gluon学习03-基础数据类型Ndarray</title>
    <url>/2017/09/23/Gluon%E5%AD%A6%E4%B9%A003-%E5%9F%BA%E7%A1%80%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8BNdarray/</url>
    <content><![CDATA[<p>本文介绍如何Gluon的基本数据类型Ndarray</p>
<a id="more"></a>
<p>本机环境介绍:</p>
<blockquote>
<p>系统:Linuxmint<br />
Python版本:Python3</p>
</blockquote>
<hr />
<h1 id="1api介绍"><a class="markdownIt-Anchor" href="#1api介绍"></a> 1.API介绍</h1>
<p>MxNet版本:1.2.0<br />
API地址:<a href="https://mxnet.incubator.apache.org/api/python/ndarray/ndarray.html">https://mxnet.incubator.apache.org/api/python/ndarray/ndarray.html</a></p>
<p>Ndarray在CPU/GPU上提供必要的张量操作,是一个多维的,固定大小的,同类型的矩阵.mxnet.ndarray与numpy.ndarray非常相似.</p>
<p><strong>The NDArray class:</strong><br />
1.属性<br />
shape/size/ndim/context/dtype</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> mxnet <span class="keyword">as</span> mx</span><br><span class="line"><span class="keyword">from</span> mxnet <span class="keyword">import</span> nd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment">#数据的形状</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = mx.nd.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x.shape</span><br><span class="line">(<span class="number">4L</span>,)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y = mx.nd.zeros((<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y.shape</span><br><span class="line">(<span class="number">2L</span>, <span class="number">3L</span>, <span class="number">4L</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#数据的多少</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = mx.nd.zeros((<span class="number">3</span>, <span class="number">5</span>, <span class="number">2</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x.size</span><br><span class="line"><span class="number">30</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.prod(x.shape)</span><br><span class="line"><span class="number">30</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#数据的阶/秩</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = mx.nd.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x.ndim</span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = mx.nd.array([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x.ndim</span><br><span class="line"><span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#数据所在的设备</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = mx.nd.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x.context</span><br><span class="line">cpu(<span class="number">0</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">type</span>(x.context)</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y = mx.nd.zeros((<span class="number">2</span>,<span class="number">3</span>), mx.gpu(<span class="number">0</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y.context</span><br><span class="line">gpu(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#数据的类型</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = mx.nd.zeros((<span class="number">2</span>,<span class="number">3</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x.dtype</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y = mx.nd.zeros((<span class="number">2</span>,<span class="number">3</span>), dtype=<span class="string">&#x27;int32&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y.dtype</span><br></pre></td></tr></table></figure>
<p>2.转换</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#转为标量,形状必须是(1,)</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = mx.nd.ones((<span class="number">1</span>,), dtype=<span class="string">&#x27;int32&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x.asscalar()</span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">type</span>(x.asscalar())</span><br><span class="line"></span><br><span class="line"><span class="comment">#复制</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = mx.nd.ones((<span class="number">2</span>,<span class="number">3</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y = x.copy()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y.asnumpy()</span><br><span class="line">array([[ <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>],</span><br><span class="line">       [ <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>]], dtype=float32)</span><br></pre></td></tr></table></figure>
<p>3.创建</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#通过自身API创建</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a=nd.arange((<span class="number">10</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line">[<span class="number">0.</span> <span class="number">1.</span> <span class="number">2.</span> <span class="number">3.</span> <span class="number">4.</span> <span class="number">5.</span> <span class="number">6.</span> <span class="number">7.</span> <span class="number">8.</span> <span class="number">9.</span>]</span><br><span class="line">&lt;NDArray <span class="number">10</span> @cpu(<span class="number">0</span>)&gt;</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b=nd.zeros((<span class="number">2</span>,<span class="number">3</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b</span><br><span class="line">[[<span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span>]]</span><br><span class="line">&lt;NDArray 2x3 @cpu(<span class="number">0</span>)&gt;</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c=nd.ones((<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c</span><br><span class="line">[[[<span class="number">1.</span>]</span><br><span class="line">  [<span class="number">1.</span>]</span><br><span class="line">  [<span class="number">1.</span>]]</span><br><span class="line"> [[<span class="number">1.</span>]</span><br><span class="line">  [<span class="number">1.</span>]</span><br><span class="line">  [<span class="number">1.</span>]]]</span><br><span class="line">&lt;NDArray 2x3x1 @cpu(<span class="number">0</span>)&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">#通过list创建</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>d=[<span class="number">6</span>,<span class="number">5</span>,<span class="number">4</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">1</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>e=nd.array(d)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>e</span><br><span class="line">[<span class="number">6.</span> <span class="number">5.</span> <span class="number">4.</span> <span class="number">3.</span> <span class="number">2.</span> <span class="number">1.</span>]</span><br><span class="line">&lt;NDArray <span class="number">6</span> @cpu(<span class="number">0</span>)&gt;</span><br></pre></td></tr></table></figure>
<p>4.形状</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#转置</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = mx.nd.arange(<span class="number">0</span>,<span class="number">6</span>).reshape((<span class="number">2</span>,<span class="number">3</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x.asnumpy()</span><br><span class="line">array([[ <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">2.</span>],</span><br><span class="line">       [ <span class="number">3.</span>,  <span class="number">4.</span>,  <span class="number">5.</span>]], dtype=float32)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x.T.asnumpy()</span><br><span class="line">array([[ <span class="number">0.</span>,  <span class="number">3.</span>],</span><br><span class="line">       [ <span class="number">1.</span>,  <span class="number">4.</span>],</span><br><span class="line">       [ <span class="number">2.</span>,  <span class="number">5.</span>]], dtype=float32)</span><br><span class="line">	   </span><br><span class="line"><span class="comment">#改变形状</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = mx.nd.arange(<span class="number">0</span>,<span class="number">6</span>).reshape(<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x</span><br><span class="line">[[<span class="number">0.</span> <span class="number">1.</span> <span class="number">2.</span>]</span><br><span class="line"> [<span class="number">3.</span> <span class="number">4.</span> <span class="number">5.</span>]]</span><br><span class="line">&lt;NDArray 2x3 @cpu(<span class="number">0</span>)&gt;</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y = x.reshape(<span class="number">3</span>,<span class="number">2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y</span><br><span class="line">[[<span class="number">0.</span> <span class="number">1.</span>]</span><br><span class="line"> [<span class="number">2.</span> <span class="number">3.</span>]</span><br><span class="line"> [<span class="number">4.</span> <span class="number">5.</span>]]</span><br><span class="line">&lt;NDArray 3x2 @cpu(<span class="number">0</span>)&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">#列多少不管,就明确是n行,列= (x.size/n)上整</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y = x.reshape(<span class="number">2</span>,-<span class="number">1</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y</span><br><span class="line">[[<span class="number">0.</span> <span class="number">1.</span> <span class="number">2.</span>]</span><br><span class="line"> [<span class="number">3.</span> <span class="number">4.</span> <span class="number">5.</span>]]</span><br><span class="line">&lt;NDArray 2x3 @cpu(<span class="number">0</span>)&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">#只要一行</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y = x.reshape(-<span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y</span><br><span class="line">[<span class="number">0.</span> <span class="number">1.</span> <span class="number">2.</span> <span class="number">3.</span> <span class="number">4.</span> <span class="number">5.</span>]</span><br><span class="line">&lt;NDArray <span class="number">6</span> @cpu(<span class="number">0</span>)&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>5.元素扩展</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#拼接,输入数组的唯独应该相同</span></span><br><span class="line">x = [[<span class="number">1</span>,<span class="number">1</span>],[<span class="number">2</span>,<span class="number">2</span>]]</span><br><span class="line">y = [[<span class="number">3</span>,<span class="number">3</span>],[<span class="number">4</span>,<span class="number">4</span>],[<span class="number">5</span>,<span class="number">5</span>]]</span><br><span class="line">z = [[<span class="number">6</span>,<span class="number">6</span>], [<span class="number">7</span>,<span class="number">7</span>],[<span class="number">8</span>,<span class="number">8</span>]]</span><br><span class="line">concat(x,y,z,dim=<span class="number">0</span>) = [[ <span class="number">1.</span>,  <span class="number">1.</span>],</span><br><span class="line">                       [ <span class="number">2.</span>,  <span class="number">2.</span>],</span><br><span class="line">                       [ <span class="number">3.</span>,  <span class="number">3.</span>],</span><br><span class="line">                       [ <span class="number">4.</span>,  <span class="number">4.</span>],</span><br><span class="line">                       [ <span class="number">5.</span>,  <span class="number">5.</span>],</span><br><span class="line">                       [ <span class="number">6.</span>,  <span class="number">6.</span>],</span><br><span class="line">                       [ <span class="number">7.</span>,  <span class="number">7.</span>],</span><br><span class="line">                       [ <span class="number">8.</span>,  <span class="number">8.</span>]]</span><br></pre></td></tr></table></figure>
<p><strong>参考:</strong><br />
<a href="https://mxnet.incubator.apache.org/api/python/ndarray/ndarray.html">NDArray API</a></p>
<p><font color='red'>每日一学,争取进步03</font></p>
]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>Gluon</tag>
      </tags>
  </entry>
  <entry>
    <title>Gluon学习01-部署环境</title>
    <url>/2017/09/19/Gluon%E5%AD%A6%E4%B9%A001-%E9%83%A8%E7%BD%B2%E7%8E%AF%E5%A2%83/</url>
    <content><![CDATA[<p>Gluon与Maxnet的关系就像Keras与Tensorflow的关系，本文介绍部署Gluon环境的整个过程</p>
<a id="more"></a>
<p>本机环境介绍:</p>
<blockquote>
<p>系统:Linuxmint<br />
Python版本:Python3</p>
</blockquote>
<h1 id="1下载并安装miniconda"><a class="markdownIt-Anchor" href="#1下载并安装miniconda"></a> 1.下载并安装Miniconda</h1>
<p><strong>(1)下载并安装</strong></p>
<p>网址:<a href="https://conda.io/miniconda.html">https://conda.io/miniconda.html</a></p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613540294748.png" alt="选择自己合适的版本" /></p>
<p>Linux环境下,使用命令<code>chmod 755 xx.sh</code>给下载的.sh文件运行权限,然后运行该脚本.按提示安装完成后需要将安装路径配置到相应文件上,一般最后提示将路径写到相应文件,如果提示不对,自己手动添加到相应文件上.比如我终端是zsh,则在<code>~/.zshrc</code>最后添加了下面配置:</p>
<blockquote>
<p>#set Miniconda<br />
export PATH=/home/wu/miniconda3/bin:$PATH</p>
</blockquote>
<p>注:该配置包含了我的用户名<code>wu</code>,复制时需做相应修改.</p>
<p><strong>(2)使用国内源,加速包的安装</strong></p>
<p>使用命令为:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 优先使用清华 conda 镜像。</span></span><br><span class="line">conda config --prepend channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 或者选用科大 conda 镜像。</span></span><br><span class="line">conda config --prepend channels http://mirrors.ustc.edu.cn/anaconda/pkgs/free/</span><br></pre></td></tr></table></figure>
<h1 id="2使用miniconda配置gluon环境"><a class="markdownIt-Anchor" href="#2使用miniconda配置gluon环境"></a> 2.使用Miniconda配置Gluon环境</h1>
<p><strong>(1)终端键入以下命令,下载相应的教程文件和配置文件</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir gluon-tutorials &amp;&amp; <span class="built_in">cd</span> gluon-tutorials</span><br><span class="line">curl https://zh.gluon.ai/gluon_tutorials_zh.tar.gz -o tutorials.tar.gz</span><br><span class="line">tar -xzvf tutorials.tar.gz &amp;&amp; rm tutorials.tar.gz</span><br></pre></td></tr></table></figure>
<p><strong>(2)配置环境</strong></p>
<p>进入下载的目录下,可以看到文件<code>environment.yml</code>,这里面包含了配置环境所需的所有库名称及版本号.打开一开,就是几个库而已.</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613540294749.png" alt="所需环境" /></p>
<p>使用以下命令来完成环境部署:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">conda env create -f environment.yml</span><br><span class="line"><span class="built_in">source</span> activate gluon</span><br></pre></td></tr></table></figure>
<h1 id="3测试"><a class="markdownIt-Anchor" href="#3测试"></a> 3.测试</h1>
<p>键入以下命令:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">jupyter notebook</span><br></pre></td></tr></table></figure>
<p>浏览器会自动打开一个页面,该页面上可用使用<code>cell(块)</code>的方式写代码,非常方便,关于Jupyter notebook的详细安装与配置,请参照  <a href="https://www.cnblogs.com/wushaogui/p/8797841.html">Jupyter开发环境搭建</a></p>
<h1 id="4使用国内服务器加速数据集下载"><a class="markdownIt-Anchor" href="#4使用国内服务器加速数据集下载"></a> 4.使用国内服务器,加速数据集下载</h1>
<p>训练模型时,如果需要在线下载数据,从国外下载数据非常慢,经常导致无法运行,可以更换为国内镜像来解决.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">MXNET_GLUON_REPO=https://apache-mxnet.s3.cn-north-1.amazonaws.com.cn/ jupyter notebook</span><br></pre></td></tr></table></figure>
<p><strong>参考:</strong><br />
<a href="http://zh.gluon.ai/chapter_crashcourse/install.html">Gluon动手学深度学习</a></p>
]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>Gluon</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo博客速度优化</title>
    <url>/2022/01/04/Hexo%E5%8D%9A%E5%AE%A2%E9%80%9F%E5%BA%A6%E4%BC%98%E5%8C%96/</url>
    <content><![CDATA[<p>本文对Hexo博客进行访问优化，使得访问速度更快了，主要是安装hexo-neat插件，实现对html、css、js、image等静态资源的高效压缩。通过压缩这些静态资源，可以减少请求的数据量从而达到优化博客访问速度的目的</p>
<a id="more"></a>
<h2 id="资源压缩"><a class="markdownIt-Anchor" href="#资源压缩"></a> 资源压缩<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup></h2>
<p><strong>安装插件</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install hexo-neat --save</span><br></pre></td></tr></table></figure>
<p><strong>配置插件</strong><br />
打开博客根目录文件<code>_config.yml</code>，添加以下配置</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># hexo-neat 压缩</span></span><br><span class="line">neat_enable: <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 压缩html</span></span><br><span class="line">neat_html:</span><br><span class="line">  <span class="built_in">enable</span>: <span class="literal">true</span></span><br><span class="line">  exclude:</span><br><span class="line"><span class="comment"># 压缩css  </span></span><br><span class="line">neat_css:</span><br><span class="line">  <span class="built_in">enable</span>: <span class="literal">true</span></span><br><span class="line">  exclude:</span><br><span class="line">    - <span class="string">&#x27;**/*.min.css&#x27;</span></span><br><span class="line"><span class="comment"># 压缩js</span></span><br><span class="line">neat_js:</span><br><span class="line">  <span class="built_in">enable</span>: <span class="literal">true</span></span><br><span class="line">  mangle: <span class="literal">true</span></span><br><span class="line">  output:</span><br><span class="line">  compress:</span><br><span class="line">  exclude:</span><br><span class="line">    - <span class="string">&#x27;**/*.min.js&#x27;</span></span><br><span class="line">    - <span class="string">&#x27;**/jquery.fancybox.pack.js&#x27;</span></span><br><span class="line">    - <span class="string">&#x27;**/index.js&#x27;</span></span><br></pre></td></tr></table></figure>
<h2 id="图片懒加载"><a class="markdownIt-Anchor" href="#图片懒加载"></a> 图片懒加载<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup></h2>
<p>即文字先出来，图片慢慢出来，显著提高加载速度</p>
<p><strong>安装插件</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install hexo-lazyload-image --save</span><br></pre></td></tr></table></figure>
<p><strong>配置文件</strong></p>
<p>打开配置文件<code>_config.yml</code>，添加以下配置</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 图片懒加载</span></span><br><span class="line">lazyload:</span><br><span class="line">  <span class="built_in">enable</span>: <span class="literal">true</span> </span><br><span class="line">  onlypost: <span class="literal">false</span></span><br><span class="line">  loadingImg: /images/loading.gif <span class="comment">#如果不填写图片则使用默认的图片</span></span><br></pre></td></tr></table></figure>
<hr class="footnotes-sep" />
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p><a href="https://www.difashi.com/2020-02/20-hexo-neat.html">hexo优化静态JS等资源压缩</a> <a href="#fnref1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn2" class="footnote-item"><p><a href="https://www.cnblogs.com/lfri/p/12221963.html">Hexo-Next提高加载速度</a> <a href="#fnref2" class="footnote-backref">↩︎</a></p>
</li>
</ol>
</section>
]]></content>
      <categories>
        <category>软件工具</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux上利用gitee为Hexo配置图床服务</title>
    <url>/2021/02/21/Hexo%E5%9B%BE%E5%BA%8A%E6%90%AD%E5%BB%BA/</url>
    <content><![CDATA[<p>本文通过小书匠为hexo搭建图床服务，图床搭建在gitee中，国内访问速度可以</p>
<a id="more"></a>
<p>搭建的步骤主要分为两个步骤</p>
<h2 id="新建图床仓库并获取令牌"><a class="markdownIt-Anchor" href="#新建图床仓库并获取令牌"></a> 新建图床仓库并获取令牌</h2>
<p><strong>新建仓库</strong></p>
<p>打开gitee，新建一个<code>公开的</code>仓库，用于做图床的存储库</p>
<p><strong>获得令牌</strong></p>
<p>令牌运行应用自行上传图片到gitee，所以需要提前获得，在gitee个人设置选项找到<code>私人令牌</code>，按下图配置新建一个令牌</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/PicGo/image-20210221172720292.png" alt="image-20210221172720292" /></p>
<h2 id="配置markdown编辑器"><a class="markdownIt-Anchor" href="#配置markdown编辑器"></a> 配置Markdown编辑器</h2>
<h3 id="配置小书匠"><a class="markdownIt-Anchor" href="#配置小书匠"></a> 配置小书匠<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup></h3>
<p>打开小书匠的配置界面，选择绑定，添加一个<code>码云图床</code>，出现以下添加界面</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/PicGo/20210221165614.png" alt="" /></p>
<h2 id="配置typora"><a class="markdownIt-Anchor" href="#配置typora"></a> 配置Typora<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup></h2>
<p>打开Typora偏好设置，依次配置下面内容：</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/PicGo/image-20210221173149180.png" alt="image-20210221173149180" /></p>
<p>第5步需要下载<code>PicGo-Core</code>，耐心等到下载完成；</p>
<p>第6步配置文件按以下配置</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/PicGo/image-20210221173900039.png" alt="image-20210221173900039" /></p>
<p>配置文件的<code>repo</code>在仓库的浏览地址找到</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/PicGo/image-20210221174346189.png" alt="image-20210221174346189" /></p>
<p>配置文件的<code>path</code>为仓库下的一个文件夹，<code>token</code>为第一步申请的</p>
<p>点击第7步前需要安装picgo的<code>gitee-uploader</code>插件，不然picgo会一直按sms的方式上传文件，而我们配置的又是gitee，所以第7步一直不会成功，安装下面的命令安装<code>gitee-uploader</code>插件</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">picgo install gitee-uploader</span><br></pre></td></tr></table></figure>
<p>点击第7步，出现下面提示，则配置成功</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/PicGo/image-20210221175128485.png" alt="image-20210221175128485" /></p>
<p>注意：在linux上已经试过用<code>PicGo-2.2.2.AppImage</code>配置<code>Typora</code>，但是出现一个难以忍受的bug，图片上传成功后居然不重命名，其实图片链接已经保存在粘贴板中，需要手动复制上去</p>
<p><strong>参考资料：</strong></p>
<hr class="footnotes-sep" />
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p><a href="https://blog.csdn.net/qq_39231769/article/details/96709675">无水印上传本地图片到网络获取地址+小书匠使用 +github和 七牛云 图床绑定–菜鸟小回</a> <a href="#fnref1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn2" class="footnote-item"><p><a href="https://blog.csdn.net/in_the_road/article/details/105733292">Typora自动上传图片配置，集成PicGo-Core，文件以时间戳命名</a> <a href="#fnref2" class="footnote-backref">↩︎</a></p>
</li>
</ol>
</section>
]]></content>
      <categories>
        <category>软件工具</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Next</tag>
        <tag>博客</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo安装Next主题</title>
    <url>/2021/02/19/Hexo%E5%AE%89%E8%A3%85Next%E4%B8%BB%E9%A2%98/</url>
    <content><![CDATA[<p>基于github pages完成博客搭建后，已经可以正常发文了，但是文字展示不美观，本文展示如何在Linux为Hexo博客安装Next主题，并进行详细配置</p>
<a id="more"></a>
<h2 id="安装next主题"><a class="markdownIt-Anchor" href="#安装next主题"></a> 安装Next主题</h2>
<p><strong>下载主题</strong></p>
<p>在博客的目录下，运行以下命令获得Next主题</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/theme-next/hexo-theme-next themes/next</span><br></pre></td></tr></table></figure>
<p><strong>更新主题</strong></p>
<p>运行以下命令即可更新主题，但这会覆盖原来的自定义修改</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> themes/next;git pull</span><br></pre></td></tr></table></figure>
<h2 id="配置next主题"><a class="markdownIt-Anchor" href="#配置next主题"></a> 配置Next主题</h2>
<p>配置博客涉及两个配置文件，一个路径是<code>[myblog]/_config.yml</code>和<code>[myblog]/theme/next/_config.yml</code>，前一个是站点配置，后一个是主题配置。下面就分别就这两个文件进行配置：</p>
<h3 id="配置站点_configyml"><a class="markdownIt-Anchor" href="#配置站点_configyml"></a> 配置站点_config.yml</h3>
<p>打开文件<code>[myblog]/_config.yml</code>，每个配置项按如下配置</p>
<h4 id="配置站点基本信息"><a class="markdownIt-Anchor" href="#配置站点基本信息"></a> 配置站点基本信息</h4>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Site</span></span><br><span class="line">title: 年轻人起来冲</span><br><span class="line">subtitle: <span class="string">&#x27;&#x27;</span></span><br><span class="line">description: <span class="string">&#x27;害怕失败是本能，勇敢面对才是本事&#x27;</span></span><br><span class="line">keywords:</span><br><span class="line">author: 绍桂</span><br><span class="line">language: zh-CN</span><br><span class="line">timezone: <span class="string">&#x27;Asia/Shanghai&#x27;</span></span><br></pre></td></tr></table></figure>
<h4 id="主题配置"><a class="markdownIt-Anchor" href="#主题配置"></a> 主题配置</h4>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Extensions</span></span><br><span class="line"><span class="comment">## Plugins: https://hexo.io/plugins/</span></span><br><span class="line"><span class="comment">## Themes: https://hexo.io/themes/</span></span><br><span class="line">theme: next</span><br></pre></td></tr></table></figure>
<h4 id="url配置"><a class="markdownIt-Anchor" href="#url配置"></a> URL配置</h4>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># URL</span></span><br><span class="line"><span class="comment">## If your site is put in a subdirectory, set url as &#x27;http://example.com/child&#x27; and root as &#x27;/child/&#x27;</span></span><br><span class="line">url: https://shaogui.life/</span><br><span class="line">root: /</span><br><span class="line">permalink: :year/:month/:day/:title/</span><br><span class="line">permalink_defaults:</span><br><span class="line">pretty_urls:</span><br><span class="line">  trailing_index: <span class="literal">true</span> <span class="comment"># Set to false to remove trailing &#x27;index.html&#x27; from permalinks</span></span><br><span class="line">  trailing_html: <span class="literal">true</span> <span class="comment"># Set to false to remove trailing &#x27;.html&#x27; from permalinks</span></span><br></pre></td></tr></table></figure>
<h4 id="翻页配置"><a class="markdownIt-Anchor" href="#翻页配置"></a> 翻页配置</h4>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Pagination</span></span><br><span class="line"><span class="comment">## Set per_page to 0 to disable pagination</span></span><br><span class="line">per_page: 8</span><br><span class="line">pagination_dir: page</span><br></pre></td></tr></table></figure>
<h3 id="配置主题_configyml"><a class="markdownIt-Anchor" href="#配置主题_configyml"></a> 配置主题_config.yml</h3>
<p>根据 Hexo 官方的推荐，不要直接修改主题的配置文件</p>
<blockquote>
<p>The file should be placed in your site folder, both <code>yml</code> and <code>json</code> are supported. <code>theme</code> inside <code>_config.yml</code> must be configured for Hexo to read <code>_config.[theme].yml</code></p>
</blockquote>
<p>而是将配置文件复制到和<code>[myblog]/_config.yml</code>同目录下，并命名为：<code>_config.next.yml</code>，在该文件上填写<strong>自己需要自定义的内容</strong>。</p>
<h4 id="网站logo配置"><a class="markdownIt-Anchor" href="#网站logo配置"></a> 网站logo配置</h4>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">favicon:</span><br><span class="line">  small: /images/favicon-16x16-next.png</span><br><span class="line">  medium: /images/favicon-32x32-next.png</span><br><span class="line">  apple_touch_icon: /images/apple-touch-icon-next.png</span><br><span class="line">  safari_pinned_tab: /images/logo.svg</span><br><span class="line">  <span class="comment">#android_manifest: /images/manifest.json</span></span><br><span class="line">  <span class="comment">#ms_browserconfig: /images/browserconfig.xml</span></span><br></pre></td></tr></table></figure>
<h4 id="主题风格配置"><a class="markdownIt-Anchor" href="#主题风格配置"></a> 主题风格配置</h4>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Schemes</span></span><br><span class="line"><span class="comment">#scheme: Muse</span></span><br><span class="line"><span class="comment">#scheme: Mist</span></span><br><span class="line"><span class="comment">#scheme: Pisces</span></span><br><span class="line">scheme: Gemini</span><br></pre></td></tr></table></figure>
<h4 id="菜单栏配置"><a class="markdownIt-Anchor" href="#菜单栏配置"></a> 菜单栏配置</h4>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">menu:</span><br><span class="line">  home: / || fa fa-home</span><br><span class="line">  categories: /categories/ || fa fa-th</span><br><span class="line">  tags: /tags/ || fa fa-tags</span><br><span class="line">  archives: /archives/ || fa fa-archive</span><br><span class="line">  about: /about/ || fa fa-user</span><br><span class="line">  <span class="comment">#schedule: /schedule/ || fa fa-calendar</span></span><br><span class="line">  <span class="comment">#sitemap: /sitemap.xml || fa fa-sitemap</span></span><br><span class="line">  <span class="comment">#commonweal: /404/ || fa fa-heartbeat</span></span><br></pre></td></tr></table></figure>
<p>注：||后面指的是图标，各个菜单实际显示的是中文，中英文对应配置文件位于<code>\themes\next\languages\zh-CN.yml</code>中，如果有其他菜单项可以在该文件配置其中文</p>
<h4 id="文章分类及标签"><a class="markdownIt-Anchor" href="#文章分类及标签"></a> 文章分类及标签<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup></h4>
<p>菜单栏中<code>categories</code>，<code>tags</code>，<code>about</code>点击后提示找不到页面，这时需要使用以下命令新建这三个页面</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo new page categories</span><br><span class="line">hexo new page tags</span><br><span class="line">hexo new page about</span><br></pre></td></tr></table></figure>
<p>运行三个命令后，均在<code>source</code>目录下生成相应的文件夹，此时菜单栏中可以打开这些项，但是没有内容，需要配置各自的<code>index.md</code></p>
<p>打开<code>source/categories/index.md</code>，添加type项</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line">title: categories</span><br><span class="line">date: 2021-02-18 21:44:21</span><br><span class="line"><span class="built_in">type</span>: categories</span><br><span class="line">---</span><br></pre></td></tr></table></figure>
<p>打开<code>source/tags/index.md</code>，添加type项</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line">title: tags</span><br><span class="line">date: 2021-02-18 21:44:21</span><br><span class="line"><span class="built_in">type</span>: tags</span><br><span class="line">---</span><br></pre></td></tr></table></figure>
<p>编辑文章时，在开头加入<code>categories</code>，<code>tags</code>项即刻对文章进行分类及打标签</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">title: xxx</span><br><span class="line">date: 2020-06-01 23:47:44</span><br><span class="line">tags: [xx,xx]</span><br><span class="line">categories: xx</span><br></pre></td></tr></table></figure>
<h4 id="顶部加载条"><a class="markdownIt-Anchor" href="#顶部加载条"></a> 顶部加载条</h4>
<p><strong>安装插件到Next主题</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/theme-next/theme-next-pace themes/next/<span class="built_in">source</span>/lib/pace</span><br></pre></td></tr></table></figure>
<p><strong>开启进度条</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Progress bar in the top during page loading.</span></span><br><span class="line"><span class="comment"># Dependencies: https://github.com/theme-next/theme-next-pace</span></span><br><span class="line"><span class="comment"># For more information: https://github.com/HubSpot/pace</span></span><br><span class="line">pace:</span><br><span class="line">  <span class="built_in">enable</span>: <span class="literal">true</span></span><br><span class="line">  <span class="comment"># Themes list:</span></span><br><span class="line">  <span class="comment"># big-counter | bounce | barber-shop | center-atom | center-circle | center-radar | center-simple</span></span><br><span class="line">  <span class="comment"># corner-indicator | fill-left | flat-top | flash | loading-bar | mac-osx | material | minimal</span></span><br><span class="line">  theme: minimal</span><br></pre></td></tr></table></figure>
<h4 id="添加访问量"><a class="markdownIt-Anchor" href="#添加访问量"></a> 添加访问量</h4>
<p>修改<code>themes/next/layout/_partials/footer.swig</code>文件</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&lt;div class=<span class="string">&quot;powered-by&quot;</span>&gt;</span><br><span class="line">    &#123;%- <span class="built_in">set</span> next_site = <span class="string">&#x27;https://theme-next.org&#x27;</span> %&#125;</span><br><span class="line">    &#123;%- <span class="keyword">if</span> theme.scheme !== <span class="string">&#x27;Gemini&#x27;</span> %&#125;</span><br><span class="line">      &#123;%- <span class="built_in">set</span> next_site = <span class="string">&#x27;https://&#x27;</span> + theme.scheme | lower + <span class="string">&#x27;.theme-next.org&#x27;</span> %&#125;</span><br><span class="line">    &#123;%- endif %&#125;</span><br><span class="line">    &#123;&#123;- __(<span class="string">&#x27;footer.powered&#x27;</span>, next_url(<span class="string">&#x27;https://hexo.io&#x27;</span>, <span class="string">&#x27;Hexo&#x27;</span>, &#123;class: <span class="string">&#x27;theme-link&#x27;</span>&#125;) + <span class="string">&#x27; &amp; &#x27;</span> + next_url(next_site, <span class="string">&#x27;NexT.&#x27;</span> + theme.scheme, &#123;class: <span class="string">&#x27;theme-link&#x27;</span>&#125;)) &#125;&#125;</span><br><span class="line">  &lt;/div&gt;</span><br></pre></td></tr></table></figure>
<p><strong>以上修改为以下：</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&lt;div class=<span class="string">&quot;powered-by&quot;</span>&gt;</span><br><span class="line">	&lt;i class=<span class="string">&quot;fa fa-user-md&quot;</span>&gt;&lt;/i&gt;</span><br><span class="line">	&lt;span id=<span class="string">&quot;busuanzi_container_site_uv&quot;</span>&gt;</span><br><span class="line">		本站访客数:&lt;span id=<span class="string">&quot;busuanzi_value_site_uv&quot;</span>&gt;&lt;/span&gt;</span><br><span class="line">	&lt;/span&gt;</span><br><span class="line">	&lt;span class=<span class="string">&quot;post-meta-divider&quot;</span>&gt;|&lt;/span&gt;</span><br><span class="line">	&lt;span id=<span class="string">&quot;busuanzi_container_site_pv&quot;</span>&gt;</span><br><span class="line">		本站访问量&lt;span id=<span class="string">&quot;busuanzi_value_site_pv&quot;</span>&gt;&lt;/span&gt;</span><br><span class="line">	&lt;/span&gt;</span><br><span class="line">&lt;/div&gt;</span><br></pre></td></tr></table></figure>
<h4 id="返回顶部按钮"><a class="markdownIt-Anchor" href="#返回顶部按钮"></a> 返回顶部按钮</h4>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">back2top:</span><br><span class="line">  <span class="built_in">enable</span>: <span class="literal">true</span></span><br><span class="line">  <span class="comment"># Back to top in sidebar.</span></span><br><span class="line">  sidebar: <span class="literal">true</span></span><br><span class="line">  <span class="comment"># Scroll percent label in b2t button.</span></span><br><span class="line">  scrollpercent: <span class="literal">true</span></span><br></pre></td></tr></table></figure>
<h4 id="修改底部标签样式"><a class="markdownIt-Anchor" href="#修改底部标签样式"></a> 修改底部标签样式</h4>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Use icon instead of the symbol # to indicate the tag at the bottom of the post</span></span><br><span class="line">tag_icon: <span class="literal">true</span></span><br></pre></td></tr></table></figure>
<h4 id="社交链接"><a class="markdownIt-Anchor" href="#社交链接"></a> 社交链接</h4>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Social Links</span></span><br><span class="line"><span class="comment"># Usage: `Key: permalink || icon`</span></span><br><span class="line"><span class="comment"># Key is the link label showing to end users.</span></span><br><span class="line"><span class="comment"># Value before `||` delimiter is the target permalink, value after `||` delimiter is the name of Font Awesome icon.</span></span><br><span class="line">social:</span><br><span class="line">  GitHub: https://github.com/WuShaogui || fab fa-github</span><br><span class="line">  E-Mail: wshglearn@163.com || fa fa-envelope</span><br><span class="line">  <span class="comment">#Weibo: https://weibo.com/yourname || fab fa-weibo</span></span><br><span class="line">  <span class="comment">#Google: https://plus.google.com/yourname || fab fa-google</span></span><br><span class="line">  <span class="comment">#Twitter: https://twitter.com/yourname || fab fa-twitter</span></span><br><span class="line">  <span class="comment">#FB Page: https://www.facebook.com/yourname || fab fa-facebook</span></span><br><span class="line">  <span class="comment">#StackOverflow: https://stackoverflow.com/yourname || fab fa-stack-overflow</span></span><br><span class="line">  <span class="comment">#YouTube: https://youtube.com/yourname || fab fa-youtube</span></span><br><span class="line">  <span class="comment">#Instagram: https://instagram.com/yourname || fab fa-instagram</span></span><br><span class="line">  <span class="comment">#Skype: skype:yourname?call|chat || fab fa-skype</span></span><br><span class="line"></span><br><span class="line">social_icons:</span><br><span class="line">  <span class="built_in">enable</span>: <span class="literal">true</span></span><br><span class="line">  icons_only: <span class="literal">false</span></span><br><span class="line">  transition: <span class="literal">false</span></span><br></pre></td></tr></table></figure>
<h4 id="打赏配置"><a class="markdownIt-Anchor" href="#打赏配置"></a> 打赏配置</h4>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Reward (Donate)</span></span><br><span class="line"><span class="comment"># Front-matter variable (unsupport animation).</span></span><br><span class="line">reward_settings:</span><br><span class="line">  <span class="comment"># If true, reward will be displayed in every article by default.</span></span><br><span class="line">  <span class="built_in">enable</span>: <span class="literal">true</span></span><br><span class="line">  animation: <span class="literal">true</span></span><br><span class="line">  comment: 坚持原创技术分享，您的支持将鼓励我继续创作！.</span><br><span class="line"></span><br><span class="line">reward:</span><br><span class="line">  wechatpay: /images/wechatpay.png</span><br><span class="line">  alipay: /images/alipay.png</span><br><span class="line">  <span class="comment">#paypal: /images/paypal.png</span></span><br><span class="line">  <span class="comment">#bitcoin: /images/bitcoin.png</span></span><br></pre></td></tr></table></figure>
<h4 id="follow_me"><a class="markdownIt-Anchor" href="#follow_me"></a> Follow_me</h4>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">follow_me:</span><br><span class="line">  <span class="comment">#Twitter: https://twitter.com/username || fab fa-twitter</span></span><br><span class="line">  <span class="comment">#Telegram: https://t.me/channel_name || fab fa-telegram</span></span><br><span class="line">  <span class="comment">#WeChat: /images/wechat_channel.jpg || fab fa-weixin</span></span><br><span class="line">  RSS: /atom.xml || fa fa-rss</span><br></pre></td></tr></table></figure>
<h4 id="github角标"><a class="markdownIt-Anchor" href="#github角标"></a> Github角标</h4>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># `Follow me on GitHub` banner in the top-right corner.</span></span><br><span class="line">github_banner:</span><br><span class="line">  <span class="built_in">enable</span>: <span class="literal">true</span></span><br><span class="line">  permalink: https://github.com/WuShaogui</span><br><span class="line">  title: Follow me on GitHub</span><br></pre></td></tr></table></figure>
<h4 id="搜索功能"><a class="markdownIt-Anchor" href="#搜索功能"></a> 搜索功能</h4>
<p>搜索功能需要安装插件实现，使用npm管理器安装以下插件</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install hexo-generator-searchdb --save</span><br></pre></td></tr></table></figure>
<p>在主题配置文件配置以下信息</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Local Search</span></span><br><span class="line"><span class="comment"># Dependencies: https://github.com/theme-next/hexo-generator-searchdb</span></span><br><span class="line">local_search:</span><br><span class="line">  <span class="built_in">enable</span>: <span class="literal">true</span></span><br><span class="line">  <span class="comment"># If auto, trigger search by changing input.</span></span><br><span class="line">  <span class="comment"># If manual, trigger search by pressing enter key or search button.</span></span><br><span class="line">  trigger: auto</span><br><span class="line">  <span class="comment"># Show top n results per article, show all results by setting to -1</span></span><br><span class="line">  top_n_per_article: 1</span><br><span class="line">  <span class="comment"># Unescape html strings to the readable one.</span></span><br><span class="line">  unescape: <span class="literal">false</span></span><br><span class="line">  <span class="comment"># Preload the search data when the page loads.</span></span><br><span class="line">  preload: <span class="literal">false</span></span><br></pre></td></tr></table></figure>
<h4 id="扩增markdown的功能"><a class="markdownIt-Anchor" href="#扩增markdown的功能"></a> 扩增Markdown的功能<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup></h4>
<p>hexo默认的渲染插件marked功能比较少，比如不支持脚注功能，部署时，脚注会出错，可以通过安装更强的渲染插件实现功能扩展。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#卸载原始markdown渲染插件</span></span><br><span class="line">npm un hexo-renderer-marked --save</span><br><span class="line"></span><br><span class="line"><span class="comment">#安装新的markdown渲染插件</span></span><br><span class="line">npm i @upupming/hexo-renderer-markdown-it-plus --save</span><br></pre></td></tr></table></figure>
<p>修改站点的配置文件<code>[myblog]/_config.yml</code>，增加以下信息</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Markdown config</span></span><br><span class="line">markdown_it_plus:</span><br><span class="line">  render:</span><br><span class="line">    html: <span class="literal">true</span>						</span><br><span class="line">    xhtmlOut: <span class="literal">false</span></span><br><span class="line">    breaks: <span class="literal">true</span></span><br><span class="line">    linkify: <span class="literal">true</span></span><br><span class="line">    typographer: <span class="literal">true</span></span><br><span class="line">    quotes: <span class="string">&#x27;“”‘’&#x27;</span></span><br><span class="line">  plugins:</span><br><span class="line">    - markdown-it-abbr</span><br><span class="line">    - markdown-it-footnote</span><br><span class="line">  anchors:	</span><br><span class="line">    level: 2</span><br><span class="line">    collisionSuffix: <span class="string">&#x27;v&#x27;</span></span><br><span class="line">    permalink: <span class="literal">true</span></span><br><span class="line">    permalinkClass: header-anchor</span><br><span class="line">    permalinkSide: <span class="string">&#x27;left&#x27;</span></span><br><span class="line">    permalinkSymbol: ¶</span><br></pre></td></tr></table></figure>
<p><code>plugins</code>指定需要扩展的功能，支持添加以下功能</p>
<ul>
<li><code>markdown-it-emoji</code>支持emoji，<code>:cat:</code>→`🐱</li>
<li><code>markdown-it-sub</code> 支持<code>H~2~O</code>→H2O</li>
<li><code>markdown-it-sup</code> 支持<code>X^2^</code>→X2</li>
<li><code>markdown-it-deflist</code> 支持自定义列表</li>
<li><code>markdown-it-abbr</code>支持<code>&lt;abbr&gt;</code>标签</li>
<li><code>markdown-it-footnote</code>支持引入参考文献。emmm就是上标数字，最后附上文献那种</li>
<li><code>markdown-it-ins</code>支持<code>++Inserted++</code> →Inserted， <code>~~Del~~ →</code>Del</li>
<li><code>markdown-it-mark</code>支持<code>==marked==</code>→inserted</li>
<li><code>markdown-it-katex</code><strong>支持katex公式</strong></li>
<li><code>markdown-it-toc-and-anchor</code>支持<code>@[toc]</code>生成目录</li>
</ul>
<p>使用以上扩展功能前，需使用以下命令安装该功能的插件</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install markdown-it-... --save</span><br></pre></td></tr></table></figure>
<p><strong>添加MathJax 数学公式支持</strong></p>
<p>在以上配置基础上，修改两个文件</p>
<h4 id="访客统计"><a class="markdownIt-Anchor" href="#访客统计"></a> 访客统计</h4>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Show Views / Visitors of the website / page with busuanzi.</span></span><br><span class="line"><span class="comment"># Get more information on http://ibruce.info/2015/04/04/busuanzi</span></span><br><span class="line">busuanzi_count:</span><br><span class="line">  <span class="built_in">enable</span>: <span class="literal">true</span></span><br><span class="line">  total_visitors: <span class="literal">true</span></span><br><span class="line">  total_visitors_icon: fa fa-user</span><br><span class="line">  total_views: <span class="literal">true</span></span><br><span class="line">  total_views_icon: fa fa-eye</span><br><span class="line">  post_views: <span class="literal">true</span></span><br><span class="line">  post_views_icon: fa fa-eye</span><br></pre></td></tr></table></figure>
<h4 id="阅读全文"><a class="markdownIt-Anchor" href="#阅读全文"></a> 阅读全文<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup></h4>
<p>在文章中，使用标记<code>&lt;!-- more --&gt;</code>实现文章摘要功能，该标记前的内容为文章摘要，显示在首页上</p>
<h4 id="文章置顶"><a class="markdownIt-Anchor" href="#文章置顶"></a> 文章置顶<sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup></h4>
<p>两个步骤完成该操作</p>
<p><strong>更换插件</strong></p>
<p>通过以下命令更换支持置顶的插件</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm uninstall hexo-generator-index --save</span><br><span class="line">npm install hexo-generator-index-pin-top --save</span><br></pre></td></tr></table></figure>
<p><strong>设置置顶标志</strong></p>
<p>打开文件：<code>/blog/themes/next/layout/_macro/post.swig</code>，在<code>&lt;div class=&quot;post-meta&quot;&gt;</code>标签下插入以下代码</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&#123;% <span class="keyword">if</span> post.top %&#125;</span><br><span class="line">   &lt;i class=<span class="string">&quot;fa fa-thumb-tack&quot;</span>&gt;&lt;/i&gt;</span><br><span class="line">   &lt;font color=7D26CD&gt;置顶&lt;/font&gt;</span><br><span class="line">   &lt;span class=<span class="string">&quot;post-meta-divider&quot;</span>&gt;|&lt;/span&gt;</span><br><span class="line">&#123;% endif %&#125;</span><br></pre></td></tr></table></figure>
<p>往后写文章时，准备置顶的文章需要在Front-matter中添加<code>top: true</code></p>
<h4 id="文章字数统计"><a class="markdownIt-Anchor" href="#文章字数统计"></a> 文章字数统计</h4>
<p><strong>安装字数统计插件</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo npm install hexo-symbols-count-time</span><br></pre></td></tr></table></figure>
<p><strong>配置开启数字统计</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Post wordcount display settings</span></span><br><span class="line"><span class="comment"># Dependencies: https://github.com/theme-next/hexo-symbols-count-time</span></span><br><span class="line">symbols_count_time:</span><br><span class="line">  separated_meta: <span class="literal">true</span></span><br><span class="line">  item_text_post: <span class="literal">true</span></span><br><span class="line">  item_text_total: <span class="literal">true</span></span><br><span class="line">  awl: 4</span><br><span class="line">  wpm: 275</span><br></pre></td></tr></table></figure>
<h4 id="文章内链接样式"><a class="markdownIt-Anchor" href="#文章内链接样式"></a> 文章内链接样式</h4>
<p>原始样式只是加一条下划线，为了更加明显显示链接，通过在文件<code>Blog/themes/next/source/css/_common/components/post/post.styl</code>添加以下样式实现</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">// 文章内链接文本样式</span><br><span class="line">.post-body p a&#123;</span><br><span class="line">  color: <span class="comment">#0593d3; //原始链接颜色</span></span><br><span class="line">  border-bottom: none;</span><br><span class="line">  border-bottom: 1px solid <span class="comment">#0593d3; //底部分割线颜色</span></span><br><span class="line">  &amp;:hover &#123;</span><br><span class="line">    color: <span class="comment">#fc6423; //鼠标经过颜色</span></span><br><span class="line">    border-bottom: none;</span><br><span class="line">    border-bottom: 1px solid <span class="comment">#fc6423; //底部分割线颜色</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="文章结束标志"><a class="markdownIt-Anchor" href="#文章结束标志"></a> 文章结束标志</h4>
<p>通过3个步骤完成该优化</p>
<p><strong>新建结束文件</strong></p>
<p>在目录<code>Blog\themes\next\layout\_macro</code>新建文件<code>passage-end-tag.swig</code>，并添加以下内容</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&lt;div&gt;</span><br><span class="line">    &#123;% <span class="keyword">if</span> not is_index %&#125;</span><br><span class="line">        &lt;div style=<span class="string">&quot;text-align:center;color: #ccc;font-size:14px;&quot;</span>&gt;-------------本文结束&lt;i class=<span class="string">&quot;fa fa-paw&quot;</span>&gt;&lt;/i&gt;感谢您的阅读-------------&lt;/div&gt;</span><br><span class="line">    &#123;% endif %&#125;</span><br><span class="line">&lt;/div&gt;</span><br></pre></td></tr></table></figure>
<p><strong>配置结束文件至文章末尾</strong></p>
<p>打开文件<code>Blog\themes\next\layout\_macro\post.swig</code>，将以下代码添加到post-body之后，post-footer之前</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&lt;div&gt;</span><br><span class="line">  &#123;% <span class="keyword">if</span> not is_index %&#125;</span><br><span class="line">    &#123;% include <span class="string">&#x27;passage-end-tag.swig&#x27;</span> %&#125;</span><br><span class="line">  &#123;% endif %&#125;</span><br><span class="line">&lt;/div&gt;</span><br></pre></td></tr></table></figure>
<p><strong>配置主题配置文件</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 文章末尾添加“本文结束”标记</span></span><br><span class="line">passage_end_tag:</span><br><span class="line">  enabled: <span class="literal">true</span></span><br></pre></td></tr></table></figure>
<h4 id="文章添加阴影"><a class="markdownIt-Anchor" href="#文章添加阴影"></a> 文章添加阴影</h4>
<p>打开<code>\themes\next\source\css\_custom\custom.styl</code>，向里面加入以下代码</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">// 主页文章添加阴影效果</span><br><span class="line"> .post &#123;</span><br><span class="line">   margin-top: 60px;</span><br><span class="line">   margin-bottom: 60px;</span><br><span class="line">   padding: 25px;</span><br><span class="line">   -webkit-box-shadow: 0 0 5px rgba(202, 203, 203, .5);</span><br><span class="line">   -moz-box-shadow: 0 0 5px rgba(202, 203, 204, .5);</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<h4 id="文字底部评论"><a class="markdownIt-Anchor" href="#文字底部评论"></a> 文字底部评论</h4>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Valine</span></span><br><span class="line"><span class="comment"># For more information: https://valine.js.org, https://github.com/xCss/Valine</span></span><br><span class="line">valine:</span><br><span class="line">  <span class="built_in">enable</span>: <span class="literal">true</span></span><br><span class="line">  appid: xxxxxxxxxxxxxxxxx <span class="comment"># Your leancloud application appid</span></span><br><span class="line">  appkey: xxxxxxxxxxxxxxxxx <span class="comment"># Your leancloud application appkey</span></span><br><span class="line">  notify: <span class="literal">false</span> <span class="comment"># Mail notifier</span></span><br><span class="line">  verify: <span class="literal">false</span> <span class="comment"># Verification code</span></span><br><span class="line">  placeholder: 留下你的评论吧 <span class="comment"># Comment box placeholder</span></span><br><span class="line">  avatar: mm <span class="comment"># Gravatar style</span></span><br><span class="line">  guest_info: nick,mail,link <span class="comment"># Custom comment header</span></span><br><span class="line">  pageSize: 10 <span class="comment"># Pagination size</span></span><br><span class="line">  language: <span class="comment"># Language, available values: en, zh-cn</span></span><br><span class="line">  visitor: <span class="literal">true</span> <span class="comment"># Article reading statistic</span></span><br><span class="line">  comment_count: <span class="literal">true</span> <span class="comment"># If false, comment count will only be displayed in post page, not in home page</span></span><br><span class="line">  recordIP: <span class="literal">true</span> <span class="comment"># Whether to record the commenter IP</span></span><br><span class="line">  serverURLs: <span class="comment"># When the custom domain name is enabled, fill it in here (it will be detected automatically by default, no need to fill in)</span></span><br><span class="line">  <span class="comment">#post_meta_order: 0</span></span><br></pre></td></tr></table></figure>
<h4 id="版权声明"><a class="markdownIt-Anchor" href="#版权声明"></a> 版权声明</h4>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Creative Commons 4.0 International License.</span></span><br><span class="line"><span class="comment"># See: https://creativecommons.org/share-your-work/licensing-types-examples</span></span><br><span class="line"><span class="comment"># Available values of license: by | by-nc | by-nc-nd | by-nc-sa | by-nd | by-sa | zero</span></span><br><span class="line"><span class="comment"># You can set a language value if you prefer a translated version of CC license, e.g. deed.zh</span></span><br><span class="line"><span class="comment"># CC licenses are available in 39 languages, you can find the specific and correct abbreviation you need on https://creativecommons.org</span></span><br><span class="line">creative_commons:</span><br><span class="line">  license: by-nc-sa</span><br><span class="line">  sidebar: <span class="literal">true</span></span><br><span class="line">  post: <span class="literal">true</span></span><br><span class="line">  language:</span><br></pre></td></tr></table></figure>
<h4 id="侧边栏配置"><a class="markdownIt-Anchor" href="#侧边栏配置"></a> 侧边栏配置</h4>
<p>将菜单栏配置在左边还是右边，以及大小</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ---------------------------------------------------------------</span></span><br><span class="line"><span class="comment"># Sidebar Settings</span></span><br><span class="line"><span class="comment"># See: https://theme-next.org/docs/theme-settings/sidebar</span></span><br><span class="line"><span class="comment"># ---------------------------------------------------------------</span></span><br><span class="line"></span><br><span class="line">sidebar:</span><br><span class="line">  <span class="comment"># Sidebar Position.</span></span><br><span class="line">  position: left</span><br><span class="line">  <span class="comment"># position: right</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Manual define the sidebar width. If commented, will be default for:</span></span><br><span class="line">  <span class="comment"># Muse | Mist: 320</span></span><br><span class="line">  <span class="comment"># Pisces | Gemini: 240</span></span><br><span class="line">  width: 240</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Sidebar Display (only for Muse | Mist), available values:</span></span><br><span class="line">  <span class="comment">#  - post    expand on posts automatically. Default.</span></span><br><span class="line">  <span class="comment">#  - always  expand for all pages automatically.</span></span><br><span class="line">  <span class="comment">#  - hide    expand only when click on the sidebar toggle icon.</span></span><br><span class="line">  <span class="comment">#  - remove  totally remove sidebar including sidebar toggle.</span></span><br><span class="line">  display: post</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Sidebar padding in pixels.</span></span><br><span class="line">  padding: 18</span><br><span class="line">  <span class="comment"># Sidebar offset from top menubar in pixels (only for Pisces | Gemini).</span></span><br><span class="line">  offset: 12</span><br><span class="line">  <span class="comment"># Enable sidebar on narrow view (only for Muse | Mist).</span></span><br><span class="line">  onmobile: <span class="literal">false</span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># Sidebar Avatar</span></span><br><span class="line">avatar:</span><br><span class="line">  <span class="comment"># Replace the default image and set the url here.</span></span><br><span class="line">  url: /images/avatar.gif</span><br><span class="line">  <span class="comment"># If true, the avatar will be dispalyed in circle.</span></span><br><span class="line">  rounded: <span class="literal">true</span></span><br><span class="line">  <span class="comment"># If true, the avatar will be rotated with the cursor.</span></span><br><span class="line">  rotated: <span class="literal">true</span></span><br></pre></td></tr></table></figure>
<h4 id="rss及rss侧边栏"><a class="markdownIt-Anchor" href="#rss及rss侧边栏"></a> RSS及RSS侧边栏</h4>
<p><strong>安装rss插件</strong></p>
<p>运行下面命令安装rss插件</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install --save hexo-generator-feed</span><br></pre></td></tr></table></figure>
<p><strong>配置rss功能</strong></p>
<p>在<code>_config.next.yml</code>中找到rss配置项，修改为以下形式</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rss: /atom.xml</span><br></pre></td></tr></table></figure>
<h4 id="设置头像"><a class="markdownIt-Anchor" href="#设置头像"></a> 设置头像</h4>
<p>无</p>
<h4 id="网站背景"><a class="markdownIt-Anchor" href="#网站背景"></a> 网站背景</h4>
<p>无</p>
<h4 id="动态背景"><a class="markdownIt-Anchor" href="#动态背景"></a> 动态背景</h4>
<p>略，暂不设置，需要消耗电脑资源，并且干扰阅读</p>
<h4 id="网站运行时间"><a class="markdownIt-Anchor" href="#网站运行时间"></a> 网站运行时间</h4>
<p>打开文件<code>themes/next/layout/_partials/footer.swig</code>，添加以下代码</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&lt;div&gt;</span><br><span class="line">&lt;span id=<span class="string">&quot;timeDate&quot;</span>&gt;载入天数...&lt;/span&gt;&lt;span id=<span class="string">&quot;times&quot;</span>&gt;载入时分秒...&lt;/span&gt;</span><br><span class="line">&lt;script&gt;</span><br><span class="line">    var now = new Date();</span><br><span class="line">    <span class="keyword">function</span> <span class="function"><span class="title">createtime</span></span>() &#123;</span><br><span class="line">        var grt= new Date(<span class="string">&quot;03/04/2020 00:00:00&quot;</span>);</span><br><span class="line">        now.setTime(now.getTime()+250);</span><br><span class="line">        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days);</span><br><span class="line">        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours);</span><br><span class="line">        <span class="keyword">if</span>(String(hnum).length ==1 )&#123;hnum = <span class="string">&quot;0&quot;</span> + hnum;&#125; minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);</span><br><span class="line">        mnum = Math.floor(minutes); <span class="keyword">if</span>(String(mnum).length ==1 )&#123;mnum = <span class="string">&quot;0&quot;</span> + mnum;&#125;</span><br><span class="line">        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);</span><br><span class="line">        snum = Math.round(seconds); <span class="keyword">if</span>(String(snum).length ==1 )&#123;snum = <span class="string">&quot;0&quot;</span> + snum;&#125;</span><br><span class="line">        document.getElementById(<span class="string">&quot;timeDate&quot;</span>).innerHTML = <span class="string">&quot;本站已安全运行 &quot;</span>+dnum+<span class="string">&quot; 天 &quot;</span>;</span><br><span class="line">        document.getElementById(<span class="string">&quot;times&quot;</span>).innerHTML = hnum + <span class="string">&quot; 小时 &quot;</span> + mnum + <span class="string">&quot; 分 &quot;</span> + snum + <span class="string">&quot; 秒&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">setInterval(<span class="string">&quot;createtime()&quot;</span>,250);</span><br><span class="line">&lt;/script&gt;</span><br><span class="line">&lt;/div&gt;</span><br></pre></td></tr></table></figure>
<h4 id="添加网易云音乐"><a class="markdownIt-Anchor" href="#添加网易云音乐"></a> 添加网易云音乐</h4>
<p>获得单曲或者歌单的<code>外链播放器</code>，将代码添加到<code>themes/next/layout/_macro/sidebar.swig</code>下，以下是一个外链播放器</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&lt;iframe frameborder=<span class="string">&quot;no&quot;</span> border=<span class="string">&quot;0&quot;</span> marginwidth=<span class="string">&quot;0&quot;</span> marginheight=<span class="string">&quot;0&quot;</span> width=330 height=86 src=<span class="string">&quot;//music.163.com/outchain/player?type=2&amp;id=481853876&amp;auto=1&amp;height=66&quot;</span>&gt;&lt;/iframe&gt;</span><br></pre></td></tr></table></figure>
<h4 id="添加彩色标签"><a class="markdownIt-Anchor" href="#添加彩色标签"></a> 添加彩色标签</h4>
<p>将标签页的标签打上颜色<sup class="footnote-ref"><a href="#fn5" id="fnref5">[5]</a></sup></p>
<p>新建文件：<code>themes\next\layout\tag-color.swig</code>，写入以下内容</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;script type&#x3D;&quot;text&#x2F;javascript&quot;&gt;</span><br><span class="line">     var alltags &#x3D; document.getElementsByClassName(&#39;tag-cloud-tags&#39;);</span><br><span class="line">     var tags &#x3D; alltags[0].getElementsByTagName(&#39;a&#39;);</span><br><span class="line">     for (var i &#x3D; tags.length - 1; i &gt;&#x3D; 0; i--) &#123;</span><br><span class="line">       var golden_ratio &#x3D; 0.618033988749895;</span><br><span class="line">       var s &#x3D; 0.5;</span><br><span class="line">       var v &#x3D; 0.999;</span><br><span class="line">       var h &#x3D; golden_ratio + Math.random()*0.8 - 0.5;</span><br><span class="line">       var h_i &#x3D; parseInt(h * 6);</span><br><span class="line">       var f &#x3D; h * 6 - h_i;</span><br><span class="line">       var p &#x3D; v * (1 - s);</span><br><span class="line">       var q &#x3D; v * (1 - f * s);</span><br><span class="line">       var t &#x3D; v * (1 - (1 - f) * s);</span><br><span class="line">       var r, g, b;</span><br><span class="line">       switch (h_i) &#123;</span><br><span class="line">          case 0:</span><br><span class="line">              r &#x3D; v;</span><br><span class="line">              g &#x3D; t;</span><br><span class="line">              b &#x3D; p;</span><br><span class="line">              break;</span><br><span class="line">          case 1:</span><br><span class="line">              r &#x3D; q;</span><br><span class="line">              g &#x3D; v;</span><br><span class="line">              b &#x3D; p;</span><br><span class="line">              break;</span><br><span class="line">          case 2:</span><br><span class="line">              r &#x3D; p;</span><br><span class="line">              g &#x3D; v;</span><br><span class="line">              b &#x3D; t;</span><br><span class="line">              break;</span><br><span class="line">          case 3 :</span><br><span class="line">              r &#x3D; p;</span><br><span class="line">              g &#x3D; q;</span><br><span class="line">              b &#x3D; v;</span><br><span class="line">              break;</span><br><span class="line">          case 4:</span><br><span class="line">              r &#x3D; t;</span><br><span class="line">              g &#x3D; p;</span><br><span class="line">              b &#x3D; v;</span><br><span class="line">              break;</span><br><span class="line">          case 5:</span><br><span class="line">              r &#x3D; v;</span><br><span class="line">              g &#x3D; p;</span><br><span class="line">              b &#x3D; q;</span><br><span class="line">              break;</span><br><span class="line">          default:</span><br><span class="line">              r &#x3D; 1;</span><br><span class="line">              g &#x3D; 1;</span><br><span class="line">              b &#x3D; 1;</span><br><span class="line">        &#125;</span><br><span class="line">       tags[i].style.background &#x3D; &quot;rgba(&quot;+parseInt(r*255)+&quot;,&quot;+parseInt(g*255)+&quot;,&quot;+parseInt(b*255)+&quot;,&quot;+0.5+&quot;)&quot;;</span><br><span class="line">     &#125;</span><br><span class="line">&lt;&#x2F;script&gt;</span><br><span class="line"></span><br><span class="line">&lt;style&gt;</span><br><span class="line">  .tag-cloud-tags&#123;</span><br><span class="line">    text-align: center;</span><br><span class="line">    counter-reset: tags;</span><br><span class="line">  &#125;</span><br><span class="line">  .tag-cloud-tags a&#123;</span><br><span class="line">    display: inline-block;</span><br><span class="line">    border: 0px;</span><br><span class="line">    border-radius: 10px;</span><br><span class="line">    padding: 0px 10px;</span><br><span class="line">    margin: 8px;</span><br><span class="line">    color: rgba(34, 34, 34, 0.8);</span><br><span class="line">    </span><br><span class="line">  &#125;</span><br><span class="line">&#x2F;* 文字前添加相应的符号，content后的Unicode可以自定义*&#x2F;</span><br><span class="line">  .tag-cloud-tags a:before&#123;</span><br><span class="line">    font-family: &#39;Font Awesome 5 Free&#39;;</span><br><span class="line">    content: &quot;\f02b&quot;;</span><br><span class="line">    font-weight: 900;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  .tag-cloud-tags a:hover&#123;</span><br><span class="line">     box-shadow: 0px 5px 15px 0px rgba(0,0,0,.4);</span><br><span class="line">     transform: scale(1.1);</span><br><span class="line">     transition-duration: 0.15s;</span><br><span class="line">  &#125;</span><br><span class="line">&lt;&#x2F;style&gt;</span><br></pre></td></tr></table></figure>
<p>打开文件：<code>theme/next/layout/page.swig</code>，修改节点<code>&lt;div class=&quot;tag-cloud-title&quot;&gt;</code>的信息如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;div class&#x3D;&quot;post-body&#123;%- if page.direction and page.direction.toLowerCase() &#x3D;&#x3D;&#x3D; &#39;rtl&#39; %&#125; rtl&#123;%- endif %&#125;&quot;&gt;</span><br><span class="line">       &#123;%- if page.type &#x3D;&#x3D;&#x3D; &#39;tags&#39; %&#125;</span><br><span class="line">         &lt;div class&#x3D;&quot;tag-cloud&quot;&gt;</span><br><span class="line">           &lt;div class&#x3D;&quot;tag-cloud-title&quot;&gt;</span><br><span class="line">             &#123;&#123; _p(&#39;counter.tag_cloud&#39;, site.tags.length) &#125;&#125;</span><br><span class="line">           &lt;&#x2F;div&gt;</span><br><span class="line">           &lt;div class&#x3D;&quot;tag-cloud-tags&quot;&gt;</span><br><span class="line">             &#123;&#123; tagcloud(&#123;</span><br><span class="line">               min_font   : theme.tagcloud.min,</span><br><span class="line">               max_font   : theme.tagcloud.max,</span><br><span class="line">               amount     : theme.tagcloud.amount,</span><br><span class="line">               color      : false,</span><br><span class="line">               start_color: theme.tagcloud.start,</span><br><span class="line">               end_color  : theme.tagcloud.end&#125;)</span><br><span class="line">             &#125;&#125;</span><br><span class="line">           &lt;&#x2F;div&gt;</span><br><span class="line">         &lt;&#x2F;div&gt;</span><br><span class="line">       &#123;% include &#39;tag-color.swig&#39;%&#125;</span><br></pre></td></tr></table></figure>
<p><strong>参考资料<sup class="footnote-ref"><a href="#fn6" id="fnref6">[6]</a></sup><sup class="footnote-ref"><a href="#fn7" id="fnref7">[7]</a></sup><sup class="footnote-ref"><a href="#fn8" id="fnref8">[8]</a></sup>：</strong></p>
<hr class="footnotes-sep" />
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p><a href="https://www.jianshu.com/p/4d37bc01290b">Hexo 添加分类及标签</a> <a href="#fnref1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn2" class="footnote-item"><p><a href="https://blog.csdn.net/qq_36667170/article/details/105846999">hexo markdown渲染器 @upupming/hexo-renderer-markdown-it-plus</a> <a href="#fnref2" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn3" class="footnote-item"><p><a href="https://blog.csdn.net/yueyue200830/article/details/104470646/">设置hexo首页只显示部分摘要（不显示全文）</a> <a href="#fnref3" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn4" class="footnote-item"><p><a href="https://blog.csdn.net/qwerty200696/article/details/79010629">hexo博客优化之文章置顶+置顶标签</a> <a href="#fnref4" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn5" class="footnote-item"><p><a href="https://blog.csdn.net/qq_39974578/article/details/114172260">给next添加彩色标签</a> <a href="#fnref5" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn6" class="footnote-item"><p><a href="http://jeffyang.top/Hexo/Hexo%E4%B8%BB%E9%A2%98Next%E7%BE%8E%E5%8C%96/">Hexo博客设置以及Next主题美化</a> <a href="#fnref6" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn7" class="footnote-item"><p><a href="https://zhuanlan.zhihu.com/p/129644138">hexo+next个性化配置</a> <a href="#fnref7" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn8" class="footnote-item"><p><a href="https://www.jianshu.com/p/9f0e90cc32c2">Hexo-NexT配置超炫网页效果</a> <a href="#fnref8" class="footnote-backref">↩︎</a></p>
</li>
</ol>
</section>
]]></content>
      <categories>
        <category>软件工具</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Next</tag>
        <tag>博客</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo操作命令备忘录</title>
    <url>/2021/03/06/Hexo%E6%93%8D%E4%BD%9C%E5%A4%87%E5%BF%98%E5%BD%95/</url>
    <content><![CDATA[<p>本文用于记录hexo常见的操作步骤，即使温习回顾</p>
<a id="more"></a>
<h2 id="hexo常见命令"><a class="markdownIt-Anchor" href="#hexo常见命令"></a> Hexo常见命令<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup></h2>
<h3 id="新建文章"><a class="markdownIt-Anchor" href="#新建文章"></a> 新建文章</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo new &lt;title&gt;</span><br><span class="line">hexo new <span class="string">&quot;post title with whitespace&quot;</span></span><br></pre></td></tr></table></figure>
<p><strong>参数：</strong></p>
<ul>
<li>-p,–path	   自定义新文章路径</li>
<li>-r,–replace   如果存在同名文件，将其覆盖</li>
<li>-s,–slug        文章Slug，作为新文章的文件名和发布后的 URL</li>
</ul>
<p>注意：文件明包含空格时，需要用双引号括起来</p>
<h3 id="新建草稿"><a class="markdownIt-Anchor" href="#新建草稿"></a> 新建草稿</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo new draft &lt;title&gt;</span><br><span class="line">hexo new draft <span class="string">&quot;draft title with whitespace&quot;</span></span><br></pre></td></tr></table></figure>
<h3 id="发布草稿"><a class="markdownIt-Anchor" href="#发布草稿"></a> 发布草稿</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo publish &lt;title&gt;</span><br><span class="line">hexo publish <span class="string">&quot;draft title with whitespace&quot;</span></span><br></pre></td></tr></table></figure>
<p>注意：title不带文件后缀<code>.md</code></p>
<h3 id="新建页面"><a class="markdownIt-Anchor" href="#新建页面"></a> 新建页面</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo new page --path about/me <span class="string">&quot;About me&quot;</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意：以上命令会创建一个 <code>source/about/me.md</code> 文件，同时 Front Matter 中的 title 为 <code>&quot;About me&quot;</code></p>
</blockquote>
<h3 id="生成博客"><a class="markdownIt-Anchor" href="#生成博客"></a> 生成博客</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo generate</span><br><span class="line">hexo g</span><br></pre></td></tr></table></figure>
<p><strong>参数：</strong></p>
<ul>
<li>-d,–deploy            文件生成后立即部署</li>
<li>-w,–watch             监视文件改动</li>
<li>-b,-bail                   生成过程中如果发生任何未处理的异常则抛出异常</li>
<li>-f,–force                强制重新生成文件</li>
<li>-c,–concurrency  最大同时生成文件的数量，默认无限制</li>
</ul>
<h3 id="本地浏览"><a class="markdownIt-Anchor" href="#本地浏览"></a> 本地浏览</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo server</span><br><span class="line">hexo s</span><br></pre></td></tr></table></figure>
<p><strong>参数：</strong></p>
<ul>
<li>-p,–port            重设端口</li>
<li>-s,–static          只使用静态文件</li>
<li>-l,–log               启动日记记录，使用覆盖记录格式</li>
</ul>
<h2 id="远程部署"><a class="markdownIt-Anchor" href="#远程部署"></a> 远程部署</h2>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo deploy</span><br><span class="line">hexo d</span><br></pre></td></tr></table></figure>
<p><strong>参数：</strong></p>
<ul>
<li>-g,–generate   部署之前预先生成静态文件</li>
</ul>
<h3 id="清除缓存"><a class="markdownIt-Anchor" href="#清除缓存"></a> 清除缓存</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo clean</span><br></pre></td></tr></table></figure>
<blockquote>
<p>清除缓存文件 (<code>db.json</code>) 和已生成的静态文件 (<code>public</code>)</p>
</blockquote>
<blockquote>
<p>在某些情况（尤其是更换主题后），如果发现您对站点的更改无论如何也不生效，您可能需要运行该命令</p>
</blockquote>
<h3 id="查看版本"><a class="markdownIt-Anchor" href="#查看版本"></a> 查看版本</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo server</span><br></pre></td></tr></table></figure>
<h2 id="hexo的yaml-front-matter"><a class="markdownIt-Anchor" href="#hexo的yaml-front-matter"></a> Hexo的YAML Front Matter<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup></h2>
<p>文章参数列举如下：</p>
<table>
<thead>
<tr>
<th>参数</th>
<th>描述</th>
<th>取值</th>
</tr>
</thead>
<tbody>
<tr>
<td>title</td>
<td>标题名</td>
<td></td>
</tr>
<tr>
<td>date</td>
<td>创建日期</td>
<td></td>
</tr>
<tr>
<td>updated</td>
<td>更新日期</td>
<td></td>
</tr>
<tr>
<td>tags</td>
<td>标签</td>
<td>- 标签1<br />- 标签2<br />- 标签3</td>
</tr>
<tr>
<td>categories</td>
<td>分类</td>
<td>- 分类<br />- 子分类<br />- 子子分类</td>
</tr>
<tr>
<td>copyright</td>
<td>是否添加版权声明</td>
<td>true</td>
</tr>
<tr>
<td>top</td>
<td>是否置顶</td>
<td>true/空</td>
</tr>
<tr>
<td>description</td>
<td>文章描述</td>
<td>空</td>
</tr>
<tr>
<td>mathjax:</td>
<td>是否添加latex公式支持</td>
<td>true</td>
</tr>
</tbody>
</table>
<p><strong>参考资料：</strong></p>
<hr class="footnotes-sep" />
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p><a href="https://hexo.io/zh-cn/docs/commands">指令 | Hexo</a> <a href="#fnref1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn2" class="footnote-item"><p><a href="https://blog.csdn.net/nineya_com/article/details/103316683">Hexo博客发表文章、草稿、添加分类和标签_玖涯博客-CSDN博客</a> <a href="#fnref2" class="footnote-backref">↩︎</a></p>
</li>
</ol>
</section>
]]></content>
      <categories>
        <category>软件工具</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Next</tag>
        <tag>博客</tag>
      </tags>
  </entry>
  <entry>
    <title>Jupyter开发环境搭建</title>
    <url>/2018/04/11/Jupyter%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/</url>
    <content><![CDATA[<p>Jupyter Notebook是一款开放源代码的Web应用程序，允许您创建和共享包含实时代码，方程式，可视化和叙述文本的文档。用途包括：数据清理和转换，数值模拟，统计建模，数据可视化，机器学习等等。</p>
<blockquote>
<p>翻译自<a href="http://jupyter.org/index.html">Jupyter官网</a></p>
</blockquote>
<a id="more"></a>
<h1 id="1jupyter安装"><a class="markdownIt-Anchor" href="#1jupyter安装"></a> 1.Jupyter安装</h1>
<p><strong>2.1检查你的python版本</strong><br />
一般在Linux上直接在命令行执行下面命令便可以可到python版本。</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613527089373.gif" alt="enter description here" title="查看系统Python版本" /></p>
<p>在Windows,命令行输入同样命令进行检查。</p>
<p><strong>2.2安装jupyter</strong></p>
<p>如果你的系统是Python 3的版本，输入以下命令安装：</p>
 <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"> python3 -m pip install --upgrade pip</span><br><span class="line">python3 -m pip install jupyter</span><br></pre></td></tr></table></figure>
<p>如果你的系统是Python 2的版本，输入以下命令安装：</p>
 <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">python -m pip install --upgrade pip</span><br><span class="line">python -m pip install jupyter</span><br></pre></td></tr></table></figure>
<h1 id="2notedown插件安装"><a class="markdownIt-Anchor" href="#2notedown插件安装"></a> 2.notedown插件安装</h1>
<p>markdown是一种文字编辑器，通过约定的符号快速写出自己需要的文档。<br />
通过下面命令在jupyter 上安装markdown</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pip install https://github.com/mli/notedown/tarball/master</span><br></pre></td></tr></table></figure>
<p>插件安装完成后，需要配置启动Jupyter是默认启动markdown插件，配置过程如下：</p>
<p>(1)生成配置文件</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">jupyter notebook --generate-config</span><br></pre></td></tr></table></figure>
<p>(2)修改配置文件<br />
Windows系统下配置文件在：C:\Users\Administrator.jupyter\jupyter_notebook_config.py<br />
Linux系统的配置文件在：~/.jupyter/jupyter_notebook_config.py</p>
<p>打开这个文件，并将下面的配置添加到文件的末尾。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">c.NotebookApp.contents_manager_class = <span class="string">&#x27;notedown.NotedownContentsManager&#x27;</span></span><br></pre></td></tr></table></figure>
<h1 id="3扩展包安装"><a class="markdownIt-Anchor" href="#3扩展包安装"></a> 3.扩展包安装</h1>
<p>Jupyter notebook extensions是一个为Jupyter notebook提供一系列扩展的库。安装它将极大提升编程效率。</p>
<p><strong>安装</strong><br />
(1) 安装Python包</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pip install jupyter_contrib_nbextensions</span><br></pre></td></tr></table></figure>
<p>(2)安装js脚本和css文件</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">jupyter contrib nbextension install --user</span><br></pre></td></tr></table></figure>
<p>安装完成后，启动jupyter notebook,会有Nbextensions这一选项，点击会出现如下图情况。</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613527089482.png" alt="Nbextensions" /></p>
<p>推荐三个插件：</p>
<blockquote>
<p>1.Collapsible Headings  代码过长时，使用这个来折叠代码，简直不能太爽<br />
2.ExecuteTime 记录Shell的最后运行时间<br />
3.ScrollDown 输出很长时，自动往下刷新</p>
</blockquote>
<h1 id="4运行jupyter"><a class="markdownIt-Anchor" href="#4运行jupyter"></a> 4.运行Jupyter</h1>
<p>Linux/Windows系统均是在命令行中输入<code>jupyter notebook</code>来启动jupyter</p>
<h1 id="5在远端服务器上运行jupyter"><a class="markdownIt-Anchor" href="#5在远端服务器上运行jupyter"></a> 5.在远端服务器上运行jupyter</h1>
<p>通常将jupyter运行在服务器上，然后通过浏览器远程使用jupyter,一般而言，在服务器启动jupyter后，需要交jupyter运行端口映射到本地，然后本地才可以访问。</p>
<p>（1）服务器启动jupyter<br />
登录进服务器后，到你想使用jupyter的目录下运行jupyter,运行方式参考<code>第4步</code></p>
<p>（2）映射服务器端口到地址<br />
服务器启动后，会在命令行告诉你，jupyter是在那个端口执行的。Linux/Mac映射比较简单，Windows目前知道使用Xshell进行映射。</p>
<p><strong>Linux/Mac映射服务器端口</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ssh tom@172.xx.xx.xx -L 8888:localhost:8888</span><br></pre></td></tr></table></figure>
<p><strong>Windows映射服务器端口</strong><br />
在Xshell上连接到服务器，并已经启动jupyter后，下一步是设置端口映射，进入当前连接的属性界面，点击<code>隧道</code>，将服务器端口与本地端口填上去，确定即可。</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613527089387.png" alt="enter description here" title="Xshell映射远程端口" /></p>
<p>参考材料：</p>
<ul>
<li><a href="http://jupyter.org/install">Jupyter官方安装过程</a></li>
<li><a href="https://blog.csdn.net/zsWang9/article/details/78771555">深度学习第一课:MXNet/Gluon环境配置和安装</a>(插件安装部分)</li>
<li><a href="https://github.com/ipython-contrib/jupyter_contrib_nbextensions">jupyter_contrib_nbextensions</a></li>
</ul>
]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux文本处理三剑客之awk</title>
    <url>/2016/06/01/Linux%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8Bawk/</url>
    <content><![CDATA[<p>本文针对linux中的文本处理“三剑客”之一的awk命令进行使用解释，awk对以行为单位对文本数据进行处理</p>
<a id="more"></a>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#查看系统环境</span></span><br><span class="line">!lsb_release -a</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<h2 id="-code1-"><a class="markdownIt-Anchor" href="#-code1-"></a> <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">No LSB modules are available.</span><br><span class="line">Distributor ID:	LinuxMint</span><br><span class="line">Description:	Linux Mint 19.3 Tricia</span><br><span class="line">Release:	19.3</span><br><span class="line">Codename:	tricia</span><br></pre></td></tr></table></figure></h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#查看文本内容</span></span><br><span class="line">!cat awk_text</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">1 M.Tansley     05/99     48311     Green     8     40     44</span><br><span class="line">2 J.Lulu     06/99     48317     green     9     24     26</span><br><span class="line">3 P.Bunny,02/99,48,Yellow,12,35,28</span><br><span class="line">4 J.Troll:07/99:4842:Brown-3:12:26:26</span><br><span class="line">5 L.Tansley:05/99:4712:Brown-2:12:30:28</span><br></pre></td></tr></table></figure>
<p>注意：jupyter运行linux指令需要在指令前加<code>!</code></p>
<h2 id="命令格式"><a class="markdownIt-Anchor" href="#命令格式"></a> 命令格式</h2>
<p><strong>awk 命令的基本格式为：</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">awk <span class="string">&#x27;BEGIN&#123; 命令1 &#125; 模式&#123; 命令2 &#125; END&#123; 命令3 &#125;&#x27;</span> 文件</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613526010218.png" alt="awk工作流程" /></p>
<ul>
<li>1、BEGIN 执行 BEGIN 块的内容，即<code>命令1</code>内容,可选。</li>
<li>2、完成 BEGIN 块的执行，开始执行body块。</li>
<li>3、读入有 \n 换行符分割的记录。</li>
<li>4、将记录按指定的域分隔符划分域，填充域。</li>
<li>5、依次执行各 BODY 块，pattern 部分匹配该行内容成功后，才会执行<code>命令2</code>的内容。</li>
<li>6、循环读取并执行各行直到文件结束，完成body块执行。</li>
<li>7、开始 END 块执行，<code>命令3</code>内容，END 块可以输出最终结果,可选。</li>
</ul>
<p><strong>选用参数</strong></p>
<table>
<thead>
<tr>
<th>选项</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>-F fs</td>
<td>指定以 fs 作为输入行的分隔符，awk 命令默认分隔符为空格或制表符。</td>
</tr>
<tr>
<td>-f file</td>
<td>从脚本文件中读取 awk 脚本指令，以取代直接在命令行中输入指令。</td>
</tr>
<tr>
<td>-v var=val</td>
<td>在执行处理过程之前，设置一个变量 var，并给其设备初始值为 val。</td>
</tr>
</tbody>
</table>
<p><strong>awk 命令的脚本命令：</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="string">&#x27;匹配规则&#123;执行命令&#125;&#x27;</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>1.匹配规则：可以使用字符串（比如 /demo/，表示查看含有 demo 字符串的行）或者正则表达式指定</p>
<p>2.执行命令：需要用大括号（{}）括起来</p>
</blockquote>
<p>注意：</p>
<ul>
<li>整个脚本命令是用单引号（’’）括起</li>
<li>在 awk 程序执行时，如果没有指定执行命令，则默认会把匹配的行输出；如果不指定匹配规则，则默认匹配文本中所有的行。</li>
</ul>
<p><strong>awk 命令的运行方式：</strong></p>
<ul>
<li>1.awk命令行: #awk</li>
<li>2.awk程序文件: #awk -f  /data/awk_script//将swk命令写到文件中，然后调用这个文件</li>
<li>3.awk脚本: #!/bin/awk -f</li>
</ul>
<h2 id="详细使用"><a class="markdownIt-Anchor" href="#详细使用"></a> 详细使用</h2>
<h3 id="指定分隔符"><a class="markdownIt-Anchor" href="#指定分隔符"></a> 指定分隔符</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">!awk -F: <span class="string">&#x27;&#123;print $1&#125;&#x27;</span> awk_text</span><br><span class="line">print(<span class="string">&#x27;--------------------------------------------------------------&#x27;</span>)   </span><br><span class="line">!awk -F: <span class="string">&#x27;&#123;print $1&#125;&#x27;</span> awk_text</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">1 M.Tansley     05/99     48311     Green     8     40     44</span><br><span class="line">2 J.Lulu     06/99     48317     green     9     24     26</span><br><span class="line">3 P.Bunny,02/99,48,Yellow,12,35,28</span><br><span class="line">4 J.Troll</span><br><span class="line">5 L.Tansley</span><br><span class="line">--------------------------------------------------------------</span><br><span class="line">1 M.Tansley     05/99     48311     Green     8     40     44</span><br><span class="line">2 J.Lulu     06/99     48317     green     9     24     26</span><br><span class="line">3 P.Bunny,02/99,48,Yellow,12,35,28</span><br><span class="line">4 J.Troll</span><br><span class="line">5 L.Tansley</span><br></pre></td></tr></table></figure>
<h3 id="从文件中读取程序"><a class="markdownIt-Anchor" href="#从文件中读取程序"></a> 从文件中读取程序</h3>
<p>跟 sed 一样，awk 允许将脚本命令存储到文件中，然后再在命令行中引用</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">!cat awk.sh</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<h2 id="-code9-"><a class="markdownIt-Anchor" href="#-code9-"></a> <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&#123;print  &quot;The fifth number after&quot;  $1  &quot;is&quot;   $6&#125;</span><br></pre></td></tr></table></figure></h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">!awk -f awk.sh awk_text</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<h2 id="-code11-"><a class="markdownIt-Anchor" href="#-code11-"></a> <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">The fifth number after1is8</span><br><span class="line">The fifth number after2is9</span><br><span class="line">The fifth number after3is</span><br><span class="line">The fifth number after4is</span><br><span class="line">The fifth number after5is</span><br></pre></td></tr></table></figure></h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">!cat awk.func</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<h2 id="-code13-"><a class="markdownIt-Anchor" href="#-code13-"></a> <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/awk -f</span></span><br><span class="line"><span class="meta">#</span><span class="bash">运行前</span></span><br><span class="line">BEGIN &#123;</span><br><span class="line">    math = 0</span><br><span class="line">    english = 0</span><br><span class="line">    computer = 0</span><br><span class="line">    printf &quot;NAME    NO.   MATH  ENGLISH  COMPUTER   TOTAL\n&quot;</span><br><span class="line">    printf &quot;---------------------------------------------\n&quot;</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">#</span><span class="bash">运行中</span></span><br><span class="line">&#123;</span><br><span class="line">    math+=$3</span><br><span class="line">    english+=$4</span><br><span class="line">    computer+=$5</span><br><span class="line">    printf &quot;%-6s %-6s %4d %8d %8d %8d\n&quot;, $1, $2, $3,$4,$5, $3+$4+$5</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">#</span><span class="bash">运行后</span></span><br><span class="line">END &#123;</span><br><span class="line">    printf &quot;---------------------------------------------\n&quot;</span><br><span class="line">    printf &quot;  TOTAL:%10d %8d %8d \n&quot;, math, english, computer</span><br><span class="line">    printf &quot;AVERAGE:%10.2f %8.2f %8.2f\n&quot;, math/NR, english/NR, computer/NR</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">!awk -f awk.func score</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">NAME    NO.   MATH  ENGLISH  COMPUTER   TOTAL</span><br><span class="line">---------------------------------------------</span><br><span class="line">Marry  2143     78       84       77      239</span><br><span class="line">Jack   2321     66       78       45      189</span><br><span class="line">Tom    2122     48       77       71      196</span><br><span class="line">Mike   2537     87       97       95      279</span><br><span class="line">Bob    2415     40       57       62      159</span><br><span class="line">---------------------------------------------</span><br><span class="line">  TOTAL:       319      393      350 </span><br><span class="line">AVERAGE:     63.80    78.60    70.00</span><br></pre></td></tr></table></figure>
<h3 id="设置变量"><a class="markdownIt-Anchor" href="#设置变量"></a> 设置变量</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">!awk -v a=<span class="number">1</span> <span class="string">&#x27;&#123;print NR,$2,$2+a&#125;&#x27;</span> awk_text</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">1 M.Tansley 1</span><br><span class="line">2 J.Lulu 1</span><br><span class="line">3 P.Bunny,02/99,48,Yellow,12,35,28 1</span><br><span class="line">4 J.Troll:07/99:4842:Brown-3:12:26:26 1</span><br><span class="line">5 L.Tansley:05/99:4712:Brown-2:12:30:28 1</span><br></pre></td></tr></table></figure>
<h3 id="内建变量"><a class="markdownIt-Anchor" href="#内建变量"></a> 内建变量</h3>
<table>
<thead>
<tr>
<th style="text-align:center">序号</th>
<th style="text-align:center">变量</th>
<th style="text-align:left">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">$n</td>
<td style="text-align:left">当前记录的第n个字段，字段间由FS分隔</td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">$0</td>
<td style="text-align:left">完整的输入记录</td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">ARGC</td>
<td style="text-align:left">命令行参数的数目</td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td style="text-align:center">ARGIND</td>
<td style="text-align:left">命令行中当前文件的位置(从0开始算)</td>
</tr>
<tr>
<td style="text-align:center">5</td>
<td style="text-align:center">ARGV</td>
<td style="text-align:left">包含命令行参数的数组</td>
</tr>
<tr>
<td style="text-align:center">6</td>
<td style="text-align:center">CONVFMT</td>
<td style="text-align:left">数字转换格式(默认值为%.6g)ENVIRON环境变量关联数组</td>
</tr>
<tr>
<td style="text-align:center">7</td>
<td style="text-align:center">ERRNO</td>
<td style="text-align:left">最后一个系统错误的描述</td>
</tr>
<tr>
<td style="text-align:center">8</td>
<td style="text-align:center">FIELDWIDTHS</td>
<td style="text-align:left">字段宽度列表(用空格键分隔)</td>
</tr>
<tr>
<td style="text-align:center">9</td>
<td style="text-align:center">FILENAME</td>
<td style="text-align:left">当前文件名</td>
</tr>
<tr>
<td style="text-align:center">10</td>
<td style="text-align:center">FNR</td>
<td style="text-align:left">各文件分别计数的行号</td>
</tr>
<tr>
<td style="text-align:center">11</td>
<td style="text-align:center">FS</td>
<td style="text-align:left">字段分隔符(默认是任何空格)</td>
</tr>
<tr>
<td style="text-align:center">12</td>
<td style="text-align:center">IGNORECASE</td>
<td style="text-align:left">如果为真，则进行忽略大小写的匹配</td>
</tr>
<tr>
<td style="text-align:center">13</td>
<td style="text-align:center">NF</td>
<td style="text-align:left">一条记录的字段的数目</td>
</tr>
<tr>
<td style="text-align:center">14</td>
<td style="text-align:center">NR</td>
<td style="text-align:left">已经读出的记录数，就是行号，从1开始</td>
</tr>
<tr>
<td style="text-align:center">15</td>
<td style="text-align:center">OFMT</td>
<td style="text-align:left">数字的输出格式(默认值是%.6g)</td>
</tr>
<tr>
<td style="text-align:center">16</td>
<td style="text-align:center">OFS</td>
<td style="text-align:left">输出记录分隔符（输出换行符），输出时用指定的符号代替换行符</td>
</tr>
<tr>
<td style="text-align:center">17</td>
<td style="text-align:center">ORS</td>
<td style="text-align:left">输出记录分隔符(默认值是一个换行符)</td>
</tr>
<tr>
<td style="text-align:center">18</td>
<td style="text-align:center">RLENGTH</td>
<td style="text-align:left">由match函数所匹配的字符串的长度</td>
</tr>
<tr>
<td style="text-align:center">19</td>
<td style="text-align:center">RS</td>
<td style="text-align:left">记录分隔符(默认是一个换行符)</td>
</tr>
<tr>
<td style="text-align:center">20</td>
<td style="text-align:center">RSTART</td>
<td style="text-align:left">由match函数所匹配的字符串的第一个位置</td>
</tr>
<tr>
<td style="text-align:center">21</td>
<td style="text-align:center">SUBSEP</td>
<td style="text-align:left">数组下标分隔符(默认值是/034)</td>
</tr>
</tbody>
</table>
<h4 id="数据字段变量"><a class="markdownIt-Anchor" href="#数据字段变量"></a> 数据字段变量</h4>
<p>awk 会自动给<code>一行</code>中的每个数据元素分配一个变量</p>
<table>
<thead>
<tr>
<th>变量</th>
<th style="text-align:left">含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>$0</td>
<td style="text-align:left">代表整个文本行；</td>
</tr>
<tr>
<td>$1</td>
<td style="text-align:left">代表文本行中的第 1 个数据字段；</td>
</tr>
<tr>
<td>$2</td>
<td style="text-align:left">代表文本行中的第 2 个数据字段；</td>
</tr>
<tr>
<td>$n</td>
<td style="text-align:left">代表文本行中的第 n 个数据字段。</td>
</tr>
</tbody>
</table>
<p>注意：在 awk 中，默认的字段分隔符是任意的空白字符（例如空格或制表符），awk 在读取一行文本时，会用预定义的字段分隔符划分每个数据字段</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看全部</span></span><br><span class="line">!awk <span class="string">&#x27;&#123;print $0&#125;&#x27;</span> awk_text</span><br><span class="line">print(<span class="string">&#x27;--------------------------------------------------------&#x27;</span>)</span><br><span class="line"><span class="comment"># 查看每一行的第一个内容</span></span><br><span class="line">!awk <span class="string">&#x27;&#123;print $1&#125;&#x27;</span> awk_text</span><br><span class="line">print(<span class="string">&#x27;--------------------------------------------------------&#x27;</span>)</span><br><span class="line"><span class="comment"># 查看每一行的最后一个内容</span></span><br><span class="line">!awk <span class="string">&#x27;&#123;print $6&#125;&#x27;</span> awk_text</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">    1 M.Tansley     05/99     48311     Green     8     40     44</span><br><span class="line">    2 J.Lulu     06/99     48317     green     9     24     26</span><br><span class="line">    3 P.Bunny,02/99,48,Yellow,12,35,28</span><br><span class="line">    4 J.Troll:07/99:4842:Brown-3:12:26:26</span><br><span class="line">    5 L.Tansley:05/99:4712:Brown-2:12:30:28</span><br><span class="line">    --------------------------------------------------------</span><br><span class="line">    1</span><br><span class="line">    2</span><br><span class="line">    3</span><br><span class="line">    4</span><br><span class="line">    5</span><br><span class="line">    --------------------------------------------------------</span><br><span class="line">    8</span><br><span class="line">    9</span><br><span class="line">```    </span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">### 其他参数</span></span></span><br><span class="line">```python</span><br><span class="line">!awk &#x27;BEGIN&#123;printf &quot;%4s %4s %4s %4s %4s %4s %4s %4s %4s\n&quot;,&quot;FILENAME&quot;,&quot;ARGC&quot;,&quot;FNR&quot;,&quot;FS&quot;,&quot;NF&quot;,&quot;NR&quot;,&quot;OFS&quot;,&quot;ORS&quot;,&quot;RS&quot;;printf &quot;---------------------------------------------\n&quot;&#125; &#123;printf &quot;%4s %4s %4s %4s %4s %4s %4s %4s %4s\n&quot;,FILENAME,ARGC,FNR,FS,NF,NR,OFS,ORS,RS&#125;&#x27; awk_text</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">    FILENAME ARGC  FNR   FS   NF   NR  OFS  ORS   RS</span><br><span class="line">    ---------------------------------------------</span><br><span class="line">    awk_text    2    1         8    1         </span><br><span class="line">    awk_text    2    2         8    2         </span><br><span class="line">    awk_text    2    3         2    3         </span><br><span class="line">    awk_text    2    4         2    4         </span><br><span class="line">    awk_text    2    5         2    5         </span><br><span class="line">```        </span><br><span class="line">  ---</span><br><span class="line">```python</span><br><span class="line">!awk &#x27;BEGIN&#123;FS=&quot;[ :]+&quot;&#125;&#123;print  $1,$2&#125;&#x27;   awk_text</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">1 M.Tansley</span><br><span class="line">2 J.Lulu</span><br><span class="line">3 P.Bunny,02/99,48,Yellow,12,35,28</span><br><span class="line">4 J.Troll</span><br><span class="line">5 L.Tansley</span><br></pre></td></tr></table></figure>
<h3 id="多个命令"><a class="markdownIt-Anchor" href="#多个命令"></a> 多个命令</h3>
<p>awk 允许将多条命令组合成一个正常的程序。要在命令行上的程序脚本中使用多条命令，只要在命令之间放个<code>分号</code>即可</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">!echo <span class="string">&quot;My name is Tom&quot;</span> | awk <span class="string">&#x27;&#123;$4=&quot;ann&quot;;print $0&#125;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">My name is ann</span><br></pre></td></tr></table></figure>
<h3 id="begin关键字与end关键字"><a class="markdownIt-Anchor" href="#begin关键字与end关键字"></a> BEGIN关键字与END关键字</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">!awk <span class="string">&#x27;BEGIN &#123; for (i = 1; i &lt;= 5; ++i) print i &#125;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td></tr></table></figure>
<h3 id="printf指定输出格式"><a class="markdownIt-Anchor" href="#printf指定输出格式"></a> printf指定输出格式</h3>
<p>printf “FORMAT” ,item1,item2,…//指格式化输出，必须指定FORMAT，不会自动换行，换行使用换行符\n;FORMAT中需要为每个item指定格式符:与item–对应</p>
<p>%c: 显示字符的ASCII码<br />
%d, %i: 显示十进制整数<br />
%e, %E:显示科学计数法数值<br />
%f：显示为浮点数<br />
%g, %G：以科学计数法或浮点形式显示数值<br />
%s：显示字符串<br />
%u：无符号整数<br />
%%: 显示%自身</p>
<p>修饰符：<br />
#[.#]：第一个数字控制显示的宽度；第二个#表示小数点后精度，%3.1f<br />
-: 左对齐（默认右对齐） %-15s<br />
+：显示数值的正负符号 %+d</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">!awk <span class="string">&#x27;BEGIN &#123;printf &quot;%s %s %-4.2f\n&quot;,&quot;TOM&quot;,&quot;man&quot;,66.1234&#125;&#x27;</span></span><br><span class="line">!awk <span class="string">&#x27;BEGIN &#123;printf &quot;%-10s %-8s %-4.2f\n&quot;,&quot;TOM&quot;,&quot;man&quot;,66.1234&#125;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">TOM man 66.12</span><br><span class="line">TOM        man      66.12</span><br></pre></td></tr></table></figure>
<h3 id="操作符"><a class="markdownIt-Anchor" href="#操作符"></a> 操作符</h3>
<ul>
<li>算数操作符 ： x+y, x-y,x*y, x/y, x^y, x%y；-x: 转换为负数 ；+x: 转换为数值</li>
<li>赋值操作符 ： =, +=, -=, *=, /=, %=, ^=   ++, –</li>
<li>比较操作符：==, !=, &gt;, &gt;=, &lt;, &lt;=</li>
<li>模式匹配符：~：左边是否和右边匹配包含 !~：是否不匹配</li>
<li>逻辑操作符:与&amp;&amp;，或||，非!</li>
<li>条件表达式（三目表达式）：</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">!echo <span class="string">&quot;1.7 2.52&quot;</span> | awk <span class="string">&#x27;&#123;printf (&quot;%2f\n&quot;,$1)&#125;&#x27;</span></span><br><span class="line">!echo <span class="string">&quot;1.7 2.52&quot;</span> | awk <span class="string">&#x27;&#123;printf (&quot;%d\n&quot;,$2)&#125;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">1.700000</span><br><span class="line">2</span><br></pre></td></tr></table></figure>
<h3 id="分支语句"><a class="markdownIt-Anchor" href="#分支语句"></a> 分支语句</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">!awk <span class="string">&#x27;BEGIN &#123;num = 10; if (num % 2 == 0) printf &quot;%d 是偶数\n&quot;, num &#125;&#x27;</span></span><br><span class="line">!awk <span class="string">&#x27;BEGIN &#123;num = 11; if (num % 2 == 0) printf &quot;%d 是偶数\n&quot;, num; else printf &quot;%d 是奇数\n&quot;, num &#125;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">10 是偶数</span><br><span class="line">11 是奇数</span><br></pre></td></tr></table></figure>
<h3 id="循环语句"><a class="markdownIt-Anchor" href="#循环语句"></a> 循环语句</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(<span class="string">&#x27;For----------------------------------------------&#x27;</span>)</span><br><span class="line">!awk <span class="string">&#x27;BEGIN &#123; for (i = 1; i &lt;= 2; ++i) print i &#125;&#x27;</span></span><br><span class="line">print(<span class="string">&#x27;While----------------------------------------------&#x27;</span>)</span><br><span class="line">!awk <span class="string">&#x27;BEGIN &#123;i = 1; while (i &lt; 3) &#123; print i; ++i &#125; &#125;&#x27;</span></span><br><span class="line">print(<span class="string">&#x27;Break----------------------------------------------&#x27;</span>)</span><br><span class="line">!awk <span class="string">&#x27;BEGIN &#123;sum = 0; for (i = 0; i &lt; 10; ++i) &#123;sum += i; if (sum &gt; 15) break; else print &quot;Sum =&quot;, sum &#125;&#125;&#x27;</span></span><br><span class="line">print(<span class="string">&#x27;Continue----------------------------------------------&#x27;</span>)</span><br><span class="line">!awk <span class="string">&#x27;BEGIN &#123;for (i = 1; i &lt;= 10; ++i) &#123;if (i % 2 == 0) print i; else continue;&#125;&#125;&#x27;</span></span><br><span class="line">print(<span class="string">&#x27;Exit----------------------------------------------&#x27;</span>)</span><br><span class="line">!awk <span class="string">&#x27;BEGIN &#123;sum = 0; for (i = 0; i &lt; 10; ++i) &#123;sum += i; if (sum &gt; 15) exit(10); else print &quot;Sum =&quot;, sum &#125;&#125;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">For----------------------------------------------</span><br><span class="line">1</span><br><span class="line">2</span><br><span class="line">While----------------------------------------------</span><br><span class="line">1</span><br><span class="line">2</span><br><span class="line">Break----------------------------------------------</span><br><span class="line">Sum = 0</span><br><span class="line">Sum = 1</span><br><span class="line">Sum = 3</span><br><span class="line">Sum = 6</span><br><span class="line">Sum = 10</span><br><span class="line">Sum = 15</span><br><span class="line">Continue----------------------------------------------</span><br><span class="line">2</span><br><span class="line">4</span><br><span class="line">6</span><br><span class="line">8</span><br><span class="line">10</span><br><span class="line">Exit----------------------------------------------</span><br><span class="line">Sum = 0</span><br><span class="line">Sum = 1</span><br><span class="line">Sum = 3</span><br><span class="line">Sum = 6</span><br><span class="line">Sum = 10</span><br><span class="line">Sum = 15</span><br></pre></td></tr></table></figure>
<h3 id="数组"><a class="markdownIt-Anchor" href="#数组"></a> 数组</h3>
<p><strong>语法格式:</strong></p>
<h2 id="-code34-"><a class="markdownIt-Anchor" href="#-code34-"></a> <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">array_name[index]=value</span><br></pre></td></tr></table></figure></h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">!awk <span class="string">&#x27;BEGIN &#123;sites[&quot;runoob&quot;]=&quot;www.runoob.com&quot;;sites[&quot;google&quot;]=&quot;www.google.com&quot;;print sites[&quot;runoob&quot;] &quot;\n&quot; sites[&quot;google&quot;]&#125;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">www.runoob.com</span><br><span class="line">www.google.com</span><br></pre></td></tr></table></figure>
<h3 id="函数"><a class="markdownIt-Anchor" href="#函数"></a> 函数</h3>
<h4 id="自定义函数"><a class="markdownIt-Anchor" href="#自定义函数"></a> 自定义函数</h4>
<p><strong>语法格式:</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">function</span> function_name(argument1, argument2, ...)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">function</span> body</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>注意：</p>
<ul>
<li>1.function_name 是用户自定义函数的名称。函数名称应该以字母开头，其后可以是数字、字母或下划线的自由组合。AWK 保留的关键字不能作为用户自定义函数的名称。</li>
<li>2.自定义函数可以接受多个输入参数，这些参数之间通过逗号分隔。参数并不是必须的。我们也可以定义没有任何输入参数的函数。</li>
<li>3.function body 是函数体部分，它包含 AWK 程序代码。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">!cat awk.func2</span><br></pre></td></tr></table></figure>
<pre><code># 返回最小值
function find_min(num1, num2)
&#123;
  if (num1 &lt; num2)
    return num1
  return num2
&#125;

# 返回最大值
function find_max(num1, num2)
&#123;
  if (num1 &gt; num2)
    return num1
  return num2
&#125;

# 主函数
function main(num1, num2)
&#123;
  # 查找最小值
  result = find_min(10, 20)
  print &quot;Minimum =&quot;, result

  # 查找最大值
  result = find_max(10, 20)
  print &quot;Maximum =&quot;, result
&#125;

# 脚本从这里开始执行
BEGIN &#123;
  main(10, 20)
&#125;  
</code></pre>
<hr />
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">!awk -f awk.func2</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Minimum = 10</span><br><span class="line">Maximum = 20</span><br></pre></td></tr></table></figure>
<h4 id="内置函数"><a class="markdownIt-Anchor" href="#内置函数"></a> 内置函数</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">!awk <span class="string">&#x27;BEGIN &#123;param = 5; result = exp(param); printf &quot;The exponential value of %f is %f.\n&quot;, param, result;&#125;&#x27;</span></span><br><span class="line">print(<span class="string">&#x27;------------------------------------------&#x27;</span>)</span><br><span class="line">!awk <span class="string">&#x27;BEGIN &#123;str = &quot;Hello, World&quot;;print &quot;String before replacement = &quot; str;sub(&quot;World&quot;, &quot;Jerry&quot;, str);print &quot;String after replacement = &quot; str&#125;&#x27;</span></span><br><span class="line">print(<span class="string">&#x27;------------------------------------------&#x27;</span>)</span><br><span class="line">!awk <span class="string">&#x27;BEGIN&#123;info=&quot;this is a test2012test!&quot;;print index(info,&quot;11111&quot;)?&quot;ok&quot;:&quot;no found&quot;;&#125;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">The exponential value of 5.000000 is 148.413159.</span><br><span class="line">------------------------------------------</span><br><span class="line">String before replacement = Hello, World</span><br><span class="line">String after replacement = Hello, Jerry</span><br><span class="line">------------------------------------------</span><br><span class="line">no found</span><br></pre></td></tr></table></figure>
<h2 id="实例列举"><a class="markdownIt-Anchor" href="#实例列举"></a> 实例列举</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#从文件中找出长度大于10的行</span></span><br><span class="line">!awk <span class="string">&#x27;length&gt;38&#x27;</span> awk_text</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<h2 id="-code44-"><a class="markdownIt-Anchor" href="#-code44-"></a> <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">1 M.Tansley     05/99     48311     Green     8     40     44</span><br><span class="line">2 J.Lulu     06/99     48317     green     9     24     26</span><br><span class="line">5 L.Tansley:05/99:4712:Brown-2:12:30:28</span><br></pre></td></tr></table></figure></h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#打印Hello world</span></span><br><span class="line">!awk <span class="string">&#x27;BEGIN &#123; print &quot;Hello, world!&quot; &#125;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>输出：</p>
<h2 id="-code46-"><a class="markdownIt-Anchor" href="#-code46-"></a> <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Hello, world!</span><br></pre></td></tr></table></figure></h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#9*9乘法表</span></span><br><span class="line">!seq <span class="number">9</span> | sed <span class="string">&#x27;H;g&#x27;</span> | awk -v RS=<span class="string">&#x27;&#x27;</span> <span class="string">&#x27;&#123;for(i=1;i&lt;=NF;i++)printf(&quot;%dx%d=%d%s&quot;, i, NR, i*NR, i==NR?&quot;\n&quot;:&quot;\t&quot;)&#125;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">1x1=1</span><br><span class="line">1x2=2	2x2=4</span><br><span class="line">1x3=3	2x3=6	3x3=9</span><br><span class="line">1x4=4	2x4=8	3x4=12	4x4=16</span><br><span class="line">1x5=5	2x5=10	3x5=15	4x5=20	5x5=25</span><br><span class="line">1x6=6	2x6=12	3x6=18	4x6=24	5x6=30	6x6=36</span><br><span class="line">1x7=7	2x7=14	3x7=21	4x7=28	5x7=35	6x7=42	7x7=49</span><br><span class="line">1x8=8	2x8=16	3x8=24	4x8=32	5x8=40	6x8=48	7x8=56	8x8=64</span><br><span class="line">1x9=9	2x9=18	3x9=27	4x9=36	5x9=45	6x9=54	7x9=63	8x9=72	9x9=81</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>软件工具</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>文本处理</tag>
      </tags>
  </entry>
  <entry>
    <title>Mxnet框架的环境搭建</title>
    <url>/2017/09/15/Mxnet%E6%A1%86%E6%9E%B6%E7%9A%84%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/</url>
    <content><![CDATA[<p>Mxnet是亚马逊开发的深度学习框架，和谷歌Tensorflow是同类型的框架。</p>
<a id="more"></a>
<p>1.安装Mxnet</p>
<p>这里只展示在线安装，源码编译安装等不演示；GPU安装与Mxnet无关，只需安装不同的Mxnet版本就可以。要使用GPU还是得另外配置好Cuda和Cudnn。</p>
<p>（1）安装依赖</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install -y wget python gcc</span><br><span class="line">wget https://bootstrap.pypa.io/get-pip.py &amp;&amp; sudo python get-pip.py</span><br></pre></td></tr></table></figure>
<p>(2)安装Mxnet</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pip install mxnet</span><br></pre></td></tr></table></figure>
<p>注：要安装GPU版本，命令是<code>pip install mxnet-cu90</code>，根据Cuda版本，安装不同mxnet-cuxx版本，具体查官网信息</p>
<p>(3)安装Graphviz（非必须）</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo apt-get install graphviz</span><br><span class="line">pip install graphviz</span><br></pre></td></tr></table></figure>
<p>2.测试是否安装完成</p>
<p>(1)进入python命令编辑界面</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">python</span><br></pre></td></tr></table></figure>
<p>(2)依次每行拷贝以下命令进行测试,最后输入一致，即表示安装完成。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; import mxnet as mx</span><br><span class="line">&gt;&gt;&gt; a = mx.nd.ones((2, 3))</span><br><span class="line">&gt;&gt;&gt; b = a * 2 + 1</span><br><span class="line">&gt;&gt;&gt; b.asnumpy()</span><br><span class="line">array([[ 3.,  3.,  3.],</span><br><span class="line">       [ 3.,  3.,  3.]], dtype=float32)</span><br></pre></td></tr></table></figure>
<p>(3)退出python控制台</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">exit</span>()</span><br></pre></td></tr></table></figure>
<p>参考资料：</p>
<ul>
<li><a href="https://mxnet.incubator.apache.org/install/index.html">Mxnet官方安装方法</a></li>
</ul>
]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>Mxnet</tag>
      </tags>
  </entry>
  <entry>
    <title>NetworkX系列教程(1)-创建graph</title>
    <url>/2018/09/10/NetworkX%E7%B3%BB%E5%88%97%E6%95%99%E7%A8%8B(1)-%E5%88%9B%E5%BB%BAgraph/</url>
    <content><![CDATA[<p>研究中经常涉及到<code>图论</code>的相关知识,而且常常面对某些术语时,根本不知道在说什么.前不久接触了<strong>NetworkX</strong>这个graph处理工具,发现这个工具已经解决绝大部分的<code>图论</code>问题(也许只是我自己认为的,没有证据证明),所以把这个工具的使用学习下,顺便学习<code>图论</code>的相关知识.</p>
<p><strong>NetworkX</strong>本来是有官方文档的,花时间去学也是可以的,我这里把认为重要的整理出来.这些内容会分几次发布,做成一个系列使用教程.</p>
<a id="more"></a>
<p><strong>系统环境</strong>:</p>
<blockquote>
<p>linuxmint 18.3<br />
python 3.5.2<br />
numpy                             1.14.3<br />
matplotlib                        1.5.1<br />
networkx                          2.1</p>
</blockquote>
<p><strong>全文注意事项</strong>:</p>
<blockquote>
<p>1.为了方便,graph我有时候会称为<code>图</code>,这时候不要将这个和图片混淆了.<br />
2.代码中会频繁使用G.clear(),这是在画新的graph之前,先清空原先的graph<br />
3.matplotlib包不能显示<code>平行边</code>,<code>自循环</code>这类的边,所以需要借助pydot包来显示,不过一般使用matplotlib来显示</p>
</blockquote>
<h1 id="创建一个graph"><a class="markdownIt-Anchor" href="#创建一个graph"></a> 创建一个Graph</h1>
<p><strong>例子:</strong><br />
下面涉及的graph如果不是特别需要,我将使用<code>图1</code>这个手动创建的graph,这个graph有双向边,有孤岛节点,有平行边,有自循环</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613548771706.png" alt="图1 例子图" title="图1 例子图" /></p>
<h2 id="导入相应包定义graph"><a class="markdownIt-Anchor" href="#导入相应包定义graph"></a> 导入相应包,定义graph</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#导入相应的包</span></span><br><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> networkx.drawing.nx_pydot <span class="keyword">import</span> to_pydot</span><br><span class="line"><span class="keyword">from</span> matplotlib.font_manager <span class="keyword">import</span> *  </span><br><span class="line"></span><br><span class="line"><span class="comment">#定义自定义字体，文件名从1.b查看系统中文字体中来,这是Linux字体路径,windows系统的字体路径自查</span></span><br><span class="line">myfont = FontProperties(fname=<span class="string">&#x27;/usr/share/fonts/truetype/wqy/wqy-zenhei.ttc&#x27;</span>)  </span><br><span class="line"><span class="comment">#解决负号&#x27;-&#x27;显示为方块的问题  </span></span><br><span class="line">matplotlib.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>]=<span class="literal">False</span> </span><br><span class="line"></span><br><span class="line"><span class="comment">#定义图的节点和边</span></span><br><span class="line">nodes=[<span class="string">&#x27;0&#x27;</span>,<span class="string">&#x27;1&#x27;</span>,<span class="string">&#x27;2&#x27;</span>,<span class="string">&#x27;3&#x27;</span>,<span class="string">&#x27;4&#x27;</span>,<span class="string">&#x27;5&#x27;</span>,<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;b&#x27;</span>,<span class="string">&#x27;c&#x27;</span>]</span><br><span class="line">edges=[(<span class="string">&#x27;0&#x27;</span>,<span class="string">&#x27;0&#x27;</span>,<span class="number">1</span>),(<span class="string">&#x27;0&#x27;</span>,<span class="string">&#x27;1&#x27;</span>,<span class="number">1</span>),(<span class="string">&#x27;0&#x27;</span>,<span class="string">&#x27;5&#x27;</span>,<span class="number">1</span>),(<span class="string">&#x27;0&#x27;</span>,<span class="string">&#x27;5&#x27;</span>,<span class="number">2</span>),(<span class="string">&#x27;1&#x27;</span>,<span class="string">&#x27;2&#x27;</span>,<span class="number">3</span>),(<span class="string">&#x27;1&#x27;</span>,<span class="string">&#x27;4&#x27;</span>,<span class="number">5</span>),(<span class="string">&#x27;2&#x27;</span>,<span class="string">&#x27;1&#x27;</span>,<span class="number">7</span>),(<span class="string">&#x27;2&#x27;</span>,<span class="string">&#x27;4&#x27;</span>,<span class="number">6</span>),(<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;b&#x27;</span>,<span class="number">0.5</span>),(<span class="string">&#x27;b&#x27;</span>,<span class="string">&#x27;c&#x27;</span>,<span class="number">0.5</span>),(<span class="string">&#x27;c&#x27;</span>,<span class="string">&#x27;a&#x27;</span>,<span class="number">0.5</span>)]</span><br><span class="line"></span><br><span class="line"><span class="comment">#用于显示图片</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ShowGraph</span>(<span class="params">G</span>):</span></span><br><span class="line">    <span class="comment">#使用pydot保存图片</span></span><br><span class="line">    P=to_pydot(G)                                                               </span><br><span class="line">    P.write_jpeg(<span class="string">&#x27;pydot.png&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#使用matplotlib保存图片</span></span><br><span class="line">    pos=nx.shell_layout(G)</span><br><span class="line">    nx.draw(G,pos,with_labels=<span class="literal">True</span>)</span><br><span class="line">    plt.savefig(<span class="string">&#x27;mat.png&#x27;</span>)</span><br><span class="line">    plt.close()  </span><br><span class="line">    </span><br><span class="line">    <span class="comment">#将前面两张图显示</span></span><br><span class="line">    plt.subplots(figsize=(<span class="number">12</span>,<span class="number">6</span>))</span><br><span class="line">    <span class="comment">#plt.suptitle(&#x27;Diffrent&#x27;)</span></span><br><span class="line">    <span class="comment">#载入matplotlib的图片</span></span><br><span class="line">    plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;matplotlib&#x27;</span>)</span><br><span class="line">    plt.imshow(Image.<span class="built_in">open</span>(<span class="string">&#x27;mat.png&#x27;</span>))</span><br><span class="line">    <span class="comment">#plt.axis(&#x27;off&#x27;)</span></span><br><span class="line">    <span class="comment">#去掉坐标刻度</span></span><br><span class="line">    plt.xticks([])</span><br><span class="line">    plt.yticks([])</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#载入pydot的图片</span></span><br><span class="line">    plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;pydot&#x27;</span>)</span><br><span class="line">    plt.imshow(Image.<span class="built_in">open</span>(<span class="string">&#x27;pydot.png&#x27;</span>))</span><br><span class="line">    <span class="comment">#plt.axis(&#x27;off&#x27;)</span></span><br><span class="line">    <span class="comment">#去掉坐标刻度</span></span><br><span class="line">    plt.xticks([])</span><br><span class="line">    plt.yticks([])</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#显示图片</span></span><br><span class="line">    plt.show() </span><br></pre></td></tr></table></figure>
<h2 id="有自循环的无向图"><a class="markdownIt-Anchor" href="#有自循环的无向图"></a> 有自循环的无向图</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#定义无向图</span></span><br><span class="line">G = nx.Graph()</span><br><span class="line"></span><br><span class="line"><span class="comment">#往图添加节点和边</span></span><br><span class="line">G.add_nodes_from(nodes)</span><br><span class="line">G.add_weighted_edges_from(edges)</span><br><span class="line"></span><br><span class="line"><span class="comment">#显示图片</span></span><br><span class="line">ShowGraph(G)</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613548771707.png" alt="png" title="有自循环的无向图" /></p>
<h2 id="有自循环的有向图"><a class="markdownIt-Anchor" href="#有自循环的有向图"></a> 有自循环的有向图</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#清除前面的无向图</span></span><br><span class="line">G.clear()</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义有向图</span></span><br><span class="line">G = nx.DiGraph()</span><br><span class="line"><span class="comment">#添加节点和边</span></span><br><span class="line">G.add_nodes_from(nodes)</span><br><span class="line">G.add_weighted_edges_from(edges)</span><br><span class="line"></span><br><span class="line"><span class="comment">#显示图片</span></span><br><span class="line">ShowGraph(G)</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613548771708.png" alt="png" title="有自循环的有向图" /></p>
<h2 id="有自循环和平行边的无向图"><a class="markdownIt-Anchor" href="#有自循环和平行边的无向图"></a> 有自循环和平行边的无向图</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#清除前面的无向图</span></span><br><span class="line">G.clear()</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义带平行边无向图</span></span><br><span class="line">G = nx.MultiGraph()</span><br><span class="line"><span class="comment">#添加节点和边</span></span><br><span class="line">G.add_nodes_from(nodes)</span><br><span class="line">G.add_weighted_edges_from(edges)</span><br><span class="line"></span><br><span class="line"><span class="comment">#显示图片</span></span><br><span class="line">ShowGraph(G)</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613548771709.png" alt="png" title="有自循环和平行边的无向图" /></p>
<h2 id="有自循环和平行边的有向图"><a class="markdownIt-Anchor" href="#有自循环和平行边的有向图"></a> 有自循环和平行边的有向图</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#清除前面的无向图</span></span><br><span class="line">G.clear()</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义带平行边有向图</span></span><br><span class="line">G = nx.MultiDiGraph()</span><br><span class="line"><span class="comment">#添加节点和边</span></span><br><span class="line">G.add_nodes_from(nodes)</span><br><span class="line">G.add_weighted_edges_from(edges)</span><br><span class="line"></span><br><span class="line"><span class="comment">#显示图片</span></span><br><span class="line">ShowGraph(G)</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613548771711.png" alt="png" title="有自循环和平行边的有向图" /></p>
]]></content>
      <categories>
        <category>图论</category>
      </categories>
      <tags>
        <tag>图论</tag>
        <tag>NetworkX</tag>
      </tags>
  </entry>
  <entry>
    <title>NetworkX系列教程(2)-graph生成器</title>
    <url>/2018/09/15/NetworkX%E7%B3%BB%E5%88%97%E6%95%99%E7%A8%8B(2)-graph%E7%94%9F%E6%88%90%E5%99%A8/</url>
    <content><![CDATA[<p>本节主要讲解如何快速使用内置的方法生成graph,官方的文档在<a href="https://networkx.github.io/documentation/stable/reference/generators.html">这里</a>,里面包含了networkX的所有graph生成器,下面的内容只是我节选的内容,并将graph画出来而已.</p>
<a id="more"></a>
<p>声明,文中重复使用了以下代码块 ,现在统一注释在这里:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.subplot(<span class="number">221</span>)  <span class="comment">#生成2*2的组图,并且当前子图在2*2矩阵的第一个位置.第二个位置是222</span></span><br><span class="line">plt.title(<span class="string">&#x27;complete_graph&#x27;</span>) <span class="comment">#子图的标题</span></span><br><span class="line">nx.draw(G, with_labels=<span class="literal">True</span>, font_weight=<span class="string">&#x27;bold&#x27;</span>) <span class="comment">#将graph画出来</span></span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>) <span class="comment">#需要坐标轴,以便框住graph</span></span><br><span class="line">plt.xticks([]) <span class="comment">#横坐标不需要刻度</span></span><br><span class="line">plt.yticks([]) <span class="comment">#纵坐标不需要刻度</span></span><br></pre></td></tr></table></figure>
<p>注意如果代码出现找不库,请返回第一个教程,把库文件导入.</p>
<h1 id="生成graph"><a class="markdownIt-Anchor" href="#生成graph"></a> 生成graph</h1>
<h2 id="小图图集的生成器"><a class="markdownIt-Anchor" href="#小图图集的生成器"></a> 小图图集的生成器</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#graph_atlas的图已经被定义,只需要按标号取出来就可以,下面将前10个取出来</span></span><br><span class="line">plt.subplots(<span class="number">2</span>,<span class="number">5</span>,figsize=(<span class="number">15</span>,<span class="number">6</span>))</span><br><span class="line"><span class="keyword">for</span> ind <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    G.clear()</span><br><span class="line">    </span><br><span class="line">    G=nx.graph_atlas(ind)</span><br><span class="line">    plt.subplot(<span class="number">2</span>,<span class="number">5</span>,ind+<span class="number">1</span>)</span><br><span class="line">    nx.draw(G,with_labels=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#下面是设置图片</span></span><br><span class="line">    plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;graph_atlas_%s&#x27;</span>%ind)</span><br><span class="line">    plt.xticks([])</span><br><span class="line">    plt.yticks([])</span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613549009214.png" alt="png" title="小图图集的生成器" /></p>
<h2 id="调用函数生成经典的graph"><a class="markdownIt-Anchor" href="#调用函数生成经典的graph"></a> 调用函数生成经典的graph</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.subplots(<span class="number">2</span>,<span class="number">2</span>,figsize=(<span class="number">15</span>,<span class="number">6</span>))</span><br><span class="line"></span><br><span class="line">K_5 = nx.complete_graph(<span class="number">5</span>)</span><br><span class="line">plt.subplot(<span class="number">221</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;complete_graph&#x27;</span>)</span><br><span class="line">nx.draw(K_5, with_labels=<span class="literal">True</span>, font_weight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line">K_3_5 = nx.complete_bipartite_graph(<span class="number">3</span>, <span class="number">5</span>)</span><br><span class="line">plt.subplot(<span class="number">222</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;complete_bipartite_graph&#x27;</span>)</span><br><span class="line">nx.draw(K_3_5, with_labels=<span class="literal">True</span>, font_weight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line">barbell = nx.barbell_graph(<span class="number">10</span>, <span class="number">10</span>)</span><br><span class="line">plt.subplot(<span class="number">223</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;barbell_graph&#x27;</span>)</span><br><span class="line">nx.draw(barbell, with_labels=<span class="literal">True</span>, font_weight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line">lollipop = nx.lollipop_graph(<span class="number">10</span>, <span class="number">20</span>)</span><br><span class="line">plt.subplot(<span class="number">224</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;lollipop_graph&#x27;</span>)</span><br><span class="line">nx.draw(lollipop, with_labels=<span class="literal">True</span>, font_weight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613549009226.png" alt="png" title="经典的graph" /></p>
<h2 id="格子graph"><a class="markdownIt-Anchor" href="#格子graph"></a> 格子graph</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">G.clear()</span><br><span class="line"></span><br><span class="line">plt.subplots(<span class="number">2</span>,<span class="number">3</span>,figsize=(<span class="number">15</span>,<span class="number">6</span>))</span><br><span class="line"><span class="comment">#二维网格图</span></span><br><span class="line">G=nx.grid_2d_graph(<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>)</span><br><span class="line">nx.draw(G,with_labels=<span class="literal">True</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;grid_2d_graph&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line"><span class="comment">#n维网格图</span></span><br><span class="line">grid_graph = nx.grid_graph(dim=[<span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">3</span>,<span class="number">2</span>)</span><br><span class="line">nx.draw(grid_graph,with_labels=<span class="literal">True</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;grid_graph&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line"><span class="comment">#m×n的六角形格子图。</span></span><br><span class="line">G=nx.hexagonal_lattice_graph(<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line">nx.draw(G,with_labels=<span class="literal">True</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;hexagonal_lattice_graph&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line"><span class="comment">#n维超立方体图形。</span></span><br><span class="line">G=nx.hypercube_graph(<span class="number">3</span>)</span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">nx.draw(G,with_labels=<span class="literal">True</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;hypercube_graph&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line"><span class="comment">#三角格子图</span></span><br><span class="line">G=nx.triangular_lattice_graph(<span class="number">1</span>,<span class="number">3</span>)</span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">3</span>,<span class="number">5</span>)</span><br><span class="line">nx.draw(G,with_labels=<span class="literal">True</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;hypercube_graph&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613549009241.png" alt="png" title="格子graph" /></p>
<h2 id="各种已经被命名的小graph"><a class="markdownIt-Anchor" href="#各种已经被命名的小graph"></a> 各种已经被命名的小graph</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.subplots(<span class="number">2</span>,<span class="number">2</span>,figsize=(<span class="number">15</span>,<span class="number">6</span>))</span><br><span class="line"></span><br><span class="line">petersen = nx.petersen_graph()</span><br><span class="line">plt.subplot(<span class="number">221</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;petersen_graph&#x27;</span>)</span><br><span class="line">nx.draw(petersen, with_labels=<span class="literal">True</span>, font_weight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line">tutte = nx.tutte_graph()</span><br><span class="line">plt.subplot(<span class="number">222</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;tutte_graph&#x27;</span>)</span><br><span class="line">nx.draw(tutte, with_labels=<span class="literal">True</span>, font_weight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line">maze = nx.sedgewick_maze_graph()</span><br><span class="line">plt.subplot(<span class="number">223</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;sedgewick_maze_graph&#x27;</span>)</span><br><span class="line">nx.draw(maze, with_labels=<span class="literal">True</span>, font_weight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line">tet = nx.tetrahedral_graph()</span><br><span class="line">plt.subplot(<span class="number">224</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;tetrahedral_graph&#x27;</span>)</span><br><span class="line">nx.draw(tet, with_labels=<span class="literal">True</span>, font_weight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613549009237.png" alt="png" title="已经被命名的小graph" /></p>
<h2 id="使用随机graph生成器"><a class="markdownIt-Anchor" href="#使用随机graph生成器"></a> 使用随机graph生成器</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.subplots(<span class="number">2</span>,<span class="number">2</span>,figsize=(<span class="number">15</span>,<span class="number">6</span>))</span><br><span class="line"></span><br><span class="line">er = nx.erdos_renyi_graph(<span class="number">10</span>, <span class="number">0.15</span>)</span><br><span class="line">plt.subplot(<span class="number">221</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;erdos_renyi_graph&#x27;</span>)</span><br><span class="line">nx.draw(er, with_labels=<span class="literal">True</span>, font_weight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line">ws = nx.watts_strogatz_graph(<span class="number">30</span>, <span class="number">3</span>, <span class="number">0.1</span>)</span><br><span class="line">plt.subplot(<span class="number">222</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;watts_strogatz_graph&#x27;</span>)</span><br><span class="line">nx.draw(ws, with_labels=<span class="literal">True</span>, font_weight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line">ba = nx.barabasi_albert_graph(<span class="number">10</span>, <span class="number">5</span>)</span><br><span class="line">plt.subplot(<span class="number">223</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;barabasi_albert_graph&#x27;</span>)</span><br><span class="line">nx.draw(ba, with_labels=<span class="literal">True</span>, font_weight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line">red = nx.random_lobster(<span class="number">10</span>, <span class="number">0.9</span>, <span class="number">0.9</span>)</span><br><span class="line">plt.subplot(<span class="number">224</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;random_lobster&#x27;</span>)</span><br><span class="line">nx.draw(red, with_labels=<span class="literal">True</span>, font_weight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613549009238.png" alt="png" title="随机graph生成器" /></p>
<h2 id="社交网络"><a class="markdownIt-Anchor" href="#社交网络"></a> 社交网络</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.subplots(<span class="number">2</span>,<span class="number">2</span>,figsize=(<span class="number">15</span>,<span class="number">6</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">#返回Zachary的空手道俱乐部图。</span></span><br><span class="line">G.clear()</span><br><span class="line">G = nx.karate_club_graph()</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">nx.draw(G,with_labels=<span class="literal">True</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;karate_club_graph&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line"><span class="comment">#戴维斯南方女性社交网络。</span></span><br><span class="line">G.clear()</span><br><span class="line">G = nx.davis_southern_women_graph()</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">nx.draw(G,with_labels=<span class="literal">True</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;davis_southern_women_graph&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613549009245.png" alt="png" title="社交网络" /></p>
<h2 id="社区"><a class="markdownIt-Anchor" href="#社区"></a> 社区</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.subplots(<span class="number">2</span>,<span class="number">2</span>,figsize=(<span class="number">15</span>,<span class="number">6</span>))</span><br><span class="line"></span><br><span class="line">er = nx.caveman_graph(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line">plt.subplot(<span class="number">221</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;caveman_graph&#x27;</span>)</span><br><span class="line">nx.draw(er, with_labels=<span class="literal">True</span>, font_weight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line">ws = nx.random_partition_graph([<span class="number">10</span>,<span class="number">10</span>,<span class="number">10</span>],<span class="number">.25</span>,<span class="number">.01</span>)</span><br><span class="line">plt.subplot(<span class="number">222</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;random_partition_graph&#x27;</span>)</span><br><span class="line">nx.draw(ws, with_labels=<span class="literal">True</span>, font_weight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line">ba = nx.ring_of_cliques(<span class="number">8</span>, <span class="number">4</span>)</span><br><span class="line">plt.subplot(<span class="number">223</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;ring_of_cliques&#x27;</span>)</span><br><span class="line">nx.draw(ba, with_labels=<span class="literal">True</span>, font_weight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line">red = nx.windmill_graph(<span class="number">4</span>,<span class="number">5</span>)</span><br><span class="line">plt.subplot(<span class="number">224</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;windmill_graph&#x27;</span>)</span><br><span class="line">nx.draw(red, with_labels=<span class="literal">True</span>, font_weight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613549009239.png" alt="png" title="社区" /></p>
<h2 id="树"><a class="markdownIt-Anchor" href="#树"></a> 树</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#返回随机树</span></span><br><span class="line">G.clear()</span><br><span class="line">G = nx.random_tree(<span class="number">10</span>)</span><br><span class="line">nx.draw(G,with_labels=<span class="literal">True</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;random_tree&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613549009240.png" alt="png" title="树" /></p>
]]></content>
      <categories>
        <category>图论</category>
      </categories>
      <tags>
        <tag>图论</tag>
        <tag>NetworkX</tag>
      </tags>
  </entry>
  <entry>
    <title>NetworkX系列教程(4)-设置graph的信息</title>
    <url>/2018/09/17/NetworkX%E7%B3%BB%E5%88%97%E6%95%99%E7%A8%8B(4)-%E8%AE%BE%E7%BD%AEgraph%E7%9A%84%E4%BF%A1%E6%81%AF/</url>
    <content><![CDATA[<p>要画出美观的graph,需要对graph里面的<code>节点</code>,<code>边</code>,<code>节点的布局</code>都要进行设置,具体可以看官方文档:<a href="https://networkx.github.io/documentation/stable/tutorial.html#adding-attributes-to-graphs-nodes-and-edges">Adding attributes to graphs, nodes, and edges</a>部分.</p>
<a id="more"></a>
<p>注意:如果代码出现找不库,请返回第一个教程,把库文件导入.</p>
<h1 id="设置graph的信息"><a class="markdownIt-Anchor" href="#设置graph的信息"></a> 设置graph的信息</h1>
<h2 id="创建graph时添加属性"><a class="markdownIt-Anchor" href="#创建graph时添加属性"></a> 创建graph时添加属性</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#G.clear()</span></span><br><span class="line">G=nx.Graph()</span><br><span class="line">G = nx.Graph(day=<span class="string">&quot;Friday&quot;</span>)</span><br><span class="line">print(<span class="string">&#x27;Assign graph attributes when creating a new graph: &#x27;</span>,G.graph)</span><br><span class="line">G.graph[<span class="string">&#x27;day&#x27;</span>] = <span class="string">&quot;Monday&quot;</span></span><br><span class="line">print(<span class="string">&#x27;Assign graph attributes when have a graph: &#x27;</span>,G.graph)</span><br></pre></td></tr></table></figure>
<p><strong>输出:</strong></p>
<blockquote>
<p>Assign graph attributes when creating a new graph:  {‘day’: ‘Friday’}<br />
Assign graph attributes when have a graph:  {‘day’: ‘Monday’}</p>
</blockquote>
<h2 id="指定节点的属性"><a class="markdownIt-Anchor" href="#指定节点的属性"></a> 指定节点的属性</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#创建时设置</span></span><br><span class="line">G.add_node(<span class="number">1</span>, time=<span class="string">&#x27;5pm&#x27;</span>)</span><br><span class="line">G.add_nodes_from([<span class="number">3</span>,<span class="number">4</span>], time=<span class="string">&#x27;2pm&#x27;</span>,color=<span class="string">&#x27;g&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#直接设置</span></span><br><span class="line">G.nodes[<span class="number">1</span>][<span class="string">&#x27;room&#x27;</span>] = <span class="number">714</span></span><br><span class="line">G.nodes[<span class="number">1</span>][<span class="string">&#x27;color&#x27;</span>] = <span class="string">&#x27;b&#x27;</span></span><br><span class="line"></span><br><span class="line">print(G.nodes.data())</span><br></pre></td></tr></table></figure>
<p><strong>输出:</strong></p>
<blockquote>
<p>[(1, {‘room’: 714, ‘time’: ‘5pm’, ‘color’: ‘b’}), (3, {‘time’: ‘2pm’, ‘color’: ‘g’}), (4, {‘time’: ‘2pm’, ‘color’: ‘g’})]</p>
</blockquote>
<h2 id="指定边的属性"><a class="markdownIt-Anchor" href="#指定边的属性"></a> 指定边的属性</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#创建时设置</span></span><br><span class="line">G.add_edge(<span class="number">1</span>, <span class="number">2</span>, weight=<span class="number">4.7</span> )</span><br><span class="line">G.add_edges_from([(<span class="number">3</span>, <span class="number">4</span>), (<span class="number">4</span>, <span class="number">5</span>)], color=<span class="string">&#x27;red&#x27;</span>,weight=<span class="number">10</span>)</span><br><span class="line">G.add_edges_from([(<span class="number">1</span>, <span class="number">2</span>, &#123;<span class="string">&#x27;color&#x27;</span>: <span class="string">&#x27;blue&#x27;</span>&#125;), (<span class="number">2</span>, <span class="number">3</span>, &#123;<span class="string">&#x27;weight&#x27;</span>: <span class="number">8</span>&#125;)])</span><br><span class="line"></span><br><span class="line"><span class="comment">#直接设置</span></span><br><span class="line">G[<span class="number">1</span>][<span class="number">2</span>][<span class="string">&#x27;weight&#x27;</span>] = <span class="number">4.7</span></span><br><span class="line">G[<span class="number">1</span>][<span class="number">2</span>][<span class="string">&#x27;color&#x27;</span>] = <span class="string">&quot;blue&quot;</span></span><br><span class="line">G.edges[<span class="number">3</span>, <span class="number">4</span>][<span class="string">&#x27;weight&#x27;</span>] = <span class="number">4.2</span></span><br><span class="line">G.edges[<span class="number">1</span>, <span class="number">2</span>][<span class="string">&#x27;color&#x27;</span>] = <span class="string">&quot;green&quot;</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;edge 1-2: &#x27;</span>,G.edges[<span class="number">1</span>,<span class="number">2</span>])</span><br><span class="line">print(<span class="string">&#x27;edge 3-4: &#x27;</span>,G.edges[<span class="number">3</span>,<span class="number">4</span>])</span><br></pre></td></tr></table></figure>
<p><strong>输出:</strong></p>
<blockquote>
<p>edge 1-2:  {‘weight’: 4.7, ‘color’: ‘green’}<br />
edge 3-4:  {‘weight’: 4.2, ‘color’: ‘red’}</p>
</blockquote>
<h2 id="显示graph"><a class="markdownIt-Anchor" href="#显示graph"></a> 显示graph</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#生成节点标签</span></span><br><span class="line">labels=&#123;&#125;</span><br><span class="line">labels[<span class="number">1</span>]=<span class="string">&#x27;1&#x27;</span></span><br><span class="line">labels[<span class="number">2</span>]=<span class="string">&#x27;2&#x27;</span></span><br><span class="line">labels[<span class="number">3</span>]=<span class="string">&#x27;3&#x27;</span></span><br><span class="line">labels[<span class="number">4</span>]=<span class="string">&#x27;4&#x27;</span></span><br><span class="line">labels[<span class="number">5</span>]=<span class="string">&#x27;5&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#获取graph中的边权重</span></span><br><span class="line">edge_labels = nx.get_edge_attributes(G,<span class="string">&#x27;weight&#x27;</span>)</span><br><span class="line">print(<span class="string">&#x27;weight of all edges:&#x27;</span>,edge_labels)</span><br><span class="line"></span><br><span class="line"><span class="comment">#生成节点位置</span></span><br><span class="line">pos=nx.circular_layout(G)</span><br><span class="line">print(<span class="string">&#x27;position of all nodes:&#x27;</span>,pos)</span><br><span class="line"></span><br><span class="line"><span class="comment">#把节点画出来</span></span><br><span class="line">nx.draw_networkx_nodes(G,pos,node_color=<span class="string">&#x27;g&#x27;</span>,node_size=<span class="number">500</span>,alpha=<span class="number">0.8</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#把边画出来</span></span><br><span class="line">nx.draw_networkx_edges(G,pos,width=<span class="number">1.0</span>,alpha=<span class="number">0.5</span>,edge_color=<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#把节点的标签画出来</span></span><br><span class="line">nx.draw_networkx_labels(G,pos,labels,font_size=<span class="number">16</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#把边权重画出来</span></span><br><span class="line">nx.draw_networkx_edge_labels(G, pos, edge_labels)</span><br><span class="line"></span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line"><span class="comment">#去掉坐标刻度</span></span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><strong>输出:</strong></p>
<blockquote>
<p>weight of all edges: {(1, 2): 4.7, (3, 4): 4.2, (2, 3): 8, (4, 5): 10}<br />
position of all nodes: {1: array([1.00000000e+00, 2.38418583e-08]), 2: array([0.30901696, 0.95105658]), 3: array([-0.80901709,  0.58778522]), 4: array([-0.80901698, -0.58778535]), 5: array([ 0.30901711, -0.95105647])}</p>
</blockquote>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613549748265.png" alt="有权无向图" title="有权无向图" /></p>
]]></content>
      <categories>
        <category>图论</category>
      </categories>
      <tags>
        <tag>图论</tag>
        <tag>NetworkX</tag>
      </tags>
  </entry>
  <entry>
    <title>NetworkX系列教程(3)-手动创建graph</title>
    <url>/2018/09/16/NetworkX%E7%B3%BB%E5%88%97%E6%95%99%E7%A8%8B(3)-%E6%89%8B%E5%8A%A8%E5%88%9B%E5%BB%BAgraph/</url>
    <content><![CDATA[<p>不可否认,日常中我们使用最多的还是,使用自己的数据去手动创建自己的图形,而不是使用生成器,现从给graph添加<code>点</code>和边入手,讲解手动创建graph.</p>
<a id="more"></a>
<p>如果代码出现找不库,请返回第一个教程,把库文件导入.</p>
<h1 id="给graph添加节点"><a class="markdownIt-Anchor" href="#给graph添加节点"></a> 给graph添加节点</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> math <span class="keyword">import</span> ceil</span><br><span class="line"></span><br><span class="line"><span class="comment">#该函数由于显示一组graph,传上来的是一组graph和这些graph的描述.</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ShowGraph</span>(<span class="params">glists,ginfo,rowsize=<span class="number">4</span></span>):</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#每行放rowsize个,计算可以放多少行</span></span><br><span class="line">    row=ceil(<span class="built_in">len</span>(glists)/rowsize)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#定义组图</span></span><br><span class="line">    plt.subplots(row,rowsize,figsize=(<span class="number">15</span>,<span class="number">3</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#开始画图</span></span><br><span class="line">    <span class="keyword">for</span> ind <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(glists)):</span><br><span class="line">        <span class="comment">#定义子图</span></span><br><span class="line">        plt.subplot(row,rowsize,ind+<span class="number">1</span>)</span><br><span class="line">        nx.draw(glists[ind],with_labels=<span class="literal">True</span>, font_weight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#设置图片</span></span><br><span class="line">        plt.title(ginfo[ind],fontproperties=myfont)</span><br><span class="line">        plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">        plt.xticks([])</span><br><span class="line">        plt.yticks([])</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#添加单个节点</span></span><br><span class="line">G1=nx.Graph()</span><br><span class="line">G1.add_node(<span class="number">1</span>)</span><br><span class="line">G1.add_node(<span class="string">&quot;spam&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#添加一组节点</span></span><br><span class="line">G2=nx.Graph()</span><br><span class="line">G2.add_nodes_from([<span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">G2.add_nodes_from(<span class="string">&quot;spam&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#使用生成器</span></span><br><span class="line">G3=nx.Graph()</span><br><span class="line">H = nx.path_graph(<span class="number">10</span>)</span><br><span class="line">G3.add_nodes_from(H)</span><br><span class="line"></span><br><span class="line"><span class="comment">#注意:G1.add_nodes_from(H)表示用H中的节点表示G1这个graph,如果要往G1这个graph添加H这个graph,形成graph中的graph,可以使用以下命令</span></span><br><span class="line">G4= nx.Graph()</span><br><span class="line">G4.add_node(<span class="number">1</span>)</span><br><span class="line">G4.add_node(H)</span><br><span class="line"></span><br><span class="line">glists=[G1,G2,G3,G4]</span><br><span class="line">ginfo=[<span class="string">&#x27;添加单个节点&#x27;</span>,<span class="string">&#x27;添加一组节点&#x27;</span>,<span class="string">&#x27;使用生成器&#x27;</span>,<span class="string">&#x27;添加子图&#x27;</span>]</span><br><span class="line">ShowGraph(glists,ginfo)</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613549143986.png" alt="png" title="给graph添加节点" /></p>
<h1 id="给graph添加边"><a class="markdownIt-Anchor" href="#给graph添加边"></a> 给graph添加边</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#删除前面的graph</span></span><br><span class="line">G1.clear()</span><br><span class="line">G2.clear()</span><br><span class="line">G3.clear()</span><br><span class="line">G4.clear()</span><br><span class="line"></span><br><span class="line"><span class="comment">#添加单边</span></span><br><span class="line">G1=nx.Graph()</span><br><span class="line">G1.add_edge(<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line">G1.add_edge(<span class="number">3</span>, <span class="string">&#x27;m&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#添加一组边</span></span><br><span class="line">G2=nx.Graph()</span><br><span class="line">e=(<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">G2.add_edge(*e)</span><br><span class="line"></span><br><span class="line"><span class="comment">#添加多组边</span></span><br><span class="line">G3=nx.Graph()</span><br><span class="line">G3.add_edges_from([(<span class="number">3</span>,<span class="number">4</span>),(<span class="number">4</span>,<span class="number">2</span>)])</span><br><span class="line"></span><br><span class="line"><span class="comment">#使用边生成器</span></span><br><span class="line">G4= nx.Graph()</span><br><span class="line">H = nx.path_graph(<span class="number">10</span>)</span><br><span class="line">G4.add_edges_from(H.edges)</span><br><span class="line"></span><br><span class="line"><span class="comment">#添加一组有权边</span></span><br><span class="line">G5=nx.Graph()</span><br><span class="line">G5.add_weighted_edges_from([(<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="number">5.0</span>), (<span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="number">3.0</span>), (<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="number">1.0</span>), (<span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;d&#x27;</span>, <span class="number">7.3</span>)])  <span class="comment">#边上权重显示看设置graph信息-&gt;指定边属性</span></span><br><span class="line"></span><br><span class="line">glists=[G1,G2,G3,G4,G5]</span><br><span class="line">ginfo=[<span class="string">&#x27;添加单边&#x27;</span>,<span class="string">&#x27;添加一组边&#x27;</span>,<span class="string">&#x27;添加多组边&#x27;</span>,<span class="string">&#x27;使用边生成器&#x27;</span>,<span class="string">&#x27;添加一组有权边&#x27;</span>]</span><br><span class="line">ShowGraph(glists,ginfo,rowsize=<span class="number">5</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613549143993.png" alt="png" title="给graph添加边" /></p>
]]></content>
      <categories>
        <category>图论</category>
      </categories>
      <tags>
        <tag>图论</tag>
        <tag>NetworkX</tag>
      </tags>
  </entry>
  <entry>
    <title>NetworkX系列教程(5)-查看graph的信息</title>
    <url>/2018/09/18/NetworkX%E7%B3%BB%E5%88%97%E6%95%99%E7%A8%8B(5)-%E6%9F%A5%E7%9C%8Bgraph%E7%9A%84%E4%BF%A1%E6%81%AF/</url>
    <content><![CDATA[<p>有时候graph建好后,我们并不清除该graph内节点的,边的信息,这就需要调用函数去查看了.</p>
<a id="more"></a>
<p>注意: 如果代码出现找不库,请返回第一个教程,把库文件导入.</p>
<h1 id="查看graph的信息"><a class="markdownIt-Anchor" href="#查看graph的信息"></a> 查看Graph的信息</h1>
<h2 id="查看graph内节点边的数量"><a class="markdownIt-Anchor" href="#查看graph内节点边的数量"></a> 查看graph内节点,边的<code>数量</code></h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#生成graph</span></span><br><span class="line">G=nx.path_graph(<span class="number">8</span>)</span><br><span class="line">nx.draw(G,with_labels=<span class="literal">True</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment">#查看节点和边的情况</span></span><br><span class="line">print(<span class="string">&#x27;number of nodes&#x27;</span>,G.number_of_nodes())</span><br><span class="line">print(<span class="string">&#x27;number of edges&#x27;</span>,G.number_of_edges())</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613549846968.png" alt="enter description here" title="例子图" /></p>
<p><strong>输出:</strong></p>
<blockquote>
<pre><code>number of nodes 8
number of edges 7
</code></pre>
</blockquote>
<h2 id="查看graph中的点边"><a class="markdownIt-Anchor" href="#查看graph中的点边"></a> 查看graph中的点,边</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#输出graph所有的点和边</span></span><br><span class="line">print(<span class="string">&#x27;all nodes of Graph&#x27;</span>,G.nodes())</span><br><span class="line">print(<span class="string">&#x27;all edges of Graph&#x27;</span>,G.edges())</span><br></pre></td></tr></table></figure>
<p><strong>输出:</strong></p>
<blockquote>
<pre><code>all nodes of Graph [0, 1, 2, 3, 4, 5, 6, 7]
all edges of Graph [(0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7)]
</code></pre>
</blockquote>
<h2 id="查看某些节点的度"><a class="markdownIt-Anchor" href="#查看某些节点的度"></a> 查看某些节点的度</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#查看节点2和3的度</span></span><br><span class="line">print(<span class="string">&#x27;degree of some nodes&#x27;</span>,G.degree([<span class="number">2</span>, <span class="number">3</span>]))</span><br></pre></td></tr></table></figure>
<p><strong>输出:</strong></p>
<blockquote>
<pre><code>degree of some nodes [(2, 2), (3, 2)]
</code></pre>
</blockquote>
<h2 id="查看节点边信息"><a class="markdownIt-Anchor" href="#查看节点边信息"></a> 查看节点&amp;边信息</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#设置一些节点信息</span></span><br><span class="line">G.nodes[<span class="number">1</span>][<span class="string">&#x27;room&#x27;</span>] = <span class="number">714</span></span><br><span class="line">G.nodes[<span class="number">1</span>][<span class="string">&#x27;color&#x27;</span>] = <span class="string">&#x27;b&#x27;</span></span><br><span class="line"><span class="comment">#设置一些边信息</span></span><br><span class="line">G[<span class="number">1</span>][<span class="number">2</span>][<span class="string">&#x27;weight&#x27;</span>] = <span class="number">4.7</span></span><br><span class="line">G[<span class="number">1</span>][<span class="number">2</span>][<span class="string">&#x27;color&#x27;</span>] = <span class="string">&quot;blue&quot;</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;imformation of one nodes&#x27;</span>,G.nodes[<span class="number">1</span>])</span><br><span class="line">print(<span class="string">&#x27;imformation of all nodes&#x27;</span>,G.nodes.data())</span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;imformation of all nodes&#x27;</span>,G.edges.data())  <span class="comment">#边不支持[x]这样的下标访问</span></span><br></pre></td></tr></table></figure>
<p><strong>输出:</strong></p>
<blockquote>
<pre><code>imformation of one nodes &#123;'room': 714, 'color': 'b'&#125;
imformation of all nodes [(0, &#123;&#125;), (1, &#123;'room': 714, 'color': 'b'&#125;), (2, &#123;&#125;), (3, &#123;&#125;), (4, &#123;&#125;), (5, &#123;&#125;), (6, &#123;&#125;), (7, &#123;&#125;)]
imformation of all nodes [(0, 1, &#123;&#125;), (1, 2, &#123;'weight': 4.7, 'color': 'blue'&#125;), (2, 3, &#123;&#125;), (3, 4, &#123;&#125;), (4, 5, &#123;&#125;), (5, 6, &#123;&#125;), (6,7, &#123;&#125;)]
</code></pre>
</blockquote>
<h2 id="遍历一个有权图"><a class="markdownIt-Anchor" href="#遍历一个有权图"></a> 遍历一个有权图</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#定义一个有权无向图</span></span><br><span class="line">FG = nx.Graph()</span><br><span class="line">FG.add_weighted_edges_from([(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0.125</span>), (<span class="number">1</span>, <span class="number">3</span>, <span class="number">0.75</span>), (<span class="number">2</span>, <span class="number">4</span>, <span class="number">1.2</span>), (<span class="number">3</span>, <span class="number">4</span>, <span class="number">0.375</span>)])</span><br><span class="line"></span><br><span class="line"><span class="comment">#遍历邻接矩阵</span></span><br><span class="line"><span class="keyword">for</span> n, nbrs <span class="keyword">in</span> FG.adj.items():</span><br><span class="line">    <span class="keyword">for</span> nbr, eattr <span class="keyword">in</span> nbrs.items():</span><br><span class="line">        wt = eattr[<span class="string">&#x27;weight&#x27;</span>]</span><br><span class="line">        <span class="comment">#权重小于0.5的输出</span></span><br><span class="line">        <span class="keyword">if</span> wt &lt; <span class="number">0.5</span>: </span><br><span class="line">            print(<span class="string">&#x27;way1-(%d, %d, %.3f)&#x27;</span> % (n, nbr, wt))</span><br><span class="line"></span><br><span class="line"><span class="comment">#遍历所有边</span></span><br><span class="line"><span class="keyword">for</span> (u, v, wt) <span class="keyword">in</span> FG.edges.data(<span class="string">&#x27;weight&#x27;</span>):</span><br><span class="line">    <span class="comment">#权重小于0.5的输出</span></span><br><span class="line">    <span class="keyword">if</span> wt &lt; <span class="number">0.5</span>: </span><br><span class="line">        print(<span class="string">&#x27;way2-(%d, %d, %.3f)&#x27;</span> % (u, v, wt))</span><br></pre></td></tr></table></figure>
<p><strong>输出:</strong></p>
<blockquote>
<pre><code>way1-(1, 2, 0.125)
way1-(2, 1, 0.125)
way1-(3, 4, 0.375)
way1-(4, 3, 0.375)
way2-(1, 2, 0.125)
way2-(3, 4, 0.375)</code></pre>
</blockquote>
]]></content>
      <categories>
        <category>图论</category>
      </categories>
      <tags>
        <tag>图论</tag>
        <tag>NetworkX</tag>
      </tags>
  </entry>
  <entry>
    <title>NetworkX系列教程(6)-对graph进行操作</title>
    <url>/2018/09/19/NetworkX%E7%B3%BB%E5%88%97%E6%95%99%E7%A8%8B(6)-%E5%AF%B9graph%E8%BF%9B%E8%A1%8C%E6%93%8D%E4%BD%9C/</url>
    <content><![CDATA[<p>graph生成后,除了有查看操作,还有移除等操作,还有其他更多操作,具体可以看<a href="https://networkx.github.io/documentation/stable/reference/algorithms/operators.html">这里</a>.下面将比较graph操作前后的不同.</p>
<p>目录:</p>
<a id="more"></a>
<p>注意: 如果代码出现找不库,请返回第一个教程,把库文件导入.</p>
<h1 id="对图进行操作"><a class="markdownIt-Anchor" href="#对图进行操作"></a> 对图进行操作</h1>
<h2 id="移除某些节点和边"><a class="markdownIt-Anchor" href="#移除某些节点和边"></a> 移除某些节点和边</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#G.clear()</span></span><br><span class="line"><span class="comment">#生成graph</span></span><br><span class="line">G=nx.path_graph(<span class="number">8</span>)</span><br><span class="line"></span><br><span class="line">plt.subplots(<span class="number">1</span>,<span class="number">2</span>,figsize=(<span class="number">15</span>,<span class="number">5</span>))</span><br><span class="line">plt.suptitle(<span class="string">&#x27;移除部分节点和边&#x27;</span>,fontproperties=myfont)</span><br><span class="line"></span><br><span class="line"><span class="comment">#画出未操作前的graph</span></span><br><span class="line">plt.subplot(<span class="number">121</span>)</span><br><span class="line">nx.draw(G, with_labels=<span class="literal">True</span>, font_weight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;操作前&#x27;</span>,fontproperties=myfont)</span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line"><span class="comment">#移除部分节点和边,移除所有的点和边使用G.clear(),不再单独测试</span></span><br><span class="line">G.remove_node(<span class="number">2</span>)</span><br><span class="line">G.remove_nodes_from([<span class="number">1</span>,<span class="number">5</span>])</span><br><span class="line">G.remove_edge(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#画出操作后的graph</span></span><br><span class="line">plt.subplot(<span class="number">122</span>)</span><br><span class="line">nx.draw(G, with_labels=<span class="literal">True</span>, font_weight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;操作后&#x27;</span>,fontproperties=myfont)</span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line"><span class="comment">#显示graph</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613549997650.png" alt="png" title="移除某些节点和边" /></p>
<h2 id="合并graph"><a class="markdownIt-Anchor" href="#合并graph"></a> 合并graph</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># G1.clear()</span></span><br><span class="line"><span class="comment"># G2.clear()</span></span><br><span class="line"><span class="comment"># G3.clear()</span></span><br><span class="line"></span><br><span class="line">plt.subplots(<span class="number">1</span>,<span class="number">3</span>,figsize=(<span class="number">15</span>,<span class="number">5</span>))</span><br><span class="line">plt.suptitle(<span class="string">&#x27;合并两个图&#x27;</span>,fontproperties=myfont)</span><br><span class="line"></span><br><span class="line"><span class="comment">#生成graph1</span></span><br><span class="line">G1=nx.path_graph(<span class="number">8</span>)</span><br><span class="line">plt.subplot(<span class="number">131</span>)</span><br><span class="line">nx.draw(G1, with_labels=<span class="literal">True</span>, font_weight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;图1&#x27;</span>,fontproperties=myfont)</span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line"><span class="comment">#生成graph2</span></span><br><span class="line">G2=nx.complete_graph(<span class="number">3</span>)</span><br><span class="line">plt.subplot(<span class="number">132</span>)</span><br><span class="line">nx.draw(G2, with_labels=<span class="literal">True</span>, font_weight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;图2&#x27;</span>,fontproperties=myfont)</span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line"><span class="comment">#移除部分节点和边,移除所有的点和边使用G.clear(),不再单独测试</span></span><br><span class="line">G3=nx.disjoint_union(G1,G2)</span><br><span class="line">plt.subplot(<span class="number">133</span>)</span><br><span class="line">nx.draw(G3, with_labels=<span class="literal">True</span>, font_weight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;合并后&#x27;</span>,fontproperties=myfont)</span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line"><span class="comment">#显示graph</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613549997656.png" alt="png" title="合并graph" /></p>
<h2 id="有向图和无向图的转化"><a class="markdownIt-Anchor" href="#有向图和无向图的转化"></a> 有向图和无向图的转化</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#无向图转有向图</span></span><br><span class="line">plt.subplots(<span class="number">1</span>,<span class="number">2</span>,figsize=(<span class="number">15</span>,<span class="number">3</span>))</span><br><span class="line">plt.suptitle(<span class="string">&#x27;无向图转换为有向图&#x27;</span>,fontproperties=myfont)</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义无向图</span></span><br><span class="line">G = nx.path_graph(<span class="number">8</span>)</span><br><span class="line"><span class="comment">#转换为有向图</span></span><br><span class="line">G2=G.to_directed()</span><br><span class="line"></span><br><span class="line"><span class="comment">#下面是可视化转换前后的两个图</span></span><br><span class="line">plt.subplot(<span class="number">121</span>)</span><br><span class="line">nx.draw(G, with_labels=<span class="literal">True</span>, font_weight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;无向图&#x27;</span>,fontproperties=myfont)</span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">122</span>)</span><br><span class="line">nx.draw(G2, with_labels=<span class="literal">True</span>, font_weight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;有向图&#x27;</span>,fontproperties=myfont)</span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br><span class="line"></span><br><span class="line"><span class="comment">#有向图转无向图</span></span><br><span class="line">G.clear()</span><br><span class="line">G2.clear()</span><br><span class="line">plt.subplots(<span class="number">1</span>,<span class="number">2</span>,figsize=(<span class="number">15</span>,<span class="number">3</span>))</span><br><span class="line">plt.suptitle(<span class="string">&#x27;有向图转换为无向图&#x27;</span>,fontproperties=myfont)</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义有向图</span></span><br><span class="line">G = nx.path_graph(<span class="number">8</span>,create_using=nx.DiGraph())</span><br><span class="line"><span class="comment">#转换为无向图</span></span><br><span class="line">G2=G.to_undirected()</span><br><span class="line"></span><br><span class="line"><span class="comment">#下面是可视化转换前后的两个图</span></span><br><span class="line">plt.subplot(<span class="number">121</span>)</span><br><span class="line">nx.draw(G, with_labels=<span class="literal">True</span>, font_weight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;有向图&#x27;</span>,fontproperties=myfont)</span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">122</span>)</span><br><span class="line">nx.draw(G2, with_labels=<span class="literal">True</span>, font_weight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;无向图&#x27;</span>,fontproperties=myfont)</span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 注:可以看出无向图转有向图时,得到的边都是双向</span></span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613549997657.png" alt="png" title="无向图转换为有向图" /></p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613549997658.png" alt="png" title="有向图转换为无向图" /></p>
]]></content>
      <categories>
        <category>图论</category>
      </categories>
      <tags>
        <tag>图论</tag>
        <tag>NetworkX</tag>
      </tags>
  </entry>
  <entry>
    <title>NetworkX系列教程(7)-对graph进行分析</title>
    <url>/2018/09/21/NetworkX%E7%B3%BB%E5%88%97%E6%95%99%E7%A8%8B(7)-%E5%AF%B9graph%E8%BF%9B%E8%A1%8C%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<p>graph构建完成后,对graph的连通等属性进行分析.</p>
<a id="more"></a>
<p>注意: #007e80如果代码出现找不库,请返回第一个教程,把库文件导入.</p>
<h1 id="对图进行分析"><a class="markdownIt-Anchor" href="#对图进行分析"></a> 对图进行分析</h1>
<p>强连通：有向图中任意两点v1、v2间存在v1到v2的路径（path）及v2到v1的路径。<br />
弱联通：将有向图的所有的有向边替换为无向边，所得到的图称为原图的基图。如果一个有向图的基图是连通图，则有向图是弱连通图。</p>
<h2 id="连通子图"><a class="markdownIt-Anchor" href="#连通子图"></a> 连通子图</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#定义图的节点和边</span></span><br><span class="line">nodes=[<span class="string">&#x27;0&#x27;</span>,<span class="string">&#x27;1&#x27;</span>,<span class="string">&#x27;2&#x27;</span>,<span class="string">&#x27;3&#x27;</span>,<span class="string">&#x27;4&#x27;</span>,<span class="string">&#x27;5&#x27;</span>,<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;b&#x27;</span>,<span class="string">&#x27;c&#x27;</span>]</span><br><span class="line">edges=[(<span class="string">&#x27;0&#x27;</span>,<span class="string">&#x27;0&#x27;</span>,<span class="number">1</span>),(<span class="string">&#x27;0&#x27;</span>,<span class="string">&#x27;1&#x27;</span>,<span class="number">1</span>),(<span class="string">&#x27;0&#x27;</span>,<span class="string">&#x27;5&#x27;</span>,<span class="number">1</span>),(<span class="string">&#x27;0&#x27;</span>,<span class="string">&#x27;5&#x27;</span>,<span class="number">2</span>),(<span class="string">&#x27;1&#x27;</span>,<span class="string">&#x27;2&#x27;</span>,<span class="number">3</span>),(<span class="string">&#x27;1&#x27;</span>,<span class="string">&#x27;4&#x27;</span>,<span class="number">5</span>),(<span class="string">&#x27;2&#x27;</span>,<span class="string">&#x27;1&#x27;</span>,<span class="number">7</span>),(<span class="string">&#x27;2&#x27;</span>,<span class="string">&#x27;4&#x27;</span>,<span class="number">6</span>),(<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;b&#x27;</span>,<span class="number">0.5</span>),(<span class="string">&#x27;b&#x27;</span>,<span class="string">&#x27;c&#x27;</span>,<span class="number">0.5</span>),(<span class="string">&#x27;c&#x27;</span>,<span class="string">&#x27;a&#x27;</span>,<span class="number">0.5</span>)]</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义graph</span></span><br><span class="line">G = nx.Graph()</span><br><span class="line">G.add_nodes_from(nodes)</span><br><span class="line">G.add_weighted_edges_from(edges)</span><br><span class="line"></span><br><span class="line"><span class="comment">#找到所有连通子图</span></span><br><span class="line">print(<span class="string">&#x27;connected_components of graph: &#x27;</span>,<span class="built_in">list</span>(nx.connected_components(G)))</span><br><span class="line"></span><br><span class="line"><span class="comment">#显示该graph</span></span><br><span class="line">nx.draw(G, with_labels=<span class="literal">True</span>, font_weight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><strong>输出:</strong></p>
<blockquote>
<pre><code>connected_components of graph:  [&#123;'a', 'b', 'c'&#125;, &#123;'4', '0', '5', '1', '2'&#125;, &#123;'3'&#125;]
</code></pre>
</blockquote>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613550122473.png" alt="png" title="连通子图例子" /></p>
<h2 id="弱联通"><a class="markdownIt-Anchor" href="#弱联通"></a> 弱联通</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#定义graph</span></span><br><span class="line">G = nx.path_graph(<span class="number">4</span>, create_using=nx.DiGraph())</span><br><span class="line">G.add_path([<span class="number">7</span>, <span class="number">8</span>, <span class="number">3</span>])</span><br><span class="line">G.add_path([<span class="number">5</span>, <span class="number">6</span>,<span class="number">9</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">#找出所有的弱连通图</span></span><br><span class="line"><span class="keyword">for</span> c <span class="keyword">in</span> nx.weakly_connected_components(G):</span><br><span class="line">    print(c)</span><br><span class="line">    </span><br><span class="line"><span class="comment">#由大到小的规模判断弱连通子图</span></span><br><span class="line">print([<span class="built_in">len</span>(c) <span class="keyword">for</span> c <span class="keyword">in</span> <span class="built_in">sorted</span>(nx.weakly_connected_components(G), key=<span class="built_in">len</span>, reverse=<span class="literal">True</span>)])</span><br><span class="line"></span><br><span class="line">nx.draw(G, with_labels=<span class="literal">True</span>, font_weight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><strong>输出:</strong></p>
<blockquote>
<pre><code>&#123;0, 1, 2, 3, 7, 8&#125;
&#123;9, 5, 6&#125;
[6, 3]
</code></pre>
</blockquote>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613550122475.png" alt="png" title="弱联通例子" /></p>
<h2 id="强连通"><a class="markdownIt-Anchor" href="#强连通"></a> 强连通</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">G.clear()</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义图</span></span><br><span class="line">G = nx.path_graph(<span class="number">4</span>, create_using=nx.DiGraph())</span><br><span class="line">G.add_path([<span class="number">3</span>, <span class="number">8</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">#找出所有的强连通子图</span></span><br><span class="line">con = nx.strongly_connected_components(G)</span><br><span class="line">print(con,<span class="built_in">type</span>(con),<span class="built_in">list</span>(con))</span><br><span class="line"></span><br><span class="line"><span class="comment">#显示该图</span></span><br><span class="line">nx.draw(G, with_labels=<span class="literal">True</span>, font_weight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><strong>输出:</strong></p>
<blockquote>
<pre><code>&lt;generator object strongly_connected_components at 0x7fe0eefe9c50&gt; &lt;class 'generator'&gt; [&#123;8, 1, 2, 3&#125;, &#123;0&#125;]
</code></pre>
</blockquote>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613550122476.png" alt="png" title="强连通例子" /></p>
<h2 id="子图"><a class="markdownIt-Anchor" href="#子图"></a> 子图</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">G.clear()</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义图</span></span><br><span class="line">G = nx.DiGraph()</span><br><span class="line">G.add_path([<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>])</span><br><span class="line"><span class="comment">#抽取图G的节点作为子图</span></span><br><span class="line">sub_graph = G.subgraph([<span class="number">5</span>, <span class="number">6</span>, <span class="number">8</span>])</span><br><span class="line"></span><br><span class="line">plt.subplots(<span class="number">1</span>,<span class="number">2</span>,figsize=(<span class="number">15</span>,<span class="number">5</span>))</span><br><span class="line"><span class="comment">#画原图</span></span><br><span class="line">plt.subplot(<span class="number">121</span>)</span><br><span class="line">nx.draw(G, with_labels=<span class="literal">True</span>, font_weight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;原图&#x27;</span>,fontproperties=myfont)</span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line"><span class="comment">#画子图</span></span><br><span class="line">plt.subplot(<span class="number">122</span>)</span><br><span class="line">nx.draw(sub_graph, with_labels=<span class="literal">True</span>, font_weight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;子图&#x27;</span>,fontproperties=myfont)</span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613550122476.png" alt="png" title="子图例子" /></p>
<h2 id="条件过滤"><a class="markdownIt-Anchor" href="#条件过滤"></a> 条件过滤</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#G.clear()</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#定义有向图</span></span><br><span class="line">G = nx.DiGraph()</span><br><span class="line">road_nodes = &#123;<span class="string">&#x27;a&#x27;</span>:&#123;<span class="string">&#x27;id&#x27;</span>:<span class="number">1</span>&#125;, <span class="string">&#x27;b&#x27;</span>:&#123;<span class="string">&#x27;id&#x27;</span>:<span class="number">1</span>&#125;, <span class="string">&#x27;c&#x27;</span>:&#123;<span class="string">&#x27;id&#x27;</span>:<span class="number">3</span>&#125;, <span class="string">&#x27;d&#x27;</span>:&#123;<span class="string">&#x27;id&#x27;</span>:<span class="number">4</span>&#125;&#125;</span><br><span class="line">road_edges = [(<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>), (<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;c&#x27;</span>), (<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;d&#x27;</span>), (<span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;d&#x27;</span>)]</span><br><span class="line">G.add_nodes_from(road_nodes.items())</span><br><span class="line">G.add_edges_from(road_edges)</span><br><span class="line"></span><br><span class="line"><span class="comment">#过滤函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">flt_func_draw</span>():</span></span><br><span class="line">    flt_func = <span class="keyword">lambda</span> d: d[<span class="string">&#x27;id&#x27;</span>] != <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> flt_func</span><br><span class="line"></span><br><span class="line">plt.subplots(<span class="number">1</span>,<span class="number">2</span>,figsize=(<span class="number">15</span>,<span class="number">5</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">#画出原图</span></span><br><span class="line">plt.subplot(<span class="number">121</span>)</span><br><span class="line">nx.draw(G, with_labels=<span class="literal">True</span>, font_weight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;过滤前&#x27;</span>,fontproperties=myfont)</span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line"><span class="comment">#过滤原图得到子图</span></span><br><span class="line">flt_func = flt_func_draw()</span><br><span class="line">part_G = G.subgraph(n <span class="keyword">for</span> n, d <span class="keyword">in</span> G.nodes(data=<span class="literal">True</span>) <span class="keyword">if</span> flt_func(d))</span><br><span class="line"></span><br><span class="line"><span class="comment">#画出子图</span></span><br><span class="line">plt.subplot(<span class="number">122</span>)</span><br><span class="line">nx.draw(part_G, with_labels=<span class="literal">True</span>, font_weight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;过滤后&#x27;</span>,fontproperties=myfont)</span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613550122477.png" alt="png" title="条件过滤后的子图" /></p>
]]></content>
      <categories>
        <category>图论</category>
      </categories>
      <tags>
        <tag>图论</tag>
        <tag>NetworkX</tag>
      </tags>
  </entry>
  <entry>
    <title>NetworkX系列教程(8)-DrawingGraph</title>
    <url>/2018/09/23/NetworkX%E7%B3%BB%E5%88%97%E6%95%99%E7%A8%8B(8)-DrawingGraph/</url>
    <content><![CDATA[<p>如果只是简单使用<code>nx.draw</code>,是无法定制出自己需要的graph,并且这样的graph内的点坐标的不定的,运行一次变一次,实际中一般是要求固定的位置,这就需要到<code>布局</code>的概念了.详细的画图信息可以看<a href="https://networkx.github.io/documentation/stable/reference/drawing.html">这里</a>,代码中的关键部分使用了英文进行注释,不在另外注释.</p>
<a id="more"></a>
<p>注意: 如果代码出现找不库,请返回第一个教程,把库文件导入.</p>
<h1 id="drawing-graph"><a class="markdownIt-Anchor" href="#drawing-graph"></a> Drawing Graph</h1>
<h2 id="使用matplotlib"><a class="markdownIt-Anchor" href="#使用matplotlib"></a> 使用Matplotlib</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#定义graph</span></span><br><span class="line">nodes=[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;b&#x27;</span>,<span class="string">&#x27;c&#x27;</span>]</span><br><span class="line">edges=[(<span class="number">0</span>,<span class="number">1</span>),(<span class="number">0</span>,<span class="number">5</span>),(<span class="number">1</span>,<span class="number">2</span>),(<span class="number">1</span>,<span class="number">4</span>),(<span class="number">2</span>,<span class="number">1</span>),(<span class="number">2</span>,<span class="number">4</span>),(<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;b&#x27;</span>),(<span class="string">&#x27;b&#x27;</span>,<span class="string">&#x27;c&#x27;</span>),(<span class="string">&#x27;c&#x27;</span>,<span class="string">&#x27;a&#x27;</span>)]</span><br><span class="line">G=nx.Graph()</span><br><span class="line">G.add_nodes_from(nodes)</span><br><span class="line">G.add_edges_from(edges)</span><br><span class="line"></span><br><span class="line"><span class="comment">#使用spring_layout布局</span></span><br><span class="line">pos=nx.spring_layout(G)</span><br><span class="line"></span><br><span class="line">plt.subplots(<span class="number">2</span>,<span class="number">4</span>,figsize=(<span class="number">18</span>,<span class="number">6</span>))</span><br><span class="line">plt.subplot(<span class="number">241</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;spring_layout&#x27;</span>)</span><br><span class="line">nx.draw(G, with_labels=<span class="literal">True</span>, font_weight=<span class="string">&#x27;bold&#x27;</span>) <span class="comment">#Draw the graph G with Matplotlib.</span></span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">242</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;draw_networkx&#x27;</span>)</span><br><span class="line">nx.draw_networkx(G) <span class="comment">#Draw the graph G using Matplotlib.</span></span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">243</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;draw_networkx_nodes&#x27;</span>)</span><br><span class="line">nx.draw_networkx_nodes(G,pos) <span class="comment">#Draw the nodes of the graph G.</span></span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">244</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;draw_networkx_edges&#x27;</span>)</span><br><span class="line">nx.draw_networkx_edges(G,pos) <span class="comment">#Draw the edges of the graph G.</span></span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">245</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;draw_networkx_labels&#x27;</span>)</span><br><span class="line">nx.draw_networkx_labels(G,pos) <span class="comment">#Draw node labels on the graph G.</span></span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">246</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;draw_networkx_edge_labels&#x27;</span>)</span><br><span class="line">nx.draw_networkx_edge_labels(G,pos) <span class="comment">#Draw edge labels.</span></span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">247</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;draw_circular&#x27;</span>)</span><br><span class="line">nx.draw_circular(G,) <span class="comment">#Draw the graph G with a circular layout.</span></span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">248</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;draw_kamada_kawai&#x27;</span>)</span><br><span class="line">nx.draw_kamada_kawai(G) <span class="comment">#Draw the graph G with a Kamada-Kawai force-directed layout.</span></span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br><span class="line"></span><br><span class="line">plt.subplots(<span class="number">1</span>,<span class="number">4</span>,figsize=(<span class="number">18</span>,<span class="number">3</span>))</span><br><span class="line">plt.subplot(<span class="number">141</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;draw_random&#x27;</span>)</span><br><span class="line">nx.draw_random(G) <span class="comment">#Draw the graph G with a random layout.</span></span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">142</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;draw_spectral&#x27;</span>)</span><br><span class="line">nx.draw_spectral(G,) <span class="comment">#Draw the graph G with a spectral layout.</span></span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">143</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;draw_spring&#x27;</span>)</span><br><span class="line">nx.draw_spring(G) <span class="comment">#Draw the graph G with a spring layout.</span></span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">144</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;draw_shell&#x27;</span>)</span><br><span class="line">nx.draw_shell(G)  <span class="comment">#Draw networkx graph with shell layout.</span></span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613550253480.png" alt="png" title="Matplotlib布局1" /></p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613550253481.png" alt="png" title="Matplotlib布局2" /></p>
<h2 id="使用graphviz-agraph-dot"><a class="markdownIt-Anchor" href="#使用graphviz-agraph-dot"></a> 使用Graphviz AGraph (dot)</h2>
<p>有些同学不知道如何安装Graphviz，我在这里作一个说明：<br />
1.linux是安装graphviz即可，我使用的命令是：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo apt install graphviz</span><br></pre></td></tr></table></figure>
<p>2.Windows我没用实践过，不过我查到Graphviz有官网，里面有windows安装包，地址看下：<br />
<a href="http://www.graphviz.org/download/">http://www.graphviz.org/download/</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">G.clear()</span><br><span class="line"><span class="keyword">from</span> networkx.drawing.nx_pydot <span class="keyword">import</span> write_dot,read_dot</span><br><span class="line"></span><br><span class="line">plt.subplots(<span class="number">1</span>,<span class="number">3</span>,figsize=(<span class="number">15</span>,<span class="number">5</span>))</span><br><span class="line">K5 = nx.complete_graph(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">A = nx.nx_agraph.to_agraph(K5) <span class="comment">#Return a pygraphviz graph from a NetworkX graph N.</span></span><br><span class="line">G1 = nx.nx_agraph.from_agraph(A) <span class="comment">#Return a NetworkX Graph or DiGraph from a PyGraphviz graph.</span></span><br><span class="line">plt.subplot(<span class="number">131</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;原图&#x27;</span>,fontproperties=myfont)</span><br><span class="line">nx.draw_random(G1) <span class="comment">#Draw the graph G with a random layout.</span></span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line">write_dot(G1, <span class="string">&#x27;graph.test&#x27;</span>) <span class="comment">#Write NetworkX graph G to Graphviz dot format on path.</span></span><br><span class="line">G2=read_dot(<span class="string">&#x27;graph.test&#x27;</span>) <span class="comment">#Return a NetworkX graph from a dot file on path.</span></span><br><span class="line">plt.subplot(<span class="number">132</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;保存原图后并读取&#x27;</span>,fontproperties=myfont)</span><br><span class="line">nx.draw_random(G2) <span class="comment">#Draw the graph G with a random layout.</span></span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line">G3 = nx.petersen_graph()</span><br><span class="line">pos = nx.nx_agraph.graphviz_layout(G3) <span class="comment">#Create node positions for G using Graphviz.</span></span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">133</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;graphviz_layout&#x27;</span>,fontproperties=myfont)</span><br><span class="line">nx.draw_random(G3) <span class="comment">#Draw the graph G with a random layout.</span></span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613550253482.png" alt="png" title="Graphviz画图" /></p>
<h2 id="图布局"><a class="markdownIt-Anchor" href="#图布局"></a> 图布局</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#定义graph</span></span><br><span class="line">nodes=[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;b&#x27;</span>,<span class="string">&#x27;c&#x27;</span>]</span><br><span class="line">edges=[(<span class="number">0</span>,<span class="number">1</span>),(<span class="number">0</span>,<span class="number">5</span>),(<span class="number">1</span>,<span class="number">2</span>),(<span class="number">1</span>,<span class="number">4</span>),(<span class="number">2</span>,<span class="number">1</span>),(<span class="number">2</span>,<span class="number">4</span>),(<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;b&#x27;</span>),(<span class="string">&#x27;b&#x27;</span>,<span class="string">&#x27;c&#x27;</span>),(<span class="string">&#x27;c&#x27;</span>,<span class="string">&#x27;a&#x27;</span>)]</span><br><span class="line">G=nx.Graph()</span><br><span class="line">G.add_nodes_from(nodes)</span><br><span class="line">G.add_edges_from(edges)</span><br><span class="line"></span><br><span class="line">plt.subplots(<span class="number">2</span>,<span class="number">3</span>,figsize=(<span class="number">18</span>,<span class="number">6</span>))</span><br><span class="line">plt.subplot(<span class="number">231</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;circular_layout&#x27;</span>)</span><br><span class="line">pos=nx.circular_layout(G) <span class="comment">#Position nodes on a circle.</span></span><br><span class="line">nx.draw(G,pos, with_labels=<span class="literal">True</span>, font_weight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">232</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;kamada_kawai_layout&#x27;</span>)</span><br><span class="line">pos=nx.kamada_kawai_layout(G) <span class="comment">#Position nodes using Kamada-Kawai path-length cost-function.</span></span><br><span class="line">nx.draw(G, pos,with_labels=<span class="literal">True</span>, font_weight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">233</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;random_layout&#x27;</span>)</span><br><span class="line">pos=nx.random_layout(G) <span class="comment">#Position nodes uniformly at random in the unit square.</span></span><br><span class="line">nx.draw(G, pos,with_labels=<span class="literal">True</span>, font_weight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">234</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;shell_layout&#x27;</span>)</span><br><span class="line">pos=nx.shell_layout(G) <span class="comment">#Position nodes in concentric circles.</span></span><br><span class="line">nx.draw(G, pos,with_labels=<span class="literal">True</span>, font_weight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">235</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;spring_layout&#x27;</span>)</span><br><span class="line">pos=nx.spring_layout(G)<span class="comment">#Position nodes using Fruchterman-Reingold force-directed algorithm.</span></span><br><span class="line">nx.draw(G, pos, with_labels=<span class="literal">True</span>, font_weight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">236</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;spectral_layout&#x27;</span>)</span><br><span class="line">pos=nx.spectral_layout(G) <span class="comment">#Position nodes using the eigenvectors of the graph Laplacian.</span></span><br><span class="line">nx.draw(G, pos, with_labels=<span class="literal">True</span>, font_weight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613550253483.png" alt="png" title="图布局" /></p>
]]></content>
      <categories>
        <category>图论</category>
      </categories>
      <tags>
        <tag>图论</tag>
        <tag>NetworkX</tag>
      </tags>
  </entry>
  <entry>
    <title>NetworkX系列教程(9)-线性代数相关</title>
    <url>/2018/09/24/NetworkX%E7%B3%BB%E5%88%97%E6%95%99%E7%A8%8B(9)-%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%9B%B8%E5%85%B3/</url>
    <content><![CDATA[<p>学过线性代数的都了解矩阵,在矩阵上的文章可做的很多,什么特征矩阵,单位矩阵等.grpah存储可以使用矩阵,比如graph的<code>邻接矩阵</code>,<code>权重矩阵</code>等,这节主要是在等到graph后,如何快速得到这些信息.详细官方文档在<a href="https://networkx.github.io/documentation/stable/reference/linalg.html">这里</a></p>
<a id="more"></a>
<p>注意: 如果代码出现找不库,请返回第一个教程,把库文件导入.</p>
<h1 id="线性代数相关"><a class="markdownIt-Anchor" href="#线性代数相关"></a> 线性代数相关</h1>
<h2 id="图矩阵"><a class="markdownIt-Anchor" href="#图矩阵"></a> 图矩阵</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#定义图的节点和边</span></span><br><span class="line">nodes=[<span class="string">&#x27;0&#x27;</span>,<span class="string">&#x27;1&#x27;</span>,<span class="string">&#x27;2&#x27;</span>,<span class="string">&#x27;3&#x27;</span>,<span class="string">&#x27;4&#x27;</span>,<span class="string">&#x27;5&#x27;</span>,<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;b&#x27;</span>,<span class="string">&#x27;c&#x27;</span>]</span><br><span class="line">edges=[(<span class="string">&#x27;0&#x27;</span>,<span class="string">&#x27;0&#x27;</span>,<span class="number">1</span>),(<span class="string">&#x27;0&#x27;</span>,<span class="string">&#x27;1&#x27;</span>,<span class="number">1</span>),(<span class="string">&#x27;0&#x27;</span>,<span class="string">&#x27;5&#x27;</span>,<span class="number">1</span>),(<span class="string">&#x27;0&#x27;</span>,<span class="string">&#x27;5&#x27;</span>,<span class="number">2</span>),(<span class="string">&#x27;1&#x27;</span>,<span class="string">&#x27;2&#x27;</span>,<span class="number">3</span>),(<span class="string">&#x27;1&#x27;</span>,<span class="string">&#x27;4&#x27;</span>,<span class="number">5</span>),(<span class="string">&#x27;2&#x27;</span>,<span class="string">&#x27;1&#x27;</span>,<span class="number">7</span>),(<span class="string">&#x27;2&#x27;</span>,<span class="string">&#x27;4&#x27;</span>,<span class="number">6</span>),(<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;b&#x27;</span>,<span class="number">0.5</span>),(<span class="string">&#x27;b&#x27;</span>,<span class="string">&#x27;c&#x27;</span>,<span class="number">0.5</span>),(<span class="string">&#x27;c&#x27;</span>,<span class="string">&#x27;a&#x27;</span>,<span class="number">0.5</span>)]</span><br><span class="line"></span><br><span class="line">plt.subplots(<span class="number">1</span>,<span class="number">2</span>,figsize=(<span class="number">10</span>,<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义一个无向图和有向图</span></span><br><span class="line">G1 = nx.Graph()</span><br><span class="line">G1.add_nodes_from(nodes)</span><br><span class="line">G1.add_weighted_edges_from(edges)</span><br><span class="line"></span><br><span class="line">G2 = nx.DiGraph()</span><br><span class="line">G2.add_nodes_from(nodes)</span><br><span class="line">G2.add_weighted_edges_from(edges)</span><br><span class="line"></span><br><span class="line">pos1=nx.circular_layout(G1)</span><br><span class="line">pos2=nx.circular_layout(G2)</span><br><span class="line"></span><br><span class="line"><span class="comment">#画出无向图和有向图</span></span><br><span class="line">plt.subplot(<span class="number">121</span>)</span><br><span class="line">nx.draw(G1,pos1, with_labels=<span class="literal">True</span>, font_weight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;无向图&#x27;</span>,fontproperties=myfont)</span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">122</span>)</span><br><span class="line">nx.draw(G2,pos2, with_labels=<span class="literal">True</span>, font_weight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;有向图&#x27;</span>,fontproperties=myfont)</span><br><span class="line">plt.axis(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">plt.xticks([])</span><br><span class="line">plt.yticks([])</span><br><span class="line"></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment">#控制numpy输出小数位数</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">np.set_printoptions(precision=<span class="number">3</span>) </span><br><span class="line"></span><br><span class="line"><span class="comment">#邻接矩阵</span></span><br><span class="line">A = nx.adjacency_matrix(G1)</span><br><span class="line">print(<span class="string">&#x27;邻接矩阵:\n&#x27;</span>,A.todense())</span><br><span class="line"></span><br><span class="line"><span class="comment">#关联矩阵</span></span><br><span class="line">I = nx.incidence_matrix(G1)</span><br><span class="line">print(<span class="string">&#x27;\n关联矩阵:\n&#x27;</span>,I.todense())</span><br><span class="line"></span><br><span class="line"><span class="comment">#拉普拉斯矩阵</span></span><br><span class="line">L=nx.laplacian_matrix(G1)</span><br><span class="line">print(<span class="string">&#x27;\n拉普拉斯矩阵:\n&#x27;</span>,L.todense())</span><br><span class="line"></span><br><span class="line"><span class="comment">#标准化的拉普拉斯矩阵</span></span><br><span class="line">NL=nx.normalized_laplacian_matrix(G1)</span><br><span class="line">print(<span class="string">&#x27;\n标准化的拉普拉斯矩阵:\n&#x27;</span>,NL.todense())</span><br><span class="line"></span><br><span class="line"><span class="comment">#有向图拉普拉斯矩阵</span></span><br><span class="line">DL=nx.directed_laplacian_matrix(G2)</span><br><span class="line">print(<span class="string">&#x27;\n有向拉普拉斯矩阵:\n&#x27;</span>,DL)</span><br><span class="line"></span><br><span class="line"><span class="comment">#拉普拉斯算子的特征值</span></span><br><span class="line">LS=nx.laplacian_spectrum(G1)</span><br><span class="line">print(<span class="string">&#x27;\n拉普拉斯算子的特征值:\n&#x27;</span>,LS)</span><br><span class="line"></span><br><span class="line"><span class="comment">#邻接矩阵的特征值</span></span><br><span class="line">AS=nx.adjacency_spectrum(G1)</span><br><span class="line">print(<span class="string">&#x27;\n邻接矩阵的特征值:\n&#x27;</span>,AS)</span><br><span class="line"></span><br><span class="line"><span class="comment">#无向图的代数连通性</span></span><br><span class="line">AC=nx.algebraic_connectivity(G1)</span><br><span class="line">print(<span class="string">&#x27;\n无向图的代数连通性:\n&#x27;</span>,AC)</span><br><span class="line"></span><br><span class="line"><span class="comment">#图的光谱排序</span></span><br><span class="line">SO=nx.spectral_ordering(G1)</span><br><span class="line">print(<span class="string">&#x27;\n图的光谱排序:\n&#x27;</span>,SO)</span><br><span class="line"></span><br><span class="line"><span class="comment">#两个矩阵的解释看:https://blog.csdn.net/Hanging_Gardens/article/details/55670356</span></span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613550454647.png" alt="图矩阵示例" /></p>
<p><strong>输出:</strong></p>
<pre><code>邻接矩阵:
 [[0.  0.  0.  0.  5.  0.  0.  0.  6. ]
 [0.  0.  0.  2.  0.  0.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.5 0.5 0.  0. ]
 [0.  2.  0.  1.  1.  0.  0.  0.  0. ]
 [5.  0.  0.  1.  0.  0.  0.  0.  7. ]
 [0.  0.  0.5 0.  0.  0.  0.5 0.  0. ]
 [0.  0.  0.5 0.  0.  0.5 0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  0.  0. ]
 [6.  0.  0.  0.  7.  0.  0.  0.  0. ]]

关联矩阵:
 [[1. 1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 1. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 1. 0. 0. 0.]
 [0. 1. 0. 0. 0. 1. 0. 1. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 1. 0.]]

拉普拉斯矩阵:
 [[11.   0.   0.   0.  -5.   0.   0.   0.  -6. ]
 [ 0.   2.   0.  -2.   0.   0.   0.   0.   0. ]
 [ 0.   0.   1.   0.   0.  -0.5 -0.5  0.   0. ]
 [ 0.  -2.   0.   3.  -1.   0.   0.   0.   0. ]
 [-5.   0.   0.  -1.  13.   0.   0.   0.  -7. ]
 [ 0.   0.  -0.5  0.   0.   1.  -0.5  0.   0. ]
 [ 0.   0.  -0.5  0.   0.  -0.5  1.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [-6.   0.   0.   0.  -7.   0.   0.   0.  13. ]]

标准化的拉普拉斯矩阵:
 [[ 1.     0.     0.     0.    -0.418  0.     0.     0.    -0.502]
 [ 0.     1.     0.    -0.707  0.     0.     0.     0.     0.   ]
 [ 0.     0.     1.     0.     0.    -0.5   -0.5    0.     0.   ]
 [ 0.    -0.707  0.     0.75  -0.139  0.     0.     0.     0.   ]
 [-0.418  0.     0.    -0.139  1.     0.     0.     0.    -0.538]
 [ 0.     0.    -0.5    0.     0.     1.    -0.5    0.     0.   ]
 [ 0.     0.    -0.5    0.     0.    -0.5    1.     0.     0.   ]
 [ 0.     0.     0.     0.     0.     0.     0.     0.     0.   ]
 [-0.502  0.     0.     0.    -0.538  0.     0.     0.     1.   ]]

有向拉普拉斯矩阵:
 [[ 0.889 -0.117 -0.029 -0.087 -0.319 -0.029 -0.029 -0.129 -0.242]
 [-0.117  0.889 -0.026 -0.278 -0.051 -0.026 -0.026 -0.114 -0.056]
 [-0.029 -0.026  0.994 -0.012 -0.009 -0.481 -0.481 -0.025 -0.01 ]
 [-0.087 -0.278 -0.012  0.757 -0.097 -0.012 -0.012 -0.052 -0.006]
 [-0.319 -0.051 -0.009 -0.097  0.994 -0.009 -0.009 -0.041 -0.434]
 [-0.029 -0.026 -0.481 -0.012 -0.009  0.994 -0.481 -0.025 -0.01 ]
 [-0.029 -0.026 -0.481 -0.012 -0.009 -0.481  0.994 -0.025 -0.01 ]
 [-0.129 -0.114 -0.025 -0.052 -0.041 -0.025 -0.025  0.889 -0.045]
 [-0.242 -0.056 -0.01  -0.006 -0.434 -0.01  -0.01  -0.045  0.994]]

拉普拉斯算子的特征值:
 [-1.436e-15  0.000e+00  4.610e-16  7.000e-01  1.500e+00  1.500e+00
  4.576e+00  1.660e+01  2.013e+01]

邻接矩阵的特征值:
 [12.068+0.000e+00j  2.588+0.000e+00j -7.219+0.000e+00j -4.925+0.000e+00j
 -1.513+0.000e+00j  1.   +0.000e+00j -0.5  +2.393e-17j -0.5  -2.393e-17j
  0.   +0.000e+00j]

无向图的代数连通性:
 0.0

图的光谱排序:
 ['4', '2', '1', '0', '5', 'b', 'c', 'a', '3']
</code></pre>
<hr />
<p>后面还有两个小节,由于对图论算法不是很明白,所以先讲明白算法原理,再使用networkX实现,如无须读算法,可以跳过算法原理部分.</p>
]]></content>
      <categories>
        <category>图论</category>
      </categories>
      <tags>
        <tag>图论</tag>
        <tag>NetworkX</tag>
      </tags>
  </entry>
  <entry>
    <title>在windows上使用nuitka打包Python项目</title>
    <url>/2021/03/16/Nuitka%E6%89%93%E5%8C%85%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/</url>
    <content><![CDATA[<p>Nuitka是Python编译器，它是用Python编写，对Python解释器的无缝替换或扩展，兼容多个CPython版本，利用该工具可以对Python文件进行打包。本文用于介绍如何在windows上使用nuitka工具打包Python，包含构建打包环境、安装nuitka、测试打包。</p>
<a id="more"></a>
<h2 id="打包环境介绍"><a class="markdownIt-Anchor" href="#打包环境介绍"></a> <strong>打包环境介绍</strong></h2>
<p>本次打包所使用的软硬件环境如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">System: windows 10 企业版 19042.804</span><br><span class="line">NVIDIA DERVER 461.</span><br><span class="line">mingw 8.0.0</span><br><span class="line">visual studio 2017</span><br><span class="line">python 3.7.10</span><br><span class="line">nuitka 0.6.12.3</span><br><span class="line">tensorflow-gpu  2.5.0.dev20210308</span><br><span class="line">cuda 11.1</span><br><span class="line">cudnn 8.0.4</span><br><span class="line">numpy 1.20.1</span><br></pre></td></tr></table></figure>
<h2 id="安装nuitka"><a class="markdownIt-Anchor" href="#安装nuitka"></a> 安装nuitka<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup></h2>
<ol>
<li>安装C编译器，有以下两个选择，任选一个安装
<ul>
<li>根据系统配置，<a href="https://sourceforge.net/projects/mingw-w64/files/mingw-w64/mingw-w64-release/">下载并安装</a>MinGW64，基于gcc8.0以上的版本，安装过程参考</li>
<li>根据系统配置，<a href="https://visualstudio.microsoft.com/downloads/">下载并安装</a>Visual Studio 2019以上的版本</li>
</ul>
</li>
<li><a href="https://www.python.org/downloads/windows">下载并安装</a>Python，确保版本为：2.6、2.7或3.3、3.4、3.5、3.6、3.7、3.8、3.9 其中一个</li>
<li>使用以下命令安装nuitka</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">python -m pip install nuitka</span><br></pre></td></tr></table></figure>
<h2 id="测试nuitka打包2"><a class="markdownIt-Anchor" href="#测试nuitka打包2"></a> 测试nuitka打包[^2]</h2>
<p><a href="http://xn--mdl-tu9d554er5ifia.py">新建文件mdl.py</a>，内容如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printinfo</span>(<span class="params">info</span>):</span></span><br><span class="line">	print(info)</span><br></pre></td></tr></table></figure>
<p><a href="http://xn--main-494f213aw1t0uau17bc55b.py">同目录下新建main.py</a>，内容如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> printinfo <span class="keyword">import</span> printinfo</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    printinfo(<span class="string">&#x27;Hello nuitka&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>测试运行无误后，运行以下命令</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">nuitka --output-dir=<span class="built_in">test</span> hello.py</span><br></pre></td></tr></table></figure>
<p>运行编译之后的exe程序，得到正确结果即安装完成</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">.\<span class="built_in">test</span>\main.exe</span><br></pre></td></tr></table></figure>
<p><strong>生成文件说明</strong></p>
<p>生成目录下，文件清理如下：</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/PicGo/image-20210316145017152.png" alt="image-20210316145017152" /></p>
<ul>
<li>main.build     nuitka打包过程的中间文件，可删除</li>
<li>main.exe        nuitka打包得到的可执行文件</li>
<li>python37.dll  Pyhton安装目录下的python37.dll的拷贝，代码使用的库包依靠该文件去查找</li>
</ul>
<hr class="footnotes-sep" />
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p><a href="https://zhuanlan.zhihu.com/p/341099225">Nuitka入门指南-新手必备 - 知乎</a><br />
[^2 ]: <a href="https://www.nuitka.net/doc/user-manual.html#id5">Nuitka User Manual</a> <a href="#fnref1" class="footnote-backref">↩︎</a></p>
</li>
</ol>
</section>
]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>打包</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>Numpy中数据的常用的保存与读取方法</title>
    <url>/2017/09/23/Numpy%E4%B8%AD%E6%95%B0%E6%8D%AE%E7%9A%84%E5%B8%B8%E7%94%A8%E7%9A%84%E4%BF%9D%E5%AD%98%E4%B8%8E%E8%AF%BB%E5%8F%96%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<p>在经常性读取大量的数值文件时(比如深度学习训练数据),可以考虑现将数据存储为Numpy格式,然后直接使用Numpy去读取,速度相比为转化前快很多.</p>
<p>下面就常用的保存数据到二进制文件和保存数据到文本文件进行介绍:</p>
<a id="more"></a>
<h1 id="保存为二进制文件npynpz"><a class="markdownIt-Anchor" href="#保存为二进制文件npynpz"></a> 保存为二进制文件(.npy/.npz)</h1>
<h2 id="numpysave"><a class="markdownIt-Anchor" href="#numpysave"></a> <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.save.html#numpy.save">numpy.save</a></h2>
<p>保存一个数组到一个二进制的文件中,保存格式是<code>.npy</code></p>
<p><strong>参数介绍</strong><br />
numpy.save(file, arr, allow_pickle=True, fix_imports=True)</p>
<blockquote>
<p>file:文件名/文件路径<br />
arr:要存储的数组<br />
allow_pickle:布尔值,允许使用Python pickles保存对象数组(可选参数,默认即可)<br />
fix_imports:为了方便Pyhton2中读取Python3保存的数据(可选参数,默认即可)</p>
</blockquote>
<p><strong>使用</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment">#生成数据</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x=np.arange(<span class="number">10</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x</span><br><span class="line">array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">#数据保存</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.save(<span class="string">&#x27;save_x&#x27;</span>,x)</span><br><span class="line"></span><br><span class="line"><span class="comment">#读取保存的数据</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.load(<span class="string">&#x27;save_x.npy&#x27;</span>)</span><br><span class="line">array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>])</span><br></pre></td></tr></table></figure>
<h2 id="numpysavez"><a class="markdownIt-Anchor" href="#numpysavez"></a> <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.savez.html#numpy.savez">numpy.savez</a></h2>
<p>这个同样是保存数组到一个二进制的文件中,但是厉害的是,它可以保存多个数组到同一个文件中,保存格式是<code>.npz</code>,它其实就是多个前面np.save的保存的<code>npy</code>,再通过打包(未压缩) 的方式把这些文件归到一个文件上,不行你去解压<code>npz</code>文件就知道了,里面是就是自己保存的多个<code>npy</code>.</p>
<p><strong>参数介绍</strong><br />
numpy.savez(file, *args, **kwds)</p>
<blockquote>
<p>file:文件名/文件路径<br />
*args:要存储的数组,可以写多个,如果没有给数组指定Key,Numpy将默认从’arr_0’,'arr_1’的方式命名<br />
kwds:(可选参数,默认即可)</p>
</blockquote>
<p><strong>使用</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment">#生成数据</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x=np.arange(<span class="number">10</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x</span><br><span class="line">array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y=np.sin(x)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y</span><br><span class="line">array([ <span class="number">0.</span>        ,  <span class="number">0.84147098</span>,  <span class="number">0.90929743</span>,  <span class="number">0.14112001</span>, -<span class="number">0.7568025</span> ,</span><br><span class="line">       -<span class="number">0.95892427</span>, -<span class="number">0.2794155</span> ,  <span class="number">0.6569866</span> ,  <span class="number">0.98935825</span>,  <span class="number">0.41211849</span>])</span><br><span class="line">	   </span><br><span class="line"><span class="comment">#数据保存</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.save(<span class="string">&#x27;save_xy&#x27;</span>,x,y)</span><br><span class="line"></span><br><span class="line"><span class="comment">#读取保存的数据</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>npzfile=np.load(<span class="string">&#x27;save_xy.npz&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>npzfile  <span class="comment">#是一个对象,无法读取</span></span><br><span class="line">&lt;numpy.lib.npyio.NpzFile <span class="built_in">object</span> at <span class="number">0x7f63ce4c8860</span>&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">#按照组数默认的key进行访问</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>npzfile[<span class="string">&#x27;arr_0&#x27;</span>]</span><br><span class="line">array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>npzfile[<span class="string">&#x27;arr_1&#x27;</span>]</span><br><span class="line">array([ <span class="number">0.</span>        ,  <span class="number">0.84147098</span>,  <span class="number">0.90929743</span>,  <span class="number">0.14112001</span>, -<span class="number">0.7568025</span> ,</span><br><span class="line">       -<span class="number">0.95892427</span>, -<span class="number">0.2794155</span> ,  <span class="number">0.6569866</span> ,  <span class="number">0.98935825</span>,  <span class="number">0.41211849</span>])</span><br></pre></td></tr></table></figure>
<p>更加神奇的是,你可以不适用Numpy默认给数组的Key,而是自己给数组有意义的Key,这样就可以不用去猜测自己加载数据是否是自己需要的.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#数据保存</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.savez(<span class="string">&#x27;newsave_xy&#x27;</span>,x=x,y=y)</span><br><span class="line"></span><br><span class="line"><span class="comment">#读取保存的数据</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>npzfile=np.load(<span class="string">&#x27;newsave_xy.npz&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#按照保存时设定组数key进行访问</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>npzfile[<span class="string">&#x27;x&#x27;</span>]</span><br><span class="line">array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>npzfile[<span class="string">&#x27;y&#x27;</span>]</span><br><span class="line">array([ <span class="number">0.</span>        ,  <span class="number">0.84147098</span>,  <span class="number">0.90929743</span>,  <span class="number">0.14112001</span>, -<span class="number">0.7568025</span> ,</span><br><span class="line">       -<span class="number">0.95892427</span>, -<span class="number">0.2794155</span> ,  <span class="number">0.6569866</span> ,  <span class="number">0.98935825</span>,  <span class="number">0.41211849</span>])</span><br></pre></td></tr></table></figure>
<p>简直不能太爽,深度学习中,有时候你保存了训练集,验证集,测试集,还包括他们的标签,用这个方式存储起来,要啥加载啥,文件数量大大减少,也不会到处改文件名去.</p>
<h2 id="numpysavez_compressed"><a class="markdownIt-Anchor" href="#numpysavez_compressed"></a> <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.savez_compressed.html#numpy.savez_compressed">numpy.savez_compressed</a></h2>
<p>这个就是在前面numpy.savez的基础上加了压缩,前面我介绍时尤其注明numpy.savez是得到的文件打包,不压缩的.这个文件就是对文件进行打包时使用了压缩,可以理解为压缩前各<code>npy</code>的文件大小不变,使用该函数比前面的numpy.savez得到的<code>npz</code>文件更小.</p>
<p><mark>注:函数所需参数和numpy.savez一致,用法完成一样.</mark></p>
<h1 id="保存到文本文件"><a class="markdownIt-Anchor" href="#保存到文本文件"></a> 保存到文本文件</h1>
<h2 id="numpysavetxt"><a class="markdownIt-Anchor" href="#numpysavetxt"></a> <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.savetxt.html#numpy.savetxt">numpy.savetxt</a></h2>
<p>保存数组到文本文件上,可以直接打开查看文件里面的内容.</p>
<p><strong>参数介绍</strong><br />
numpy.savetxt(fname, X, fmt=’%.18e’, delimiter=’ ‘, newline=’\n’, header=’’, footer=’’, comments=’# ', encoding=None)</p>
<blockquote>
<p>fname:文件名/文件路径,如果文件后缀是<code>.gz</code>,文件将被自动保存为<code>.gzip</code>格式,np.loadtxt可以识别该格式<br />
X:要存储的1D或2D数组<br />
fmt:控制数据存储的格式<br />
delimiter:数据列之间的分隔符<br />
newline:数据行之间的分隔符<br />
header:文件头步写入的字符串<br />
footer:文件底部写入的字符串<br />
comments:文件头部或者尾部字符串的开头字符,默认是’#’<br />
encoding:使用默认参数</p>
</blockquote>
<p><strong>使用</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment">#生成数据</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = y = z = np.ones((<span class="number">2</span>,<span class="number">3</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x</span><br><span class="line">array([[<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">       [<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>]])</span><br><span class="line">	   </span><br><span class="line"><span class="comment">#保存数据</span></span><br><span class="line">np.savetxt(<span class="string">&#x27;test.out&#x27;</span>, x)</span><br><span class="line">np.savetxt(<span class="string">&#x27;test1.out&#x27;</span>, x,fmt=<span class="string">&#x27;%1.4e&#x27;</span>)</span><br><span class="line">np.savetxt(<span class="string">&#x27;test2.out&#x27;</span>, x, delimiter=<span class="string">&#x27;,&#x27;</span>)</span><br><span class="line">np.savetxt(<span class="string">&#x27;test3.out&#x27;</span>, x,newline=<span class="string">&#x27;a&#x27;</span>)</span><br><span class="line">np.savetxt(<span class="string">&#x27;test4.out&#x27;</span>, x,delimiter=<span class="string">&#x27;,&#x27;</span>,newline=<span class="string">&#x27;a&#x27;</span>)</span><br><span class="line">np.savetxt(<span class="string">&#x27;test5.out&#x27;</span>, x,delimiter=<span class="string">&#x27;,&#x27;</span>,header=<span class="string">&#x27;abc&#x27;</span>)</span><br><span class="line">np.savetxt(<span class="string">&#x27;test6.out&#x27;</span>, x,delimiter=<span class="string">&#x27;,&#x27;</span>,footer=<span class="string">&#x27;abc&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>保存下来的文件都是友好的,可以直接打开看看有什么变化.</p>
<h2 id="numpyloadtxt"><a class="markdownIt-Anchor" href="#numpyloadtxt"></a> <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.loadtxt.html#numpy.loadtxt">numpy.loadtxt</a></h2>
<p>根据前面定制的保存格式,相应的加载数据的函数也得变化.</p>
<p><strong>参数介绍</strong><br />
numpy.loadtxt(fname, dtype=&lt;class ‘float’&gt;, comments=’#’, delimiter=None, converters=None, skiprows=0, usecols=None, unpack=False, ndmin=0, encoding=‘bytes’)</p>
<blockquote>
<p>fname:文件名/文件路径,如果文件后缀是<code>.gz</code>或<code>.bz2</code>,文件将被解压,然后再载入<br />
dtype:要读取的数据类型<br />
comments:文件头部或者尾部字符串的开头字符,用于识别头部,尾部字符串<br />
delimiter:划分读取上来值的字符串<br />
converters:数据行之间的分隔符<br />
…后面不常用的就不写了</p>
</blockquote>
<p><strong>使用</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">np.loadtxt(<span class="string">&#x27;test.out&#x27;</span>)</span><br><span class="line">np.loadtxt(<span class="string">&#x27;test2.out&#x27;</span>, delimiter=<span class="string">&#x27;,&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>参考资料:<br />
<a href="https://docs.scipy.org/doc/numpy/reference/routines.io.html">官方API-Routines</a></p>
]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>numpy</tag>
      </tags>
  </entry>
  <entry>
    <title>Python中多层List展平为一层</title>
    <url>/2018/06/29/Python%E4%B8%AD%E5%A4%9A%E5%B1%82List%E5%B1%95%E5%B9%B3%E4%B8%BA%E4%B8%80%E5%B1%82/</url>
    <content><![CDATA[<p>使用Python脚本的过程中,偶尔需要使用<code>list多层转一层</code>,又总是忘记怎么写搜索关键词,所以总是找了很久,现在把各种方法记录下来,方便自己也方便大家.</p>
<p>方法很多,现在就简单写8种,后面再对这8种方法做基准测试.</p>
<p>声明:文中的方法均收集自<a href="https://stackoverflow.com/questions/952914/making-a-flat-list-out-of-list-of-lists-in-python">Making a flat list out of list of lists in Python</a></p>
<a id="more"></a>
<h1 id="方法汇总"><a class="markdownIt-Anchor" href="#方法汇总"></a> 方法汇总</h1>
<p><strong>1.定义减层方法</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> functools</span><br><span class="line"><span class="keyword">import</span> itertools</span><br><span class="line"><span class="keyword">import</span> numpy</span><br><span class="line"><span class="keyword">import</span> operator</span><br><span class="line"><span class="keyword">import</span> perfplot</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Iterable  <span class="comment"># or from collections.abc import Iterable</span></span><br><span class="line"><span class="keyword">from</span> iteration_utilities <span class="keyword">import</span> deepflatten</span><br><span class="line"></span><br><span class="line"><span class="comment">#使用两次for循环</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forfor</span>(<span class="params">a</span>):</span></span><br><span class="line">    <span class="keyword">return</span> [item <span class="keyword">for</span> sublist <span class="keyword">in</span> a <span class="keyword">for</span> item <span class="keyword">in</span> sublist]</span><br><span class="line"></span><br><span class="line"><span class="comment">#通过sum</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sum_brackets</span>(<span class="params">a</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">sum</span>(a, [])</span><br><span class="line"></span><br><span class="line"><span class="comment">#使用functools內建模块</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">functools_reduce</span>(<span class="params">a</span>):</span></span><br><span class="line">    <span class="keyword">return</span> functools.reduce(operator.concat, a)</span><br><span class="line"></span><br><span class="line"><span class="comment">#使用itertools內建模块</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">itertools_chain</span>(<span class="params">a</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">list</span>(itertools.chain.from_iterable(a))</span><br><span class="line"></span><br><span class="line"><span class="comment">#使用numpy</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">numpy_flat</span>(<span class="params">a</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">list</span>(numpy.array(a).flat)</span><br><span class="line"></span><br><span class="line"><span class="comment">#使用numpy</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">numpy_concatenate</span>(<span class="params">a</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">list</span>(numpy.concatenate(a))</span><br><span class="line"></span><br><span class="line"><span class="comment">#自定义函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">flatten</span>(<span class="params">items</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Yield items from any nested iterable; see REF.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> items:</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(x, Iterable) <span class="keyword">and</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(x, (<span class="built_in">str</span>, <span class="built_in">bytes</span>)):</span><br><span class="line">            <span class="keyword">yield</span> <span class="keyword">from</span> flatten(x)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">yield</span> x</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pylangs_flatten</span>(<span class="params">a</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">list</span>(flatten(a))</span><br><span class="line"></span><br><span class="line"><span class="comment">#使用库iteration_utilities</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">iteration_utilities_deepflatten</span>(<span class="params">a</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">list</span>(deepflatten(a, depth=<span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p><strong>2.测试</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a=[[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>],[<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>]]</span><br><span class="line">print(a)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;--------------------------&#x27;</span>)</span><br><span class="line"></span><br><span class="line">print(forfor(a))</span><br><span class="line">print(sum_brackets(a))</span><br><span class="line">print(functools_reduce(a))</span><br><span class="line">print(itertools_chain(a))</span><br><span class="line">print(numpy_flat(a))</span><br><span class="line">print(numpy_concatenate(a))</span><br><span class="line">print(pylangs_flatten(a))</span><br><span class="line">print(iteration_utilities_deepflatten(a))</span><br></pre></td></tr></table></figure>
<p><mark>输出:</mark></p>
<blockquote>
<p>[[1, 2, 3], [4, 5, 6], [7, 8, 9]]<br />
--------------------------<br />
[1, 2, 3, 4, 5, 6, 7, 8, 9]<br />
[1, 2, 3, 4, 5, 6, 7, 8, 9]<br />
[1, 2, 3, 4, 5, 6, 7, 8, 9]<br />
[1, 2, 3, 4, 5, 6, 7, 8, 9]<br />
[1, 2, 3, 4, 5, 6, 7, 8, 9]<br />
[1, 2, 3, 4, 5, 6, 7, 8, 9]<br />
[1, 2, 3, 4, 5, 6, 7, 8, 9]<br />
[1, 2, 3, 4, 5, 6, 7, 8, 9]</p>
</blockquote>
<hr />
<h1 id="各种方法的基准测试消耗时间对比"><a class="markdownIt-Anchor" href="#各种方法的基准测试消耗时间对比"></a> 各种方法的基准测试(消耗时间对比)</h1>
<p>各种方法在小数据上消耗时间差别不大,如果数据很小,没必要为了选择而烦恼,如果数据很大,可以参考下面基准测试的结果来选择减层方法.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> simple_benchmark <span class="keyword">import</span> benchmark</span><br><span class="line"></span><br><span class="line"><span class="comment">#基准测试</span></span><br><span class="line">b = benchmark(</span><br><span class="line">    [forfor, sum_brackets, functools_reduce, itertools_chain,numpy_flat, numpy_concatenate, pylangs_flatten,iteration_utilities_deepflatten],</span><br><span class="line">    arguments=&#123;<span class="number">2</span>**i: [[<span class="number">0</span>]*<span class="number">5</span>]*(<span class="number">2</span>**i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">13</span>)&#125;,</span><br><span class="line">    argument_name=<span class="string">&#x27;number of inner lists&#x27;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">#显示测试结果</span></span><br><span class="line">plt.subplots(<span class="number">1</span>,<span class="number">1</span>,figsize=(<span class="number">15</span>,<span class="number">10</span>))</span><br><span class="line">b.plot()</span><br><span class="line">plt.legend(loc = <span class="string">&#x27;upper left&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613527188071.png" alt="消耗时间对比" /></p>
<p>相同数据量,纵轴方向越小,方法越快.</p>
<hr />
<p>代码可以从<a href="https://files.cnblogs.com/files/wushaogui/list%E5%A4%9A%E5%B1%82%E8%BD%AC%E4%B8%80%E5%B1%82.ipynb.zip">这里</a>下载,需要部署Jupyter环境,可参考我的博客部署方法.</p>
]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Python中的各种排序问题</title>
    <url>/2018/06/30/Python%E4%B8%AD%E7%9A%84%E5%90%84%E7%A7%8D%E6%8E%92%E5%BA%8F%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<p>在编写Python时,经常需要进行排序操作,简单的list排序还是很容易的,碰到复杂的就没办法,只能去查了,现在把编程过程中遇到的所有排序问题列下来,欢迎大家提供更加简洁,高效的排序方法,也欢迎<br />
大家给出自己在Python遇到的排序问题.</p>
<p>Python排序根本依赖于两个内建的函数:</p>
<ul>
<li>list.sort()         对list成员进行排序，不返回副本</li>
<li>sorted(list)    对list成员进行排序，返回副本</li>
</ul>
<blockquote>
<p>注:以下使用sorted(list)进行演示</p>
</blockquote>
<a id="more"></a>
<h1 id="基本的排序"><a class="markdownIt-Anchor" href="#基本的排序"></a> 基本的排序</h1>
<h2 id="列表list"><a class="markdownIt-Anchor" href="#列表list"></a> 列表(list)</h2>
<h3 id="按列表元素大小排序"><a class="markdownIt-Anchor" href="#按列表元素大小排序"></a> 按列表元素大小排序</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#数值类型</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">sorted</span>([<span class="number">1</span>,<span class="number">6</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">5</span>,<span class="number">7</span>,<span class="number">4</span>])</span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#字符类型</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">sorted</span>([<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;d&#x27;</span>,<span class="string">&#x27;e&#x27;</span>,<span class="string">&#x27;b&#x27;</span>,<span class="string">&#x27;f&#x27;</span>,<span class="string">&#x27;c&#x27;</span>])</span><br><span class="line">[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;d&#x27;</span>, <span class="string">&#x27;e&#x27;</span>, <span class="string">&#x27;f&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#字符串类型</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">sorted</span>([<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;ad&#x27;</span>,<span class="string">&#x27;ada&#x27;</span>,<span class="string">&#x27;ad1&#x27;</span>,<span class="string">&#x27;abe&#x27;</span>,<span class="string">&#x27;b&#x27;</span>,<span class="string">&#x27;f&#x27;</span>,<span class="string">&#x27;c&#x27;</span>])</span><br><span class="line">[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;abe&#x27;</span>, <span class="string">&#x27;ad&#x27;</span>, <span class="string">&#x27;ad1&#x27;</span>, <span class="string">&#x27;ada&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;f&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#字符串中包含大小写</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">sorted</span>([<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;ad&#x27;</span>,<span class="string">&#x27;ada&#x27;</span>,<span class="string">&#x27;A&#x27;</span>,<span class="string">&#x27;ad1&#x27;</span>,<span class="string">&#x27;abe&#x27;</span>,<span class="string">&#x27;Abe&#x27;</span>,<span class="string">&#x27;b&#x27;</span>,<span class="string">&#x27;f&#x27;</span>,<span class="string">&#x27;c&#x27;</span>])</span><br><span class="line">[<span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;Abe&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;abe&#x27;</span>, <span class="string">&#x27;ad&#x27;</span>, <span class="string">&#x27;ad1&#x27;</span>, <span class="string">&#x27;ada&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;f&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#小写字母优先</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">sorted</span>([<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;ad&#x27;</span>,<span class="string">&#x27;ada&#x27;</span>,<span class="string">&#x27;A&#x27;</span>,<span class="string">&#x27;ad1&#x27;</span>,<span class="string">&#x27;abe&#x27;</span>,<span class="string">&#x27;Abe&#x27;</span>,<span class="string">&#x27;b&#x27;</span>,<span class="string">&#x27;f&#x27;</span>,<span class="string">&#x27;c&#x27;</span>],key=<span class="built_in">str</span>.lower)</span><br><span class="line">[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;abe&#x27;</span>, <span class="string">&#x27;Abe&#x27;</span>, <span class="string">&#x27;ad&#x27;</span>, <span class="string">&#x27;ad1&#x27;</span>, <span class="string">&#x27;ada&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;f&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p>规则解释:</p>
<ol>
<li>如果list内的元素是字符/字符串,默认优先将<mark>大写字母</mark>排前面,其次再按照规则2进行排序;通过参数<code>key=str.lower</code>控制其从<mark>小字母</mark>优先排.</li>
<li>如果list内的元素是字符/字符串,将<mark>依次</mark>按照该字符/字符串的<mark>ASCCII值 #800023</mark>进行排序</li>
<li>虽然列表内的元素的类型可以不一样,但是sotred(list)<mark>不支持 #80000f</mark>列表中既有数字又有字符的排序</li>
</ol>
<h3 id="按列表元素的属性"><a class="markdownIt-Anchor" href="#按列表元素的属性"></a> 按列表元素的属性</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#按列表元素的长度进行排序</span></span><br><span class="line"><span class="built_in">sorted</span>([<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;ad&#x27;</span>,<span class="string">&#x27;ada&#x27;</span>,<span class="string">&#x27;A&#x27;</span>,<span class="string">&#x27;ad1&#x27;</span>,<span class="string">&#x27;abe&#x27;</span>,<span class="string">&#x27;Abe&#x27;</span>,<span class="string">&#x27;b&#x27;</span>,<span class="string">&#x27;f&#x27;</span>,<span class="string">&#x27;c&#x27;</span>],key=<span class="keyword">lambda</span> <span class="built_in">str</span>:<span class="built_in">len</span>(<span class="built_in">str</span>))</span><br><span class="line">[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;f&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;ad&#x27;</span>, <span class="string">&#x27;ada&#x27;</span>, <span class="string">&#x27;ad1&#x27;</span>, <span class="string">&#x27;abe&#x27;</span>, <span class="string">&#x27;Abe&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p>注:<br />
lambda为匿名函数,没有函数的具体名称,使用匿名函数是为了使代码更为精简.实际上<code>lambda str:len(str)</code>等价于:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Getlenght</span>(<span class="params"><span class="built_in">str</span></span>):</span></span><br><span class="line">	<span class="keyword">return</span> <span class="built_in">len</span>(<span class="built_in">str</span>)</span><br></pre></td></tr></table></figure>
<h2 id="字典dictory"><a class="markdownIt-Anchor" href="#字典dictory"></a> 字典(dictory)</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#对字典进行排序</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">sorted</span>(&#123;<span class="number">1</span>: <span class="string">&#x27;D&#x27;</span>, <span class="number">5</span>: <span class="string">&#x27;B&#x27;</span>, <span class="number">2</span>: <span class="string">&#x27;B&#x27;</span>, <span class="number">4</span>: <span class="string">&#x27;E&#x27;</span>, <span class="number">3</span>: <span class="string">&#x27;A&#x27;</span>&#125;)</span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#按照字典中的values的大小进行排序</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">dict</span></span><br><span class="line">&#123;<span class="number">1</span>: <span class="string">&#x27;DE&#x27;</span>, <span class="number">2</span>: <span class="string">&#x27;DDDB&#x27;</span>, <span class="number">3</span>: <span class="string">&#x27;A&#x27;</span>, <span class="number">4</span>: <span class="string">&#x27;QPOIE&#x27;</span>, <span class="number">5</span>: <span class="string">&#x27;WWB&#x27;</span>&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">dict</span>.items()</span><br><span class="line">dict_items([(<span class="number">1</span>, <span class="string">&#x27;DE&#x27;</span>), (<span class="number">2</span>, <span class="string">&#x27;DDDB&#x27;</span>), (<span class="number">3</span>, <span class="string">&#x27;A&#x27;</span>), (<span class="number">4</span>, <span class="string">&#x27;QPOIE&#x27;</span>), (<span class="number">5</span>, <span class="string">&#x27;WWB&#x27;</span>)])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">sorted</span>(<span class="built_in">dict</span>.items(),key=<span class="keyword">lambda</span> value:value[<span class="number">1</span>])</span><br><span class="line">[(<span class="number">3</span>, <span class="string">&#x27;A&#x27;</span>), (<span class="number">2</span>, <span class="string">&#x27;DDDB&#x27;</span>), (<span class="number">1</span>, <span class="string">&#x27;DE&#x27;</span>), (<span class="number">4</span>, <span class="string">&#x27;QPOIE&#x27;</span>), (<span class="number">5</span>, <span class="string">&#x27;WWB&#x27;</span>)]</span><br><span class="line"></span><br><span class="line"><span class="comment">#按照字典中的values的长度进行排序</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">sorted</span>(<span class="built_in">dict</span>.items(),key=<span class="keyword">lambda</span> value:<span class="built_in">len</span>(value[<span class="number">1</span>]))</span><br><span class="line">[(<span class="number">3</span>, <span class="string">&#x27;A&#x27;</span>), (<span class="number">1</span>, <span class="string">&#x27;DE&#x27;</span>), (<span class="number">5</span>, <span class="string">&#x27;WWB&#x27;</span>), (<span class="number">2</span>, <span class="string">&#x27;DDDB&#x27;</span>), (<span class="number">4</span>, <span class="string">&#x27;QPOIE&#x27;</span>)]</span><br></pre></td></tr></table></figure>
<p>对字典进行排序,实际上是对字典keys组成的list进行排序,即sorted(dict)==sorted(sorted.values())</p>
<h2 id="元组tuple排序"><a class="markdownIt-Anchor" href="#元组tuple排序"></a> 元组(tuple)排序</h2>
<h3 id="单个元组排序和列表的方法一样"><a class="markdownIt-Anchor" href="#单个元组排序和列表的方法一样"></a> 单个元组排序和列表的方法一样</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#元组排序</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tup1=(<span class="number">1</span>,<span class="number">5</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">2</span>,<span class="number">7</span>,<span class="number">6</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">sorted</span>(tup1)</span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tup2=(<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;d&#x27;</span>,<span class="string">&#x27;f&#x27;</span>,<span class="string">&#x27;b&#x27;</span>,<span class="string">&#x27;e&#x27;</span>,<span class="string">&#x27;c&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">sorted</span>(tup2)</span><br><span class="line">[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;d&#x27;</span>, <span class="string">&#x27;e&#x27;</span>, <span class="string">&#x27;f&#x27;</span>]</span><br></pre></td></tr></table></figure>
<h3 id="元组列表"><a class="markdownIt-Anchor" href="#元组列表"></a> 元组列表</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>tuplist=[(<span class="string">&#x27;a&#x27;</span>,<span class="number">1</span>),(<span class="string">&#x27;c&#x27;</span>,<span class="number">4</span>),(<span class="string">&#x27;e&#x27;</span>,<span class="number">0</span>),(<span class="string">&#x27;d&#x27;</span>,<span class="number">2</span>),(<span class="string">&#x27;f&#x27;</span>,<span class="number">3</span>)]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>student_tuples = [(<span class="string">&#x27;john&#x27;</span>, <span class="string">&#x27;A&#x27;</span>, <span class="number">15</span>),(<span class="string">&#x27;jane&#x27;</span>, <span class="string">&#x27;B&#x27;</span>, <span class="number">12</span>),(<span class="string">&#x27;dave&#x27;</span>, <span class="string">&#x27;B&#x27;</span>, <span class="number">10</span>),]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span></span><br><span class="line"><span class="comment">#直接对元组列表进行排序</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">sorted</span>(tuplist)</span><br><span class="line">[(<span class="string">&#x27;a&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;c&#x27;</span>, <span class="number">4</span>), (<span class="string">&#x27;d&#x27;</span>, <span class="number">2</span>), (<span class="string">&#x27;e&#x27;</span>, <span class="number">0</span>), (<span class="string">&#x27;f&#x27;</span>, <span class="number">3</span>)]</span><br><span class="line"></span><br><span class="line"><span class="comment">#按照元组的第某个值进行排序</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">sorted</span>(tuplist,key=<span class="keyword">lambda</span> tup:tup[<span class="number">1</span>])</span><br><span class="line">[(<span class="string">&#x27;e&#x27;</span>, <span class="number">0</span>), (<span class="string">&#x27;a&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;d&#x27;</span>, <span class="number">2</span>), (<span class="string">&#x27;f&#x27;</span>, <span class="number">3</span>), (<span class="string">&#x27;c&#x27;</span>, <span class="number">4</span>)]</span><br><span class="line"></span><br><span class="line"><span class="comment">#按照元组的第某个值进行排序</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">sorted</span>(student_tuples, key=<span class="keyword">lambda</span> student: student[<span class="number">2</span>])</span><br><span class="line">[(<span class="string">&#x27;dave&#x27;</span>, <span class="string">&#x27;B&#x27;</span>, <span class="number">10</span>), (<span class="string">&#x27;jane&#x27;</span>, <span class="string">&#x27;B&#x27;</span>, <span class="number">12</span>), (<span class="string">&#x27;john&#x27;</span>, <span class="string">&#x27;A&#x27;</span>, <span class="number">15</span>)]</span><br></pre></td></tr></table></figure>
<p>注:直接对元组列表进行排序是按照元组的<mark>第一个值</mark>进行排序</p>
<h1 id="高级排序"><a class="markdownIt-Anchor" href="#高级排序"></a> 高级排序</h1>
<h2 id="使用operator模块"><a class="markdownIt-Anchor" href="#使用operator模块"></a> 使用Operator模块</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> operator <span class="keyword">import</span> itemgetter, attrgetter</span><br><span class="line"></span><br><span class="line"><span class="comment">#一个排序关键字</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">sorted</span>(student_tuples, key=itemgetter(<span class="number">2</span>))</span><br><span class="line">[(<span class="string">&#x27;dave&#x27;</span>, <span class="string">&#x27;B&#x27;</span>, <span class="number">10</span>), (<span class="string">&#x27;jane&#x27;</span>, <span class="string">&#x27;B&#x27;</span>, <span class="number">12</span>), (<span class="string">&#x27;john&#x27;</span>, <span class="string">&#x27;A&#x27;</span>, <span class="number">15</span>)]</span><br><span class="line"></span><br><span class="line"><span class="comment">#两个排序关键字</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">sorted</span>(student_tuples, key=itemgetter(<span class="number">1</span>,<span class="number">2</span>))</span><br><span class="line">[(<span class="string">&#x27;john&#x27;</span>, <span class="string">&#x27;A&#x27;</span>, <span class="number">15</span>), (<span class="string">&#x27;dave&#x27;</span>, <span class="string">&#x27;B&#x27;</span>, <span class="number">10</span>), (<span class="string">&#x27;jane&#x27;</span>, <span class="string">&#x27;B&#x27;</span>, <span class="number">12</span>)]</span><br></pre></td></tr></table></figure>
<h2 id="字符串的多关键字排序"><a class="markdownIt-Anchor" href="#字符串的多关键字排序"></a> 字符串的多关键字排序</h2>
<p>基于上面的多关键字排序,可以对字符串做一些有趣的排序,平常我们对字符串进行排序时,可能带有数字,这时候排序只是像平常那样逐个字符串<mark>ASCCII值 #800023</mark>进行排序:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>list01=[<span class="string">&#x27;dog1&#x27;</span>,<span class="string">&#x27;cat3&#x27;</span>,<span class="string">&#x27;bird7&#x27;</span>,<span class="string">&#x27;swan4&#x27;</span>,<span class="string">&#x27;penguin6&#x27;</span>,<span class="string">&#x27;cattle5&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#字符串排序</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">sorted</span>(list01)</span><br><span class="line">[<span class="string">&#x27;bird7&#x27;</span>, <span class="string">&#x27;cat3&#x27;</span>, <span class="string">&#x27;cattle5&#x27;</span>, <span class="string">&#x27;dog1&#x27;</span>, <span class="string">&#x27;penguin6&#x27;</span>, <span class="string">&#x27;swan4&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p>但是有时候我们需要按照字符串中的字母进行排序,这时候就需要将字符串中的数字切割出来,然后传入key参数给sorted.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#按照字符串的某个数字进行排序</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> re</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="function"><span class="keyword">def</span> <span class="title">sort_str</span>(<span class="params"><span class="built_in">str</span></span>):</span></span><br><span class="line">	<span class="keyword">if</span> <span class="built_in">str</span>:</span><br><span class="line">		<span class="keyword">try</span>:</span><br><span class="line">			c=re.findall(<span class="string">&#x27;\d+&#x27;</span>,<span class="built_in">str</span>)[<span class="number">0</span>]</span><br><span class="line">		<span class="keyword">except</span>:</span><br><span class="line">			c=-<span class="number">1</span></span><br><span class="line">		<span class="keyword">return</span> <span class="built_in">int</span>(c)</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">sorted</span>(list01,key=sort_str)</span><br><span class="line">[<span class="string">&#x27;dog1&#x27;</span>, <span class="string">&#x27;cat3&#x27;</span>, <span class="string">&#x27;swan4&#x27;</span>, <span class="string">&#x27;cattle5&#x27;</span>, <span class="string">&#x27;penguin6&#x27;</span>, <span class="string">&#x27;bird7&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p>如果字符串中类似这样的,而你只想对字符串的某些位置的数字进行排序,我们先来看看只针对字符串一个特定位置的排序.</p>
<blockquote>
<p>[‘cb_cha0_amni0’,‘cb_cha0_amni2’,‘cb_cha1_amni1’,‘cb_cha0_amni3’]</p>
</blockquote>
<p>使用上面的排序方法得到</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>list02=[<span class="string">&#x27;cb_cha0_amni0&#x27;</span>,<span class="string">&#x27;cb_cha0_amni2&#x27;</span>,<span class="string">&#x27;cb_cha1_amni1&#x27;</span>,<span class="string">&#x27;cb_cha0_amni3&#x27;</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">sorted</span>(list02,key=sort_str)</span><br><span class="line">[<span class="string">&#x27;cb_cha0_amni0&#x27;</span>, <span class="string">&#x27;cb_cha0_amni2&#x27;</span>, <span class="string">&#x27;cb_cha0_amni3&#x27;</span>, <span class="string">&#x27;cb_cha1_amni1&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p>上面的自定义提取数字的函数<code>c=re.findall('\d+',str)[0]</code>这一句决定了要对字符串的第几个数字进行排序,假设我要对上面字符数组的第二个值进行排序,重新定义一个提取数值的方法,每次调用返回字符串的第二个数字.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="function"><span class="keyword">def</span> <span class="title">sort_str1</span>(<span class="params"><span class="built_in">str</span></span>):</span></span><br><span class="line">	<span class="keyword">if</span> <span class="built_in">str</span>:</span><br><span class="line">		<span class="keyword">try</span>:</span><br><span class="line">			c=re.findall(<span class="string">&#x27;\d+&#x27;</span>,<span class="built_in">str</span>)[<span class="number">1</span>]</span><br><span class="line">		<span class="keyword">except</span>:</span><br><span class="line">			c=-<span class="number">1</span></span><br><span class="line">		<span class="keyword">return</span> <span class="built_in">int</span>(c)</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">sorted</span>(list02,key=sort_str1)</span><br><span class="line">[<span class="string">&#x27;cb_cha0_amni0&#x27;</span>, <span class="string">&#x27;cb_cha1_amni1&#x27;</span>, <span class="string">&#x27;cb_cha0_amni2&#x27;</span>, <span class="string">&#x27;cb_cha0_amni3&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p>比较炸的是你的需求是:<mark>按照字符串中的多个字母排序(比如优先按照第一个字母排序,然后按照第二个字母排序) #007e80</mark></p>
<p>一个想法是:把字符串解析为元组,然后使用<code>itemgetter</code>来完成多关键字排序.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#字符串已经被拆分为元组</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>list03=[(<span class="string">&#x27;cb_cha&#x27;</span>,<span class="number">0</span>,<span class="string">&#x27;_amni&#x27;</span>,<span class="number">0</span>),(<span class="string">&#x27;cb_cha&#x27;</span>,<span class="number">1</span>,<span class="string">&#x27;_amni&#x27;</span>,<span class="number">1</span>),(<span class="string">&#x27;cb_cha&#x27;</span>,<span class="number">0</span>,<span class="string">&#x27;_amni&#x27;</span>,<span class="number">2</span>),(<span class="string">&#x27;cb_cha&#x27;</span>,<span class="number">0</span>,<span class="string">&#x27;_amni&#x27;</span>,<span class="number">3</span>)]</span><br><span class="line"></span><br><span class="line"><span class="comment">#对元祖进行多关键字排序</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>listtmp=<span class="built_in">sorted</span>(list03, key=itemgetter(<span class="number">1</span>,<span class="number">3</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>listtmp</span><br><span class="line">[(<span class="string">&#x27;cb_cha&#x27;</span>, <span class="number">0</span>, <span class="string">&#x27;_amni&#x27;</span>, <span class="number">0</span>), (<span class="string">&#x27;cb_cha&#x27;</span>, <span class="number">0</span>, <span class="string">&#x27;_amni&#x27;</span>, <span class="number">2</span>), (<span class="string">&#x27;cb_cha&#x27;</span>, <span class="number">0</span>, <span class="string">&#x27;_amni&#x27;</span>, <span class="number">3</span>), (<span class="string">&#x27;cb_cha&#x27;</span>, <span class="number">1</span>, <span class="string">&#x27;_amni&#x27;</span>, <span class="number">1</span>)]</span><br><span class="line"></span><br><span class="line"><span class="comment">#将排序后的元组转成字符串</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">list</span>(<span class="built_in">map</span>(<span class="keyword">lambda</span> strtmp:<span class="string">&#x27;&#x27;</span>.join(<span class="built_in">map</span>(<span class="built_in">str</span>,strtmp)),listtmp))</span><br><span class="line">[<span class="string">&#x27;cb_cha0_amni0&#x27;</span>, <span class="string">&#x27;cb_cha0_amni2&#x27;</span>, <span class="string">&#x27;cb_cha0_amni3&#x27;</span>, <span class="string">&#x27;cb_cha1_amni1&#x27;</span>]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>注:这里用了匿名函数和多个map,这对处理大量的数据是的问题,会耗费很多时间.这种情况比较好的方法是使用excle进行排序,当然,你得手动先将数据分割成一列一列的.</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613527346517.png" alt="EXCLE的自定义排序" /></p>
]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Tex家族关系</title>
    <url>/2019/02/06/Tex%E5%AE%B6%E6%97%8F%E5%85%B3%E7%B3%BB/</url>
    <content><![CDATA[<p>文章自<a href="https://liam.page/2014/09/08/latex-introduction/"><code>一份其实很短的 LaTeX 入门文档</code></a>学习，整理所得。</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613527698526.png" alt="Tex家族关系" /></p>
<a id="more"></a>
<h1 id="tex家族关系图"><a class="markdownIt-Anchor" href="#tex家族关系图"></a> Tex家族关系图</h1>
<h2 id="排版引擎"><a class="markdownIt-Anchor" href="#排版引擎"></a> 排版引擎</h2>
<blockquote>
<p>1.所谓的引擎，是指能够实现断行、分页等操作的程序（请注意这并不是定义）</p>
<p>2.标记语言，是指一种将控制命令和文本结合起来的格式，它的主体是其中的文本而控制命令则实现一些特殊效果（同样请注意这并不是定义）</p>
</blockquote>
<h3 id="tex"><a class="markdownIt-Anchor" href="#tex"></a> Tex</h3>
<blockquote>
<p>1.TeX 的源代码是后缀为 .tex 的纯文本文件。使用任意纯文本编辑器，都可以修改</p>
</blockquote>
<h3 id="pdftex"><a class="markdownIt-Anchor" href="#pdftex"></a> pdfTeX</h3>
<blockquote>
<p>dvi 格式是为了排版而产生的，它本身并不支持所谓的「交叉引用」，pdfTeX 直接输出 pdf 格式的文档，这也是 pdfTeX 相对 TeX 进步（易用性方面）的地方</p>
</blockquote>
<h3 id="pdflatex"><a class="markdownIt-Anchor" href="#pdflatex"></a> pdfLaTeX</h3>
<blockquote>
<p>pdfLaTeX 这个程序的主要工作依旧是将 LaTeX 格式的文档进行解释，不过此次是将解释之后的结果交付给 pdfTeX 引擎处理</p>
</blockquote>
<h3 id="xetex"><a class="markdownIt-Anchor" href="#xetex"></a> XeTeX</h3>
<blockquote>
<p>XeTeX 引擎直接支持 Unicode 字符。也就是说现在不使用 CJK 也能排版中日韩文的文档了，并且这种方式要比之前的方式更加优秀。</p>
</blockquote>
<h3 id="xelatex"><a class="markdownIt-Anchor" href="#xelatex"></a> XeLaTeX</h3>
<blockquote>
<p>XeLaTeX 和 XeTeX 的关系与 pdfLaTeX 和 pdfTeX 的关系类似</p>
</blockquote>
<h3 id="luatex"><a class="markdownIt-Anchor" href="#luatex"></a> LuaTeX</h3>
<blockquote>
<p>正在开发完善的一个 TeX 引擎</p>
</blockquote>
<h2 id="发行"><a class="markdownIt-Anchor" href="#发行"></a> 发行</h2>
<blockquote>
<p>所谓 TeX 发行，也叫 TeX 发行版、TeX 系统或者 TeX 套装，指的是包括 TeX 系统的各种可执行程序，以及他们执行时需要的一些辅助程序和宏包文档的集合：</p>
<ul>
<li>CTeX</li>
<li>MiKTeX</li>
<li>TeX Live<br />
概要: 后面两个最流行的两个发行，自带TeXworks编辑器</li>
</ul>
</blockquote>
<h2 id="编辑器"><a class="markdownIt-Anchor" href="#编辑器"></a> 编辑器</h2>
<h3 id="专门的tex编辑器"><a class="markdownIt-Anchor" href="#专门的tex编辑器"></a> 专门的Tex编辑器</h3>
<ul>
<li>TeXworks</li>
</ul>
<blockquote>
<ul>
<li>TeXworks 是 TeX Live 自带的编辑器，而 TeX Live 是 TeX User Group</li>
<li>出品的跨平台发行版，各个操作系统都可以使用 几乎所有 TeX 发行版都带有 TeXworks TeXworks</li>
<li>十分简洁，除了最基本的功能之外，没有其他复杂的东西，能使你将注意力集中在 TeX 的学习上。</li>
</ul>
</blockquote>
<ul>
<li>TeXmaker</li>
<li>TeXstudio</li>
<li>WinEdt</li>
</ul>
<h3 id="文本编辑器"><a class="markdownIt-Anchor" href="#文本编辑器"></a> 文本编辑器</h3>
<ul>
<li>ATOM</li>
<li>Sublime Text</li>
<li>Visual Studio Code</li>
</ul>
<h2 id="宏包"><a class="markdownIt-Anchor" href="#宏包"></a> 宏包</h2>
<blockquote>
<ul>
<li>
<p>所谓宏包，就是一系列控制序列的合集。这些控制序列太常用，以至于人们会觉得每次将他们写在导言区太过繁琐，于是将他们打包放在同一个文件中，成为所谓的宏包</p>
</li>
<li>
<p>请注意，CTeX 宏集和 CTeX 套装是两个不同的东西。CTeX 宏集本质是 LaTeX 宏的集合，包含若干文档类（.cls 文件）和宏包（.sty 文件）。CTeX 套装是一个过时的 TeX 系统。</p>
</li>
</ul>
</blockquote>
<h3 id="ctex"><a class="markdownIt-Anchor" href="#ctex"></a> CTeX</h3>
<blockquote>
<ul>
<li>
<p>CTeX 宏集和 CTeX 套装是两个不同的东西。CTeX 宏集本质是 LaTeX 宏的集合，包含若干文档类（.cls 文件）和宏包（.sty 文件）。CTeX 套装是一个过时的 TeX 系统</p>
</li>
<li>
<p>新版 CTeX 宏集的默认能够自动检测用户的操作系统，并为之配置合适的字库</p>
</li>
</ul>
</blockquote>
<h2 id="latex"><a class="markdownIt-Anchor" href="#latex"></a> Latex</h2>
<blockquote>
<ul>
<li>
<p>排版系统： LaTeX 利用 TeX 的控制命令，定义了许多新的控制命令并封装成一个可执行文件。这个可执行文件会去解释 LaTeX 新定义的命令成为 TeX 的控制命令，并最终交由 TeX 引擎进行排版。</p>
</li>
<li>
<p>最终进行断行、分页等操作的，是 TeX 引擎</p>
</li>
<li>
<p>LaTeX 实际上是一个工具，它将用户按照它的格式编写的文档解释成 TeX 引擎能理解的形式并交付给 TeX 引擎处理，再将最终结果返回给用户</p>
</li>
</ul>
</blockquote>
]]></content>
      <categories>
        <category>软件工具</category>
      </categories>
      <tags>
        <tag>Tex</tag>
      </tags>
  </entry>
  <entry>
    <title>Zotero使用教程(1)-安装及配置</title>
    <url>/2016/06/01/Zotero%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B(1)-%E5%AE%89%E8%A3%85%E5%8F%8A%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<p>作为一名科研人员，经常要阅读大量文献（当然我收集&gt;&gt;阅读，哎！），收集来的文献一般我们使用文件夹管理，通常使用文件夹命名和层级分布解决论文的分类问题。</p>
<p>但是，实际上，我需要一种不打开文档就能知道文档说啥的工具，不需要打开文档一点点看标注，才能理解论文说了啥的工具。并且，文档不仅可以在电脑端查看，还可以在移动设备进行查看，甚至推送到Kindle上进行阅读。</p>
<p>下面从Zotero的安装和配置的过程进行讲解，方便搞科研的小伙伴们。</p>
<a id="more"></a>
<h1 id="zotero的安装"><a class="markdownIt-Anchor" href="#zotero的安装"></a> Zotero的安装</h1>
<p>官方链接： <a href="https://www.zotero.org/">https://www.zotero.org/</a></p>
<p>根据自己的系统下载相应文件：</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613546961981.jpg" alt="下载Zotero" /></p>
<blockquote>
<p>注：右边框是浏览器插件，用于从浏览器保存信息到Zotero。</p>
</blockquote>
<p>安装过程不详细说了，如果你的系统是Linux,把下载的压缩包解压缩后，里面就有可运行程序，将解压缩后的文件夹整个拷贝到相应目录（比如：/opt/Zotero_linux-x86_64），为方便启动，也可以配置路径到系统中。</p>
<h1 id="配置根据个人喜好"><a class="markdownIt-Anchor" href="#配置根据个人喜好"></a> 配置（根据个人喜好）</h1>
<p>启动Zotero成功后，在<code>编辑</code>那里找到<code>首选项</code>，配置以下信息：</p>
<blockquote>
<p>1.中文界面：在<code>高级</code>里的<code>常规</code>中配置语言<br />
2.文件存储位置：这个文件存储位置就是首次启动是设置的位置，如果首次启动没设置好，可以在<code>高级</code>里的<code>文件和文件夹</code>中配置<br />
3.登录个人账号（我没有用Zotero的账号）：这个打开设置界面，在<code>同步</code>下进行设置。只有登录这个账号后才可以选择远程同步方式，比如：同步到Zotero（空间小），WebDav同步（可以用坚果云，不过我同样没用，因为同步上去的东西我看不懂，后面我同样用坚果云备份，但是是同步一个插件规范后的文件）</p>
</blockquote>
<p>注：设置的对应英文名字我在这不进行另外标注</p>
<h1 id="zotero的插件"><a class="markdownIt-Anchor" href="#zotero的插件"></a> Zotero的插件</h1>
<p>Zotero的插件是让我爱上它真正的原因，没找到Zotero之前，我也用过类似工具，始终觉得不顺手，不是收费（原谅学生党这样说，有钱还是可以支持的），就是存储空间受限。</p>
<p><strong>(1) ZotFile</strong><br />
Zotero的神级插件，这玩意可以自动获取导入文件的元数据，自动命名附件（这真的太神奇了 ）！</p>
<p>安装方式<br />
点击 <a href="https://github.com/jlegewie/zotfile/releases">ZotFile</a> 下载插件后，在Zotero的菜单栏的<code>工具</code>找到<code>插件</code>，点击下面红框：</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613546961965.jpg" alt="本地安装插件" /></p>
<p>然后选择<code>Install Add-on From File</code></p>
<p>配置<br />
在工具目录下，点击<code>ZotFile Preferences</code></p>
<ul>
<li>配置附加文件默认目录</li>
</ul>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613546961980.jpg" alt="附加文件默认目录" /></p>
<p>这个目录是为了快速添加附件，当你保存下来的条目没有任何附加时，而你又想为条目添加一些pdf,ppt等附件，你将文件下载到该目录后，右键点击该条目，选择<code>Attach new file</code>，插件会自动加载该目录下最新更新的文件到该条目下。</p>
<ul>
<li>配置文档存储样式</li>
</ul>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613546961983.jpg" alt="定义附件存储位置" /></p>
<p>勾选红框上面的勾选框，然后设置相应目录，这个设置是为了快速按一定命名方式导出附件，比如论文可以按下面格式导出：</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613546961982.jpg" alt="附件导出格式" /></p>
<p>这里的文档命名格式：时间_作者_文档名</p>
<p>是不是很清新的命名，包含很多信息吧，更多命名方式参考：<a href="http://zotfile.com/">http://zotfile.com/</a>   中的“RENAMING RULES”</p>
<p>更为神奇的是，这个目录设置为坚果云的同步目录，这样文档可以跨设备进行浏览了，等我下次更新吧。</p>
<p><strong>(2) Zotero Scholar Citations</strong><br />
<a href="https://github.com/beloglazov/zotero-scholar-citations">Zotero Scholar Citations</a> 开源在github上。是一个引用次数更新插件，不过这个插件需要翻出去才能使用。</p>
<p>安装方式<br />
点击上面链接，把相应的.xpi文件下载下来，然后像前面一样进行本地安装。</p>
<p>配置<br />
不需要配置，直接在相应目录下右键，然后点击<code>update citations</code>，插件会去谷歌学术搜索把当前引用次数下载下来，但是由于谷歌的限制，一次不要更新太多，我曾经一次更新很多，现在到不好使了。</p>
<p><font color="red">注：文献引用次数会在条目的<code>其他</code>列下显示。</font></p>
]]></content>
      <categories>
        <category>软件工具</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Zotero</tag>
      </tags>
  </entry>
  <entry>
    <title>Zotero使用教程(2)-数据备份</title>
    <url>/2016/06/02/Zotero%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B(2)-%E6%95%B0%E6%8D%AE%E5%A4%87%E4%BB%BD/</url>
    <content><![CDATA[<p>这篇文章的目标是让你无论是 <code>换系统</code>，<code>重新安装zotero</code>等都可以还原回你的文献库，而且整个过程基本是自动完成的。</p>
<a id="more"></a>
<p>这部分解决下面的两种情况：</p>
<blockquote>
<p>1.zotero有自己既定的一套存储方式，不是一般的文件管理器那样直接看到其pdf，这个可以通过前篇文章的插件zotfile解决。但是<strong>如果想备份这个插件导出来的pdf,该如何解决呢？</strong><br />
2.zotero不仅保存了pdf,还有各种各样的笔记，网页，如果仅仅保存pdf,显然是不够的。虽然zotero支持整个文献库的导入导出，但是得时常去手动备份，很是麻烦。</p>
</blockquote>
<p>在这里我极度向大家推荐，跨平台的同步工具 <code>坚果云</code>，只需要往设定的同步盘放入文件，文件就自动备份到云端，并且有移动版本，可以随时随地查看自己的文献。</p>
<p>下面是我的坚果云目录：</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613486879369.png" alt="坚果云目录设置" /></p>
<p>目录解释：<br />
<strong>Zotero</strong>  是Zotero的存储目录，无论你在zotero作笔记，加标签等操作，zotero会存储到这里，然后坚果云自动同步，实现备份,重新安装zotero时，只需要设置该目录为存储目录，文献库就会和原来一模一样（包括笔记，网页啥的都在啊）。</p>
<p><strong>Zotero_papers</strong> 是使用插件zotfile导出的pdf文件目录，在Zotero导出到该目录后，坚果云会自动同步到云端，实现备份</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613486879375.png" alt="移动端查看导出的pdf" /></p>
<p>注：图片中导出pdf的有文件夹的层级关系，是因为我在Zotero的文献就是按照层级划分的，插件zotfile会按照层级自动新建文件夹到<strong>Zotero_papers</strong></p>
]]></content>
      <categories>
        <category>软件工具</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Zotero</tag>
      </tags>
  </entry>
  <entry>
    <title>linuxmint系统定制与配置（1）-系统初始配置</title>
    <url>/2018/07/13/linuxmint%E7%B3%BB%E7%BB%9F%E5%AE%9A%E5%88%B6%E4%B8%8E%E9%85%8D%E7%BD%AE%EF%BC%881%EF%BC%89-%E7%B3%BB%E7%BB%9F%E5%88%9D%E5%A7%8B%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<p>经常安装新的系统，每次安装完都得去搜索一边如何将系统部署为之前的环境，不仅耗费时间，还不一定能弄回之前的环境，现在把从<code>裸机</code>-&gt;到<code>工作环境</code>的系统定制及配置过程记录下来，期间的配置文件尽量记录下来，以便后面直接使用</p>
<a id="more"></a>
<p>本人的工作环境自评：现在是一名研究生，爱琢磨新的技术，linux系统linuxmint）上的主要是学习，做科研，些许的休闲（听歌，浏览器看视频）.</p>
<h1 id="裸机第一次启动该干什么"><a class="markdownIt-Anchor" href="#裸机第一次启动该干什么"></a> 裸机第一次启动，该干什么？</h1>
<p>系统安装过程中我一般选择时Engshli，因为终端跳转目录时，如果文件名是中文名的，比较不方便，并且我觉得系统毕竟默认是英文的，安装时选择是英文，会不会导致后面系统使用会出现兼容问题（这个完全属于猜测，没有证实或没能证实）。总之，我觉得系统安装就用英文吧，后面第一次开机就该改语言，没影响什么。</p>
<h2 id="看开机引导"><a class="markdownIt-Anchor" href="#看开机引导"></a> 看开机引导</h2>
<p>裸机启动，登录进去后看到第一个界面就是欢迎界面。在这个界面中可以快速配置一些必要的信息。从而开启你的Linux高效的工作方式。</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613471971818.png" alt="开机欢迎界面" /></p>
<p><strong>系统快照</strong>： linuxmint19开始，可以随时备份系统快照。以后机器遇到什么不可以解决的问题时，利用这个快照，可以随时将系统重置会快照的系统。</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613472335902.png" alt="创建系统快照" /></p>
<p><strong>驱动管理器</strong>： 主要是显卡的驱动可以在这里快速安装（注意：电脑需先联上互联网）</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613472335903.png" alt="系统驱动管理" /></p>
<p><strong>系统更新</strong>： 查看系统当前可用更新，这可能需要更新几次（注意：电脑需先联上互联网）</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613472335904.png" alt="更新" /></p>
<p>其他选项此时暂不设置。尤其需要注意的是，如果联网安装过程过慢时，可以选择不安装，待下面设置了国内软件源后再更新。</p>
<h2 id="改系统语言"><a class="markdownIt-Anchor" href="#改系统语言"></a> 改系统语言</h2>
<p>欢迎向导看完之后，现在开始将系统设置为简体中文，中文界面可以方便后面的设置。在系统设置里找到<code>language</code>这一项，然后选择<code>Chinese，China UTF-8</code>，然后点击下面的应用到整个系统。</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613472335910.png" alt="更改系统语言" /></p>
<p>更改系统语言需要重启才可以生效，现在就重启。<mark>这里注意了</mark>，重启选择文件目录语言时，必须选择保留原名字，这样是方便终端进行目录的调整，如果你改成中文，以后就知道怎么悲惨了。（如果很不幸你该了中文，那就把系统语言设置为英文再设置回中文）</p>
<h2 id="改软件源"><a class="markdownIt-Anchor" href="#改软件源"></a> 改软件源</h2>
<p>重启后，开始更新软件源，因为以后免不了在线安装软件包和更新系统，但是直接使用官方的服务器更新可能比较慢，这时候我们需要将软件源设置为国内的。</p>
<p>在设置中找到<code>软件源</code>，依次点击<code>主要</code>和<code>基础</code>，点进去以后也不要立即选，等系统测试各个源的速度后，选择一个速度最快的当作软件源</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613472335915.png" alt="更换软件源" /></p>
<h2 id="更新系统"><a class="markdownIt-Anchor" href="#更新系统"></a> 更新系统</h2>
<p>如果在开机引导界面没有更新系统，现在换了软件源，可以更快更新软件了。现在就进入<code>更新管理器</code>进行更新，如果想使用终端进行更新，依次使用使用一下命令。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sudo apt update</span><br><span class="line">sudo apt uograde</span><br></pre></td></tr></table></figure>
<h2 id="重启系统"><a class="markdownIt-Anchor" href="#重启系统"></a> 重启系统</h2>
<p>至此，系统层面的设置已完成，下面是针对个人用户更加详细，个性化的设置了，现在开始重启系统，让前面的配置开始生效。（如果存储空间足够，可以在此时备份一个快照）。</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>linuxmint系统定制与配置（2）-输入法</title>
    <url>/2018/07/13/linuxmint%E7%B3%BB%E7%BB%9F%E5%AE%9A%E5%88%B6%E4%B8%8E%E9%85%8D%E7%BD%AE%EF%BC%882%EF%BC%89-%E8%BE%93%E5%85%A5%E6%B3%95/</url>
    <content><![CDATA[<p>本文是linuxmint安装完成的第二个设置，即安装rime输入法，并进行个性化配置，RIME的官网在<a href="https://rime.im/">这里</a></p>
<a id="more"></a>
<h1 id="安装"><a class="markdownIt-Anchor" href="#安装"></a> 安装</h1>
<p>刚开始是使用ibus-rime,后来使用过程感觉不舒服，就换回fcitx-rime。使用以下命令安装fcitx-rime</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sudo apt install fcitx fcitx-rime</span><br></pre></td></tr></table></figure>
<h1 id="配置"><a class="markdownIt-Anchor" href="#配置"></a> 配置</h1>
<p>我现在基本使用的是默认配置，不过我拼音不太准确，所以我喜欢使用<code>地球注音</code>，这样打出的字能看到拼音。感觉很不错。基本上使用过程是下面这样的：</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613474558167.png" alt="fcitx-rime使用" /></p>
<p><strong>配置过程</strong><br />
1.在输入法中添加rime<br />
2.切换到rime后，按下F4进入进入下面两个配置过程</p>
<p>3.默认的配置已经很好用了，本来想自定义一下界面，发现相关资料很少，所以就不折腾了。首先选择地球注音。</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613474558168.png" alt="选择地球注音" /></p>
<p>注：如果候选项无<code>地球拼音</code>，使用下面命令进行安装</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo apt-get install librime-data-terra-pinyin</span><br></pre></td></tr></table></figure>
<p>并在<code>/home/wu/.config/fcitx/rime/default.yaml</code>中添加下’- schema: terra_pinyin’(引号不加)</p>
<p>其次是选择<code>中/汉/半</code>，然后选择<code>繁体字-&gt;简体字</code></p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613474558169.png" alt="繁体字转简体字" /></p>
<p>注：选字列表竖排显示是在fcitx设置中选择的</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613474558170.png" alt="选字列表竖排显示" /></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>linuxmint系统定制与配置（3）-字体</title>
    <url>/2018/07/13/linuxmint%E7%B3%BB%E7%BB%9F%E5%AE%9A%E5%88%B6%E4%B8%8E%E9%85%8D%E7%BD%AE%EF%BC%883%EF%BC%89-%E5%AD%97%E4%BD%93/</url>
    <content><![CDATA[<p>系统中自带的字体实在太难看了，看起来不清晰，不明确，特别是终端字体比较难看，正所谓有一个好的字体，可以带来好心情，并提高工作与效率。</p>
<a id="more"></a>
<h1 id="常用中文字体"><a class="markdownIt-Anchor" href="#常用中文字体"></a> 常用中文字体</h1>
<p>文泉驿微黑,微软雅黑,思源黑体</p>
<h1 id="字体安装"><a class="markdownIt-Anchor" href="#字体安装"></a> 字体安装</h1>
<h2 id="检查已安装字体"><a class="markdownIt-Anchor" href="#检查已安装字体"></a> 检查已安装字体</h2>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">fc-list             <span class="comment">#检查已安装的所有字体</span></span><br><span class="line">fc-list :lang=zh    <span class="comment">#只检查中文</span></span><br></pre></td></tr></table></figure>
<h2 id="安装字体"><a class="markdownIt-Anchor" href="#安装字体"></a> 安装字体</h2>
<p>安装字体提供在线和本地两种方法，一般安装完字体后，还需要手动建立字体缓存。</p>
<h3 id="字体安装-2"><a class="markdownIt-Anchor" href="#字体安装-2"></a> 字体安装</h3>
<p><strong>（1）在线安装</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo apt-get install ttf-wqy-microhei  <span class="comment">#文泉驿-微米黑</span></span><br><span class="line">sudo apt-get install ttf-wqy-zenhei   <span class="comment">#文泉驿-正黑</span></span><br><span class="line">sudo apt-get install xfonts-wqy     <span class="comment">#文泉驿-点阵宋体</span></span><br></pre></td></tr></table></figure>
<p><strong>（2）本地安装</strong><br />
现拿到字体 雅黑：msyh.ttf ，把它拷贝到两个位置(<code>~/.fonts</code>和<code>/usr/share/fonts/</code>)后，再授予权限即完成安装</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mv msyh.ttf ~/.fonts         <span class="comment">#拷贝到相应目录</span></span><br><span class="line">mv msyh.ttf /usr/share/fonts/zh_CN   <span class="comment">#拷贝到相应目录</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> ~/.fonts;chmod 766 msyh.ttf     <span class="comment">#授予权限</span></span><br><span class="line"><span class="built_in">cd</span> ~/.config//usr/share/fonts/zh_CN;chmod 766 msyh.ttf   <span class="comment">#授予权限</span></span><br></pre></td></tr></table></figure>
<p><strong>思源黑体</strong>需要下载字体文件进行安装，里面简体中文的就只有几个，不知道为什么不分开，而是要去下载<br />
1G多的文件，我把字体下载下来了，并把开源字体存储在：链接: &gt;<a href="https://pan.baidu.com/s/1eGeTsOG2m0b2cs_-s-4T5A">https://pan.baidu.com/s/1eGeTsOG2m0b2cs_-s-4T5A</a> 密码: krt7<br />
下载下来后，字体文件直接被<code>字体管理器</code>识别了，直接点击安装即可。</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613484243866.png" alt="使用字体管理器进行字体安装" /></p>
<h3 id="更新字体缓存"><a class="markdownIt-Anchor" href="#更新字体缓存"></a> 更新字体缓存</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkfontscale</span><br><span class="line">mkfontdir</span><br><span class="line">fc-cache -fv  </span><br><span class="line"><span class="comment">#通常复制字体进~/.fonts就会自动刷新字体，如果没有，用这个命令，如果复制进的是/usr/share/fonts/，用sudo fc-cache -fv</span></span><br></pre></td></tr></table></figure>
<p>经过这两个步骤完成字体的安装，可以用<code>fc-list</code>查看是否更新字体到字体库中，也可以在选择字体时查看。</p>
<h1 id="字体环境配置"><a class="markdownIt-Anchor" href="#字体环境配置"></a> 字体环境配置</h1>
<p>在linuxmint的环境中，可以在设置-&gt;字体找到字体设置界面，其他Linux系统自查。我的设置如下，由于我是经常要面对电脑的，所以喜欢把自己放大一点，变黑明显点。</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613484243886.png" alt="字体设置" /></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>linuxmint系统定制与配置（5）-效率配置</title>
    <url>/2018/07/13/linuxmint%E7%B3%BB%E7%BB%9F%E5%AE%9A%E5%88%B6%E4%B8%8E%E9%85%8D%E7%BD%AE%EF%BC%885%EF%BC%89-%E6%95%88%E7%8E%87%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<p>本文针对zsh终端及登录服务器等常用操作进行快捷配置，提高日常工作效率</p>
<a id="more"></a>
<h1 id="zsh安装与配置"><a class="markdownIt-Anchor" href="#zsh安装与配置"></a> zsh安装与配置</h1>
<h2 id="安装"><a class="markdownIt-Anchor" href="#安装"></a> 安装</h2>
<h3 id="检查当前的终端类型"><a class="markdownIt-Anchor" href="#检查当前的终端类型"></a> 检查当前的终端类型</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="variable">$SHELL</span></span><br></pre></td></tr></table></figure>
<p>一般情况下，系统会默认安装bash,所以会得到以下输出：</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613485022428.png" alt="检查终端类型" /></p>
<h3 id="安装zsh"><a class="markdownIt-Anchor" href="#安装zsh"></a> 安装zsh</h3>
<p>(1)安装zsh到系统</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sudo apt-get install zsh</span><br></pre></td></tr></table></figure>
<p>(2)设置zsh为默认的终端</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">chsh -s $(which zsh)</span><br></pre></td></tr></table></figure>
<p>(3)检查设置是否成功<br />
首先是注销系统，重新登录，然后在终端使用<code>echo $SHELL</code>检查当前使用终端，如果输出是包含zsh文字，表示安装成功。</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613485022529.png" alt="检查终端设置是否成功" /></p>
<h2 id="美化zsh"><a class="markdownIt-Anchor" href="#美化zsh"></a> 美化zsh</h2>
<p>从上面的图看出，未美化前的zsh输出没有任何颜色区分，这样的zsh不是提高我们效率的zsh.<br />
这时候就需要<code>Oh My Zsh</code>这个框架来管理zsh的配置。</p>
<p>安装<code>Oh My Zsh</code>可以使用以下两种方法：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sh -c <span class="string">&quot;$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)&quot;</span></span><br></pre></td></tr></table></figure>
<p>或</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sh -c <span class="string">&quot;$(wget https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh -O -)&quot;</span></span><br></pre></td></tr></table></figure>
<p>安装完成后，可以通过编辑<code>~/.zshrc</code>的这个文件来对zsh来进行配置（插件，主题等）。下面是通过配置这个文件来提高工作效率的过程,主题和插件我就使用默认的，没有深入折腾。</p>
<h2 id="配置zsh"><a class="markdownIt-Anchor" href="#配置zsh"></a> 配置zsh</h2>
<h3 id="别名设置"><a class="markdownIt-Anchor" href="#别名设置"></a> 别名设置</h3>
<p>别名，即是通过将一个长命令映射到更短的特殊字符，终端输入该特殊字符相当于输入特殊字符。</p>
<p><strong>解压相关</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">alias</span> -s gz=<span class="string">&#x27;tar -xzvf&#x27;</span> </span><br><span class="line"><span class="built_in">alias</span> -s tgz=<span class="string">&#x27;tar -xzvf&#x27;</span> </span><br><span class="line"><span class="built_in">alias</span> -s zip=<span class="string">&#x27;unzip&#x27;</span> </span><br><span class="line"><span class="built_in">alias</span> -s bz2=<span class="string">&#x27;tar -xjvf&#x27;</span> </span><br></pre></td></tr></table></figure>
<p><strong>文档编辑相关</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">alias</span> -s php=vim</span><br><span class="line"><span class="built_in">alias</span> -s py=vim </span><br><span class="line"><span class="built_in">alias</span> -s rb=vim </span><br><span class="line"><span class="built_in">alias</span> -s html=vim</span><br></pre></td></tr></table></figure>
<p>注：需提前安装vim</p>
<p><strong>远程登录服务器与端口映射</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">alias</span> labser=<span class="string">&#x27;ssh tom@172.xxx.xxx.xxx&#x27;</span></span><br><span class="line"><span class="built_in">alias</span> sshl8888=<span class="string">&#x27;ssh tom@172.xxx.xxx.xxx -L 8888:localhost:8888&#x27;</span></span><br><span class="line"><span class="built_in">alias</span> sshl8889=<span class="string">&#x27;ssh tom@172.xxx.xxx.xxx -L 8889:localhost:8889&#x27;</span></span><br><span class="line"><span class="built_in">alias</span> sshl8890=<span class="string">&#x27;ssh tom@172.xxx.xxx.xxx -L 8890:localhost:8890&#x27;</span></span><br></pre></td></tr></table></figure>
<p><strong>通配符设置</strong><br />
使用zsh后，有些时候无法使用通配符，需要在配置文件中加入下面一行。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">setopt</span> nonomatch</span><br></pre></td></tr></table></figure>
<p>把以上配置信息拷贝到<code>~/.zshrc</code>文件末尾，然后使用<code>source ~/.zshrc</code>使之生效。</p>
<hr />
<h1 id="自动登录服务器"><a class="markdownIt-Anchor" href="#自动登录服务器"></a> 自动登录服务器</h1>
<p>每次远程登录服务器，需要手动敲命令和输入密码，如如果要连接多个窗口或者远程拷贝文件，效率就非常低下了。这里使用zsh的别名，配合使用xxxx,达到一个很短的命令登录到服务器内。</p>
<p>ssh服务有两种验证用户登录的方式，一种是基于密码口令的认证，一种是基于密钥的认证。一般的手动登录属于密码口令登录，</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613485022539.png" alt="密码口令登录服务器" /></p>
<p>下面是ssh基于密钥认证过程图示</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613485022530.png" alt="ssh免密登录" /></p>
<p>下面是生成和分配密钥对的过程：</p>
<p><strong>生成密钥</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ssh-keygen -t rsa</span><br></pre></td></tr></table></figure>
<p><strong>复制公钥到服务器</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ssh-copy-id -i ~/.ssh/id_rsa.pub tom@172.xxx.xxx.xxx</span><br></pre></td></tr></table></figure>
<p>结合上面的别名，比如可以直接输入<code>labser</code>就登录到服务器来，快的中间不到1s的功夫，大大提高工作效率；拷贝文件时，没有做别名设置仍然需要输入原命令，但是可以免密拷贝。</p>
<hr />
<h1 id="快捷键配置"><a class="markdownIt-Anchor" href="#快捷键配置"></a> 快捷键配置</h1>
<p>Linuxmint设置里面的<code>键盘</code>项，有一栏快捷键，里面可以设置自定义快捷键。</p>
<p><strong>截图快捷键</strong><br />
我使用<code>Shutter</code>进行截图，每次需要截图，使用快捷键，调出Shutter的选区截图（命令是shutter -s）,所以我的设置如图。</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613485022536.png" alt="自定义快捷键" /></p>
<p><strong>锁屏</strong><br />
平常喜欢使用super+L进行锁屏，所以这样设置快捷键。</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613485022537.png" alt="锁屏快捷键" /></p>
<p><strong>终端新开一个tab</strong><br />
打开终端后，喜欢使用super+T在同一终端下新开一个页面。</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613485022538.png" alt="终端新开一个tab" /></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>linux上cuda与cudnn环境搭建</title>
    <url>/2017/05/19/linux%E4%B8%8Acuda%E4%B8%8Ecudnn%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/</url>
    <content><![CDATA[<p>本文介绍在linux上如何安装cuda及cudnn</p>
<a id="more"></a>
<p>cuda官网：<a href="https://developer.nvidia.com/cuda-downloads">https://developer.nvidia.com/cuda-downloads</a></p>
<h2 id="cuda下载"><a class="markdownIt-Anchor" href="#cuda下载"></a> cuda下载</h2>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613529405158.png" alt="下载cuda" /></p>
<h2 id="cuda安装"><a class="markdownIt-Anchor" href="#cuda安装"></a> cuda安装</h2>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-ubuntu1804.pin</span><br><span class="line">sudo mv cuda-ubuntu1804.pin /etc/apt/preferences.d/cuda-repository-pin-600</span><br><span class="line">wget http://developer.download.nvidia.com/compute/cuda/10.2/Prod/local_installers/cuda-repo-ubuntu1804-10-2-local-10.2.89-440.33.01_1.0-1_amd64.deb</span><br><span class="line">sudo dpkg -i cuda-repo-ubuntu1804-10-2-local-10.2.89-440.33.01_1.0-1_amd64.deb</span><br><span class="line">sudo apt-key add /var/cuda-repo-10-2-local-10.2.89-440.33.01/7fa2af80.pub</span><br><span class="line">sudo apt-get updatesudo apt-get -y install cuda</span><br></pre></td></tr></table></figure>
<p>cudnn官网：<a href="https://developer.nvidia.com/rdp/cudnn-download">https://developer.nvidia.com/rdp/cudnn-download</a></p>
<h2 id="cudnn安装"><a class="markdownIt-Anchor" href="#cudnn安装"></a> cudnn安装</h2>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo dpkg -i libcudnn7_7.6.5.32-1+cuda10.2_amd64.deb</span><br></pre></td></tr></table></figure>
<h2 id="测试"><a class="markdownIt-Anchor" href="#测试"></a> 测试</h2>
<p>重启系统，然后运行下面例子</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#查找测试例子所在位置</span></span><br><span class="line">locate cuda | grep <span class="string">&#x27;samples&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#编译测试例子</span></span><br><span class="line">sudo make -j8</span><br><span class="line"></span><br><span class="line"><span class="comment">#运行测试例子</span></span><br><span class="line"> ./deviceQuery</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613529405176.png" alt="测试成功提示" /></p>
<p>输出提示PASS,则安装成功！！！</p>
]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>cuda</tag>
      </tags>
  </entry>
  <entry>
    <title>linux上wps系统缺失字体</title>
    <url>/2016/06/01/linux%E4%B8%8Awps%E7%B3%BB%E7%BB%9F%E7%BC%BA%E5%A4%B1%E5%AD%97%E4%BD%93/</url>
    <content><![CDATA[<p>在Linux上新安装WPS后，第一次打开就出现以下问题：</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613525052698.png" alt="wps系统缺失字体" /></p>
<p><strong>问题原因：</strong><br />
Linux上缺少windows字体，把字体添加上去即可。</p>
<a id="more"></a>
<p><strong>操作步骤：</strong><br />
1.下载缺失字体</p>
<blockquote>
<p>国内下载地址：<a href="https://www.dropbox.com/s/lfy4hvq95ilwyw5/wps_symbol_fonts.zip">https://www.dropbox.com/s/lfy4hvq95ilwyw5/wps_symbol_fonts.zip</a><br />
国外下载地址：<a href="https://pan.baidu.com/s/17-glCiVNTc70ZDu35dpDjg">https://pan.baidu.com/s/17-glCiVNTc70ZDu35dpDjg</a><br />
<mark>字体下载后，将其解压到/usr/share/fonts中,终端执行以下命令即可</mark></p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">unzip wps_symbol_fonts.zip</span><br><span class="line">sudo mv  wps_symbol_fonts  /usr/share/fonts</span><br></pre></td></tr></table></figure>
<p>2.修改字体权限，终端执行以下命令</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/share/fonts/</span><br><span class="line">chmod 755 wps_symbol_fonts</span><br><span class="line"><span class="built_in">cd</span> /usr/share/fonts/wps_symbol_fonts</span><br><span class="line">chmod 644 *</span><br></pre></td></tr></table></figure>
<p>3.生成字体索引,终端执行以下命令</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/share/fonts/wps_symbol_fonts</span><br><span class="line">sudo mkfontscale</span><br><span class="line">sudo mkfontdir</span><br></pre></td></tr></table></figure>
<p>4.更新字体缓存,终端执行以下命令</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo fc-cache</span><br></pre></td></tr></table></figure>
<p>5.重启WPS</p>
<blockquote>
<p>问题解决</p>
</blockquote>
]]></content>
      <categories>
        <category>软件工具</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>WPS</tag>
      </tags>
  </entry>
  <entry>
    <title>linux的文件夹共享功能设置</title>
    <url>/2016/06/01/linux%E7%9A%84%E6%96%87%E4%BB%B6%E5%A4%B9%E5%85%B1%E4%BA%AB%E5%8A%9F%E8%83%BD%E8%AE%BE%E7%BD%AE/</url>
    <content><![CDATA[<p>本文解释linux系统向其他系统共享文件的流程，并以ipad访问过程演示</p>
<a id="more"></a>
<p>1.新建共享文件夹<br />
<img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613526191640.png" alt="enter description here" /></p>
<p>2.设置共享用户<br />
<img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613526191641.png" alt="enter description here" /></p>
<blockquote>
<p>好像要求用户wu先是系统用户</p>
</blockquote>
<p>3.终端访问</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613526191645.png" alt="enter description here" /></p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613526191646.png" alt="enter description here" /></p>
<blockquote>
<p>！需填写密码</p>
</blockquote>
]]></content>
      <categories>
        <category>软件工具</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>文件共享</tag>
      </tags>
  </entry>
  <entry>
    <title>lixuxmint系统定制与配置（4）-应用安装</title>
    <url>/2018/07/13/lixuxmint%E7%B3%BB%E7%BB%9F%E5%AE%9A%E5%88%B6%E4%B8%8E%E9%85%8D%E7%BD%AE%EF%BC%884%EF%BC%89-%E5%BA%94%E7%94%A8%E5%AE%89%E8%A3%85/</url>
    <content><![CDATA[<p>本文针对列出目前linux上常用的软件，其实每个软件都有自己的个性化配置，以后有时间了，逐个记录下来。编程主力环境是Python,编辑器使用Jupyter,这个编辑器是在远程服务器启动，映射端口到本地来编辑。</p>
<a id="more"></a>
<p><strong>浏览器：</strong> 自带的firfox，Opear(我需要两个浏览器，一个浏览器用来浏览网页，一个用来编程)<br />
<strong>文档编辑器：</strong> 自带的libreoffice,自带的文本编辑器，Markdown编辑器（Typro）</p>
<p><strong>Pdf文档：</strong> FoxitReader<br />
<a href="https://www.foxitsoftware.cn/downloads/">https://www.foxitsoftware.cn/downloads/</a></p>
<p><strong>文献管理：</strong> Zotero<br />
<a href="https://www.zotero.org/">https://www.zotero.org/</a></p>
<p><strong>文档备份：</strong> 坚果云<br />
（下载&amp;Python3运行环境）<a href="https://www.jianguoyun.com/s/downloads/linux">https://www.jianguoyun.com/s/downloads/linux</a><br />
登录出现链接错误提示：<a href="https://blog.csdn.net/jasonzhoujx/article/details/80640566">https://blog.csdn.net/jasonzhoujx/article/details/80640566</a></p>
<p><strong>字典：</strong> goldendict<br />
安装/设置/添加字典</p>
<p><strong>版本控制：</strong> Git</p>
<p><strong>截图：</strong> shutter<br />
shutter内图片编辑器安装看下面这篇文章<br />
<a href="https://www.linuxidc.com/Linux/2018-04/151911.htm">Ubuntu 18.04中的Shutter禁用了“编辑”选项解决-Linux公社</a></p>
<p><strong>gif录屏：</strong> peak</p>
<p>**思维导图：**Xmind<br />
<a href="https://www.xmind.cn/">https://www.xmind.cn/</a><br />
<a href="https://my.oschina.net/2012/blog/1590732">https://my.oschina.net/2012/blog/1590732</a></p>
<p>KX上网：shadowsocks-gui<br />
<a href="https://github.com/shadowsocks/shadowsocks-qt5/releases">https://github.com/shadowsocks/shadowsocks-qt5/releases</a></p>
<p><strong>音乐：</strong> 网易云音乐<br />
到<a href="http://music.163.com/#/download">这里</a>下载Linux版本，然后使用以下命令安装。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sudo dpkg -i netease-cloud-music_1<span class="number">.1</span><span class="number">.0</span>_amd64_ubuntu.deb</span><br></pre></td></tr></table></figure>
<p>安装完成后，如果<code>遇到点击了，却没有启动</code>的问题，在这个文件<code>/usr/share/applications/netease-cloud-music.desktop</code>的exec添加<code>--no-sandbox</code>，然后<mark>重启</mark>即解决。</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613484442233.png" alt="修改后的文件" /></p>
<p><strong>视频：</strong> 使用浏览器观看</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>opencv的关键模块介绍</title>
    <url>/2021/02/22/opencv%E7%9A%84%E5%85%B3%E9%94%AE%E6%A8%A1%E5%9D%97/</url>
    <content><![CDATA[<p>通过opencv的各个模块的功能认识opencv能做什么</p>
<a id="more"></a>
<p><strong>主模块</strong></p>
<table>
<thead>
<tr>
<th>模块</th>
<th>功能描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>core</td>
<td>核心功能模块，模块主要包含 OpenCV 库的基础结构以及基本操作，例如OpenCV基本数据结构、绘图函数、数组操作相关函数、动态数据结构等。</td>
</tr>
<tr>
<td>imgproc</td>
<td>这个模块名称是由image（图像）和process（处理）两个单词的缩写组和而成，是重要的图像处理模块，其主要包括图像滤波、几何变换、直方图、特征检测与目标检测等。</td>
</tr>
<tr>
<td>imgcodecs</td>
<td>图像文件读取与保存模块，主要用于图像文件读取与保存。</td>
</tr>
<tr>
<td>videoio</td>
<td>视频输入输出模块，主要用于读取与写入视频或者图像序列。</td>
</tr>
<tr>
<td>highgui</td>
<td>高层GUI图形用户界面，包含创建和操作显示图像的窗口、处理鼠标事件以及键盘命令、提供图形交互可视化界面等。</td>
</tr>
<tr>
<td>video</td>
<td>视频分析模块，主要包含运动估计、背景分离、对象跟踪等视频处理相关内容。</td>
</tr>
<tr>
<td>calib3d</td>
<td>由calibration（校准）和3D这两个单词的缩写组合而成，通过名字我们可以知道，模块主要包含相机标定与立体视觉等功能，例如物体位姿估计、三维重建、摄像头标定等。</td>
</tr>
<tr>
<td>features2d</td>
<td>这个模块名称是由features（特征）和2D这两个单词的缩写组合而成，其功能主要为处理图像特征点，例如特征检测、描述与匹配等。</td>
</tr>
<tr>
<td>objdetect</td>
<td>目标检测模块，主要用于图像目标检测，例如检测Haar特征。</td>
</tr>
<tr>
<td>dnn</td>
<td>深度学习模块，这个模块是OpenCV 4版本的一个特色，其主要包括构建神经网络、加载序列化网络模型等。但是该模块目前仅适用于正向传递计算（测试网络），原则上不支持反向计算（训练网络）。</td>
</tr>
<tr>
<td>ml</td>
<td>机器学习模块，主要为统计分类、回归和数据聚类等。</td>
</tr>
<tr>
<td>flann</td>
<td>这个模块名称是Fast Library for Approximate Nearest Neighbors（快速近似最近邻库）的缩写，这个模块是高维的近似近邻快速搜索算法库，主要包含快速近似最近邻搜索与聚类等。</td>
</tr>
<tr>
<td>photo</td>
<td>计算摄影模块，主要包含图像修复和去噪等。</td>
</tr>
<tr>
<td>stitching</td>
<td>图像拼接模块，主要包含特征点寻找与匹配图像、估计旋转、自动校准、接缝估计等图像拼接过程的相关内容。</td>
</tr>
<tr>
<td>gapi</td>
<td>这个模块是OpenCV 4.0中新增加的模块，旨在加速常规的图像处理，与其他模块相比，这个模块主要充当框架而不是某些特定的计算机视觉算法。</td>
</tr>
</tbody>
</table>
<p><strong>扩展模块</strong></p>
<table>
<thead>
<tr>
<th>模块</th>
<th>功能描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>alphamat</td>
<td>给定输入图像和输入Trimap，此模块专用于计算图像的Alpha遮罩。</td>
</tr>
<tr>
<td>aruco</td>
<td>此模块专用于方形基准标记（也称为增强现实标记）。这些标记可用于轻松，快速和强大地进行相机姿态估计。</td>
</tr>
<tr>
<td>bgsegm</td>
<td>改善的前景-背景分割</td>
</tr>
<tr>
<td>bioinspired</td>
<td>该模块提供生物视觉系统模型（人类视觉系统和其他）。 它还提供利用这些生物启发模型的衍生对象。</td>
</tr>
<tr>
<td>ccalib</td>
<td>全方位摄像机标定和立体三维重建</td>
</tr>
<tr>
<td>cnn_3dobj</td>
<td>3D对象分类和姿势估计</td>
</tr>
<tr>
<td>cudaarithm</td>
<td>cuda的矩阵操作</td>
</tr>
<tr>
<td>cudabgsegm</td>
<td>cuda的背景分割</td>
</tr>
<tr>
<td>cudacodec</td>
<td>cuda的视频编码解码</td>
</tr>
<tr>
<td>cudafeatures2d</td>
<td>cuda上的特征挖掘</td>
</tr>
<tr>
<td>cudafilters</td>
<td>cuda的图片过滤</td>
</tr>
<tr>
<td>cudaimgproc</td>
<td>cuda上的图片处理</td>
</tr>
<tr>
<td>cudalegacy</td>
<td>Legacy support</td>
</tr>
<tr>
<td>cudaobjdetect</td>
<td>cuda上的目标识别</td>
</tr>
<tr>
<td>cudaoptflow</td>
<td>cuda上的光流分析</td>
</tr>
<tr>
<td>cudastereo</td>
<td>立体匹配</td>
</tr>
<tr>
<td>cudawarping</td>
<td>图像变换</td>
</tr>
<tr>
<td>cudev</td>
<td>实现 CUDA 版本的核心功能，类似 core/ 模块中的基础算法。</td>
</tr>
<tr>
<td>cvv</td>
<td>视觉交互结界面</td>
</tr>
<tr>
<td>datasets</td>
<td>数据集模块包括用于处理不同数据集的类：加载数据，评估数据集上的不同算法，包含基准等。</td>
</tr>
<tr>
<td>dnn_objdetect</td>
<td>DNN used for object detection</td>
</tr>
<tr>
<td>dnn_superres</td>
<td>DNN used for super resolution</td>
</tr>
<tr>
<td>dpm</td>
<td>改进的变形部件为基础的模型</td>
</tr>
<tr>
<td>face</td>
<td>人脸识别模块</td>
</tr>
<tr>
<td>freetype</td>
<td>Drawing UTF-8 strings with freetype/harfbuzz</td>
</tr>
<tr>
<td>fuzzy</td>
<td>基于模糊数学的图形处理</td>
</tr>
<tr>
<td>hdf</td>
<td>分层数据格式输入输出</td>
</tr>
<tr>
<td>hfs</td>
<td>Hierarchical Feature Selection for Efficient Image Segmentation</td>
</tr>
<tr>
<td>img_hash</td>
<td>The module brings implementations of different image hashing algorithms.</td>
</tr>
<tr>
<td>intensity_transform</td>
<td>The module brings implementations of intensity transformation algorithms to adjust image contrast.</td>
</tr>
<tr>
<td>julia</td>
<td>Julia bindings for OpenCV</td>
</tr>
<tr>
<td>line_descriptor</td>
<td>对图像中提取的直线的描述</td>
</tr>
<tr>
<td>optflow</td>
<td>光流算法</td>
</tr>
<tr>
<td>ovis</td>
<td>OGRE 3D Visualiser</td>
</tr>
<tr>
<td>phase_unwrapping</td>
<td>Phase Unwrapping API</td>
</tr>
<tr>
<td>plot</td>
<td>画图功能</td>
</tr>
<tr>
<td>quality</td>
<td>Image Quality Analysis (IQA) API</td>
</tr>
<tr>
<td>rapid</td>
<td>silhouette based 3D object tracking</td>
</tr>
<tr>
<td>reg</td>
<td>图像配准</td>
</tr>
<tr>
<td>rgbd</td>
<td>图像深度的获取、表示以及物体三维点的计算等。根据相机内参、外参计算真实深度</td>
</tr>
<tr>
<td>saliency</td>
<td>好的程序接口</td>
</tr>
<tr>
<td>sfm</td>
<td>由运动恢复结构的三维重建方法</td>
</tr>
<tr>
<td>shape</td>
<td>形状匹配算法模块。用于描述形状、比较形状</td>
</tr>
<tr>
<td>stereo</td>
<td>立体匹配</td>
</tr>
<tr>
<td>structured_light</td>
<td>结构光的标定程序接口</td>
</tr>
<tr>
<td>superres</td>
<td>增大分辨率</td>
</tr>
<tr>
<td>surface_matching</td>
<td>面匹配</td>
</tr>
<tr>
<td>text</td>
<td>文本检测和识别模块，可以使用开源OCR Tesseract作为后端</td>
</tr>
<tr>
<td>tracking</td>
<td>多目标TLD算法跟踪</td>
</tr>
<tr>
<td>videostab</td>
<td>解决相机移动时拍摄的视频不够稳定的问题</td>
</tr>
<tr>
<td>viz</td>
<td>三维可视化模块。底层实现基于 VTK 这个第三方库</td>
</tr>
<tr>
<td>xfeatures2d</td>
<td>SIFT、SURF等二维特征提取算法</td>
</tr>
<tr>
<td>ximgproc</td>
<td>扩展图像处理算法，快速边缘检测、图像滤波，图像分割、超像素</td>
</tr>
<tr>
<td>xobjdetect</td>
<td>扩展目标检测算法</td>
</tr>
<tr>
<td>xphoto</td>
<td>扩展photo模块</td>
</tr>
</tbody>
</table>
<h1 id="如何使用opencv"><a class="markdownIt-Anchor" href="#如何使用opencv"></a> 如何使用opencv?</h1>
]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>opencv</tag>
      </tags>
  </entry>
  <entry>
    <title>lixuxmint系统定制与配置（6）-个性化配置</title>
    <url>/2018/07/13/lixuxmint%E7%B3%BB%E7%BB%9F%E5%AE%9A%E5%88%B6%E4%B8%8E%E9%85%8D%E7%BD%AE%EF%BC%886%EF%BC%89-%E4%B8%AA%E6%80%A7%E5%8C%96%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<p>在系统安装完毕，基础的应用安装也弄完后，最后是按照自己的使用习惯配置系统使用环境，本文主要基于<code>linuxmint</code>的系统特性进行配置，主要分为以下几个部分对系统进行配置。</p>
<a id="more"></a>
<h1 id="系统环境配置"><a class="markdownIt-Anchor" href="#系统环境配置"></a> 系统环境配置</h1>
<h2 id="桌面布局"><a class="markdownIt-Anchor" href="#桌面布局"></a> 桌面布局</h2>
<h3 id="整体布局"><a class="markdownIt-Anchor" href="#整体布局"></a> 整体布局</h3>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1566053785015.png" alt="桌面布局" /></p>
<h3 id="桌面控件"><a class="markdownIt-Anchor" href="#桌面控件"></a> 桌面控件</h3>
<h4 id="系统负载"><a class="markdownIt-Anchor" href="#系统负载"></a> 系统负载</h4>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613485314126.png" alt="系统负载" /></p>
<h4 id="网络速度"><a class="markdownIt-Anchor" href="#网络速度"></a> 网络速度</h4>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613485314121.png" alt="网络速度" /></p>
<h4 id="天气"><a class="markdownIt-Anchor" href="#天气"></a> 天气</h4>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613485314122.png" alt="天气" /></p>
<h4 id="快捷键-快速锁屏"><a class="markdownIt-Anchor" href="#快捷键-快速锁屏"></a> 快捷键-快速锁屏</h4>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613485314123.png" alt="快速锁屏" /></p>
<h1 id="应用配置"><a class="markdownIt-Anchor" href="#应用配置"></a> 应用配置</h1>
<p>firfox</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613485314124.png" alt="插件展示" /></p>
<table>
<thead>
<tr>
<th>序号</th>
<th>插件名</th>
<th>作用</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>VivaldiFox</td>
<td>网页标签颜色随内容变化</td>
</tr>
<tr>
<td>2</td>
<td>SwitchyOmegaα</td>
<td>快速切换浏览器是否代理</td>
</tr>
<tr>
<td>3</td>
<td>Anki 划词制卡助手</td>
<td>收集网页陌生单词</td>
</tr>
<tr>
<td>4</td>
<td>夜间助手</td>
<td>调节网页背景色</td>
</tr>
<tr>
<td>5</td>
<td>Textmarker</td>
<td>给网页文字作标记（加粗，上色）</td>
</tr>
<tr>
<td>6</td>
<td>Evernote Web Clipper</td>
<td>印象笔记插件-裁剪网页</td>
</tr>
</tbody>
</table>
<p>rime<br />
选择架构fcitx<br />
设置输入法<br />
美化输入法</p>
<p>小书匠<br />
帐号登录<br />
博客发布设置<br />
图床设置</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613485314125.png" alt="图床设置" /></p>
<p>Calibre<br />
存储目录设置<br />
书库导入<br />
插件安装</p>
<p>坚果云<br />
帐号登录<br />
同步目录设置</p>
<p>Zotero<br />
存储目录设置</p>
<p>Shutter<br />
基础配置<br />
安装“编辑扩展”</p>
<p>VLC</p>
<p>Anki</p>
<p>Godenldict</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>在windows上安装MinGW-w64</title>
    <url>/2021/03/10/windows%E4%B8%8A%E5%AE%89%E8%A3%85minGW/</url>
    <content><![CDATA[<blockquote>
<p>MinGW(全称为，Minimalist GNU for Windows)，它实际上是将经典的开源 C语言编译器 GCC 移植到了 Windows 平台下，并且包含了 Win32API ，因此可以将源代码编译为可在 Windows 中运行的可执行程序。而且还可以使用一些 Windows 平台不具备的，但是Linux平台具备的开发工具和API函数。用一句话来概括就是：MinGW 就是 GCC 的 Windows 版本<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup></p>
</blockquote>
<a id="more"></a>
<h2 id="mingw-w64安装"><a class="markdownIt-Anchor" href="#mingw-w64安装"></a> MinGW-w64安装</h2>
<p>有两种方式安装MinGW-w64，第一种是下载压缩包安装；第二种是使用<a href="https://sourceforge.net/projects/mingw-w64/files/Toolchains%20targetting%20Win32/Personal%20Builds/mingw-builds/installer/mingw-w64-install.exe">MinGW-w64下载器</a>安装。下面以浏览器下载安装为例，介绍其安装流程及压缩包命名规则。</p>
<h4 id="下载压缩包安装"><a class="markdownIt-Anchor" href="#下载压缩包安装"></a> 下载压缩包安装</h4>
<ol>
<li><strong>下载压缩包：</strong><a href="https://sourceforge.net/projects/mingw-w64/files/mingw-w64/">在这里下载</a>MinGW-w64，文件命名方式<a href="#filename_rule">如下</a>，根据自己系统及需要下载对应版本，本此安装系统为windows10(64bit)，选择了[x86_64-posix-sjlj](<a href="https://sourceforge.net/projects/mingw-w64/files/Toolchains">https://sourceforge.net/projects/mingw-w64/files/Toolchains</a> targetting Win64/Personal Builds/mingw-builds/8.1.0/threads-posix/sjlj/x86_64-8.1.0-release-posix-sjlj-rt_v6-rev0.7z)</li>
<li>**解压压缩包：**将路径<code>mingw64/bin</code>配置到系统环境变量<code>PATH</code>中；<code>mingw64/lib</code>配置到环境变量LIB中；<code>mingw64/bin</code>配置到环境变量INCLUDE中</li>
<li>**测试安装：**打开windows终端cmd，输入<code>gcc -v</code>，无误后安装成功</li>
</ol>
<h4 id="span-idfilename_rule文件命名方式解释span"><a class="markdownIt-Anchor" href="#span-idfilename_rule文件命名方式解释span"></a> <span id="filename_rule">文件命名方式解释</span> <sup class="footnote-ref"><a href="#fn1" id="fnref1:1">[1:1]</a></sup></h4>
<ul>
<li><strong>version</strong>: GCC编译器版本</li>
<li><strong>architecture</strong>: 电脑系统类型，i686指32位系统；x86_64指64位系统</li>
<li><strong>threads</strong>: 线程类型，posix指可移植的操作系统接口，UNIX系统支持该标准；win32指windows下的一个标准</li>
<li><strong>exception</strong>: 异常处理类型，32位系统有2种：dwarf和sjlj；64位系统同样2种：seh 和 sjlj。3种类型的区别为<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup>：
<ul>
<li><strong>sjlj</strong>：可用于32位和64位 – 不是“零成本”：即使不抛出exception，也会造成较小的性能损失（在exception大的代码中约为15％） – 允许exception遍历例如窗口callback</li>
<li><strong>seh</strong>：结构化异常处理，利用FS段寄存器，将原点压入栈，遇到异常弹出，seh 是新发明的，而 sjlj 则是古老的，seh 性能比较好，但不支持 32位。 sjlj 稳定性好，支持 32位</li>
<li><strong>dwarf</strong>：只有32位可用 – 没有永久的运行时间开销 – 需要整个调用堆栈被启用，这意味着exception不能被抛出，例如Windows系统DLL。</li>
</ul>
</li>
<li><strong>build revision</strong>: 建立修订</li>
</ul>
<p><strong>参考资料：</strong></p>
<hr class="footnotes-sep" />
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p><a href="https://blog.csdn.net/u010429831/article/details/106766165/">Windows系统下安装配置 MinGW-w64 开发环境_yunfan-CSDN博客</a> <a href="#fnref1" class="footnote-backref">↩︎</a> <a href="#fnref1:1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn2" class="footnote-item"><p><a href="https://www.cnblogs.com/cangqinglang/p/11074124.html">MinGW-w64安装教程——著名C/C++编译器GCC的Windows版本</a> <a href="#fnref2" class="footnote-backref">↩︎</a></p>
</li>
</ol>
</section>
]]></content>
      <categories>
        <category>软件工具</category>
      </categories>
      <tags>
        <tag>MinGW64</tag>
        <tag>windows</tag>
      </tags>
  </entry>
  <entry>
    <title>书摘：《从行动开始（与其花3小时想，不如花5分钟做。为你系统介绍在日本和美国广受欢迎的行为科学管理方法！）》-石田淳</title>
    <url>/2021/02/11/%E4%B9%A6%E6%91%98_%E4%BB%8E%E8%A1%8C%E5%8A%A8%E5%BC%80%E5%A7%8B%EF%BC%88%E4%B8%8E%E5%85%B6%E8%8A%B13%E5%B0%8F%E6%97%B6%E6%83%B3%EF%BC%8C%E4%B8%8D%E5%A6%82%E8%8A%B15%E5%88%86%E9%92%9F%E5%81%9A%E3%80%82%E4%B8%BA%E4%BD%A0%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D%E5%9C%A8%E6%97%A5%E6%9C%AC%E5%92%8C%E7%BE%8E%E5%9B%BD%E5%B9%BF%E5%8F%97%E6%AC%A2%E8%BF%8E%E7%9A%84%E8%A1%8C%E4%B8%BA%E7%A7%91%E5%AD%A6%E7%AE%A1%E7%90%86%E6%96%B9%E6%B3%95%EF%BC%81%EF%BC%89-%E7%9F%B3%E7%94%B0%E6%B7%B3.hexo/</url>
    <content><![CDATA[<div class="douban-card-block">
	<a class="douban-card" href="https://book.douban.com/subject/26828557">
		<div class="douban-card-bgimg" style="background-image: url('https://images.weserv.nl/?url=https://img2.doubanio.com/view/subject/s/public/s28858263.jpg');"></div>
		<div class="douban-card-left">
			<div class="douban-card-img" style="background-image: url('https://images.weserv.nl/?url=https://img2.doubanio.com/view/subject/s/public/s28858263.jpg');"></div>
		</div>
		<div class="douban-card-right" style="line-height: 1.7;">
			<div class="douban-card-item"><span>书名: </span><strong>从行动开始</strong></div>
			<div class="douban-card-item"><span>作者: </span><span>[日]石田淳</span></div>
			<div class="douban-card-item"><span>出版年份: </span><span>2016-9</span></div>
			<div class="douban-card-item"><span>评分: </span><span>7.2</span></div>
		</div>
	</a>
</div>
<style>
	.douban-card-block {
		display: flex;
		justify-content: center;
		align-items: center;
		width: 100%;
		max-height: 400px;
	}
	.douban-card {
		display: flex;
		margin: 30px 10px;
		padding: 15px;
		border-radius: 10px;
		position: relative;
		justify-content: center;
		align-items: center;
		overflow: hidden;
		color: antiquewhite;
		text-decoration: none;
	}
	.douban-card:hover {
		text-decoration: none;
	}
	.douban-card-bgimg {
		position: absolute;
		width: 115%;
		height: 115%;
		filter: blur(15px) brightness(0.6);
		background-size: 100%;
		background-position: center;
		background-repeat: no-repeat;
	}
	.douban-card-img {
		position: relative;
		height: 130px;
		width: 80px;
		background-size: 100%;
		background-position: center;
		background-repeat: no-repeat;
	}
	.douban-card-img {
		position: relative;
		height: 130px;
		width: 80px;
	}
	.douban-card-left {
		position: relative;
		display: flex;
		flex-direction: column;
		align-items: center;
	}
	.douban-card-right {
		position: relative;
		display: flex;
		flex-direction: column;
		margin-left: 12px;
		font-size: 16px;
		font-family: 'Courier New', Courier, monospace;
		line-height: 1.3;
		color: antiquewhite;
	}
	.douban-card-item {
		margin-top: 4px;
	}
</style>
<a id="more"></a>
<h2 id="自序"><a class="markdownIt-Anchor" href="#自序"></a> 自序</h2>
<blockquote>
<p>认为只要拥有坚强的意志，就能够比别人更加努力，就能更好地控制自己的感情，就能够成功，认为改变自己首先必须让自己变成一个意志坚强的人，这种想法本身就是错误的。也正因为你有这样的想法，所以你才一直都没有改变。</p>
</blockquote>
<blockquote>
<p>能够导出结果的只有“行动”。不管你有多么坚强的意志，如果没有行动的话仍然不会产生任何结果。反之，就算意志非常薄弱，但如果采取行动的话一样能够收获成功。明明只要将注意力都集中在简单的“行动”上就好了，可是你却将注意力集中在所谓抽象的“意志”上。</p>
</blockquote>
<blockquote>
<p>我们每个人都有“负面思考”的习惯，在这种习惯的影响下，我们总是把事情往坏的方向想，所以要想“凭借坚强的意志让事情走上正轨”是非常困难的。要记住，最重要的是结果，而能够导出结果的只有行动，与意志无关。</p>
</blockquote>
<h2 id="第一章你之所以难以改变的原因"><a class="markdownIt-Anchor" href="#第一章你之所以难以改变的原因"></a> 第一章你之所以难以改变的原因</h2>
<blockquote>
<p>在行动科学管理术的理论中，一切结果都是行动的积累。好的结果是好的行动不断重复带来的，而不断重复坏的行动只能带来坏的结果。所以，我们应该关注的不是“性格”和“态度”，而是“行动”。</p>
</blockquote>
<blockquote>
<p>一个打算戒烟的人一整天都没有吸烟，会认为自己的意志力很强，第二天他只吸了一根，却会立刻陷入“为什么我的意志力这么薄弱”的自责之中。</p>
</blockquote>
<blockquote>
<p>这种认知的偏差是人类特有的思维方式，其他动物并没有。</p>
</blockquote>
<blockquote>
<p>向别人展示的不是你坚强的意志；同样的，你也没有必要对自己展示坚强的意志。你只要取得结果就够了。而要想取得结果，必不可少的是行动。</p>
</blockquote>
<blockquote>
<p>与很久之后不确定的结果相比，能够立刻得到的结果对人类的行动会产生决定性的影响。明知道吃蛋糕会增加体重却仍然打算吃蛋糕，也是因为同样的理由。增加体重是几天之后的事，甚至有可能所增加的体重并没有想象中那么多。与之相比，“美味的满足”却是立刻而且确实能够获得的结果。所以人们才会选择吃蛋糕。</p>
</blockquote>
<blockquote>
<p>人类的思考从根本上就带有偏见，尤其是涉及“金钱”这个最应该理性对待的问题时，偏见会变得更加严重。</p>
</blockquote>
<blockquote>
<p>人类之所以不愿意接受确定的损失，是因为“不愿承认自己失败”。我们就是这样害怕失败。</p>
</blockquote>
<blockquote>
<p>据说每个人每天会出现700次自动思考。在这些思考之中有内容比较清晰的，也有意识模糊不清的，但基本上都是负面思考。也就是说，在你的大脑中每天会出现700条负面信息。</p>
</blockquote>
<blockquote>
<p>比如，你的邻居在街上与你擦肩而过但却没有打招呼。明明那个人只是没注意到你而已，但是你心里却会有“他是不是讨厌我啊？上个月我是不是得罪了他？”的想法……或者你在工作中只是出现了一点小问题，可你会想“哎呀，我又犯错误了。</p>
</blockquote>
<blockquote>
<p>我们要正确认识眼前的情况，然后设定好必须要做的事情。接着我们要思考什么是应该最先做的，按照先后顺序采取行动。如果出现问题，应该思考原因，然后正确应对。</p>
</blockquote>
<blockquote>
<p>人类是行动和意志不协调的麻烦的生物，那么我们作为“无法完全理性行动的人类”，要想为实现目标而改变自己，应该怎么做呢？如果还像以前一样企图凭意志的力量来控制自己，只会不断地失败。</p>
</blockquote>
<blockquote>
<p>当你想要实现某种目标，或者想要变成理想中的自己时，都应该把焦点放在“行动”上。只有行动起来，才会发现自己好的地方和坏的地方，以及应该改善的地方。至于改善的方案是否有效，是需要通过行动来进行判断的。</p>
</blockquote>
<h2 id="第二章戒除那些毁掉你人生的习惯"><a class="markdownIt-Anchor" href="#第二章戒除那些毁掉你人生的习惯"></a> 第二章戒除那些毁掉你人生的习惯</h2>
<blockquote>
<p>一个被“认知偏差”的臆想所束缚的人，在采取明确的行动之前，很容易产生许多乱七八糟的想法。</p>
</blockquote>
<blockquote>
<p>来说，“正念”就是将注意力全部集中在此刻，不被过去和未来所影响，只专注于眼前事物。</p>
</blockquote>
<blockquote>
<p>逃避一时的困难，将来只会给自己带来更大的麻烦。虽然道理很简单，但是很多人却仍然选择眼前的安逸。就好像很多人明明有重要的工作要做，但却把时间都浪费在浏览网页上一样。</p>
</blockquote>
<h2 id="第三章小心你深信不疑的陷阱"><a class="markdownIt-Anchor" href="#第三章小心你深信不疑的陷阱"></a> 第三章小心你“深信不疑”的陷阱</h2>
<blockquote>
<p>不安、猜疑等负面情绪，都是由我们大脑中的自动化思考所引发的，是非理性思维的不断强化。这时候我们往往会失去冷静的判断力，在面对重要的问题时做出错误的选择。</p>
</blockquote>
<blockquote>
<p>当你在人际交往中受到刺激时，请冷静地回想一下当时的状况，然后试着分析当时对话的内容。如果你能够将那些对话都写在纸上冷静地阅读一下，就会发现其实“并没有什么大不了的”。</p>
</blockquote>
<blockquote>
<p>谁也无法回到过去，所以也无法消除那些不愉快的往事。但是，已经过去的事根本没有消除的必要，因为过去已经不存在了。不管是多么不愉快的事，它们都只存在于我们的记忆之中，而并非存在于现实之中。所以，沉浸于过去的人相当于被不存在的东西束缚住了。</p>
</blockquote>
<blockquote>
<p>只要将注意力集中在“现在”的“现实”之上，就可以解决绝大多数的问题。甚至可以说，没有什么问题是这种方法不能解决的。反之，总是沉浸在过去之中的人，会经常出现许多问题。而且因为谁也无法回到过去，所以那些问题永远也无法得到解决。</p>
</blockquote>
<blockquote>
<p>不同的人对事物的认知方式存在差异，人们的认知大体可以分为“让自己感到轻松的认知”和“让自己感到辛苦的认知”两种。“让自己感到轻松的认知”建立在对眼前发生的事的冷静判断之上，而“让自己感到辛苦的认知”则是由对事实扭曲的认识和毫无根据的臆测所带来的。</p>
</blockquote>
<blockquote>
<p>总而言之，关键在于不要过分关注自己做不到的事。因为在我们的脑海中，一天浮现出700次的“自动化思考”几乎都是负面信息，而我们经常会将负面信息放大。</p>
</blockquote>
<blockquote>
<p>问题不在于“做不到”，而在于你“不肯原谅自己”。因为你不肯原谅自己，这种狭隘的态度会给你造成多余的压力，使你连本来能够做到的事情都做不到了。</p>
</blockquote>
<blockquote>
<p>开始”。你之所以一直无法改变，是因为你每次开始的时候都因为“认知偏差”而感觉自己“这次肯定也不行”。从今往后请原谅真实的自己，这样一来，你就可以对一切进行自我管理。</p>
</blockquote>
<blockquote>
<p>当发生某件事情的时候，应该只将意识集中在“眼前的事实”上，排除多余的印象、思考、喜恶，只接受其最真实的状态。这种方法被称为“正念”或者“ACT（Acceptance&amp;CommitmentTherapy）”，在心理和精神医疗领域都很被重视。</p>
</blockquote>
<blockquote>
<p>找出客观的原因，用正确的认知来应对，然后通过多次乘车来达到“就算坐车也不会肚子疼”的状态时，你才能彻底从苦痛之中解脱出来。这就是认知行为疗法。</p>
</blockquote>
<blockquote>
<p>用“正念”法来进行自我管理，就是让自己彻底面对现实。或许会有人觉得这是非常难的，但实际上这是非常简单的，因为我们只要不考虑事实以外的事情就好。人类总是习惯于逃避事实，特别是在事实让人不愉快的时候。</p>
</blockquote>
<blockquote>
<p>关键在于，愤怒和不安等负面情绪有时候是完全与“现在”和“现实”无关的。只要冷静地想一下就会发现，所有的负面情绪都是因为对过去的后悔和对未来的担忧而产生的。所以，只要敢于正视这些负面的情绪，就会发现其实事实并没有那么可怕。当你感觉自己将要被负面情绪吞噬的时候，千万不要放任负面情绪，而应该将意识集中在“现实”和“现在”。</p>
</blockquote>
<blockquote>
<p>事实上，并没有人会故意去轻视别人，但没有采取充分的应对措施，的确会使人产生被轻视的感觉。这正是“认知偏差”的典型案例。</p>
</blockquote>
<blockquote>
<p>如果将自己愤怒的原因归结于外在因素，那么就说明你被周围的环境和他人的言行所左右了。</p>
</blockquote>
<blockquote>
<p>如果你不能凭借自己的行动来改变现状，那么就无法从负面的情绪中摆脱出来。人在一帆风顺的时候，一旦稍微遇到点不如意的事就很容易自暴自弃。但是，就这样彻底松开方向盘真的对吗？</p>
</blockquote>
<blockquote>
<p>不要因为过去的事情而懊悔，不要因为对未来的不安而畏缩不前，更不要因为周围的环境而心存怨恨。只有把握“现在”和“现实”，你的人生才会变得更加灿烂。</p>
</blockquote>
<h2 id="第四章从小习惯开始"><a class="markdownIt-Anchor" href="#第四章从小习惯开始"></a> 第四章从小习惯开始</h2>
<blockquote>
<p>自己的幸福度，毫无疑问是由自己决定的。</p>
</blockquote>
<blockquote>
<p>如果不能搞清楚“对自己来说什么是幸福”和“我想要变成什么样的人”，那么你只能感到不满和不幸。</p>
</blockquote>
<blockquote>
<p>“行动科学管理术”认为，无法取得理想结果的原因只有两点：1.不知道应该怎么做2.虽然知道应该怎么做，但不知道如何坚持</p>
</blockquote>
<blockquote>
<p>“行动科学管理术”为了让人们能够在无法立刻得到“好的结果”的情况下仍然能够坚持行动，专门设计了许多“报酬”，但是这些报酬最好不涉及金钱，就算涉及也最好不要涉及高价的东西。</p>
</blockquote>
<blockquote>
<p>为了将那些能够取得好结果的行动变成习惯，并且彻底摆脱导致坏结果的行动，褒奖和成就感是不可忽视的。</p>
</blockquote>
<blockquote>
<p>改变自己并不意味着否定现在的自己，而是让现在的自己得到成长。所以，请不要讨厌现在的自己。只有现在的自己，才能够取得进步。</p>
</blockquote>
<blockquote>
<p>绝对不能自暴自弃。一定要相信自己，放松心情开始行动。</p>
</blockquote>
<blockquote>
<p>改变现在的自己，并不是让你改变人格，而是努力让现在的自己变得更加优秀。但改变不可能一蹴而就，而应该循序渐进。</p>
</blockquote>
<blockquote>
<p>如果因为勉强自己而失败，会导致认知出现巨大的偏差，把自己逼入穷途末路。事实上，不管多大的失败都不能证明你这个人一无是处，但认知的偏差却会让你给自己贴上失败者的标签。如果这样的情况重复出现，那你的人生就真的完蛋了。</p>
</blockquote>
<blockquote>
<p>为了尽可能地减轻我们在日常生活中出现的压力，应该排除模糊不清的因素，使一切都“可视化”。不要总是思考那些模糊不清的内容。</p>
</blockquote>
<blockquote>
<p>所谓“实况转播”，简单来说就是“将自己正在做的事情用语言文字的形式在脑海中确认一遍”。通过将自己的行动读给自己听，可以完全排除过去和将来的干扰，将意识完全集中于现在。</p>
</blockquote>
<blockquote>
<p>每天都努力工作却总是看不到头的日子会使人产生巨大的压力。人们会对工作越来越厌倦并最终放弃。</p>
</blockquote>
<h2 id="第五章避开陷阱"><a class="markdownIt-Anchor" href="#第五章避开陷阱"></a> 第五章避开陷阱</h2>
<blockquote>
<p>很多人认为压力与发生的事情有直接的联系。但实际上并不是“发生事情→产生压力”，而是“发生事情→个人认知→产生压力”，人类对所发生事情的“认知”才是产生压力的主要因素。如果认知出现偏差，即便只是一些无谓的小事也会产生多余的负面情绪，导致产生巨大的压力。</p>
</blockquote>
<blockquote>
<p>“正念法”可以让你的注意力完全集中在“现在”和“现实”之上，排除过去和未来对你的干扰。只要时刻将注意力完全集中在“现在发生的事情”上，在认识事物的时候就能够摘掉有色眼镜，不会使自己产生无谓的压力。</p>
</blockquote>
<blockquote>
<p>消除压力最重要的还是面对自我。与“行动科学管理术”类似的认知行为疗法也认为，不逃避压力，正视压力而采取行动才能够从根本上解决问题。</p>
</blockquote>
<blockquote>
<p>困扰你的问题，并不是因为你的性格导致的，更不是毅力能够解决的。只有正视现实并且采取行动，才是解决问题的不二法门。</p>
</blockquote>
<blockquote>
<p>要想战胜眼前的诱惑，首先你必须充分了解“人类很难坚持做任何事”（也就是说不要责备自己无法坚持），然后专门制定一套能够帮助自己坚持下去的方法。</p>
</blockquote>
<blockquote>
<p>只有以自己为基准在力所能及的范围内一点一点地改变，才能坚持行动。如果你真的想要改变自己，就不要被周围的价值观所左右，循序渐进地做自己想做的事，这才是最重要的。</p>
</blockquote>
<blockquote>
<p>不管面对多么困难的状况，都不要认为自己是个没用的人，因为这种想法是毫无意义的。自我贬低只会造成“认知偏差”。冷静客观地分析状况，寻找解决方法，然后实践这个方法，这样就能避免陷入毫无根据的“认知偏差”之中。不要冲动，保持理性。不要主观，保持客观。不要抽象，保持具体。</p>
</blockquote>
<blockquote>
<p>遇到问题的时候，只要从当事人视角转换到第三者视角，就能够调整心态，明白“现在应该做什么”。</p>
</blockquote>
<blockquote>
<p>绝对不要忘记，你想要实现什么目标，你想要变成什么样子，都是由现在的你决定的，而不是由世俗的价值观和流行的标准决定的。</p>
</blockquote>
<blockquote>
<p>人类总是背负着超出自己认知的思维负担，这会使人产生多余的思考。</p>
</blockquote>
<blockquote>
<p>坐禅也好，散步也好，甚至只是闭上眼睛也好。“现在，我要整理自己的感情，从“认知偏差”中摆脱出来，让意识回到现实。”只要这样想一想就足够了。在每天睡觉之前拿出5分钟来整理自己的感情，可以很好地减轻你的压力。如果不这样做，任凭由“认知偏差”产生的负面感情蔓延，那么你的未来恐怕也很难变好。</p>
</blockquote>
<h2 id="第六章认同自己"><a class="markdownIt-Anchor" href="#第六章认同自己"></a> 第六章认同自己</h2>
<blockquote>
<p>1.自己成功的经历：在此之前有过相同或者相似的成功经历。2.替代性经历：虽然自己没有经历过，但看别人成功，因此认为自己也能够成功。3.语言说服：即便自己对行动的成功毫无自信，但别人对你说“你能行”。4.情绪和生理的变化：由成就感和喜悦导致生理状态发生变化。当你想要做什么事的时候，可以利用上述四点来提高你的自我激励能力。</p>
</blockquote>
<blockquote>
<p>你之所以无法达成目标，想要改变却迟迟无法行动，就是因为你太过依赖“干劲”和“毅力”等抽象的东西。</p>
</blockquote>
<blockquote>
<p>如果感到不安却不去解决，自己总放不下心来。为了能够随心所欲地行动，为了能够变成更好的自己，为了构建出满意的人生，请多和自己交流沟通。</p>
</blockquote>
<blockquote>
<p>如果不能最大限度地利用自己的时间，那么你既不能达成目标，也无法改变自己。请将杂乱无章的项目整理清楚，把有限的时间和精力都集中在必要的行动上吧。</p>
</blockquote>
<blockquote>
<p>我们既想达成目标，让自己变得更好，又想最大限度地享受现在的快乐，关键在于在这两者之间找到一个平衡。找不到平衡的人，很难实现理想的人生。</p>
</blockquote>
<blockquote>
<p>我们的情绪很容易出现波动，尽管我们知道应该以自己作为判断的基准，但遇到实际情况时还是可能产生“认知偏差”。在感情混乱的情况下，我们会在不经意间以世俗或他人为标准对事物进行判断，结果陷入与事实不符的臆想之中。如果对这种偏差置之不理，那么你好不容易积累起来的好的习惯都将失去意义，人生的道路也会朝着错误的方向越走越远。</p>
</blockquote>
<blockquote>
<p>首先，人类很容易产生“认知偏差”，而“认知偏差”会妨碍你达成目标和改变自己。其次，为了实现你的目标，成为理想中的自己，你需要的不是坚强的意志，而是从小做起的行动。因为这些内容我都已经反复强调过，想必大家应该都已经理解了。从今往后请不要再重复同样的错误，更加自信地改变自己的人生吧。最后我还有一个请求，那就是不要说“从明天开始”。</p>
</blockquote>
<blockquote>
<p>你能够不以世俗的价值观为基准，而以自己为基准改变自己的人生；你能够从小的行动开始，踏实地积累和坚持；你能够专注于现实和现在；你会对这样的自己感到喜悦，并给予褒奖。这样的你将无所不能，你可以随心所欲地改变自己。</p>
</blockquote>
]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>读书</tag>
      </tags>
  </entry>
  <entry>
    <title>书摘：《Keras快速上手：基于Python的深度学习实战》-谢梁;鲁颖;劳虹岚</title>
    <url>/2020/06/02/%E4%B9%A6%E6%91%98_Keras%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98-%E8%B0%A2%E6%A2%81;%E9%B2%81%E9%A2%96;%E5%8A%B3%E8%99%B9%E5%B2%9A.hexo/</url>
    <content><![CDATA[<div class="douban-card-block">
	<a class="douban-card" href="https://book.douban.com/subject/27093647">
		<div class="douban-card-bgimg" style="background-image: url('https://images.weserv.nl/?url=https://img3.doubanio.com/view/subject/s/public/s29499730.jpg');"></div>
		<div class="douban-card-left">
			<div class="douban-card-img" style="background-image: url('https://images.weserv.nl/?url=https://img3.doubanio.com/view/subject/s/public/s29499730.jpg');"></div>
		</div>
		<div class="douban-card-right" style="line-height: 1.7;">
			<div class="douban-card-item"><span>书名: </span><strong>Keras快速上手：基于Python的深度学习实战</strong></div>
			<div class="douban-card-item"><span>作者: </span><span>谢梁</span></div>
			<div class="douban-card-item"><span>出版年份: </span><span>2017-8</span></div>
			<div class="douban-card-item"><span>评分: </span><span>4.7</span></div>
		</div>
	</a>
</div>
<style>
	.douban-card-block {
		display: flex;
		justify-content: center;
		align-items: center;
		width: 100%;
		max-height: 400px;
	}
	.douban-card {
		display: flex;
		margin: 30px 10px;
		padding: 15px;
		border-radius: 10px;
		position: relative;
		justify-content: center;
		align-items: center;
		overflow: hidden;
		color: antiquewhite;
		text-decoration: none;
	}
	.douban-card:hover {
		text-decoration: none;
	}
	.douban-card-bgimg {
		position: absolute;
		width: 115%;
		height: 115%;
		filter: blur(15px) brightness(0.6);
		background-size: 100%;
		background-position: center;
		background-repeat: no-repeat;
	}
	.douban-card-img {
		position: relative;
		height: 130px;
		width: 80px;
		background-size: 100%;
		background-position: center;
		background-repeat: no-repeat;
	}
	.douban-card-img {
		position: relative;
		height: 130px;
		width: 80px;
	}
	.douban-card-left {
		position: relative;
		display: flex;
		flex-direction: column;
		align-items: center;
	}
	.douban-card-right {
		position: relative;
		display: flex;
		flex-direction: column;
		margin-left: 12px;
		font-size: 16px;
		font-family: 'Courier New', Courier, monospace;
		line-height: 1.3;
		color: antiquewhite;
	}
	.douban-card-item {
		margin-top: 4px;
	}
</style>
<a id="more"></a>
<h2 id="1准备深度学习的环境"><a class="markdownIt-Anchor" href="#1准备深度学习的环境"></a> 1准备深度学习的环境</h2>
<blockquote>
<p>cuDNN是NVIDIA开发的专门强化卷积神经网络模型训练的库，全称为NVIDIACUDADeepNeuralNetworklibrary，支持常见的深度学习软件，比如CNTK、Caffe、Theano、Keras、TensorFlow等。cuDNN对卷积神经网络模型的训练速度能提升2~3倍，</p>
</blockquote>
<blockquote>
<p>CNMeM是NVIDIA开发的一个显存管理分配软件。预先给深度学习项目分配足够的显存能有效提高训练速度，一般提升10%左右。</p>
</blockquote>
<h2 id="2数据收集与处理"><a class="markdownIt-Anchor" href="#2数据收集与处理"></a> 2数据收集与处理</h2>
<blockquote>
<p>TF-IDF（TermFrequency–InverseDocumentFrequency）是一种用于进行信息检索与数据挖掘的常用加权技术，用以评估一个词对于一个段落集或一个语料库中的其中一个段落的重要程度。</p>
</blockquote>
<blockquote>
<p>Word2Vec是Google推出的用来进行词的向量表达的开源工具包，这个名字也是该工具包所代表的算法的称号。</p>
</blockquote>
<blockquote>
<p>Word2Vec的主要思想是把词表达为低维度向量的形式，含义相近的词在这个低维度向量空间中的位置相近，而不相关的词则距离较远。</p>
</blockquote>
<h2 id="3深度学习简介"><a class="markdownIt-Anchor" href="#3深度学习简介"></a> 3深度学习简介</h2>
<blockquote>
<p>大多数神经网络中都包含四类函数：组合函数（CombinationFunction）、激活函数（ActivationFunction）、误差函数（ErrorFunction）和目标函数（ObjectFunction）。</p>
</blockquote>
<blockquote>
<p>在网络中间将向量映射为标量的函数就被称为组合函数。常见的组合函数包括线性组合函数和基于欧式空间距离的函数，比如在RBF网络中常用的函数。</p>
</blockquote>
<blockquote>
<p>激活函数通常都是将一个实数域上的值映射到一个有限域中，因此也被称为塌缩函数。比如常见的tanh或者logistic函数，都是将无限的实数域上的数值压缩到（-1，1）或者（0，1）之间的有限域中。如果这个激活函数不做任何变换，则被称为Identity或者线性激活函数。激活函数的主要作用是为隐含层引入非线性。一个只有线性关系隐含层的多层神经网络不会比一般的只包含输入层和输出层的两层神经网络更加强大，因为线性函数的函数仍然是一个线性函数。但是加入非线性以后，多层神经网络的预测能力就得到了显著提高。</p>
</blockquote>
<blockquote>
<p>对于后向传播算法，激活函数必须可微，而且如果这个函数是在有限域中的话，则效果更好，因此像logistic、tanh、高斯函数等都是比较常见的选择，这类函数也被统称为sigmoid函数。</p>
</blockquote>
<blockquote>
<p>早期的理论认为sigmoid激活函数通常比threshold激活函数（比如ReLU等激活函数）好。</p>
</blockquote>
<blockquote>
<p>梯度消亡指的是梯度（误差的信号）随着隐藏层数的增加成指数减小。这是因为在后向传播算法中，对梯度的计算使用链式法则，因此在第n层时需要将前面各层的梯度都相乘，但是由于sigmoid函数的值域在（-1，1）或者（0，1）之间，因此多个很小的数相乘以后第n层的梯度就会接近于0，造成模型训练的困难。</p>
</blockquote>
<blockquote>
<p>对于输出层，读者应该尽量选择适合因变量分布的激活函数。对于只有0，1取值的双值因变量，logistic函数是一个较好的选择。对于有多个取值的离散因变量，比如0到9数字的识别，softmax激活函数是logistic激活函数的自然衍生。对于有有限值域的连续因变量，logistic或者tanh激活函数都可以用，但是需要将因变量的值域伸缩到logistic或者tanh对应的值域中。如果因变量取值为正，但是没有上限，那么指数函数是一个较好的选择。如果因变量没有有限值域，或者虽然是有限值域但是边界未知，那么最好采用线性函数作为激活函数。</p>
</blockquote>
<blockquote>
<p>模型输出值p和真实值y之间的差异一般被称为残差或者误差，但是这个值并不能直接用来衡量模型的质量。当一个模型完美的时候（虽然这不可能出现），其误差为0，而当一个模型不够完美的时候，其误差不论为负值还是正值，都偏离0；因此衡量模型质量的是误差偏离0的相对值，即误差函数的值越接近于0，模型的性能越好，反之则模型的性能越差。误差函数也被称为损失函数。常用的误差函数如下。</p>
</blockquote>
<blockquote>
<p>交叉熵可以被解释为映射到最可能的类别的概率的对数。因此，当预测值的分布和实际因变量的分布尽可能一致时，交叉熵最小。</p>
</blockquote>
<blockquote>
<p>目标函数是需要在训练阶段直接最小化的那个函数。</p>
</blockquote>
<blockquote>
<p>批量，即Batch，是深度学习中的一个重要概念。批量通常指两个不同的概念——如果对应的是模型训练方法，那么批量指的是将所有数据处理完以后一次性更新权重或者参数的估计；如果对应的是模型训练中的数据，那么批量通常指的是一次输入供模型计算用的数据量。这两个概念有着紧密的关系。</p>
</blockquote>
<blockquote>
<p>在离线学习中，所有的数据都可以被反复获取，比如上面的批量学习就是离线学习的一种。而在在线学习中，每个观测值在处理以后会被遗弃，同时参数得到更新。</p>
</blockquote>
<blockquote>
<p>离线学习有如下几个优点。对于任何固定个数的参数，目标函数都可以直接被计算出来，因此很容易验证模型训练是否在朝着所需要的方向发展。计算精度可以达到任意合理的程度。可以使用各种不同的算法来避免出现局部最优的情况。可以采用训练、验证、测试三分法对模型的普适度进行验证。可以计算预测值及其置信区间。</p>
</blockquote>
<blockquote>
<p>在深度学习中，采用sigmoid激活函数的隐藏层或者输出层的神经元通常在计算网络输入时加入一个偏移值，称为Bias。对于线性输出神经元，偏移项就是回归中的截距项。</p>
</blockquote>
<blockquote>
<p>三个常见的“标准化”数据处理动作。（1）重放缩（Rescaling）：通常指将一个向量加上或者减去一个常量，再乘以或者除以一个常量。比如将华氏温度转换为摄氏温度就是一个重放缩的过程。（2）规范化（Normalization）：通常指将一个向量除以其范数，比如采用欧式空间距离，则用向量的方差作为范数来规范化向量。在深度学习中，规范化通常采用极差为范数，即将向量减去最小值，并除以其极差，从而使数值范围在0到1之间。（3）标准化（Standardization）：通常指将一个向量移除其位置和规模的度量。比如一个服从正态分布的向量，可以减去其均值，并除以其方差来标准化数据，从而获得一个服从标准正态分布的向量。</p>
</blockquote>
<h2 id="4keras入门"><a class="markdownIt-Anchor" href="#4keras入门"></a> 4Keras入门</h2>
<blockquote>
<p>Keras针对几种常见的输入深度学习模型和输入数据形态，提供了几个易于使用的工具来处理数据，包括针对序列模型的数据预处理、针对文字输入的数据处理，以及针对图片输入的数据处理。所有函数都在Keras.preprocessing这个库里面，分别有text、sequence和image三个子库。</p>
</blockquote>
<blockquote>
<p>在文字的建模实践中，一般都需要把原始文字拆解成单字、单词或者词组，然后将这些拆分后的要素进行索引、标记化供机器学习算法使用。这种预处理叫作标注（Tokenize）。</p>
</blockquote>
<blockquote>
<p>对于已经读入的文字的预处理包含以下几个步骤。（1）文字拆分。（2）建立索引。（3）序列补齐（Padding）。（4）转换为矩阵。（5）使用标注类批量处理文本文件。所有跟文字相关的预处理函数都在Keras.preprocessing.text这个子库里。但是这是为英文文字设计的，如果是处理中文，因为中英文的差异，建议使用结巴分词里提供的切分函数cut来进行文字拆分。</p>
</blockquote>
<blockquote>
<p>根据结巴分词的介绍，其使用了如下算法来进行中文分词。基于前缀词典实现高效的词图扫描，生成句子中汉字所有可能成词情况所构成的有向无环图（DAG）。采用动态规划查找最大概率路径，找出基于词频的最大切分组合。对于未登录词，采用了基于汉字成词能力的HMM模型，使用Viterbi算法。</p>
</blockquote>
<blockquote>
<p>完成分词以后，得到的单字或者单词并不能直接用于建模，还需要将它们转换成数字序号，才能进行后续处理。这就是建立索引。建立索引的方法很简单，对于拆分出来的每一个单字或者单词，排序之后编号即可。</p>
</blockquote>
<blockquote>
<p>建立索引也可以使用OneHot编码法，即对于K个不同的单字或者单词，依次设定一个1到K之间的数值来索引这K个单字或者单词构成的词汇表。</p>
</blockquote>
<blockquote>
<p>一般要将大量不同的数据映射到一个有限空间中，通常采用的方法都是哈希表，one_hot函数也不例外。</p>
</blockquote>
<blockquote>
<p>最终索引之后的文字信息会被按照索引编号放入多维矩阵中用来建模。这个多维矩阵的行宽对应于所有拆分后的单字或者单词，但是在将索引放入矩阵中之前，需要先进行序列补齐的工作。这是因为将一段话拆分成单一的词以后，丢失了重要的上下文信息，因此将上下文的一组词放在一起建模能保持原来的上下文信息，从而提高建模的质量。</p>
</blockquote>
<blockquote>
<p>序列补齐分两种情况。</p>
</blockquote>
<blockquote>
<p>第一种情况是自然的文本序列，比如微博或者推特上的一段话，都是一个自然的单字或者单词序列，而待建模的数据是由很多微博或者推特组成的，或者对一组文章进行建模，每篇文章中的每一句话构成一个文本序列。这个时候每句话的长度不一，需要进行补齐为统一长度。第二种情况是将一个由K个（K较大）具备一定顺序的单词串拆分成小块的连续子串，每个子串只有M个（M&lt;K）单词。</p>
</blockquote>
<blockquote>
<p>所有的建模都只能使用多维矩阵，因此最后必须将索引过的文字元素转换成可以用于建模的矩阵。Keras提供了两种方法。第一种方法是使用pad_sequences函数。</p>
</blockquote>
<blockquote>
<p>第二种方法是使用下面将要介绍的标注类来进行。</p>
</blockquote>
<blockquote>
<p>当批量处理文本文件时，需要一种更高效的方法。Keras提供了一个标注类（Tokenizerclass）来进行文本处理。</p>
</blockquote>
<blockquote>
<p>另外一种对序列数据的处理方法叫作跳跃语法（SkipGram）模型。这是TomasMikolov在2013年提出的单词表述（WordRepresentation）模型，它把每个单词映射到一个M维的空间，它有一个更著名的别名，即Word2Vec。</p>
</blockquote>
<blockquote>
<p>在Keras的预处理模块中有一个skipgrams的函数，将一个词向量索引标号按照两种可选方式转化为一系列两两元素的组合（w1，w2）和标注z。如果w2跟w1是紧挨着的，则标注z为1，为正样本；如果w2是从不相邻的其他元素中随机抽取的，则标注z为负样本。</p>
</blockquote>
<blockquote>
<p>Keras为图片数据的输入提供了一个很好的接口，即Keras.preprocessing.image.ImageDataGenerator类。这个类生成一个数据生成器（Generator）对象，依照循环批量产生对应于图像信息的多维矩阵。</p>
</blockquote>
<blockquote>
<p>在Keras中设定了两类深度学习模型：一类是序列模型（Sequential类）；一类是通用模型（Model类）。</p>
</blockquote>
<blockquote>
<p>通用模型可以用来设计非常复杂、任意拓扑结构的神经网络，例如有向无环网络、共享层网络等。类似于序列模型，通用模型通过函数化的应用接口来定义模型。</p>
</blockquote>
<blockquote>
<p>对于序列模型和通用模型，它们的主要差异在于如何定义从输入层到输出层的各层结构。首先，在序列模型里，是先定义序列模型对象的；而在通用模型中是先定义从输入层到输出层各层要素的，包括尺寸结构。其次，在序列模型中，当有了一个模型对象以后，可以通过add方法对其依次添加各层信息，包括激活函数和网络尺寸来定义整个神经网络；而在通用模型中，是通过不停地封装含有各层网络结构的函数作为参数来定义网络结构的。最后，在序列模型中，各层只能依次线性添加；而在通用模型中，因为采用了封装的概念，可以在原有的网络结构上应用新的结构来快速生成新的模型，因此灵活度要高很多，特别是在具有多种类型的输入数据的情况下，比如在Keras手册中就举了一个教神经网络看视频进行自然语言问答的例子。在这个例子中，输入数据有两种：一是视频图像；二是自然语言的提问。首先通过构造多层卷积神经网络使用序列模型来对图像编码，然后将这个模型放入TimeDistributed函数中建立视频编码，最后使用LSTM对编码建模，同时对自然语言也进行从文字到向量的转换，在合并两个网络以后，将合并的网络作为参数输入下一个全连接层进行计算，并输出可能的回答。</p>
</blockquote>
<blockquote>
<p>Keras预先定义了很多对象用于帮助构造Keras的网络结构，比如常用的激活函数、参数初始化方法、正则化方法等。</p>
</blockquote>
<blockquote>
<p>选择。Keras提供了大量预定义好的激活函数，方便定制各种不同的网络结构。在Keras中使用激活对象有两种方法：一是单独定义一个激活层；二是在前置层里面通过激活选项来定义所需的激活函数。</p>
</blockquote>
<blockquote>
<p>初始化对象（Initializer）用于随机设定网络层激活函数中的权重值或者偏置项的初始值，包括kernel_initializer和bias_initializer。好的权重初始化值能帮助加快模型收敛速度。Keras预先定义了很多不同的初始化对象，包括：Zeros，将所有参数值都初始化为0。Ones，将所有参数值都初始化为1。Constant（value=1），将所有参数值都初始化为某一个常量，比如这里设置为1。RandomNormal，将所有参数值都按照一个正态分布所生成的随机数来初始化。正态分布的均值默认为0，而标准差默认为0.05。可以通过mean和stddev选项来修改。TruncatedNormal，使用一个截断正态分布生成的随机数来初始化参数向量，默认参数均值为0，标准差为0.05。对于均值的两个标准差之外的随机数会被遗弃并重新取样。这种初始化方法既有一定的多样性，又不会产生特别偏的值，因此是比较推荐的方法。针对不同的常用分布选项，Keras还提供了两个基于这种方法的特例，即glorot_normal和he_normal。前者的标准差不再是0.05，而是输入向量和输出向量的维度的函数：￼其中n1是输入向量的维度，而n2是输出向量的维度；后者的标准差只是输入向量的维度的函数：￼RandomUniform，按照均匀分布所生成的随机数来初始化参数值，默认的分布参数最小值为-0.05，最大值为0.05，可以通过minval和maxval选项分别修改。针对常用的分布选项，Keras还提供了两个基于这个分布的特例即glorot_uniform和he_uniform。前者均匀分布的上下限是输入向量和输出向量的维度的函数：￼而在后者上下限只是输入向量的维度的函数：￼自定义，用户可以自定义一个与参数维度相符合的初始化函数。下面的例子来自于Keras手册，使用后台的正态分布函数生成一组初始值，在定义网络层的时候调用这个函数即可。</p>
</blockquote>
<blockquote>
<p>在建模的时候，正则化是防止过度拟合的一个很常用的手段。在神经网络中也提供了正则化的手段，分别应用于权重参数、偏置项以及激活函数，对应的选项分别是kernel_regularizer、bias_reuglarizier和activity_regularizer。它们都可以应用Keras.regularizier.Regularizer对象，这个对象提供了定义好的一阶、二阶和混合的正则化方法，分别将前面的Regularizier替换为l1（x）、l2（x）和l1_l2（x1，x2），其中x或者x1，x2为非负实数，表明正则化的权重。</p>
</blockquote>
<blockquote>
<p>核心层（CoreLayer）是构成神经网络最常用的网络层的集合，包括：全连接层、激活层、放弃层、扁平化层、重构层、排列层、向量反复层、Lambda层、激活值正则化层、掩盖层。所有的层都包含一个输入端和一个输出端，中间包含激活函数以及其他相关参数等。（1）全连接层。在神经网络中最常见的网络层就是全连接层，在这个层中实现对神经网络里面的神经元的激活。</p>
</blockquote>
<blockquote>
<p>（2）激活层。激活层是对上一层的输出应用激活函数的网络层，这是除应用activation选项之外，另一种指定激活函数的方式。其用法很简单，只要在参数中指明所需的激活函数即可，预先定义好的函数直接引用其名字的字符串，或者使用TensorFlow和Theano自带的激活函数。</p>
</blockquote>
<blockquote>
<p>（3）放弃层。放弃层（Dropout）是对该层的输入向量应用放弃策略。在模型训练更新参数的步骤中，网络的某些隐含层节点按照一定比例随机设置为不更新状态，但是权重仍然保留，从而防止过度拟合。</p>
</blockquote>
<blockquote>
<p>（4）扁平化层。扁化层（Flatten）是将一个维度大于或等于3的高维矩阵按照设定“压扁”为一个二维的低维矩阵。</p>
</blockquote>
<blockquote>
<p>（5）重构层。重构层（Reshape）的功能和Numpy的Reshape方法一样，将一定维度的多维矩阵重新排列构造为一个新的保持同样元素数量但是不同维度尺寸的矩阵。</p>
</blockquote>
<blockquote>
<p>（6）排列层。排列层（Permute）按照给定的模式来排列输入向量的维度。这个方法在连接卷积网络和时间递归网络的时候非常有用。其参数是输入矩阵的维度编号在输出矩阵中的位置。</p>
</blockquote>
<blockquote>
<p>（7）向量反复层。顾名思义，向量反复层就是将输入矩阵重复多次。</p>
</blockquote>
<blockquote>
<p>（8）Lambda层。Lambda层可以将任意表达式包装成一个网络层对象。参数就是表达式，一般是一个函数，可以是一个自定义函数，也可以是任意已有的函数。</p>
</blockquote>
<blockquote>
<p>（9）激活值正则化层。这个网络层的作用是对输入的损失函数更新正则化。（10）掩盖层。该网络层主要使用在跟时间有关的模型中，比如LSTM。其作用是输入张量的时间步，在给定位置使用指定的数值进行“屏蔽”，用以定位需要跳过的时间步。</p>
</blockquote>
<blockquote>
<p>针对常见的卷积操作，Keras提供了相应的卷积层API，包括一维、二维和三维的卷积操作、切割操作、补零操作等。卷积在数学上被定义为作用于两个函数f和g上的操作来生成一个新的函数z。这个新的函数是原有两个函数的其中一个（比如f）在另一个（比如g）的值域上的积分或者加权平均。</p>
</blockquote>
<blockquote>
<p>卷积操作分为一维、二维和三维，对应的方法分别是Conv1D、Conv2D和Conv3D，这些方法有同样的选项，只是作用于不同维度的数据上，因此适用于不同的业务情景。</p>
</blockquote>
<blockquote>
<p>一维卷积通常被称为时域卷积，因为其主要应用在以时间排列的序列数据上，其使用卷积核对一维数据的邻近信号进行卷积操作来生成一个张量。二维卷积通常被称为空域卷积，一般应用在与图像相关的输入数据上，也是使用卷积核对输入数据进行卷积操作的。三维卷积也执行同样的操作。</p>
</blockquote>
<blockquote>
<p>Conv1D、Conv2D和Conv3D的选项几乎相同。filters：卷积滤子输出的维度，要求整数。kernel_size：卷积核的空域或时域窗长度。要求是整数或整数的列表，或者是元组。如果是单一整数，则应用于所有适用的维度。strides：卷积在宽或者高维度的步长。要求是整数或整数的列表，或者是元组。如果是单一整数，则应用于所有适用的维度。如果设定步长不为1，则dilation_rate选项的取值必须为1。padding：补齐策略，取值为valid、same或causal。causal将产生因果（膨胀的）卷积，即output[t]不依赖于input[t+1：]，在不能违反时间顺序的时序信号建模时有用。请参考WaveNet：AGenerativeModelforRawAudio，section2.1.。valid代表只进行有效的卷积，即对边界数据不处理。same代表保留边界处的卷积结果，通常会导致输出shape与输入shape相同。data_format：数据格式，取值为channels_last或者channels_first。这个选项决定了数据维度次序，其中channels_last对应的数据维度次序是（批量数，高，宽，频道数），而channels_first对应的数据维度次序为（批量数，频道数，高，宽）。activation：激活函数，为预定义或者自定义的激活函数名，请参考前面的“网络层对象”部分的介绍。如果不指定该选项，将不会使用任何激活函数（即使用线性激活函数：a（x）=x）。dilation_rate：该选项指定扩张卷积（DilatedConvolution）中的扩张比例。要求为整数或由单个整数构成的列表/元组，如果dilation_rate不为1，则步长一项必须设为1。use_bias：指定是否使用偏置项，取值为True或者False。kernel_initializer：权重初始化方法，为预定义初始化方法名的字符串，或用于初始化权重的函数。请参考前面的“网络层对象”部分的介绍。bias_initializer：偏置初始化方法，为预定义初始化方法名的字符串，或用于初始化偏置的函数。请参考前面的“网络层对象”部分的介绍。kernel_regularizer：施加在权重上的正则项，请参考前面的关于网络层对象中正则项的介绍。bias_regularizer：施加在偏置项上的正则项，请参考前面的关于网络层对象中正则项的介绍。activity_regularizer：施加在输出上的正则项，请参考前面的关于网络层对象中正则项的介绍。kernel_constraints：施加在权重上的约束项，请参考前面的关于网络层对象中约束项的介绍。bias_constraints：施加在偏置项上的约束项，请参考前面的关于网络层对象中约束项的介绍。</p>
</blockquote>
<blockquote>
<p>除上面介绍的卷积层以外，还有一些特殊的卷积层，比如SeparableConv2D、Conv2DTranspose、UpSampling1D、UpSampling2D、UpSampling3D、ZeroPadding1D、ZeroPadding2D、ZeroPadding3D等，</p>
</blockquote>
<blockquote>
<p>池化（Pooling）是在卷积神经网络中对图像特征的一种处理，通常在卷积操作之后进行。池化的目的是为了计算特征在局部的充分统计量，从而降低总体的特征数量，防止过度拟合和减少计算量。</p>
</blockquote>
<blockquote>
<p>Keras的池化层按照计算的统计量分为最大统计量池化和平均统计量池化；按照维度分为一维、二维和三维池化层；按照统计量计算区域分为局部池化和全局池化。</p>
</blockquote>
<blockquote>
<p>（1）最大统计量池化方法：</p>
</blockquote>
<blockquote>
<p>（2）平均统计量池化方法：这个方法的选项和数据格式要求跟最大化统计量池化方法一样，只是池化方法使用局部平均值而不是局部最大值作为充分统计量，</p>
</blockquote>
<blockquote>
<p>（3）全局池化方法：该方法应用全部特征维度的统计量来代表特征，因此会压缩数据维度。</p>
</blockquote>
<blockquote>
<p>在局部池化方法中，输出维度和输入维度是一样的，只是特征的维度尺寸因为池化变小；但是在全局池化方法中，输出维度小于输入维度，如在二维全局池化方法中输入维度为（样本数，频道数，行，列），全局池化以后行和列的维度都被压缩到全局统计量中，因此输出维度只有（样本数，频道数）二维。</p>
</blockquote>
<blockquote>
<p>循环层（RecurrentLayer）用来构造跟序列有关的神经网络。但是其本身是一个抽象类，无法实例化对象，在使用时应该使用LSTM，GRU和SimpleRNN三个子类来构造网络层。</p>
</blockquote>
<blockquote>
<p>简单循环层。SimpleRNN是循环层的一个子类，用来构造全连接的循环层，是循环网络最直接的应用，使用recurrent.SimipleRNN来调用。长短记忆层。LSTM是循环层的另一个子类，和简单循环层相比，其隐藏状态的权重网络稀疏。带记忆门的循环层（GRU）。</p>
</blockquote>
<blockquote>
<p>嵌入层（EmbeddingLayer）是使用在模型第一层的一个网络层，其目的是将所有索引标号映射到致密的低维向量中，</p>
</blockquote>
<blockquote>
<p>合并层是指将多个网络产生的张量通过一定方法合并在一起，</p>
</blockquote>
<blockquote>
<p>合并层支持不同的合并方法，包括：元素相加（merge.Add）、元素相乘（merge.Multiply）、元素取平均（merge.Average）、元素取最大（merge.Maximum）、叠加（merge.Concatenate）、矩阵相乘（merge.Dot）。</p>
</blockquote>
<blockquote>
<p>奇异值矩阵分解是一种基本的数学工具，被应用于大量的数据挖掘算法中，比较有名的有协同过滤（CollaborativeFiltering），PCA回归</p>
</blockquote>
<blockquote>
<p>矩阵分解的目的是解析矩阵的结构，提取重要信息，去除噪声，实现数据压缩等。比如在奇异值矩阵分解中，信息都集中在头几个特征向量中，使用这几个向量有可能较好地（即均方差尽可能小地）复原原来的矩阵，同时只需要保留较少的数据。</p>
</blockquote>
<blockquote>
<p>SVD基于以下线性代数定理：任何m×n的实数矩阵X可以表示为如下三个矩阵的乘积：m×r的酉矩阵U，被称为左特征向量矩阵；r×r的对角阵S，被称为特征值矩阵；r×n的酉矩阵VT，被称为右特征向量矩阵，其中r≤n。</p>
</blockquote>
<h2 id="5推荐系统"><a class="markdownIt-Anchor" href="#5推荐系统"></a> 5推荐系统</h2>
<blockquote>
<p>矩阵分解可以认为是一种信息压缩。这里有两种理解。第一种理解，用户和内容不是孤立的，用户喜好有相似性，内容也有相似性。压缩是把用户和内容数量化，压缩成k维的向量。</p>
</blockquote>
<blockquote>
<p>第二种理解，从深度学习的角度，用户表示输入层（UserRepresentation）通常用OneHot编码，这没问题，但是通过第一层全连接神经网络就可以到达隐藏层，就是所谓的嵌入层（EmbeddingLayer），也就是我们之前提到的向量压缩过程。</p>
</blockquote>
<blockquote>
<p>从机器学习的角度来说，模型是为了抓住数据的主要特征，去掉噪声。越复杂、越灵活的模型带来的噪声越多，降低维度则可以有效地避免过度拟合现象的出现。</p>
</blockquote>
<blockquote>
<p>一般批量大小为几百，迭代次数可以达到上百到几百范围。损失一般一开始会下降得比较快，随后慢慢下降。通常做法是等损失稳定下来后再结束训练会比较好。</p>
</blockquote>
<blockquote>
<p>训练数据拟合得好，只能说明算法本身是在做正确的优化事情，并不能说明模型在未知的数据集上是否是好的，也不能说明模型抓住了本质，排除了噪声。</p>
</blockquote>
<blockquote>
<p>交替最小二乘法的想法很简单，我们要解决的是分解矩阵M近似等于两个新矩阵A和B的乘积，限制条件是A、B的值不能太大，并且部分M的数据已知。类似于坐标下降法（CoordinateDescent）的想法，我们可以先固定A，这样求B就是一个最小二乘法的问题。类似的，得到了B以后固定B，再求A，循环迭代。如果最后A、B都收敛，即它们在两次迭代间的变换小于一个阈值时，就可以认为找到了问题的解。</p>
</blockquote>
<blockquote>
<p>宽深模型适用的场合是有多个特征，有些特征需要用交叉项特征合成（宽度模型），而有些特征需要进行高维抽象（深度模型）。宽深模型很好地结合了宽度模型和深度模型，同时具有记忆性和普适性，从而提高准确率。</p>
</blockquote>
<blockquote>
<p>协同过滤的含义是，利用众人的数据协助推断。一个经典的例子是，很多人买了牛奶的同时都买了面包，已知你买了牛奶，那么给你推荐面包就是很自然的事情。在实际数据上，这种方法效果一般，原因是类似于亚马逊等网站的商品太多了，用户之间很少能找到有很多重复的商品项，所以相似用户的构造会不准确。因而类似的规则便有很多噪声。</p>
</blockquote>
<blockquote>
<p>因子分解机是谷歌研究科学家S.Rendle教授提出的。它是矩阵分解的推广，可以使用多维特征变量。</p>
</blockquote>
<blockquote>
<p>玻尔兹曼向量机是谷歌副总裁、深度学习的开山鼻祖GeoffreyHinton提出的。该模型建立了电影及其表征之间的概率联系。从用户的行为可以推断出用户对于电影表征的偏好的概率表示；反过来，这些电影表征的偏好又可以用来给用户推荐电影。这种概率联系是通过RBM模型学出来的。</p>
</blockquote>
<blockquote>
<p>评判模型一般有两种指标：线上和线下。</p>
</blockquote>
<blockquote>
<p>线上需要设计实验，基于一定的随机规则对用户、设备或者浏览器Cookie进行分组，然后设定一些指标，观察这些指标在实验期运用新模型是否比旧模型好。</p>
</blockquote>
<blockquote>
<p>线上指标的优点是快速和因果关系明确；缺点是无法测试对长期目标的影响，并且容易不太稳定，受比如新奇效果（NoveltyEffect）或者实验渗透率的影响。</p>
</blockquote>
<blockquote>
<p>通常的做法是，在线下建模型的时候，用线下指标给出一个最好的模型。然后，把这个新模型和现有的在线模型拿到线上去，进行数据收集和统计分析，利用短期指标给出是否要推广新模型的结论。</p>
</blockquote>
<blockquote>
<p>在推荐系统中，评分类的数据一般用均方差（MeanSquaredError）作为评判标准；而对于隐含回馈数据，一般用基于信息检索的概念中的精确率（推荐10部电影，用户看了几部）和召回率（用户感兴趣的5部电影，是否都在推荐列表里）作为最常用的指标。</p>
</blockquote>
<h2 id="6图像识别"><a class="markdownIt-Anchor" href="#6图像识别"></a> 6图像识别</h2>
<blockquote>
<p>卷积神经网络（见图6.3）是一种自动化特征提取的机器学习模型。</p>
</blockquote>
<blockquote>
<p>神经网络就是建立了这样一个映射关系，或者称为函数。它通过建立网状结构，辅以矩阵的加、乘等运算，最后输出每个图像属于每个类别的概率，并且取概率最高的作为我们的决策依据。</p>
</blockquote>
<blockquote>
<p>用深度学习解决图像识别的问题，从直观上讲，是一个从细节到抽象的过程。</p>
</blockquote>
<blockquote>
<p>抽象就是把图像中的各种零散的特征通过某种方式汇总起来，形成新的特征，而利用这些新的特征更容易区分图像的类别。</p>
</blockquote>
<blockquote>
<p>深度神经网络最上层的特征是最抽象的。</p>
</blockquote>
<blockquote>
<p>后向传播算法的本质是高等代数里的链式法则。其原理就是机器不断通过现有参数在批量数据上所得到的标注和这些批量数据的真实标注的差距，给网络指示怎么调整网络模型和过滤器，即各种参数，从而在下一次批量数据上表现更好一些。下一次批量数据经过调整后的模型可能仍有很大的误差，网络会提示怎么进一步调整模型的权重和过滤器。这样不断反复，最终等过滤器和网络权重稳定下来，网络的训练就完成了。</p>
</blockquote>
<blockquote>
<p>卷积神经网络是深度学习的一种模型。它和一般的深度学习模型的主要区别是对模型有两个强假设。一般的深度学习模型只是假设模型有几层，每层有几个节点，然后把上下层之间的节点全部连接起来，这种模型的优点是灵活，缺点是灵活带来的副作用，即过度拟合。</p>
</blockquote>
<blockquote>
<p>过滤器一般需要的参数比较少，比如5×5×3的过滤器需要75个参数就可以了。这和多层神经网络相比，相当于我们只是把隐含层和局部输入联系在一起，而这两层之间的权重只需要75个参数。其他超过这个局部范围的区域的网络权重都是0。</p>
</blockquote>
<blockquote>
<p>第二个是局部像素的相关性，即局部区域的像素值一般差的不太多。基于此衍生了一种处理技术——MaxPooling，即在局部，比如在224×224的格子里，取局部区域像素值的最大值。</p>
</blockquote>
<blockquote>
<p>从另一个角度看，任何一个卷积神经网络其实都是通过对整个神经网络权重附加参数共享这一限制而实现的。所以卷积神经网络和全连接神经网络是可以相互转换的。</p>
</blockquote>
<blockquote>
<p>一般一个卷积层包括3个部分：卷积步骤、非线性变化（一般是relu、tanh、sigmoid等）和MaxPooling。有的网络还包括了Dropout这一步。总结来说，一些流行的卷积神经网络，比如LeNet、VGG16等，都是通过构造多层的卷积层，使得原来“矮胖”型的图像输入层（224×224×3）立体，变成比如1×1×4096之类的“瘦长”型立体，最后做一个单层的网络，把“瘦长”型立体和输出层（类别）联系在一起。</p>
</blockquote>
<blockquote>
<p>在局部扫描的过程中，有一个参数叫步长，就是指过滤器以多大的跨度上下或左右平移地扫描。</p>
</blockquote>
<blockquote>
<p>对于经由过滤器局部扫描后的卷积层图像，由于处理边界不同，一般有两种处理方式。一种是在局部扫描过程中对图像边界以外的一层或多层填上0，平移的时候可以将其移出边界到达0的区域。这样的好处是在以1为步长的局部扫描完以后，所得的新图像和原图像长宽一致，被称作zeropadding（samepadding）。另一种是不对边界外做任何0的假定，所有平移都在边界内，被称作validpadding，使用这种方式通常扫描完的图像尺寸会比原来的小。</p>
</blockquote>
<h2 id="7自然语言情感分析"><a class="markdownIt-Anchor" href="#7自然语言情感分析"></a> 7自然语言情感分析</h2>
<blockquote>
<p>进行情感分析有如下难点：第一，文字非结构化，有长有短，很难适合经典的机器学习分类模型。第二，特征不容易提取。文字可能是谈论这个主题的，也可能是谈论人物、商品或事件的。人工提取特征耗费的精力太大，效果也不好。第三，词与词之间有联系，把这部分信息纳入模型中也不容易。</p>
</blockquote>
<blockquote>
<p>深度学习适合做文字处理和语义理解，是因为深度学习结构灵活，其底层利用词嵌入技术可以避免文字长短不均带来的处理困难。使用深度学习抽象特征，可以避免大量人工提取特征的工作。深度学习可以模拟词与词之间的联系，有局部特征抽象化和记忆功能。</p>
</blockquote>
<blockquote>
<p>第一，文字分词。英语分词可以按照空格分词，中文分词可以参考jieba。第二，建立字典，给每个词标号。第三，把段落按字典翻译成数字，变成一个array。</p>
</blockquote>
<blockquote>
<p>为了克服文字长短不均和将词与词之间的联系纳入模型中的困难，人们使用了一种技术——词嵌入。简单说来，就是给每个词赋一个向量，向量代表空间里的点，含义接近的词，其向量也接近，这样对于词的操作就可以转化为对于向量的操作了，在深度学习中，这被叫作张量（tensor）。</p>
</blockquote>
<blockquote>
<p>从优化的角度讲，深度学习网络还有其他一些梯度下降优化方法，比如Adagrad等。它们的本质都是解决在调整神经网络模型过程中如何控制学习速度的问题。</p>
</blockquote>
<h2 id="8文字生成"><a class="markdownIt-Anchor" href="#8文字生成"></a> 8文字生成</h2>
<blockquote>
<p>基于深度学习的检索式对话系统在后两点上有较大的改进。通过机器学习，可以实现软匹配，不需要询问语句模式一定要在库里出现，如果通过对词汇和其组织顺序的建模发现有较高概率匹配的数据点，就能实现比较好的回应。其次，深度学习方法提供了更高的灵活性，能够实现记忆和识别等功能。</p>
</blockquote>
]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>读书</tag>
      </tags>
  </entry>
  <entry>
    <title>书摘：《你的自律给你自由》-小椰子</title>
    <url>/2021/02/09/%E4%B9%A6%E6%91%98_%E4%BD%A0%E7%9A%84%E8%87%AA%E5%BE%8B%E7%BB%99%E4%BD%A0%E8%87%AA%E7%94%B1-%E5%B0%8F%E6%A4%B0%E5%AD%90.hexo/</url>
    <content><![CDATA[<div class="douban-card-block">
	<a class="douban-card" href="https://book.douban.com/subject/30424251">
		<div class="douban-card-bgimg" style="background-image: url('https://images.weserv.nl/?url=https://img9.doubanio.com/view/subject/s/public/s29970134.jpg');"></div>
		<div class="douban-card-left">
			<div class="douban-card-img" style="background-image: url('https://images.weserv.nl/?url=https://img9.doubanio.com/view/subject/s/public/s29970134.jpg');"></div>
		</div>
		<div class="douban-card-right" style="line-height: 1.7;">
			<div class="douban-card-item"><span>书名: </span><strong>你的自律给你自由</strong></div>
			<div class="douban-card-item"><span>作者: </span><span>小椰子</span></div>
			<div class="douban-card-item"><span>出版年份: </span><span>2018-8</span></div>
			<div class="douban-card-item"><span>评分: </span><span>6.9</span></div>
		</div>
	</a>
</div>
<style>
	.douban-card-block {
		display: flex;
		justify-content: center;
		align-items: center;
		width: 100%;
		max-height: 400px;
	}
	.douban-card {
		display: flex;
		margin: 30px 10px;
		padding: 15px;
		border-radius: 10px;
		position: relative;
		justify-content: center;
		align-items: center;
		overflow: hidden;
		color: antiquewhite;
		text-decoration: none;
	}
	.douban-card:hover {
		text-decoration: none;
	}
	.douban-card-bgimg {
		position: absolute;
		width: 115%;
		height: 115%;
		filter: blur(15px) brightness(0.6);
		background-size: 100%;
		background-position: center;
		background-repeat: no-repeat;
	}
	.douban-card-img {
		position: relative;
		height: 130px;
		width: 80px;
		background-size: 100%;
		background-position: center;
		background-repeat: no-repeat;
	}
	.douban-card-img {
		position: relative;
		height: 130px;
		width: 80px;
	}
	.douban-card-left {
		position: relative;
		display: flex;
		flex-direction: column;
		align-items: center;
	}
	.douban-card-right {
		position: relative;
		display: flex;
		flex-direction: column;
		margin-left: 12px;
		font-size: 16px;
		font-family: 'Courier New', Courier, monospace;
		line-height: 1.3;
		color: antiquewhite;
	}
	.douban-card-item {
		margin-top: 4px;
	}
</style>
<a id="more"></a>
<h2 id="你的不自律正在慢慢毁掉你"><a class="markdownIt-Anchor" href="#你的不自律正在慢慢毁掉你"></a> 你的不自律，正在慢慢毁掉你</h2>
<blockquote>
<p>我见过的最不求上进的人，他们为现状焦虑，又没有毅力践行决心去改变自己。三分钟热度，时常憎恶自己的不争气，坚持最多的事情就是坚持不下去。终日混迹社交网络，脸色蜡黄地对着手机和电脑的冷光屏，可以说上几句话的人却寥寥无几。他们以最普通的身份埋没在人群中，却过着最最煎熬的日子。</p>
</blockquote>
<blockquote>
<p>唯有自律，才是解决人生痛苦的根本途径。</p>
</blockquote>
<blockquote>
<p>许多人习惯将自己不自律的原因推卸给他人和外界环境</p>
</blockquote>
<blockquote>
<p>推卸责任的时候，可能感觉舒服和痛快，却永远无法进步，心智永远无法成熟。趋利避害、逃避责任是人类的天性，但是每个人的人生轨迹都是由自己主宰的。</p>
</blockquote>
<blockquote>
<p>推卸责任容易，坚持一件事很难。想要变得自律，必须从敢于承担责任开始。</p>
</blockquote>
<blockquote>
<p>假如我们像动物一样，听从欲望、逃避痛苦，我们并不是真的自由，因为我们成了欲望和冲动的奴隶。我们不是在选择，而是在服从。唯有自律，自律使我们与众不同，自律令我们活得更高级。</p>
</blockquote>
<h2 id="一个人开始废掉的三种迹象"><a class="markdownIt-Anchor" href="#一个人开始废掉的三种迹象"></a> 一个人开始废掉的三种迹象</h2>
<blockquote>
<p>在大城市里，搞废一个人的方式特别简单。给你一个安静狭小的空间，给你一根网线，最好再加一个外卖电话。好了，你开始废了。</p>
</blockquote>
<blockquote>
<p>低质量的长期宅，确实能改变一个人的心智、外貌，甚至是人生。</p>
</blockquote>
<blockquote>
<p>人喜欢在舒适熟悉的环境中待着。而这种舒适区一旦建立，你就会变得无比依赖，慢慢地爱上周围的墙，恋上舒适的小屋，从而不愿意飞出去看看，怕看到外面熙熙攘攘的世界。</p>
</blockquote>
<blockquote>
<p>一个人开始废掉的迹象之一，就是不再走出自己的舒适区。</p>
</blockquote>
<blockquote>
<p>一个人老去的标志，绝不是老成稳重、沉默寡言，而是不肯再尝试，不肯再容许自己置身不熟悉的境地。</p>
</blockquote>
<blockquote>
<p>当你停止了学习、故步自封，将自己囚禁在得过且过的牢笼中，那么你已经朝平庸迈进了一大步。</p>
</blockquote>
<blockquote>
<p>一个人开始废掉的迹象之二，便是沉溺于短期快感之中，不再做长期投入。</p>
</blockquote>
<blockquote>
<p>毁掉我们的不是我们所憎恨的东西，而恰恰是我们所热爱的东西。</p>
</blockquote>
<blockquote>
<p>任何时候，一个人都不应该做自己情绪的奴隶，不应该使一切行动都受制于自己的情绪，而应该反过来控制情绪。无论境况多么糟糕，你应该去努力支配你的环境，把自己从黑暗中拯救出来。</p>
</blockquote>
<blockquote>
<p>一个人开始废掉的迹象之三，是沦为情绪的奴隶。</p>
</blockquote>
<h2 id="二十几岁你凭什么穷得心安理得"><a class="markdownIt-Anchor" href="#二十几岁你凭什么穷得心安理得"></a> 二十几岁，你凭什么穷得心安理得</h2>
<blockquote>
<p>二十几岁的日子，应该是炙热的、丰富的、无所畏惧的。我只想跳脱出理所当然的平庸，拒绝我不愿妥协的一切。</p>
</blockquote>
<blockquote>
<p>二十几岁，穷并不可怕，但是千万不要穷得心安理得。</p>
</blockquote>
<h2 id="比赚钱更重要的是培养这三种思维方式"><a class="markdownIt-Anchor" href="#比赚钱更重要的是培养这三种思维方式"></a> 比赚钱更重要的是培养这三种思维方式</h2>
<blockquote>
<p>财富是一个人思考能力的产物。”唯有去连接更多的人和信息，突破自己的认知局限，转变自己的思维方式，进而转化成行动，才能让自己摆脱又穷又忙的窘境。</p>
</blockquote>
<h2 id="千万别让这三种心态害了你"><a class="markdownIt-Anchor" href="#千万别让这三种心态害了你"></a> 千万别让这三种心态害了你</h2>
<blockquote>
<p>现实生活中，我们总能看到一些安于现状的人。他们胆小而拘谨，害怕做出任何改变。就算机会摆在眼前，他们也会因为害怕而不敢向前一步。</p>
</blockquote>
<blockquote>
<p>生活并不会遵从某个人的愿望发展。改变随时有可能降临，但积极地面对改变却会让你发现更好的奶酪。</p>
</blockquote>
<blockquote>
<p>02</p>
</blockquote>
<blockquote>
<p>嫉妒为何物？自己不去努力，不去付诸行动，揪着对方的弱点不放，连自己也落得下作，这就叫嫉妒。</p>
</blockquote>
<blockquote>
<p>在我们的生活中，有多少人敢于抓住机会，推荐自己？我们的心态，更像成语“守株待兔”中的主人公，守着一个叫作“机会”的树桩，幻想着能够被机遇和好运砸中。</p>
</blockquote>
<blockquote>
<p>人生有时就像一场赛跑，任何的拖沓都可能导致结果的不理想。机遇总是稍纵即逝，没有人会等你，现实更不会迁就你。不要抱着“守株待兔”的心态，让失败和懊悔一步步向你逼近。</p>
</blockquote>
<h2 id="为什么你奋斗了那么久还是挤不进有钱阶层"><a class="markdownIt-Anchor" href="#为什么你奋斗了那么久还是挤不进有钱阶层"></a> 为什么你奋斗了那么久，还是挤不进“有钱阶层”</h2>
<blockquote>
<p>阻碍你通往财富自由的，不是你的原生家庭，也不是你不够努力，而是你的思维方式。</p>
</blockquote>
<blockquote>
<p>穷人总是倾向于得到一份稳定的薪水或计时工资。每个月的同一时间，有一笔固定的钱汇到他们的账户上，这能让他们有安全感。然而这份安全感也是有代价的，代价便是：凭着每个月稳定的固定工资，你永远无法实现财富自由。</p>
</blockquote>
<blockquote>
<p>富人，通常都有着自己的赚钱体系。或创业，自己成立公司，或成为某一领域不可替代的专家。他们往往早早就建立好了自己的系统，利用别人的时间赚钱。完成了初期的资本积累后，剩下的就是让钱生钱。房产增值、利息、股权收益……</p>
</blockquote>
<blockquote>
<p>如果你的目标是舒适，你就永远没有成为富人的机会。但如果你的目标是成为有钱人，那你终将会有大把舒适的机会。</p>
</blockquote>
<h2 id="有这种想法的人只会越过越穷"><a class="markdownIt-Anchor" href="#有这种想法的人只会越过越穷"></a> 有这种想法的人，只会越过越穷</h2>
<blockquote>
<p>穷人通常目光短浅、精神短视，恐惧未知、拒绝改变，因此重复做着错误的选择。</p>
</blockquote>
<blockquote>
<p>反观我们自身，有多少人会把轻松的事情留给今天的自己，把困难的事情留给明天？对于穷人来说更是如此。</p>
</blockquote>
<blockquote>
<p>贫穷，既是贫穷的原因，也是贫穷的结果。希望你我能从这四点贫穷的本质中获得启发，学会跳出局限性、用长远的眼光看待问题；积极拓宽获取知识的途径，明确自己的目标；克服拖延和懒惰，学会自控。</p>
</blockquote>
<h2 id="一个人有没有见识就藏在这三个细节里"><a class="markdownIt-Anchor" href="#一个人有没有见识就藏在这三个细节里"></a> 一个人有没有见识，就藏在这三个细节里</h2>
<blockquote>
<p>我始终相信，我读过的所有书都不会白读，它总会在未来日子的某一个场合帮助我表现得更出色，读书是可以给人以力量的，它更能给人快乐。</p>
</blockquote>
<blockquote>
<p>那些看似无用的诗词歌赋、历史人文，其实会潜藏到一个人的气质里、谈吐上。有见识的人，总会坚持阅读，不断刷新自己的眼界，挑战新的领域。所以他们才能气质如兰、口吐莲花，能对身边的事物都有着自己深刻的见解。</p>
</blockquote>
<blockquote>
<p>有见识的人，会从一个地方去到另一个地方，去感受不同文化的差异、不同思想的碰撞，让自己的视野和格局都得到进一步的提升。</p>
</blockquote>
<blockquote>
<p>旅行，不是单纯的“上车睡觉、下车拍照”，而是一种改变。去看日出日落、星辰大海，见天地、见众生、见自己，与自己进行深层次的交流。</p>
</blockquote>
<blockquote>
<p>缺见识，让多少人平庸一辈子。别总拘泥在你以为熟悉又舒适的小圈子里，世界从来不只是你身边的样子。</p>
</blockquote>
<h2 id="世界正在惩罚不爱思考的人"><a class="markdownIt-Anchor" href="#世界正在惩罚不爱思考的人"></a> 世界正在惩罚不爱思考的人</h2>
<blockquote>
<p>外表看起来勤奋，却忽略了更重要的精神上的思考。越来越多的人在逃避思考，希望能用战术上的勤奋，来掩饰战略的懒惰。</p>
</blockquote>
<blockquote>
<p>不爱思考的人，将自己有限的时间和精力都安排得满满当当，效果却不理想。不爱思考，你的勤奋和忙碌毫无价值。</p>
</blockquote>
<blockquote>
<p>我们刷着公众号、微博、今日头条、知乎，被刺激性的标题所吸引，打开正文后匆匆扫了两眼又马上关掉；占领着热搜榜的永远是明星八卦、丑闻爆料、矛盾纠葛，对个人成长毫无意义，最大的用处就是成为人们津津乐道的谈资；我们在游戏中寻找成就感，却不知自己的上升空间正被一点一点占据；我们越来越缺乏耐心去好好看完一本书，相对的，却收藏了越来越多篇“干货”，渴望通过一篇文章就能摆脱平庸、发家致富。</p>
</blockquote>
<blockquote>
<p>逃避思考、只顾当下的娱乐，也许会让我们暂时过得很轻松。然而，时间一长，你会发现：不爱思考的人，正在慢慢失去深度思考的能力，变得越来越肤浅、越来越缺乏内涵。</p>
</blockquote>
<blockquote>
<p>选择目标、找到重点，过滤掉不必要的信息，才能让你告别低水平勤奋。</p>
</blockquote>
<blockquote>
<p>我们的大脑，本质上是排斥深度思考的。一方面，深度思考要求投入大量的精力，另一方面，我们进行深度思考时，接收不到外界的刺激。</p>
</blockquote>
<blockquote>
<p>我们宁愿将碎片时间拿来愉悦自己，用各种不费脑的娱乐来取悦自己。</p>
</blockquote>
<blockquote>
<p>你想要学会深度思考，就去练习深度思考。即使刻意练习的过程中，会伴随着一定程度的痛苦。但当你一步一步接近自己的目标时，你会乐在其中，获得更高级的愉悦。</p>
</blockquote>
<blockquote>
<p>人生最终的价值在于觉醒和思考的能力，而不只在于生存。”如果你不想总是脑袋空空，带着混沌的大脑碌碌无为地度过一生，你应该拥有思考的能力。</p>
</blockquote>
<h2 id="你活得那么累为什么还生活在社会底层"><a class="markdownIt-Anchor" href="#你活得那么累为什么还生活在社会底层"></a> 你活得那么累，为什么还生活在社会底层</h2>
<blockquote>
<p>在这个快节奏的社会中，收获并不是与付出成正比的，而是与付出的稀缺性成正比。</p>
</blockquote>
<blockquote>
<p>一个人是否能够创造价值，决定其是否值钱；而一个人所拥有的能力是否稀缺，决定其能够值多少钱。</p>
</blockquote>
<blockquote>
<p>为什么你那么辛苦，却仍然生活在社会底层？决定你待遇的，不是你有多努力，甚至也不是你有多能干，而是你的位置有多不可取代，你的核心竞争力有多强，你有多不可复制。</p>
</blockquote>
<h2 id="别让你的精致仅仅是生活在朋友圈里"><a class="markdownIt-Anchor" href="#别让你的精致仅仅是生活在朋友圈里"></a> 别让你的精致，仅仅是生活在朋友圈里</h2>
<blockquote>
<p>不少人沉溺在他人对自我的评价里，因此费力地迎合着别人的喜好、刻意讨好，在朋友圈里营造着假象、发着违心的话语。</p>
</blockquote>
<blockquote>
<p>幸福是一种内心的稳定。当你开始关注自己、认真生活，你会发现，比起虚拟世界的点赞，每天都在进步的自己更值得期待。</p>
</blockquote>
<h2 id="未来的你会感谢现在自律的自己"><a class="markdownIt-Anchor" href="#未来的你会感谢现在自律的自己"></a> 未来的你，会感谢现在自律的自己</h2>
<blockquote>
<p>及时享乐，放纵自己的欲望，看上去活得随心所欲。但她却不知道：每一个不自律的行为，都会给她带来更大的痛苦。</p>
</blockquote>
<blockquote>
<p>不自律，让一个人在浑浑噩噩、随波逐流的日子里，毫无意义地耗费着生命。到头来，身体和意志力都在自我放纵中逐渐沉沦，一个人离毁灭也就不远了。</p>
</blockquote>
<blockquote>
<p>我们上班摸鱼、刷朋友圈，下班打游戏、看没有营养的网文和狗血电视剧。我们毫无顾忌地吃垃圾食品，放弃健身和有益的阅读。我们熬夜修仙，仿佛时间永远不够用，内心的空虚和迷茫却渐渐将我们吞噬。</p>
</blockquote>
<blockquote>
<p>年少时，我以为随心所欲才是自由。直到现在才明白，自律，才能带来真正的自由。</p>
</blockquote>
<blockquote>
<p>当自律成为一种习惯、一种生活方式，一个人的人格和智慧也会变得更加完善。</p>
</blockquote>
<blockquote>
<p>节制的本质就是认识自己。只有自律，才能让你洗尽铅华，遇见最本真的自己，收获最纯粹的快乐。</p>
</blockquote>
<blockquote>
<p>我不再暴躁地吃下很多东西，而是学会享受食物最原本的滋味。慢慢地咀嚼每一口米饭、每一根青菜，只要一点点美味就足以让我心满意足；我不再浮躁地追求别人拥有的东西，而是让心灵真正沉静下来，做些对自己来说最重要的事情；我开始倾听内心的声音，开始爱上了规律的生活。</p>
</blockquote>
<blockquote>
<p>那些活得极度不自律的人，大部分都作茧自缚，在堕落中慢慢沉沦。做欲望的奴隶看似轻松，到头来却只会给我们带来更大的痛苦。</p>
</blockquote>
<blockquote>
<p>不懂节制的人，总是在内疚、焦虑和无尽的悔恨中煎熬。而自律，才是唯一的救赎。月满则亏，水满则溢。节制，让自己更能珍惜生活中的每一寸感动，获得真正的喜悦。</p>
</blockquote>
<h2 id="毁掉你的不是高房价而是没有方向的自己"><a class="markdownIt-Anchor" href="#毁掉你的不是高房价而是没有方向的自己"></a> 毁掉你的不是高房价，而是没有方向的自己</h2>
<blockquote>
<p>没有方向的努力，不是投资自己，而是瞎忙活、花钱打水漂。看起来正能量无比，实际上毫无意义。除了感动自己，永远也不可能让你成为成功者，过上你想要的生活。</p>
</blockquote>
<blockquote>
<p>选对方向，比盲目前进更重要。投资自己也要讲究回报，正确地投资自己不单单是为了赚取金钱和所谓的房子，更重要的是让我们活得更有尊严、更有价值。</p>
</blockquote>
<h2 id="层次越低的人越喜欢花时间在这三件事上"><a class="markdownIt-Anchor" href="#层次越低的人越喜欢花时间在这三件事上"></a> 层次越低的人越喜欢花时间在这三件事上</h2>
<blockquote>
<p>层次越低的人，越喜欢花时间在娱乐八卦上。越来越多的人患上了网络依存症，对各类娱乐新闻上瘾、产生依赖，人云亦云，附和跟风，沉溺在虚拟的世界中不能自拔。</p>
</blockquote>
<blockquote>
<p>你的时间花在哪，你就会成为什么样的人。格局高的人，不会花太多时间在娱乐上。</p>
</blockquote>
<blockquote>
<p>层次越低的人，比起关注自己，越喜欢花更多的时间在关注他人上。</p>
</blockquote>
<blockquote>
<p>当一个人把他的精力和时间从关注外界转向关注自身的成长时，才能拥有更高的格局。</p>
</blockquote>
<blockquote>
<p>层次越低的人，越喜欢花时间在不重要不紧急的事上。</p>
</blockquote>
<h2 id="第3章圈子决定了你的层次"><a class="markdownIt-Anchor" href="#第3章圈子决定了你的层次"></a> 第3章圈子决定了你的层次</h2>
<blockquote>
<p>一辈子很长，要和有趣的人在一起。</p>
</blockquote>
<h2 id="人际交往中这样说话的人不可深交"><a class="markdownIt-Anchor" href="#人际交往中这样说话的人不可深交"></a> 人际交往中这样说话的人不可深交</h2>
<blockquote>
<p>对亲近的人挑剔是本能，但克服本能，做到对亲近的人不挑剔，则是种教养。</p>
</blockquote>
<blockquote>
<p>跟有同理心的人聊天。和这样的人说话，总是有如沐春风之感。同理心，又叫换位思考，是指站在对方立场设身处地思考的一种方式。有同理心的人，能够体会他人的情绪，理解他人的立场和感受。</p>
</blockquote>
<h2 id="边界感才是人与人之间最宝贵的品质"><a class="markdownIt-Anchor" href="#边界感才是人与人之间最宝贵的品质"></a> 边界感，才是人与人之间最宝贵的品质</h2>
<blockquote>
<p>真正成熟的人，在对待朋友的时候，懂得明确界限、自尊自爱。当界限感逐渐缺失，朋友间所有的东西都拿来共享，反而不利于关系的稳定和持续。</p>
</blockquote>
<blockquote>
<p>真正成熟的人，对待亲人的时候，懂得真诚沟通、保持各自的人格独立。很多人在试图维系亲人间的亲近感时，不自觉地放弃或者模糊了与亲人的界限，这样做无疑会损害彼此的关系。</p>
</blockquote>
<h2 id="判断一个人是否靠谱就看这三点"><a class="markdownIt-Anchor" href="#判断一个人是否靠谱就看这三点"></a> 判断一个人是否靠谱，就看这三点</h2>
<blockquote>
<p>真正靠谱的人，拥有很强的执行力，凡是答应别人的事就一定会做到。正因如此，我们才更愿意安心地把事情交给他，我们才会发自内心去信任他。</p>
</blockquote>
<blockquote>
<p>一个靠谱的人，为人处世坦荡磊落、问心无愧。这样的人，往往更容易得到信赖与尊重，人生更容易顺风顺水。</p>
</blockquote>
<blockquote>
<p>如果一件事情很烦琐，他会列出所有的细节，分解任务。如果一件事情很重要，他会预留出时间多检查几遍。如果一件事情可能有漏洞，他会尽可能地预想出每一种意外情况，事先想好补救措施。</p>
</blockquote>
<blockquote>
<p>在物欲横流、浮躁焦虑的现代社会，一个执行力强、做事磊落、喜欢未雨绸缪的人，更能带给我们稳妥和信赖。</p>
</blockquote>
<h2 id="这几种人会不断拖垮你一定要远离"><a class="markdownIt-Anchor" href="#这几种人会不断拖垮你一定要远离"></a> 这几种人会不断拖垮你，一定要远离</h2>
<blockquote>
<p>几乎99.9%的父母都会不自觉地对小孩进行情感勒索，这种情况只会让小孩越来越觉得跟父母相处是被迫的，也无法享受跟父母相处的快乐，甚至觉得跟父母通个电话都有压力。</p>
</blockquote>
<h2 id="人际交往中永远不要和这三类人纠缠"><a class="markdownIt-Anchor" href="#人际交往中永远不要和这三类人纠缠"></a> 人际交往中，永远不要和这三类人纠缠</h2>
<blockquote>
<p>生活只有10%是靠你创造的，而有90%则是看你如何去对待的。”我们一生的精力十分有限，不是每个人都值得你去浪费口舌。</p>
</blockquote>
<h2 id="什么样的朋友最值得你用心交"><a class="markdownIt-Anchor" href="#什么样的朋友最值得你用心交"></a> 什么样的朋友最值得你用心交</h2>
<blockquote>
<p>有趣的朋友在一起，他们在一念之间就能计划出一个令人惊喜的行程，喜欢即刻出发，喜欢未知的挑战；他们对生活充满好奇与热情，就像一个永不疲倦的小太阳，随时散发着正能量；他们有时脑洞奇大无比，有时又像小孩子般纯真，总是想尝试新鲜的事物。</p>
</blockquote>
<blockquote>
<p>有趣的人，他不是走进你的世界，而是为你打开一扇窗去参观他的世界。</p>
</blockquote>
<h2 id="一个人的涵养有多高看这三点就知道"><a class="markdownIt-Anchor" href="#一个人的涵养有多高看这三点就知道"></a> 一个人的涵养有多高，看这三点就知道</h2>
<blockquote>
<p>越有涵养的人，越喜欢在低调中修炼自己。低调的人，理性又不浮躁，谦虚却不卑微，不争强好胜、不事事张扬。</p>
</blockquote>
<blockquote>
<p>腹有诗书气自华。读书，才是体现一个人涵养高低的最好方式。</p>
</blockquote>
<blockquote>
<p>一个人的外表，会随着时间的流逝而悄然改变，唯有内在的涵养会历久弥新。</p>
</blockquote>
<h2 id="迷茫时培养这三种思维方式让自己增值"><a class="markdownIt-Anchor" href="#迷茫时培养这三种思维方式让自己增值"></a> 迷茫时，培养这三种思维方式让自己增值</h2>
<blockquote>
<p>所谓的绿灯思维便是，对自己接触到的新信息，保持一种开放的心态，不要带有任何偏见或先入为主。只要一有人提出任何想法或建议，你就要开始思考：为什么这个想法或建议是可行的。</p>
</blockquote>
<blockquote>
<p>学习不只是一段在脑子里完成的过程，只有当你真正将自己学会的东西变成实际行动时，你才是在真正地学习。</p>
</blockquote>
<h2 id="做对这三点一年时间快速提升学习和工作能力"><a class="markdownIt-Anchor" href="#做对这三点一年时间快速提升学习和工作能力"></a> 做对这三点，一年时间快速提升学习和工作能力</h2>
<blockquote>
<p>人最终要走上一条由自我意志推动的路。那种意志你可能一时看不清，却能感受到它和周围磕磕绊绊的摩擦。摩擦越剧烈，人就越痛苦。而你越痛苦，就越说明周遭环境和你的意志之间不匹配，所以你不得不改变你的处境。</p>
</blockquote>
<blockquote>
<p>一个人如果长期没有目标，得过且过，自然会对生活感到厌倦，容易精神疲乏，甚至造成忧郁、焦虑等症状。想要走出这种困境，首先应为自己订立生活目标。</p>
</blockquote>
<blockquote>
<p>对生活现状的不满意，是你想要进步的证据。年轻时的投资肯定能收回成本，只有不断学习下去，你才能遇见更好的自己。</p>
</blockquote>
<h2 id="每天早上六点起床你的人生赚了什么"><a class="markdownIt-Anchor" href="#每天早上六点起床你的人生赚了什么"></a> 每天早上六点起床，你的人生赚了什么</h2>
<blockquote>
<p>能控制早晨的人，方可控制人生。</p>
</blockquote>
<blockquote>
<p>你怎样度过一个早上，基本就怎样度过一生。</p>
</blockquote>
<h2 id="哪个瞬间会让你觉得读书真有用"><a class="markdownIt-Anchor" href="#哪个瞬间会让你觉得读书真有用"></a> 哪个瞬间会让你觉得读书真有用</h2>
<blockquote>
<p>读书的用处，不一定在于功成名就、荣华富贵，更重要的是提升了一个人的修养和谈吐，拓展了眼界和见识，让你拥有更多选择的权利，获得内心的平静。</p>
</blockquote>
<blockquote>
<p>读书让人拥有富足的心灵、无可比拟的气质。一个人的美貌会随着岁月的流逝而慢慢消失殆尽，而美好的气质却能够永存不朽。</p>
</blockquote>
<blockquote>
<p>读书的意义大概就是，用生活所感去读书，用读书所得去生活吧。</p>
</blockquote>
<blockquote>
<p>一日不读书，尘生其中；两日不读书，言语乏味；三日不读书，面目可憎。</p>
</blockquote>
<blockquote>
<p>你读过的书，暴露了你的人生层次。身处这样一个浮躁的时代，能坚持读书的人，更显可贵。而总有一天，你会发现，你读过的书、学过的知识会由量变到质变，进而给你的人生带来意想不到的改变。</p>
</blockquote>
<h2 id="坚持做这三件事活成自己想要的模样"><a class="markdownIt-Anchor" href="#坚持做这三件事活成自己想要的模样"></a> 坚持做这三件事，活成自己想要的模样</h2>
<blockquote>
<p>如果我们连续打了五个小时的游戏，或者连续逛了五个小时的网店、看了五个小时的电视剧，我们通常会产生一些罪恶感。这种罪恶感达到一定的阈值后，我们会开始暗示自己的大脑：要开始学习或工作了。</p>
</blockquote>
<blockquote>
<p>连续做五个小时的轻松、熟练、无关紧要的伪工作，却不会引起我们的罪恶感。虽然同样是浪费时间，但伪工作却会麻痹我们的大脑，让我们自欺欺人地以为我们在做的是正经事。</p>
</blockquote>
<blockquote>
<p>花在处理不重要的琐事上的时间，丝毫不能证明你的能力。当明白这个道理后，我开始拒绝做伪工作，过滤掉那些不必要、完全是消磨时间的工作，集中精力去做那些最重要的事。</p>
</blockquote>
<blockquote>
<p>为了不让自己脑袋变得越来越空，我一直坚持深度阅读。在阅读过程中，读到有感触的内容，有时候会摘抄进笔记本里，有时候会在旁边标注读书笔记。</p>
</blockquote>
<blockquote>
<p>静下心来读一本书，可以跨越时空，接触到那些最杰出的想法，体味最美妙的文笔。坚持深度阅读，让我学会了深度思考，遇到生活中的一些问题可以更加游刃有余地处理解决。</p>
</blockquote>
<blockquote>
<p>一心多用，很可能让我们的大脑受到伤害。一心多用，是对深度思考能力的摧残。</p>
</blockquote>
<blockquote>
<p>专注，是这个时代最稀缺又最重要的品质。</p>
</blockquote>
<blockquote>
<p>除非你去改变一些你每天都做的事情，否则，你的生活只能一如既往。成功的秘密就隐藏在你的日常行为中。</p>
</blockquote>
<h2 id="为什么有的女生活得像开了挂"><a class="markdownIt-Anchor" href="#为什么有的女生活得像开了挂"></a> 为什么有的女生活得像开了挂</h2>
<blockquote>
<p>每一个不自律的行为，都只会让自己离理想的状态越来越远。每一个开挂的人生背后，都是扎扎实实的努力和付出。</p>
</blockquote>
<blockquote>
<p>在人生的道路上，为追求真正属于自己的生活而竭尽全力，饱尝辛酸和痛苦的人生才是魅力的人生。</p>
</blockquote>
<blockquote>
<p>人生没有白走的路，每一步都算数。在漫长的岁月里，你是否为自己的生命注入了新的东西？还是依旧浑浑噩噩，羡慕着别人开挂般的人生，自己却不肯付出努力？</p>
</blockquote>
<h2 id="不摆脱这种思维模式将会毁掉你的一生"><a class="markdownIt-Anchor" href="#不摆脱这种思维模式将会毁掉你的一生"></a> 不摆脱这种思维模式，将会毁掉你的一生</h2>
<blockquote>
<p>悲观的人很容易放弃，常常陷入对自我的怀疑、批判之中。习惯性的悲观想法会导致更多不顺利的事降临到我们头上，而且这种想法会使我们很容易陷入抑郁状态，使我们不能发挥出原有的能力。</p>
</blockquote>
<blockquote>
<p>用悲观的思维模式看待人生的人，常常在开始做一件事情之前就想到种种失败的可能性。大量关于失败的悲观预想，会让一个人沉浸在挫败和痛苦之中。为了避开这些痛苦，悲观的人干脆不再尝试，不再付诸行动。这样只会导致失去更多的机会，失去从头再来的可能性，变得愈加平庸。</p>
</blockquote>
<blockquote>
<p>轻度的悲观可以让我们在做事之前三思，不会做出愚蠢的决定。但总是用悲观的思维模式去看待事物，我们永远不敢去尝试新事物，也不会知道我们的潜力有多大。</p>
</blockquote>
<h2 id="正确的思维方式比所谓的努力更重要"><a class="markdownIt-Anchor" href="#正确的思维方式比所谓的努力更重要"></a> 正确的思维方式，比所谓的努力更重要</h2>
<blockquote>
<p>世界并不是非对即错、非黑即白。单一思维会让我们思想僵化，缺乏创新。我们需要学习不陷入固有的思维模式，用更经济的方式解决问题。只有这样，才能跳出局限，以前所未有的新视角、新观点去认识事物。</p>
</blockquote>
<blockquote>
<p>省钱”的最高境界，就是投资自己。将自己的时间和精力花费在未来能够增值的事情上，才能让自己变得更值钱。</p>
</blockquote>
<blockquote>
<p>低端勤奋，不需要动脑，精疲力竭后，感动了自己，导致他们不可能提升自己，没办法让自己更值钱。</p>
</blockquote>
<blockquote>
<p>当你的勤奋不能转化为价值时，你的勤奋只是低端的勤奋。低端的勤奋，把自己感动得一塌糊涂，却收效甚微。</p>
</blockquote>
<h2 id="高层次的人生从来不在这三件事上节省"><a class="markdownIt-Anchor" href="#高层次的人生从来不在这三件事上节省"></a> 高层次的人生，从来不在这三件事上节省</h2>
<blockquote>
<p>不出时间运动的人，迟早会腾出时间来减肥；腾不出时间睡觉的人，迟早会腾出时间来生病。</p>
</blockquote>
<blockquote>
<p>高层次的人生，从来不在经营人脉这件事上节省。在这个时代，人脉带来大量的知识跨界，能够让你学得更快、视野更广、思考更全面。</p>
</blockquote>
<blockquote>
<p>只有跨出自己的舒适区，去接触自己的未知领域，不断地学习和改进，才是对自己最好的投资。</p>
</blockquote>
<blockquote>
<p>高层次的人生，从来不在投资自己这件事上节省。多读书，汲取优秀的人的思想；多旅行，变得更加豁达开朗；多培养挖掘自己的技能，让自己在职场中变得不可代替，这些都能帮助我们成为更好的人。</p>
</blockquote>
<h2 id="自律的人生开了挂"><a class="markdownIt-Anchor" href="#自律的人生开了挂"></a> 自律的人生开了挂</h2>
<blockquote>
<p>当一个人缺乏自律的时候，他做的事情总是在受习惯和诱惑的影响，要么就是被他人的思想观念所扰，几乎永远不可能去做内心真正渴望的事。你会发现：那些自律到极致的人，都拥有了开挂的人生。</p>
</blockquote>
<blockquote>
<p>自律的前期是兴奋的，中期是痛苦的，后期是享受的。但有没有发现，大部分人都在自律的中期——痛苦期徘徊太久，以至于把痛苦当作自律。</p>
</blockquote>
<blockquote>
<p>千万不要放纵自己，给自己找借口。对自己严格一点，时间长了，自律便成为一种习惯、一种生活方式，你的人格和智慧也因此变得更加完美。</p>
</blockquote>
<h2 id="这个不经意的坏习惯会让你越过越穷"><a class="markdownIt-Anchor" href="#这个不经意的坏习惯会让你越过越穷"></a> 这个不经意的坏习惯，会让你越过越穷</h2>
<blockquote>
<p>如果你确实很有钱，在高档商品上随便挥霍一点倒也无妨。但假如你还只是个想要致富的普通人，那么，这样的消费不可能让你成为有钱人，永远也不会。</p>
</blockquote>
<blockquote>
<p>坚持记账，可以让自己从日常开支中总结出规律，避免自己又在不经意间增加不必要的开支。更重要的是，可以通过记账培养自己的耐心，有规律地规划自己的生活。只有逼着自己看清在消费上的坏习惯，才能真正有所成长。</p>
</blockquote>
<blockquote>
<p>不合理的消费习惯，却只会让你在物质中迷失自我、无法掌控自己的人生。不要让这个不经意的坏习惯，导致你越来越穷。</p>
</blockquote>
<h2 id="越会赚钱的人越喜欢将时间花在这三件事上"><a class="markdownIt-Anchor" href="#越会赚钱的人越喜欢将时间花在这三件事上"></a> 越会赚钱的人，越喜欢将时间花在这三件事上</h2>
<blockquote>
<p>这个世界很残酷，努力不一定有结果，但是不努力一定没结果。人生，从来不怕大器晚成，怕的是一生平庸。希望年轻的我们，都能尽力而为，不要仅仅满足于现状。</p>
</blockquote>
<h2 id="三十岁之前请逼自己成为这种人"><a class="markdownIt-Anchor" href="#三十岁之前请逼自己成为这种人"></a> 三十岁之前，请逼自己成为这种人</h2>
<blockquote>
<p>在这个国度，只有不停奔跑，才能让你保持在原地。如果你要抵达另一个地方，你必须以双倍于现在的速度奔跑。只有掌控好时间的人，才能掌控自己的人生。</p>
</blockquote>
<blockquote>
<p>生活当中，有趣和好奇心是为了取悦自己，有意思和有用是为了取悦别人。</p>
</blockquote>
<blockquote>
<p>与摄入过多垃圾食品和含糖饮料一样，“无趣的生活”会导致细胞损伤，加速人体老化，进而缩短寿命。</p>
</blockquote>
<blockquote>
<p>“走出你的舒适区，去感受、去接触奇迹发生的地方，感受尴尬、感受嘲笑、感受冒险。”接触奇怪的事情或情境，接触狂野的想法，接触让你哆嗦的事情，接触奇怪的景色、全新的声音。相信我，会很有意思的。</p>
</blockquote>
<blockquote>
<p>当一个人缺乏自律的时候，他做的事情永远受到即时诱惑的影响，永远也不可能去做内心真正渴望的事情。</p>
</blockquote>
<h2 id="层次越低的人越喜欢拖延"><a class="markdownIt-Anchor" href="#层次越低的人越喜欢拖延"></a> 层次越低的人，越喜欢拖延</h2>
<blockquote>
<p>别把窘境迁怒于命运或别人，唯一可以抱怨的，只是不够努力的自己。</p>
</blockquote>
<blockquote>
<p>我们都因拖延而焦虑，却又在焦虑中拖延。</p>
</blockquote>
<blockquote>
<p>“人们拖沓的主要原因是恐惧。”我们总是担心被他人评判或者自我评判，害怕自己的不足被发现，害怕付出最大的努力还是做得不够好，害怕达不到要求。</p>
</blockquote>
<blockquote>
<p>学习新的知识、进行一项有挑战的工作，这类任务会让我们大脑的某个部分发出疼痛的信号，你会不由自主地想将任务滞后，选择“待会儿再说”。</p>
</blockquote>
<blockquote>
<p>在做一项重要任务的时候，找一个可以让你静下心来、集中精神的工作区域。</p>
</blockquote>
<blockquote>
<p>将一项大的、复杂的任务分解成简单、具体的步骤，按照步骤来完成，并且记录进度，最好找人监督你的成果。</p>
</blockquote>
<blockquote>
<p>逃避是可耻的，也并没有用，只有行动才是治疗拖延的最佳良药。</p>
</blockquote>
<h2 id="为什么叫你不要过度自律"><a class="markdownIt-Anchor" href="#为什么叫你不要过度自律"></a> 为什么叫你不要过度自律</h2>
<blockquote>
<p>其实，大多数人的意志力都很薄弱，因为自律只是一时的行为，而失控却是生活的常态。</p>
</blockquote>
<blockquote>
<p>自律需要大量的能量。每个人的自控力就像肌肉一样有限，它被使用之后会渐渐疲惫。如果你不让肌肉休息，你就会完全失去力量，就像运动员把自己逼到筋疲力尽一样。每次使用自控力都会有消耗，任何给你的身心带来压力的东西，都有可能摧毁你的意志力。</p>
</blockquote>
<blockquote>
<p>为什么自律会这么难？因为我一开始就给自己定了一个过高的目标，这个目标让我时刻处于压力环境下。当我们感到情绪低落、感到压力巨大时，大脑更容易受到诱惑。对我来说，那高脂肪、高糖分的“安慰”食物，比什么都能缓解我的压力，却也因此，摧毁了我的自控力。</p>
</blockquote>
<blockquote>
<p>在自律这件事情上，任何挫折都会引起这种恶性循环。你可能只因多喝了一杯酒、多玩了一局游戏，或者晚起了十分钟，就会陷入无限的自责中，为了安抚这种情绪，你会倾向于喝更多的酒、玩更多局游戏、干脆赖在床上不起来。导致更多堕落的行为并不是第一次的放弃，而是第一次放弃之后产生的羞耻感、罪恶感、失控感和绝望感。</p>
</blockquote>
<blockquote>
<p>我们都知道只有自律才能获得自由。但是过度自律却容易引起适得其反的效果。每个人的意志力都是有限的，一旦你将它消耗殆尽，你在诱惑面前就会毫无防备。</p>
</blockquote>
<h2 id="你对待生活的态度暴露了你的层次"><a class="markdownIt-Anchor" href="#你对待生活的态度暴露了你的层次"></a> 你对待生活的态度，暴露了你的层次</h2>
<blockquote>
<p>现在的我们，越来越习惯凑合和将就。拿工作忙当借口，吃着油腻的快餐、放弃健身和阅读，每天顶着黑眼圈浑浑噩噩地度过。</p>
</blockquote>
<blockquote>
<p>一个人专注于寻找生活中的美好、讲究生活情趣的过程，也就是提升自己、重塑身心的过程。</p>
</blockquote>
<blockquote>
<p>层次越高的人，越不喜欢将就。你越是将就，人生就越是不讲究。你</p>
</blockquote>
<blockquote>
<p>学会培养生活的情趣，可以从简单的小事开始：买一张柔软舒适的床，遵循早睡早起的生物钟；养几株充满生命力的盆栽，将房间布置得整洁干净；冰箱里塞满水果与蔬菜，每天为自己做一顿营养又健康的早餐；坚持锻炼身体，拒绝消极的情绪，学会将元气满满的微笑挂在嘴边。</p>
</blockquote>
<blockquote>
<p>生活会用平淡消磨掉我们的热情，唯有懂得为自己的生活增添乐趣，才能对未来充满希望。</p>
</blockquote>
<h2 id="不爱计较的人活得到底有多赚"><a class="markdownIt-Anchor" href="#不爱计较的人活得到底有多赚"></a> 不爱计较的人，活得到底有多赚</h2>
<blockquote>
<p>在这不停地计较得失中，我们忘了自己的初衷，忘了真正重要的事情。当一个人的注意力被计较和算计所占据，他的格局只会越来越小。</p>
</blockquote>
<blockquote>
<p>我们经常用“格局”来评判一个人。格局大的人，你会感觉他身上有宏大的气场，有广阔的眼界，有不俗的涵养。相反，格局小的人，只对眼前的蝇头小利感兴趣，凡事斤斤计较，内涵让人一望到底。</p>
</blockquote>
<blockquote>
<p>你在乎的、计较的，往往能反映出你的水平。格局越大、层次越高的人，反而计较得越少。</p>
</blockquote>
<h2 id="月薪多少钱才能给你想要的安全感"><a class="markdownIt-Anchor" href="#月薪多少钱才能给你想要的安全感"></a> 月薪多少钱，才能给你想要的安全感</h2>
<blockquote>
<p>人的一切痛苦，本质上都是对自己无能的愤怒。</p>
</blockquote>
<blockquote>
<p>我们追求经济独立，钱不是最终的目标，钱所带来的自由选择的权利才是。</p>
</blockquote>
<h2 id="从明天起做个不好相处的人"><a class="markdownIt-Anchor" href="#从明天起做个不好相处的人"></a> 从明天起，做个“不好相处”的人</h2>
<blockquote>
<p>很多人习惯去做一个体贴、顺从的人，却把握不好那个度，结果不知不觉把自己变成了别人眼中的老好人。身边的人有事没事都喜欢麻烦你，你来者不拒，然后遇到各种情况却总是让你先退让，而他们还对此习以为常甚至不以为然，结果就是事情都让你做了，亏也全让你吃了。</p>
</blockquote>
<blockquote>
<p>生活中，我们往往因为害怕失去别人，而不懂得拒绝。殊不知，不懂拒绝，毫无底线的妥协，会让自己失去更多。</p>
</blockquote>
<blockquote>
<p>心理学上有个专业术语，叫“阿伦森效应”，指的是人们最喜欢那些对自己的喜爱、奖励、赞扬不断增加的人或物，最不喜欢那些不断减少的人或物。当有人找你帮忙，你次次都没有拒绝，为自己树立了一个“老好人”的形象，对方也习惯了你的好，变得习以为常、不再感激。</p>
</blockquote>
<blockquote>
<p>过分的牺牲和忍让只会让身边的人越来越骄纵，带不来任何的感激之心。每个人都有自己的个性和原则，没有必要为了讨好别人而勉强自己去做不想做的事。</p>
</blockquote>
<blockquote>
<p>你一开始就太好说话，什么事情都答应，什么东西都给，什么错误都原谅，对方对你的心理预期值就会处于过高的位置，无论你做什么对方都觉得理所应当。只有先抑后扬，对方才会感到惊喜。</p>
</blockquote>
<h2 id="放弃你的沉没成本别再用不分手相互折磨"><a class="markdownIt-Anchor" href="#放弃你的沉没成本别再用不分手相互折磨"></a> 放弃你的沉没成本，别再用不分手相互折磨</h2>
<blockquote>
<p>一个成熟的人应该知道，你在做任何事情的时候都有沉没成本。有时候舍弃也是一种获得。希望你不要被已经成为过去的成本所束缚，连未来的美好时光都耽误了。</p>
</blockquote>
<h2 id="定期扔这三样东西会让你活得更高级"><a class="markdownIt-Anchor" href="#定期扔这三样东西会让你活得更高级"></a> 定期扔这三样东西，会让你活得更高级</h2>
<blockquote>
<p>如果你自己不强大，那些社交其实没有什么用。只有等价的交换，才能得到合理的帮助。</p>
</blockquote>
<blockquote>
<p>放弃无用的社交，把更多的时间留给自己和家人。专心做自己喜欢做的事，因为人生最曼妙的风景，是内心的淡定与从容。</p>
</blockquote>
<blockquote>
<p>对待诱惑，不要因为便宜就去买一些自己并不需要的东西，而是买一些质量上乘、真正适合自己的物品；对待生活，定期整理房间，丢掉不再适合自己的物品，人生就不会有那么多烦恼。</p>
</blockquote>
<blockquote>
<p>我们需要的是一种深度思考、适当放空、化繁为简的能力，这需要我们学会过滤多余的信息。</p>
</blockquote>
<h2 id="独处是一个成年人最好的奢侈品"><a class="markdownIt-Anchor" href="#独处是一个成年人最好的奢侈品"></a> 独处，是一个成年人最好的奢侈品</h2>
<blockquote>
<p>以前喜欢一个人，现在喜欢一个人。独处，是一个成年人最好的奢侈品。</p>
</blockquote>
<blockquote>
<p>拥有独处的能力，是一个人情感成熟的重要标志之一。</p>
</blockquote>
<blockquote>
<p>利用独处的时间为自己增值，才能把生活的点滴过成诗。真正拉开你与他人差距的，有时候恰恰就是独处的时光。</p>
</blockquote>
<blockquote>
<p>一个人最好的状态，无非是既能享受得了繁华，也能安顿一个人的时光。在这些时光里，愿我们终将与孤独握手言和，重新拥有对抗未知的勇气。</p>
</blockquote>
<h2 id="仪式感对我们来说到底有多重要"><a class="markdownIt-Anchor" href="#仪式感对我们来说到底有多重要"></a> 仪式感对我们来说到底有多重要</h2>
<blockquote>
<p>有时候，你觉得生活太粗糙，那是因为你没有想办法让它变得精致。只有仪式感，才能让你放大每一种情绪，让缱绻在岁月中的日常琐碎，变成充满感动的细水长流。</p>
</blockquote>
<blockquote>
<p>仪式是一件很重要的事情。喝牛奶时，你替我擦掉嘴边的白泡沫，是仪式；出门时，你把我的领带给调整好，是仪式；走路时，你蹲下来帮我系好鞋带，是仪式；逛街时，你记得我喜欢的衣服买来送给我，是仪式。</p>
</blockquote>
<blockquote>
<p>一个人上班的状态其实从穿着就能看出，如果穿得过于休闲，上班的状态也会比较轻松，可能会影响工作效率。这种仪式感，意味着对自我的严格要求，对每一个场合的尊重。</p>
</blockquote>
<blockquote>
<p>有仪式感的人生，才使我们切切实实有了存在感。不是为他人留下什么印象，而是自己的心在真切地感知生命，充满热忱地面对生活。</p>
</blockquote>
<blockquote>
<p>在漫长而无边的黑夜里，只有善待自己，才能让生活变得精致而丰盛。愿你我能感受平凡生活中的小确幸，重新拾起对未来的美好向往。</p>
</blockquote>
<h2 id="你的文化层次有多高看这三点就知道"><a class="markdownIt-Anchor" href="#你的文化层次有多高看这三点就知道"></a> 你的文化层次有多高，看这三点就知道</h2>
<blockquote>
<p>文化可以用四句话表达：根植于内心的修养；无需提醒的自觉；以约束为前提的自由；为别人着想的善良。</p>
</blockquote>
<blockquote>
<p>不管环境如何浮躁或如何荒芜，有文化的人已然可以丰富自己的内心，并从中获得安宁。他们习惯独处、懂得独处、渴望独处，在独处中思考、在独处中升华。一个有文化的人，不畏惧独处，更喜欢在独处中默默提升自己。</p>
</blockquote>
<h2 id="深到骨子里的教养是从不做这件事"><a class="markdownIt-Anchor" href="#深到骨子里的教养是从不做这件事"></a> 深到骨子里的教养，是从不做这件事</h2>
<blockquote>
<p>一个人最大的恶意，就是把自己的理解强加于别人，把所有的结果理所当然用自己的过程来解释，并一直认为自己是正确的。</p>
</blockquote>
<blockquote>
<p>这一生，太多人都是在负重前行。你永远都不会知道别人经历了什么，因此也不要妄自评价。</p>
</blockquote>
<blockquote>
<p>每个人各有自己的生活取向和价值选择，不要做他人生活的审判者。</p>
</blockquote>
<blockquote>
<p>深入骨髓的教养，是从不随意评价他人。</p>
</blockquote>
<blockquote>
<p>人生最曼妙的风景，是内心的淡定与从容。专注自身，你会拥有更广阔的天空。</p>
</blockquote>
<h2 id="有一种教养叫不给别人添麻烦"><a class="markdownIt-Anchor" href="#有一种教养叫不给别人添麻烦"></a> 有一种教养，叫“不给别人添麻烦”</h2>
<blockquote>
<p>有一种教养，就是力所能及地做好自己的事，不给别人添麻烦。</p>
</blockquote>
<blockquote>
<p>朋友之间，如果长时间不联系，感情容易变淡，想要维系，需要多联系、多走动。并不代表，要理所当然地麻烦别人，让别人为难还毫无自察之心。</p>
</blockquote>
<h2 id="情商高的人都有这三种特质"><a class="markdownIt-Anchor" href="#情商高的人都有这三种特质"></a> 情商高的人，都有这三种特质</h2>
<blockquote>
<p>情商高的本质，是懂得真心实意地站在对方角度着想。</p>
</blockquote>
<blockquote>
<p>情商高的人，不会将时间花在无用的批评上，而是会尽量设身处地地去想问题：他为什么这么做？怎样才能让他不这么做？这比批评和训斥要有效得多。</p>
</blockquote>
<blockquote>
<p>一个人的成就，情商占80%，专业技术、智商占20%。为人处世的能力，有时候比智力和工作能力更为重要。拥有良好的情商，才能建立起良好的人际关系，获得他人的尊重和认可。</p>
</blockquote>
<blockquote>
<p>情商高的人，一般拥有这三种特质：不会随意评判别人、善用利他思维、懂得倾听他人的意见。真正的高情商，不是靠钻研谈话技巧、说话技术就能够练成的，最重要的是拥有一颗懂得换位思考、设身处地地替别人着想的心。</p>
</blockquote>
<h2 id="聊天时的这三个细节真的很加分"><a class="markdownIt-Anchor" href="#聊天时的这三个细节真的很加分"></a> 聊天时的这三个细节，真的很加分</h2>
<blockquote>
<p>做一个善于倾听的人，鼓励别人谈论他们自己，这是让别人喜欢你的方式之一。</p>
</blockquote>
<blockquote>
<p>做一个会说话的人，首先就要多积累、多思考。只有不断地去接触和学习新事物，积累知识、整合知识，变成自己的东西，才能不断输出。</p>
</blockquote>
<blockquote>
<p>在聊天过程中，同理心才是最终的秘诀。当你认为别人的感受和你自己的一样重要时，气氛才会融洽。每个人都有表达的欲望和被认可的期待，聊天就是让这种欲望释放的时刻。</p>
</blockquote>
<h2 id="情商高的人从不说这四句话"><a class="markdownIt-Anchor" href="#情商高的人从不说这四句话"></a> 情商高的人，从不说这四句话</h2>
<blockquote>
<p>情商越高的人，越不会用语言暴力来伤害别人。如果你懂得适当地遣词造句，不至于引起口角、抵抗，造成对别人的伤害，你与他人冲突的可能性降低，压力自然也会大大减小。</p>
</blockquote>
<blockquote>
<p>一个高情商的人，必定能够体察自己的情绪，控制和管理自己的言语。学会退步忍让，凡事三思而后行，遇到矛盾冲突时，不要为一点小事大动肝火、随意指责。</p>
</blockquote>
<blockquote>
<p>柔软对话，也是一种力量的表现。一个人的高情商，根植于为他人着想的善良中，知道别人的不易、懂得用同理心换位思考，不会用语言伤人。</p>
</blockquote>
<h2 id="生活中的三个细节能出卖一个人的人品"><a class="markdownIt-Anchor" href="#生活中的三个细节能出卖一个人的人品"></a> 生活中的三个细节，能出卖一个人的人品</h2>
<blockquote>
<p>只有最亲的人才会无休止地包容你，这份包容不应该被肆无忌惮地挥霍。</p>
</blockquote>
<blockquote>
<p>一个人品极好的人，绝不会被戾气所控，因为他们的温柔与耐心已深入骨髓。</p>
</blockquote>
]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>读书</tag>
      </tags>
  </entry>
  <entry>
    <title>书摘：《你的知识需要管理》－田志刚</title>
    <url>/2021/04/09/%E4%B9%A6%E6%91%98_%E4%BD%A0%E7%9A%84%E7%9F%A5%E8%AF%86%E9%9C%80%E8%A6%81%E7%AE%A1%E7%90%86_%E7%94%B0%E5%BF%97%E5%88%9A/</url>
    <content><![CDATA[<p>一本介绍如何经营自己知识的书籍，从学习知识、保存知识、知识共享、知识使用和知识创新五个方面进行讲述，有一定的借鉴意义。说实话这本书偏工具类，以前拿小屏看没感觉，限制在大屏看，感觉很多内容都是纯粹列举<code>要点</code>，能读进去的很少（也可能我手机看过了）看到作者举例直接跳过了，所以我大概不到一天就翻完这本书了。我认为好的书它是用严密的<strong>逻辑链条</strong>去慢慢跟你讲道理的，不是突然一个例子，突然一个要点，这本书就会卡住我，阅读情绪经常是这样的：读这一部分是“有点道理”，读下一部分是“好像是这样的”，往后是“不是吧”，所以说这本书并没有打动我。之所以说这本书偏工具，是因为书中有部分内容直接教如何使用工具去实践的。</p>
<p>当然，对于作者管理知识的五个要点我是同意的，这五个要点是循序渐进的，是闭环流动的，作者倡导以下观点我是赞同的，也是我第一次从这本书获得的<code>知识</code>：</p>
<ol>
<li><strong>信息与知识有区别</strong></li>
<li><strong>终身学习以适应社会发展需要</strong></li>
<li><strong>显性知识隐性化以创造价值</strong></li>
<li><strong>共享知识以提升个人竞争力</strong></li>
<li><strong>持续创新以确保价值的独特性</strong></li>
</ol>
<a id="more"></a>
<hr />
<p><strong>阅读书摘及笔记：</strong></p>
<blockquote>
<p>现在，所谓无知不是指没有知识，而是不会展示自己的知识、不会发挥知识的价值、不会发现新知识、不会学习新知识，也不去创造知识。对于主要靠知识谋生的知识工作者而言，你的知识管理过程是否运转自如，是个人发展和个人竞争力能否持续提升的关键</p>
</blockquote>
<blockquote>
<p>人要靠自己，但靠自己不是依靠自己的体力，而是要靠自己的脑力，靠知识</p>
</blockquote>
<blockquote>
<p>依靠知识绝对不是依靠文凭，也不是依靠你现在掌握的知识量，不要认为掌握了某些知识就可以一劳永逸地解决你一辈子的问题。个人可以依靠的知识，是指在一定的知识基础上，能够随着社会环境的变化，不断确定自己的专业方向并快速学习知识、分享知识、使用和创新知识并创造价值的过程，这个过程就是对你的知识进行有效管理的过程，也是提升你的知识力的过程。现在每个人都必须要考虑自己如何快速学习知识、学习什么知识、如何保存掌握的知识、如何分享知识给你的合作伙伴、如何使用和创新知识</p>
</blockquote>
<blockquote>
<p>对于知识的爆炸，解决的方式是你要明确自己的知识需求。知识虽多但人生有限，如果知识不能被你所用，不能成为“你的知识”，这些知识对你也没有作用</p>
</blockquote>
<blockquote>
<p>知识又可以分为显性知识和隐性知识。所谓显性知识是指能够用语言、文字、肢体等方式表达清楚的知识；而隐性知识则是虽然知道如何做，但却很难告诉别人或者写明白、说明白的知识。从掌握知识的角度讲，大量的知识以隐性的成分存在着，而能显性化的部分较少。你虽然知道某个事情是怎么样或者如何做，但如果让你讲出来，你可能发现能够表达的会很少，如果进一步要求你写出来，可能能写的就更少了。古语“书不尽言、言不尽意”就是这个意思，是说你能写的要比能说的少，能说的要比你知道的少，本质上就是显性和隐性知识的问题</p>
</blockquote>
<blockquote>
<p>隐性知识和显性知识之间存在着相互转换的过程</p>
</blockquote>
<blockquote>
<p>隐性知识显性化应该成为现代人的一项必备能力，如果你不能显性化你的知识，就无法建立你的竞争力。为什么中医中药很难做大，一个很重要的原因是它们主要依靠隐性知识作判断，所以传承、复制的难度较大，因此就很难快速发展</p>
</blockquote>
<blockquote>
<p>隐性知识还有一些特点，了解这些特点对于你管理自己的知识很有价值。</p>
<ul>
<li>你的隐性知识可能只是对你自己是隐性的，对于其他人、其他的机构可能已经是显性知识，这就需要你在前人基础上进行学习，明白是否已经有类似的显性知识；</li>
<li>隐性知识需要环境（此时、此地），并非永远是隐性的；</li>
<li>谁能将隐性的知识最先显性化，谁就是知识创新的开拓者。譬如许多大师的创新，多年后也有不同的人表达，但前者是大师，因为他最早将隐性知识显性化；</li>
<li>隐性知识显性化能力成为人与人之间能力差别的重要方面。将自己的隐性知识显性化应该成为每个知识工作者应具备的能力之一；</li>
<li>隐性知识显性化需要需求、环境等外力的作用，外力的拉动加上个人显性化的意愿，可以促进隐性知识显性化的过程；</li>
<li>社区是促进隐性知识显性化的环境；</li>
<li>隐性知识显性化的方法：讨论、回答提问、需求的压力、工作分解、流程分析等；</li>
<li>不能用通俗、简单的语言和文字表述知识，表明对该领域知识掌握得不够深入。</li>
</ul>
</blockquote>
<blockquote>
<p>知识与信息不同，知识除了要靠经验去消化汇集来的信息，还要去验证、思考，甚至在亲身体验过程中，去发现问题、解决问题</p>
</blockquote>
<blockquote>
<p>在当今时代下，个人的成长和发展以及个人竞争优势的建立，绝对不是靠信息的数量（虽然缺乏信息和获取信息的能力可以成为一个人发展的劣势）。不要以为你整天在互联网上就掌握了知识，互联网上的信息和知识你能获得我也能获得，互联网上有显性的知识也有信息，显性的知识必须跟你个人的原有知识结合起来，转化成你的隐性知识，加上对环境的判断才能发挥作用。</p>
</blockquote>
<blockquote>
<p>学历可以作为你知识水平的一个表现，但其表达的只是在某时、某地的知识存量，是否能持续地更新知识、是否能持续地共享和传播自己的知识、是否能将已有的知识用好用足来获取价值、是否能持续地创新知识引领发展，只有这些才是个人竞争力的源泉</p>
</blockquote>
<blockquote>
<p>但我们满足于仅仅不是文盲吗？虽然你学习了众多知识，但单位里领导不重视你、同事不跟你合作，你的知识有用吗？如果你掌握了众多知识，但你的知识不会利用，甚至不能给你换来养家糊口的钱，更不用说成就自己的事业，这样的知识有用吗？如果你总是学习别人的知识，读死书、死读书，在别人后面亦步亦趋，不能进行知识创新，那你的竞争优势在哪里？</p>
</blockquote>
<blockquote>
<p>人只能依靠自己，而依靠自己最重要的一点是依靠自己对个人知识过程的管理。只有对整个知识过程的管理才是现代人发展竞争力和竞争优势的源泉</p>
</blockquote>
<blockquote>
<p>不学习当然不行，但学习也不一定行。你必须知道要学习什么知识，获取什么知识；同时，学习任何领域的知识必须达到一定的深度，否则你的知识就是常识。而常识怎么可能给你带来个人的竞争优势呢？</p>
</blockquote>
<blockquote>
<p>终身学习的理念在20世纪中叶就被明确地提了出来，因为人们发现技术、知识的快速更新不仅影响了生产、流通和消费等领域，而且影响到每个人的日常生活。若要与之适应，人们就必须用新的知识、技能和观念来武装自己。终身教育强调现代人必须不间断地进行学习，更新个人知识，才能保持适当的应变能力，保证个人竞争力</p>
</blockquote>
<blockquote>
<p>更进一步说，学习本身不是目的。学习知识是为了我们能够工作、生活得更好，更幸福，能帮助我们度过快乐的一生。学习的目的是为了提高我们个人的竞争力，使我们能够在这么多的知识工作者当中脱颖而出，取得自己的成就</p>
</blockquote>
<blockquote>
<p>确定你的学习方向</p>
<ul>
<li>第一，你的价值观是什么？</li>
<li>第二，你的个人目标是什么?</li>
<li>第三，你的性格是什么？</li>
</ul>
</blockquote>
<blockquote>
<p>现在信息和知识越来越多，所以你在学习的时候需要确定自己的方向。在确定方向后，你就需要在你确定的方向上正向积累，争取成为一个领域的专家</p>
</blockquote>
<blockquote>
<p>你的学习方法模型</p>
<ul>
<li>第一，掌握该领域的基础知识。</li>
<li>第二，了解该领域的全貌。</li>
<li>第三，跟踪并掌握该领域的最新知识。</li>
<li>第四，在实践中学习和创新。</li>
</ul>
</blockquote>
<blockquote>
<p>人们下载的知识是显性知识的一种表现形式，对于这部分知识，如果没有被你处理过（阅读，知道是什么；思考，知道对你有什么用），根本不可能成为“你的知识”，根本不会对你产生一点点作用，只会让你“淹没在知识中”而无法自拔</p>
</blockquote>
<blockquote>
<p>只有那些符合个人发展目标的知识，只有经过自己的阅读、思考后保存的知识才有价值，这样的知识保存才是有价值的保存</p>
</blockquote>
<blockquote>
<p>任何人都有区别于他人的优势，你怎么突出自己的优势、特点和能力，怎么让更多的人知道你、了解你、认识你、信任你，方法就是共享你的知识，通过知识影响别人。更深入地说，我们现在的大部分工作都需要与人协作才能完成，通常人们会选择什么样的协作对象呢？比如招聘新员工或者提升一个经理，可想而知一定会是自己了解的人、信任的人！所以每个知识工作者都应该去主动共享和传播自己的知识，愿意将自己的知识显性化，这一方面会促进自己的学习，另一方面也能为树立自己的个人品牌发挥作用。</p>
</blockquote>
<blockquote>
<p>共享知识的好处</p>
<ul>
<li>故事一：共享带来合作</li>
<li>故事二：共享协助找到工作</li>
</ul>
</blockquote>
<blockquote>
<p>能共享出来才能真正掌握</p>
</blockquote>
<blockquote>
<p>在现实中，很多时候我们以为自己知道，但是当我们用语言说出来或者写出来的时候，你却会发现自己很难说得系统、完整，很难让别人明白。造成这种状况的主要原因是你对该知识点的掌握并没有达到你所认为的那样成熟，这时候你应该再去深入学习、研究这个知识点，经过更多的实践和与人交流，更广泛的阅读、讨论，才能慢慢地成熟起来。</p>
</blockquote>
<blockquote>
<p>仅有显性知识是不够的</p>
</blockquote>
<blockquote>
<p>个人知识的价值由两个因素决定：</p>
<ul>
<li>第一个因素是你的知识的独特性。知识的独特性也分两种，第一种是专，在某个方向上深入，别人都不如我深，所以我有独特性，比如读博士基本上是这个意思。还有一种是博，我既会拍电影又会画画，还会说相声、做木匠，这样的人以综合优势树立自己的独特性</li>
<li>第二个因素是社会对知识的需求</li>
</ul>
</blockquote>
<blockquote>
<p>让你升值的三个绝招</p>
<ul>
<li>第一，向前看三年。</li>
<li>第二，持续提高你知识的独特性</li>
<li>第三，通过知识共享树立你的个人品牌。</li>
</ul>
</blockquote>
]]></content>
  </entry>
  <entry>
    <title>书摘：《如何有效阅读【樊登读书、十点读书推荐！学会有效阅读只需3周，YouTube千万点击的大师阅读课】》-藤原和博</title>
    <url>/2019/03/22/%E4%B9%A6%E6%91%98_%E5%A6%82%E4%BD%95%E6%9C%89%E6%95%88%E9%98%85%E8%AF%BB%E3%80%90%E6%A8%8A%E7%99%BB%E8%AF%BB%E4%B9%A6%E3%80%81%E5%8D%81%E7%82%B9%E8%AF%BB%E4%B9%A6%E6%8E%A8%E8%8D%90%EF%BC%81%E5%AD%A6%E4%BC%9A%E6%9C%89%E6%95%88%E9%98%85%E8%AF%BB%E5%8F%AA%E9%9C%803%E5%91%A8%EF%BC%8CYouTube%E5%8D%83%E4%B8%87%E7%82%B9%E5%87%BB%E7%9A%84%E5%A4%A7%E5%B8%88%E9%98%85%E8%AF%BB%E8%AF%BE%E3%80%91-%E8%97%A4%E5%8E%9F%E5%92%8C%E5%8D%9A.hexo/</url>
    <content><![CDATA[<div class="douban-card-block">
	<a class="douban-card" href="https://book.douban.com/subject/26789567">
		<div class="douban-card-bgimg" style="background-image: url('https://images.weserv.nl/?url=https://img9.doubanio.com/view/subject/s/public/s28705474.jpg');"></div>
		<div class="douban-card-left">
			<div class="douban-card-img" style="background-image: url('https://images.weserv.nl/?url=https://img9.doubanio.com/view/subject/s/public/s28705474.jpg');"></div>
		</div>
		<div class="douban-card-right" style="line-height: 1.7;">
			<div class="douban-card-item"><span>书名: </span><strong>如何有效阅读一本书</strong></div>
			<div class="douban-card-item"><span>作者: </span><span>[日本]奥野宣之</span></div>
			<div class="douban-card-item"><span>出版年份: </span><span>2016-6</span></div>
			<div class="douban-card-item"><span>评分: </span><span>7.3</span></div>
		</div>
	</a>
</div>
<style>
	.douban-card-block {
		display: flex;
		justify-content: center;
		align-items: center;
		width: 100%;
		max-height: 400px;
	}
	.douban-card {
		display: flex;
		margin: 30px 10px;
		padding: 15px;
		border-radius: 10px;
		position: relative;
		justify-content: center;
		align-items: center;
		overflow: hidden;
		color: antiquewhite;
		text-decoration: none;
	}
	.douban-card:hover {
		text-decoration: none;
	}
	.douban-card-bgimg {
		position: absolute;
		width: 115%;
		height: 115%;
		filter: blur(15px) brightness(0.6);
		background-size: 100%;
		background-position: center;
		background-repeat: no-repeat;
	}
	.douban-card-img {
		position: relative;
		height: 130px;
		width: 80px;
		background-size: 100%;
		background-position: center;
		background-repeat: no-repeat;
	}
	.douban-card-img {
		position: relative;
		height: 130px;
		width: 80px;
	}
	.douban-card-left {
		position: relative;
		display: flex;
		flex-direction: column;
		align-items: center;
	}
	.douban-card-right {
		position: relative;
		display: flex;
		flex-direction: column;
		margin-left: 12px;
		font-size: 16px;
		font-family: 'Courier New', Courier, monospace;
		line-height: 1.3;
		color: antiquewhite;
	}
	.douban-card-item {
		margin-top: 4px;
	}
</style>
<a id="more"></a>
<h2 id="从出于兴趣的阅读到为了开拓人生的阅读"><a class="markdownIt-Anchor" href="#从出于兴趣的阅读到为了开拓人生的阅读"></a> “从出于兴趣的阅读”到“为了开拓人生的阅读”</h2>
<blockquote>
<p>我们已经进入了每个人都必须要对自己的幸福论进行整理，得出属于自己的原创的幸福论的时代。</p>
</blockquote>
<blockquote>
<p>这是一个如果不能拥有“只属于自己”的幸福论，就无法获得幸福的时代。</p>
</blockquote>
<h2 id="如何构筑只属于自己的幸福论"><a class="markdownIt-Anchor" href="#如何构筑只属于自己的幸福论"></a> 如何构筑“只属于自己”的幸福论</h2>
<blockquote>
<p>自己给幸福下定义，从现在自身所处的地方、前进的方向，到想要实现怎样的成就，这一切都必须由自己来决定。</p>
</blockquote>
<h2 id="被有阅读习惯的人和没有阅读习惯的人一分为二的社会"><a class="markdownIt-Anchor" href="#被有阅读习惯的人和没有阅读习惯的人一分为二的社会"></a> 被“有阅读习惯的人”和“没有阅读习惯的人”一分为二的社会</h2>
<blockquote>
<p>我再一次意识到一个事实，如果不能通过读书积累知识，是没有办法拥有自己的观点的。</p>
</blockquote>
<blockquote>
<p>单凭网上的信息只能进行浅显的思考这一观点。我认为在进行深层次的逻辑性思考方面，书是绝对不可或缺的东西。</p>
</blockquote>
<h2 id="有效阅读量决定了薪酬高低"><a class="markdownIt-Anchor" href="#有效阅读量决定了薪酬高低"></a> 有效阅读量，决定了薪酬高低</h2>
<blockquote>
<p>看不看书决定了报酬的高低，是通过读书无限接近专家的薪资水平，还是不读书无限接近自由工作者的薪资水平呢？看书与否会将你的道路分为这两条。</p>
</blockquote>
<h2 id="通过阅读所习得的人生中极为重要的两种能力"><a class="markdownIt-Anchor" href="#通过阅读所习得的人生中极为重要的两种能力"></a> 通过阅读所习得的人生中极为重要的两种能力</h2>
<blockquote>
<p>读书不仅能够实现自己想要做的事，还能帮助我们学习两种能力。那就是“注意力”和“平衡感”。</p>
</blockquote>
<h2 id="阅读训练一如何阅读获得想象力"><a class="markdownIt-Anchor" href="#阅读训练一如何阅读获得想象力"></a> 阅读训练一：如何阅读，获得想象力</h2>
<blockquote>
<p>在电视或是手机上看视频的机会越多，就越会加速这种倾向。正如酒井教授所解说的脑的运作那样，人光是处理源源不断地闯进视觉区域中的影像就已经筋疲力尽了，根本没有空闲对看到的影像进行想象。自然而然，电视和视频的制作方也渐渐不要求观众对影像进行想象了。了解到电视所具有的这种特征之后，加拿大的媒体学者马歇尔·麦克卢汉（Mcluhan）将其称为“冷媒介”。研究结果表明，我们在日常生活中所获取的信息总量的70%以上是由视觉获得的。只要电视作用于视觉让人们看到与现实相近的事物，观众就容易冷静（cool）地对其产生认同感。与此相对，广播是只能听得到声音的媒体。因为能够给予我们的信息量是有限的，所以能够在很大程度上激起听众的想象力，与此同时变得兴奋，情绪渐渐高涨（hot）。因此，马歇尔·麦克卢汉将广播称为“热媒体”。这样看来，读书和听广播一样，都可以说是凭借语言来激发想象力的媒体。并且，读书与被动地获得信息的广播不同，必须要由看书人主动地获取信息，是非常适合“activelearning（自主学习）”的媒体。</p>
</blockquote>
<h2 id="阅读训练三如何阅读将自己的大脑与作者的大脑连接起来"><a class="markdownIt-Anchor" href="#阅读训练三如何阅读将自己的大脑与作者的大脑连接起来"></a> 阅读训练三：如何阅读，将自己的大脑与作者的大脑连接起来</h2>
<blockquote>
<p>通过读书我们可以获得各种各样的感受器，并且在自己脑内储存各种各样的大脑碎片，这就是读书带给我们的帮助。</p>
</blockquote>
<h2 id="阅读训练五如何阅读以获得更多mikata想法或伙伴"><a class="markdownIt-Anchor" href="#阅读训练五如何阅读以获得更多mikata想法或伙伴"></a> 阅读训练五：如何阅读，以获得更多“mikata”（想法或伙伴）</h2>
<blockquote>
<p>读书是读者把作者所获得的知识输入自己大脑中的行为。通过把自己的大脑和他人的“大脑碎片”相连接，自己的大脑可以得到扩张。通过理解作者看待世界的角度和知识，读者可以丰富对世界的看法，拥有进行多面的复眼思考的能力。如果扩大了世界观（看法），就不会轻易被鱼龙混杂的消息所欺骗，在做决定时，供你选择的项目也会变多，这样风险也会降低，所以越多读书就越能保护自己。</p>
</blockquote>
<h2 id="阅读训练六如何阅读预测未来趋势"><a class="markdownIt-Anchor" href="#阅读训练六如何阅读预测未来趋势"></a> 阅读训练六：如何阅读，预测未来趋势</h2>
<blockquote>
<p>读书就是一个把自己的大脑和他人的大脑碎片相结合的行为；而我们脑内所吸收的他人的大脑碎片将会增殖，并且开始互相连接在一起。这会产生全新的思考和意见，而预测未来便是其副产物。</p>
</blockquote>
<h2 id="阅读训练十一如何阅读创造出自己的意见"><a class="markdownIt-Anchor" href="#阅读训练十一如何阅读创造出自己的意见"></a> 阅读训练十一：如何阅读，创造出自己的意见</h2>
<blockquote>
<p>为了消除这个自卑感，我认为自己有必要扩大自己的见识。但并不是说看一本书就能立即生效，所谓见识是需要积累的。只要见识的积累量没有超过一定的刻度，是没有办法创造出自己的意见的。</p>
</blockquote>
<h2 id="阅读训练十三如何阅读建立未来规划"><a class="markdownIt-Anchor" href="#阅读训练十三如何阅读建立未来规划"></a> 阅读训练十三：如何阅读，建立未来规划</h2>
<blockquote>
<p>每个人都在某个地方有所欠缺，但是许多人不知道那个自己所欠缺的部分到底是什么。如果在现实社会中，我们只是得过且过地活着的话，是很难注意到的。要怎么做才能注意到那个自己所欠缺的部分呢？这个问题的答案就在书本之中。</p>
</blockquote>
<blockquote>
<p>要想让团体内的交流变得充实起来，读书也是非常有效的。</p>
</blockquote>
<h2 id="从今往后的时代中不可或缺的信息综合能力"><a class="markdownIt-Anchor" href="#从今往后的时代中不可或缺的信息综合能力"></a> 从今往后的时代中不可或缺的“信息综合能力”</h2>
<blockquote>
<p>所谓信息处理能力，指的就是在世界观固定的情况下玩游戏的时候，最快得出正确答案的能力。</p>
</blockquote>
<blockquote>
<p>所谓信息综合能力，就是把自身所具备的知识和技巧相结合，得出“让自己能够认同的答案”的能力。这并不是指去想什么才是正确答案，关键是要自己创造出能让自己信服的答案。</p>
</blockquote>
<h2 id="阅读是一种工具独处的最好方式便是阅读"><a class="markdownIt-Anchor" href="#阅读是一种工具独处的最好方式便是阅读"></a> 阅读是一种工具：独处的最好方式便是阅读</h2>
<blockquote>
<p>作者的世界观和读者的世界观之间会发生化学反应，进而诞生出全新的世界观。这就是为什么读书可以丰富对世界的看法，交到新的伙伴。</p>
</blockquote>
<h2 id="成年人要如何磨炼信息综合能力"><a class="markdownIt-Anchor" href="#成年人要如何磨炼信息综合能力"></a> 成年人要如何磨炼信息综合能力</h2>
<blockquote>
<p>那些已经对“过家家游戏”没有兴趣的成人要怎么做才好呢？当然了，哪怕成了大人，也有锻炼信息综合能力的方法。其一，旅行。</p>
</blockquote>
<h2 id="有百分百遇到好书的方法吗"><a class="markdownIt-Anchor" href="#有百分百遇到好书的方法吗"></a> 有百分百遇到好书的方法吗</h2>
<blockquote>
<p>我推荐那些真的想要得到对自己来说很重要的书的人进行习惯性的“乱读（广泛阅读）”。这样有可能形成自己从未有过的思考方法，还可能因为读书和陌生的人相遇。在</p>
</blockquote>
<h2 id="在阅读成为习惯之前强制方法也是必要的"><a class="markdownIt-Anchor" href="#在阅读成为习惯之前强制方法也是必要的"></a> 在阅读成为习惯之前，强制方法也是必要的</h2>
<blockquote>
<p>教育，就是“传染”和感染。爱读书的人，读书的时候表情真的是非常丰富的。哪怕在很安静地看书，也会向周围释放出一股气场。</p>
</blockquote>
<h2 id="单单看书是远远不够的"><a class="markdownIt-Anchor" href="#单单看书是远远不够的"></a> 单单看书是远远不够的</h2>
<blockquote>
<p>在最后我想告诉各位的是，只是一个劲读书，把书中的知识输入大脑，可能还是没办法养成读书的习惯。</p>
</blockquote>
]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>读书</tag>
      </tags>
  </entry>
  <entry>
    <title>书摘：《如何想到又做到》-[美]SeanYoung</title>
    <url>/2020/06/21/%E4%B9%A6%E6%91%98_%E5%A6%82%E4%BD%95%E6%83%B3%E5%88%B0%E5%8F%88%E5%81%9A%E5%88%B0-%5B%E7%BE%8E%5DSeanYoung.hexo/</url>
    <content><![CDATA[<div class="douban-card-block">
	<a class="douban-card" href="https://book.douban.com/subject/30348435">
		<div class="douban-card-bgimg" style="background-image: url('https://images.weserv.nl/?url=https://img3.doubanio.com/view/subject/s/public/s29891760.jpg');"></div>
		<div class="douban-card-left">
			<div class="douban-card-img" style="background-image: url('https://images.weserv.nl/?url=https://img3.doubanio.com/view/subject/s/public/s29891760.jpg');"></div>
		</div>
		<div class="douban-card-right" style="line-height: 1.7;">
			<div class="douban-card-item"><span>书名: </span><strong>如何想到又做到</strong></div>
			<div class="douban-card-item"><span>作者: </span><span>[美]SeanYoung</span></div>
			<div class="douban-card-item"><span>出版年份: </span><span>2018-10</span></div>
			<div class="douban-card-item"><span>评分: </span><span>7.5</span></div>
		</div>
	</a>
</div>
<style>
	.douban-card-block {
		display: flex;
		justify-content: center;
		align-items: center;
		width: 100%;
		max-height: 400px;
	}
	.douban-card {
		display: flex;
		margin: 30px 10px;
		padding: 15px;
		border-radius: 10px;
		position: relative;
		justify-content: center;
		align-items: center;
		overflow: hidden;
		color: antiquewhite;
		text-decoration: none;
	}
	.douban-card:hover {
		text-decoration: none;
	}
	.douban-card-bgimg {
		position: absolute;
		width: 115%;
		height: 115%;
		filter: blur(15px) brightness(0.6);
		background-size: 100%;
		background-position: center;
		background-repeat: no-repeat;
	}
	.douban-card-img {
		position: relative;
		height: 130px;
		width: 80px;
		background-size: 100%;
		background-position: center;
		background-repeat: no-repeat;
	}
	.douban-card-img {
		position: relative;
		height: 130px;
		width: 80px;
	}
	.douban-card-left {
		position: relative;
		display: flex;
		flex-direction: column;
		align-items: center;
	}
	.douban-card-right {
		position: relative;
		display: flex;
		flex-direction: column;
		margin-left: 12px;
		font-size: 16px;
		font-family: 'Courier New', Courier, monospace;
		line-height: 1.3;
		color: antiquewhite;
	}
	.douban-card-item {
		margin-top: 4px;
	}
</style>
<a id="more"></a>
<h2 id="扉页"><a class="markdownIt-Anchor" href="#扉页"></a> 扉页</h2>
<blockquote>
<p>阶梯模型：研究表明，把焦点放在小步骤上，一个人便会有更高的成功概率。然而，就算人们知道这一点，也无法把改变坚持下去。这是因为，他们不明白这些步骤要有多小，又没有模型可供参考。</p>
</blockquote>
<p>这个确实。在做日常的规划的时候，有时候能会把步骤目标理想混混搅在一起。经常规划一些。很大很大的步骤，无法在短期内完成，如此便导致了。不能形成对自己的持续激励。很容易放弃。</p>
<blockquote>
<p>极度容易：人们往往以为自己明白容易的具体程度。“极度容易”一章将介绍怎样让事情变得真正容易，从而让你更可能坚持下去。行为在前：你是否听说过“有志者事竟成”的说法？或者是否听说过“想法到位了，行动就会跟上”？“思想决定行为”是许多畅销励志书和流行心理学图书的理论基础。这些书会宣扬：人们可以通过自我改变的想象和意愿，来改变自己的行为。可惜这根本是错的。</p>
</blockquote>
<p>在这里我想说一个问题就是。我这个人管不住自己，平常经常做一些控制不了自己的事情。应该是属于冲动行为。如。看视频。看电视剧看电影，看动漫看比赛。甚至玩游戏。是不是我在日常生活中把这件事情安排的太简单？触手可及。没有设置障碍。所以比较容易养这种习惯了。</p>
<blockquote>
<p>社会心理学家现在知道，真实情况应该是反过来的。人们需要改变自己的行为，思想才会随之改变。你要“哄着”大脑，让它意识到改变可行。</p>
</blockquote>
<p>这是一个比较新的观点。以前我一直执着于要先把自己的想法内心去改变。自己的行为是跟着改变。读了这本书之后。感觉是行动，在先。用行动的影响对于行为改变而是一个逐步改变的过程，不是一个。是观念的改变，有行动，突然改变了一个突变的过程。</p>
<blockquote>
<p>致命吸引：你该怎样把一件事情变得有吸引力，让自己不停地做下去呢？一种流行的方法是将其“游戏化”。具体就是，通过奖励人们积分、徽章和金钱，让某种活动或产品变得有吸引力，进而使人们愿意继续做或继续使用下去</p>
</blockquote>
<p>在致命私隐这一环节。我想比较或者几乎没有为自己的行为。是如果类似的奖励。有很多奖励，又不是一个成功兑现的过程。这会目标任务设置一下。这次的奖励太大，无法实现。就是欺骗自己。</p>
<blockquote>
<p>反复铭刻：很多成功人士会告诉你，他们之所以成功不是因为智力或才华出众，而是因为知道该怎样有效地利用个人时间。</p>
</blockquote>
<p>坚持这件事情，如果单纯说坚持。心疼的习惯那就是没问题。我们心脏希望。那这个过程就是痛苦的。</p>
<blockquote>
<p>人类的大脑渴望高效运转，它的一项功能就是让人付出最少，做事更多。如果你反复看到、听到或闻到某种东西（哪怕你并未意识到），大脑也会存储相关信息，让你无须思考便可迅速认出它、检索它。</p>
</blockquote>
<p>是的，对此深有感触。这也解释了。人为什么天性就是懒的。</p>
<blockquote>
<p>把所有的精力都放在实现第一步上，然后花时间回顾你的进展。接着在第二步中重复这个过程。</p>
</blockquote>
<blockquote>
<p>大多数人以为自己正在朝着目标迈小步子，但实际上他们的步子还不够小。毕竟，小的概念很主观。如果你让5个人列出完成同一项任务所需的所有小步骤，那么每个人都会想出不同大小的步骤来。</p>
</blockquote>
<blockquote>
<p>针对“锚定效应”的研究表明，环境确实会改变人们的答案。不同的环境会让一个人把注意力集中在那些本不相关却能影响最终决定的事情上。</p>
</blockquote>
<blockquote>
<p>人们往往以为自己规划的就是达成目标的小步骤，但实际上，他们设计的步骤相当大。那</p>
</blockquote>
<blockquote>
<p>很多时候人们以为自己规划的是步骤，但其实规划的是目标或梦想。</p>
</blockquote>
<blockquote>
<p>一开始，你说不定会觉得设定一个个“阶梯”太难了。毕竟，阶梯模型依赖于你能否准确地估计实现某件事需要多长时间。但人们不见得总是精于预测。这就是为什么我会建议你找3个值得信任的人来帮忙的原因。你要先自己设定目标，再征求他们的意见，看看你设定的目标是不是真正的目标。如果他们说你要花3个月以上的时间才能完成它，那么它说不定就是你的梦想。把梦想刻在脑海里以保持动力，接着选择一个大约要用1个星期到1个月的时间来实现的真正的目标，然后去规划实现该目标的小步骤。</p>
</blockquote>
<blockquote>
<p>社群要想对成员产生持久的影响，就需要有足够多的人为社群提供力量，创造社交磁力。对于规模非常小的社群，比如5人以下的社群来说，每个人都需要付出努力来建立社交磁力。而对于较大的社群来说，需要15%的参与者投身社交磁力的建设工作。</p>
</blockquote>
<p>所以在这方面是我的弱项。天上的热霞。反正我觉得是天生。姐，以后怎么解决？现在还没有思路。反正真是一个妈。</p>
<blockquote>
<p>你越是积极地参与，其社交磁力就越强，你也就越有可能实现持久的改变。</p>
</blockquote>
<blockquote>
<p>大多数心理学家认为，人天生并没有所谓的动机型人格。人是因为环境的关系，因为在正确的时间处在了正确的或错误的位置，才去做事情的。</p>
</blockquote>
<blockquote>
<p>●头三件最重要的东西是：金钱、社会关系和健康。</p>
</blockquote>
<blockquote>
<p>金钱、社会关系和健康，从人生之初就很重要。对大多数人来说，它们在此后的生命里仍将同等重要。健康和社会关系能很好地激励人们坚持做事的原因就在于此。金钱能激励股票经纪人每个月去寻找新客户。对亲密关系的需求能激励情侣长年厮守，哪怕他们偶有争执。对健康的承诺，诱使人们终身购买膳食补剂。</p>
</blockquote>
<blockquote>
<p>生活可以让人们产生新的动机、新的做事理由。如果我们学会把焦点放在真正重要的事情上，哪怕是悲剧事件上，也能拥有快乐和幸福。</p>
</blockquote>
<blockquote>
<p>你会为了更健康、更多的钱、跟亲友更亲近而改变吗？只要你找到了对你真正重要的东西，就可以应用本书中其他的几种武器来激发重要性的力量，让自己为目标而坚持。</p>
</blockquote>
<blockquote>
<p>人们总是希望事情很容易做。他们喜欢容易做的事情，也会坚持做那些极度容易的事情。</p>
</blockquote>
<blockquote>
<p>面对障碍，人很快就会放弃做某件事。反过来说，如果你学会了怎样消除障碍，就能很容易继续做下去。</p>
</blockquote>
<blockquote>
<p>虽然人们总以为自己希望拥有更多的选择，但实际上，选择太多会让一个人难以做事。</p>
</blockquote>
<blockquote>
<p>很显然，人们会不断去做对自己来说容易做的事情，这看起来很符合直觉思维。但是只知道这一点没有什么用，人们还是难以坚持。</p>
</blockquote>
<blockquote>
<p>让事情变得简单、容易，才是聪明的做法，有助于我们坚持到底。</p>
</blockquote>
<blockquote>
<p>简而言之，如果你无法坚持某件事情，请消除那些妨碍你做它的因素。就是这么容易。</p>
</blockquote>
<blockquote>
<p>持久的行为改变通常并不始于意识告诉身体要做出持久的改变；它始于先做一些小小的行为改变，接着让意识反映出这种改变</p>
</blockquote>
<blockquote>
<p>神经记忆可以让人们回顾自己过去的行为，看到自己的改变，从而坚持做之前没法做到的事情。</p>
</blockquote>
<blockquote>
<p>制造神经记忆的另一种方法是直面那些让你恐惧的东西。一</p>
</blockquote>
<blockquote>
<p>不必控制自己的想法，只要对自己的行为做一些小小的改变，你的意识就会跟着改变。</p>
</blockquote>
<blockquote>
<p>有大量研究表明，人们会凭借自己的生理和情绪征兆，了解自己是什么人、在想些什么、怎样采取行动。例</p>
</blockquote>
<blockquote>
<p>我们无须努力控制自己意识里冒出来的想法，只需要应用微不足道的生理或情绪层面的神经记忆法，就能带来意识和行为上的重大变化。</p>
</blockquote>
<blockquote>
<p>阶梯模型能发挥作用的一个原因是，人们完成的每一步，都提升了他们坚持下去的承诺感。</p>
</blockquote>
<blockquote>
<p>持久的行为改变始于行为的实际的、实体的变化，而不是思想中的变化。</p>
</blockquote>
<blockquote>
<p>把无聊的事情变得有趣、具有奖励的性质，有助于你坚持目标，不管你的目标是什么。</p>
</blockquote>
<blockquote>
<p>日常生活中，我们只是习惯了以某种方式行事。如果做某件事的结果不好，我们就不会再做；如果结果好，我们就会重复这种行动或行为。</p>
</blockquote>
<blockquote>
<p>人不需要额外的奖励去做本来就感兴趣的事情。如果你开始为这些活动附加奖励，人们说不定会认为这些活动不像自己想象的那么有趣，因为竟然需要奖励才有人去做它。</p>
</blockquote>
<blockquote>
<p>如果你反复做一些对自己有益的事情，比如吃得更健康、采取更安全的工作方式、更具当下意识，这些活动就会铭刻到大脑中，让你更容易坚持做下去。</p>
</blockquote>
<blockquote>
<p>怎样用其他事情取代看似牢不可破的习惯，以此来实现持久改变。</p>
</blockquote>
<blockquote>
<p>一旦习惯建立起来，大脑便达到一种稳定的平衡状态，并能够放松下来。如此一来，习惯就变成了默认行为。</p>
</blockquote>
<blockquote>
<p>冥想会给人们的健康、幸福、人际关系和生产能力带来持久的变化，甚至改变大脑的解剖结构。</p>
</blockquote>
<p>我没有正儿八经的使用过冥想这个方法。</p>
<blockquote>
<p>把行为变成习惯，有助于将它铭刻在大脑里，增加“黏性”，以便坚持。</p>
</blockquote>
<blockquote>
<p>实施某种行为（穿上跑鞋）可以变成“磁铁”，导致另一件相关且可取的行为（跑步）发生。</p>
</blockquote>
<blockquote>
<p>铭刻是一种能帮你坚持到底的强大力量。如果你想要每天锻炼，设定好锻炼时间，点击闹钟，遵照执行。你越是能坚持，它就越是会铭刻到大脑里，你也就越容易继续做下去。</p>
</blockquote>
<blockquote>
<p>新技术给我们的生活带来了更多的娱乐、更高的效率，但它们也在损害我们的健康。智能手机、即时聊天工具和电子游戏等可以让人们更快、更轻松地沟通，带给人娱乐，但同时也让人感到紧张，失去耐心并上瘾。对从前需要等待几天甚至几个星期才能有消息的事情，我们现在总盼着立刻就能得到回复。</p>
</blockquote>
<blockquote>
<p>尽管阅读一本书能让人有改变的动力，就像听了一场励志演讲，但除非人们迅速着手行动，否则这种动力是无法持久的。</p>
</blockquote>
<blockquote>
<p>阶梯模型：实施非常小的步骤，使用步骤、目标和梦想的模型。例如，如果你正在为新公司做目标规划，别打算在本周末之前就锁定第一位客户。这或许只是个梦想，不妨先设定较小的步骤：这星期先会见3名潜在新客户。社交磁力：加入那些正在做你想做之事的人的队伍中。社会支持和社会竞争能促进行为改变。要事为先：改变要想持久，请确保这是一件对你真正重要的事情。极度容易：让事情变得更容易做。如果事情容易做，人们就会去做；如果不容易，你就很难坚持。行为在前：意识爱捉弄我们。掌握它捉弄你的窍门，为你所用。例如，按照富兰克林的建议，促使他人为你做件充满善意的事，赢得新的朋友。致命吸引：对于自己需要做的事情，如果能得到奖励，你就会坚持做下去。反复铭刻：反复做某事。大脑会因为重复和一致行为给予你奖励。改变行为的秘诀是，用新行为替代旧行为。但只有借助适当的武器，新行为才能坚持下去。</p>
</blockquote>
<blockquote>
<p>创建持续变化的过程分为两步：首先，确定你想改变的行为属于我所说的A类行为、B类行为还是C类行为；接下来，利用所需的武器来改变这种行为。</p>
</blockquote>
<blockquote>
<p>首先，确定你尝试改变的行为是A类行为、B类行为或C类行为。为了确定某事属于A类行为、B类行为，还是C类行为，你需要问自己，是什么阻止了你（或其他人）实现改变。找到问题往往比听起来更加困难，因为人们并不见得总能意识到是什么原因阻止了自己做某事。</p>
</blockquote>
<blockquote>
<p>你是否还没意识到自己在做什么，行为就发生了，也就是你是无意识地做它的？如果是，那么它可能就属于自动行为。这是不是一件你能意识到但感觉无力阻止的事情呢？如果是，那么它可能就属于冲动行为。这是不是一件你能意识到，但很难获得足够的动力去改变的事情？如果是，这可能就属于常见行为。其次，一旦你确定了某事是A类行为、B类行为还是C类行为，就可运用所需的武器去改变它。</p>
</blockquote>
]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>读书</tag>
      </tags>
  </entry>
  <entry>
    <title>书摘：《少有人走的路》-[美]M·斯科特·派克</title>
    <url>/2019/04/21/%E4%B9%A6%E6%91%98_%E5%B0%91%E6%9C%89%E4%BA%BA%E8%B5%B0%E7%9A%84%E8%B7%AF-%5B%E7%BE%8E%5DM%C2%B7%E6%96%AF%E7%A7%91%E7%89%B9%C2%B7%E6%B4%BE%E5%85%8B.hexo/</url>
    <content><![CDATA[<div class="douban-card-block">
	<a class="douban-card" href="https://book.douban.com/subject/1775691">
		<div class="douban-card-bgimg" style="background-image: url('https://images.weserv.nl/?url=https://img2.doubanio.com/view/subject/s/public/s2144391.jpg');"></div>
		<div class="douban-card-left">
			<div class="douban-card-img" style="background-image: url('https://images.weserv.nl/?url=https://img2.doubanio.com/view/subject/s/public/s2144391.jpg');"></div>
		</div>
		<div class="douban-card-right" style="line-height: 1.7;">
			<div class="douban-card-item"><span>书名: </span><strong>少有人走的路</strong></div>
			<div class="douban-card-item"><span>作者: </span><span>[美国]斯科特·派克</span></div>
			<div class="douban-card-item"><span>出版年份: </span><span>2007-1</span></div>
			<div class="douban-card-item"><span>评分: </span><span>8.3</span></div>
		</div>
	</a>
</div>
<style>
	.douban-card-block {
		display: flex;
		justify-content: center;
		align-items: center;
		width: 100%;
		max-height: 400px;
	}
	.douban-card {
		display: flex;
		margin: 30px 10px;
		padding: 15px;
		border-radius: 10px;
		position: relative;
		justify-content: center;
		align-items: center;
		overflow: hidden;
		color: antiquewhite;
		text-decoration: none;
	}
	.douban-card:hover {
		text-decoration: none;
	}
	.douban-card-bgimg {
		position: absolute;
		width: 115%;
		height: 115%;
		filter: blur(15px) brightness(0.6);
		background-size: 100%;
		background-position: center;
		background-repeat: no-repeat;
	}
	.douban-card-img {
		position: relative;
		height: 130px;
		width: 80px;
		background-size: 100%;
		background-position: center;
		background-repeat: no-repeat;
	}
	.douban-card-img {
		position: relative;
		height: 130px;
		width: 80px;
	}
	.douban-card-left {
		position: relative;
		display: flex;
		flex-direction: column;
		align-items: center;
	}
	.douban-card-right {
		position: relative;
		display: flex;
		flex-direction: column;
		margin-left: 12px;
		font-size: 16px;
		font-family: 'Courier New', Courier, monospace;
		line-height: 1.3;
		color: antiquewhite;
	}
	.douban-card-item {
		margin-top: 4px;
	}
</style>
<a id="more"></a>
<h2 id="出版者语"><a class="markdownIt-Anchor" href="#出版者语"></a> 出版者语</h2>
<blockquote>
<p>深入心灵，是一段艰难的旅程，也是一条少有人走的路。</p>
</blockquote>
<h2 id="中文版序"><a class="markdownIt-Anchor" href="#中文版序"></a> 中文版序</h2>
<blockquote>
<p>人可以拒绝任何东西，但绝对不可以拒绝成熟。拒绝成熟，实际上就是在回避问题、逃避痛苦。回避问题和逃避痛苦的趋向，是人类心理疾病的根源，不及时处理，你就会为此付出沉重的代价，承受更大的痛苦。心智成熟不可能一蹴而就，它是一个艰苦的旅程。</p>
</blockquote>
<h2 id="问题和痛苦"><a class="markdownIt-Anchor" href="#问题和痛苦"></a> 问题和痛苦</h2>
<blockquote>
<p>解决人生问题的关键在于自律。人若缺少自律，就不可能解决任何麻烦和问题。在某些方面自律，只能解决某些问题，全面的自律才能解决人生所有的问题。</p>
</blockquote>
<blockquote>
<p>人生是一个不断面对问题并解决问题的过程。问题可以开启我们的智慧，激发我们的勇气。为解决问题而努力，我们的思想和心灵就会不断成长，心智就会不断成熟。</p>
</blockquote>
<blockquote>
<p>回避问题和逃避痛苦的倾向，是人类心理疾病的根源。</p>
</blockquote>
<blockquote>
<p>简单地说，所谓自律，就是主动要求自己以积极的态度去承受痛苦，解决问题。自律有四个原则：推迟满足感、承担责任、忠于事实、保持平衡。</p>
</blockquote>
<h2 id="推迟满足感"><a class="markdownIt-Anchor" href="#推迟满足感"></a> 推迟满足感</h2>
<blockquote>
<p>推迟满足感，就是不贪图暂时的安逸，先苦后甜，重新设置人生快乐与痛苦的次序：首先，面对问题并感受痛苦；然后，解决问题并享受更大的快乐。在充满问题和痛苦的人生中，推迟满足感是唯一可行的生活方式。</p>
</blockquote>
<h2 id="子不教谁之过"><a class="markdownIt-Anchor" href="#子不教谁之过"></a> 子不教，谁之过</h2>
<blockquote>
<p>对自我价值的认可是自律的基础，因为当一个人觉得自己很有价值时，就会采取一切必要的措施来照顾自己。自律是自我照顾，自我珍惜，而不是自暴自弃。</p>
</blockquote>
<blockquote>
<p>要让孩子养成推迟满足感的习惯，就必须让他们学会自律。要让他们学会自律，对安全感产生信任，不仅需要父母真心投入，还需要父母表里如一的爱和持之以恒的照顾，这是父母送给子女最好的礼物。如果这份礼物无法从父母那里获得，孩子也有可能从其他渠道得到，不过其过程必然更为艰辛，通常要经过一生的鏖战，而且常常以失败告终。</p>
</blockquote>
<h2 id="解决问题的时机"><a class="markdownIt-Anchor" href="#解决问题的时机"></a> 解决问题的时机</h2>
<blockquote>
<p>许多人都没有付出足够的时间和精力，去解决知识、社交、心理方面的问题——就像我对待机械问题的态度一样。</p>
</blockquote>
<blockquote>
<p>问题一旦出现，就想立刻解决，不然就会思绪烦乱、寝食不安。这样的心态显然不切实际，但一厢情愿地等待问题自行消失，则是更为可怕的事情，通常不会带来任何好结果。</p>
</blockquote>
<blockquote>
<p>忽视问题的存在，反映出人们不愿推迟满足感的心理。前面已经说过，直面问题会使人感觉痛苦。问题通常不可能自行消失，若不解决，就会永远存在，阻碍心智的成熟</p>
</blockquote>
<h2 id="承担责任"><a class="markdownIt-Anchor" href="#承担责任"></a> 承担责任</h2>
<blockquote>
<p>不能及时解决自己面临的问题，这些问题就会像山一样横亘在我们心中，阻碍心灵的成长和心智的成熟。很多人显然忽略了这个道理。我们必须面对属于自己的问题，这是解决问题的基本前提。</p>
</blockquote>
<h2 id="神经官能症与人格失调症"><a class="markdownIt-Anchor" href="#神经官能症与人格失调症"></a> 神经官能症与人格失调症</h2>
<blockquote>
<p>求助于心理医生的大多数人，所患的不是神经官能症，就是人格失调症。它们都是责任感出现问题所致，</p>
</blockquote>
<blockquote>
<p>神经官能症患者为自己强加责任，人格失调症患者则不愿承担原本属于自己的责任。</p>
</blockquote>
<blockquote>
<p>只有通过大量的生活体验，让心灵充分成长，心智足够成熟，我们才能够正确认识自己，客观评定自己和他人应该承担的责任。</p>
</blockquote>
<blockquote>
<p>你不能解决问题，你就会成为问题。</p>
</blockquote>
<h2 id="逃避自由"><a class="markdownIt-Anchor" href="#逃避自由"></a> 逃避自由</h2>
<blockquote>
<p>大多数患者力不从心的根源，在于他们总想逃避自由，不去为自己的问题、自己的生活承担责任。他们感到乏力，是因为他们放弃了自己的力量。如果得到治疗，他们就会知道，作为成年人，他们一生都充满选择和决定的机会。接受这一事实，就会变成自由的人；无法接受这种事实，就会永远觉得自己是个牺牲品。</p>
</blockquote>
<h2 id="忠于事实"><a class="markdownIt-Anchor" href="#忠于事实"></a> 忠于事实</h2>
<blockquote>
<p>实事求是，杜绝虚假，因为虚假与事实完全对立。我们越是了解事实，处理问题就越是得心应手；对事实了解得越少，思维就越是混乱。虚假、错觉和幻想只能让我们不知所措</p>
</blockquote>
<blockquote>
<p>我们对现实的观念就像是一张地图，凭借这张地图，我们才能了解人生的地形、地貌和沟壑，指引自己的道路。如果地图准确无误，我们就能确定自己的位置，知道自己要到什么地方，怎样到达那里；如果地图信息失真，漏洞百出，我们就会迷失方向。</p>
</blockquote>
<blockquote>
<p>我们出生时，并不是带着地图来到世界的。为了在人生的旅途上顺利行进，我们需要努力绘制自己的地图。我们的努力程度越高，对事实的认识越清楚，地图的准确性就越高。</p>
</blockquote>
<blockquote>
<p>绘制人生地图的艰难，不在于我们需要从头开始，而在于需要不断修订，才能使地图的内容准确翔实。</p>
</blockquote>
<blockquote>
<p>人生苦短，我们只想一帆风顺。我们由儿童成长为青年人、中年人乃至老年人，付出了不懈的努力，才绘成了现在这幅关于人生观和世界观的地图，似乎各方面都完美无缺。一旦新的信息与过去的观念发生冲突，需要对地图大幅度修正，我们就会感到恐惧，宁可对新的信息视而不见。</p>
</blockquote>
<h2 id="移情过时的地图"><a class="markdownIt-Anchor" href="#移情过时的地图"></a> 移情：过时的地图</h2>
<blockquote>
<p>移情的定义。我的定义是：把产生和适用于童年时期的那些感知世界、对世界做出反应的方式，照搬到成年后的环境中，尽管这些方式已经不再适用于新的环境。</p>
</blockquote>
<blockquote>
<p>逃避现实的痛苦是人类的天性，只有通过自律，我们才能逐渐克服现实的痛苦，及时修改自己的地图，逐步成长。我们必须忠于事实，尽管这会带来暂时的痛苦，但远比沉湎于虚假的舒适中要好。我们必须忍受暂时的不适感，追求事实而不是假象，并承受这一过程的痛苦。要让心灵获得成长，心智走向成熟，就要竭尽全力，不惜一切代价，完全忠于事实。</p>
</blockquote>
<h2 id="迎接挑战"><a class="markdownIt-Anchor" href="#迎接挑战"></a> 迎接挑战</h2>
<blockquote>
<p>完全忠于事实的生活到底意味着什么呢？首先，它意味着我们要用一生的时间进行不间断地严格地自我反省。我们通过自身与外界的接触来认识世界。</p>
</blockquote>
<blockquote>
<p>忠于事实的生活还意味着我们要敢于接受外界的质疑和挑战。这</p>
</blockquote>
<blockquote>
<p>完全忠于事实的第三个要求，就是我们需要一辈子保持诚实。我们必须不断自我反省，确保我们的言语能够准确地表述出我们所认知的事实。</p>
</blockquote>
<blockquote>
<p>人们不仅对别人撒谎，也会对自己撒谎。由于对别人撒谎违背自己的良知，会遭到良心的谴责，这会使我们感到痛苦，所以，为了逃避这种痛苦，人们便会对自己撒谎</p>
</blockquote>
<blockquote>
<p>心理医生最重要的任务，就是让患者说出真话。长时间自欺欺人，使人的愧疚积聚，就会导致心理疾病。</p>
</blockquote>
<h2 id="隐瞒真相"><a class="markdownIt-Anchor" href="#隐瞒真相"></a> 隐瞒真相</h2>
<blockquote>
<p>谎言通常分为两种：白色谎言和黑色谎言。所谓黑色谎言，就是彻头彻尾地撒谎，叙述的情况与现实完全不符；所谓白色谎言，其本身或许能反映事实，却有意隐瞒大部分真相</p>
</blockquote>
<blockquote>
<p>怎样做才不致违背忠于事实的自律精神呢？我们应该采取如下原则：首先，永远不要说假话，避免黑色谎言；其次，要牢牢记住，除非是迫不得已，或者出于重大道德因素的考虑，否则，不说出全部真相就等于说谎；第三，不可因个人自私自利的欲望，例如满足权力欲、刻意讨上司的欢心、逃避修订心灵地图的挑战等，而将部分真相隐瞒下来；第四，只有在对对方确有好处的情况下，才能有选择地隐瞒部分真相；第五，尽可能忠实地评估对方的需要。这是一件极为复杂的工作，只有以真爱为出发点，才能做出恰当的评判和选择；第六，评估的要领在于，对方能否借助我们提供的事实获得心灵的成长。最后一点需要铭记在心的是，我们通常会低估而不是高估别人运用事实使心灵获得成长的能力。</p>
</blockquote>
<blockquote>
<p>很多人惧怕其中的痛苦，宁可选择有限的诚实和开放，这等同于生活在封闭状态中，不敢把自己以及自己的地图呈现给世人。自我封闭尽管表面上容易，却会让我们付出惨痛的代价。以开放的心态和积极的努力，不断修订人生地图，才能使我们的心灵获得成长。这样的人因为从未说过假话，所以他们可以充满自信地告诉世人，自己给这个世界带来的是启迪和澄清，而不是困扰，并以此为荣。最终他们会获得完全的自由，不必苦于每日的东躲西藏。与过于封闭的人相比，开放的人拥有更健康的心理状态，更美好的人际关系。他们开诚布公，不必文过饰非，因此少了很多忧愁和烦恼。</p>
</blockquote>
<h2 id="保持平衡"><a class="markdownIt-Anchor" href="#保持平衡"></a> 保持平衡</h2>
<blockquote>
<p>失去平衡远比放弃更为痛苦。我想不管是谁，经过人生旅途的急转弯时，都必须放弃某些快乐，放弃属于自己的某一部分。除非永远停留在原地，中止生命之旅，否则这样的放弃是不可避免的。</p>
</blockquote>
<h2 id="抑郁的价值"><a class="markdownIt-Anchor" href="#抑郁的价值"></a> 抑郁的价值</h2>
<blockquote>
<p>心理学家埃里克·艾瑞克森曾列举出人生各阶段的八种危机。只有放弃旧的、过时的观念和习惯，才能渡过危机，顺利进入人生的下一阶段。不少人不敢面对现实，或者无法放弃早已过时的东西，所以无法克服心理和精神的危机，只能止步不前，不能享受到新生带来的欢悦，也不能顺利地进入更加成熟的心智发展阶段。</p>
</blockquote>
<blockquote>
<p>总体说来，这些就是我们在人生过程中必须放弃的生活环境、个人欲望和处世态度。放弃这些的过程就是心智完美成长的过程。</p>
</blockquote>
<h2 id="放弃与新生"><a class="markdownIt-Anchor" href="#放弃与新生"></a> 放弃与新生</h2>
<blockquote>
<p>有一种暂时的放弃自我值得一提，因为这一种放弃是成年生活必须掌握的一种技能，也是促进心智成熟不可或缺的工具。</p>
</blockquote>
<blockquote>
<p>我必须超越现有的一切，超越以自我为中心的观念。消除由个人经验产生的成见之后，才会获得成熟的认识。这一过程包括两个步骤：消除熟悉的过去，追求新鲜的未来。面对陌生的人、事、物，我需要让昔日的经验、当前的需求和未来的期待一并出席，共同对我的需求和现实状况进行评估，做出恰当的判断和决定。为了体验新鲜事物的独特性，我必须以包容一切的姿态，说服既有的成见和观念暂时退位，让陌生、新奇的事物进入感官世界。</p>
</blockquote>
<blockquote>
<p>假使人生的目标就是逃避痛苦，那你完全可以得过且过，不必寻求精神和意识的发展。但是不经痛苦和折磨，就无法实现灵魂的超越。即便达到了很高的精神境界，但那时痛苦的强烈程度，可能远远超过你的想象，让你最终无法承受。</p>
</blockquote>
<h2 id="爱的定义"><a class="markdownIt-Anchor" href="#爱的定义"></a> 爱的定义</h2>
<blockquote>
<p>爱是人们自律的原动力。</p>
</blockquote>
<blockquote>
<p>爱，是为了促进自己和他人心智成熟，而不断拓展自我界限，实现自我完善的一种意愿。</p>
</blockquote>
<blockquote>
<p>真正的爱是行动，是一种由意愿而产生的行动。爱一个人却没有付诸行动，就等于从未爱过。</p>
</blockquote>
<h2 id="坠入情网"><a class="markdownIt-Anchor" href="#坠入情网"></a> 坠入情网</h2>
<blockquote>
<p>永远活在自我界限中，只会给人带来孤独。有的人把自我界限当成是一把保护伞，比如那些性格孤僻的人，因其童年生活都很不快乐，甚至遭到过不同程度的伤害，所以对于他们而言，外面的世界充满险恶，孤独和寂寞反倒能够给他们带来安全感。但是，我们中的大部分人还是渴望摆脱孤独，冲出自我界限的牢笼。</p>
</blockquote>
<h2 id="再谈自我界限"><a class="markdownIt-Anchor" href="#再谈自我界限"></a> 再谈自我界限</h2>
<blockquote>
<p>在爱的过程中，我们感觉自己的灵魂无限延伸，奔向心爱的对象。我们渴望给对方滋养，希望对方能够成长。被自我界限之外的对象吸引，促使我们产生冲动，想把激情乃至生命献给对方，心理学家把这种状态称之为“精神贯注”。</p>
</blockquote>
<blockquote>
<p>恋爱或性却有可能成为真爱的开始，因为恋爱和性爱造成的自我界限的暂时消失，可以使我们对对方做出承诺，而在履行承诺的过程中，真正的爱便可能产生。</p>
</blockquote>
<h2 id="依赖性"><a class="markdownIt-Anchor" href="#依赖性"></a> 依赖性</h2>
<blockquote>
<p>真正的爱是自由的选择。真正相爱的人，不一定非要生活在一起，只是选择生活在一起罢了。</p>
</blockquote>
<blockquote>
<p>所谓消极性依赖，是指患者只在乎别人能为他们做什么，却从不考虑自己能为对方付出多少。</p>
</blockquote>
<blockquote>
<p>依赖性过强的人，总是把失去伴侣的支持当成极其恐怖的事。他们丝毫不肯降低对他人的依赖度，也不肯给予对方更多的自由。</p>
</blockquote>
<blockquote>
<p>只想获取却不愿付出，心智就会永远停留在不成熟的状态，这只会对人生构成限制和束缚，给人际关系造成破坏，让别人跟着遭殃，而不是促进别人的心灵成长。</p>
</blockquote>
<h2 id="精神贯注"><a class="markdownIt-Anchor" href="#精神贯注"></a> 精神贯注</h2>
<blockquote>
<p>过分依赖的人只关心自己的滋养，只在乎自己的感受，只想自己过得丰富而充实。他们渴望快乐和享受，不能忍受成长的痛苦、孤独和寂寞。他们既不关心自己心智的成熟，也不关心别人心智的成熟，哪怕是他们依赖的对象。他们只关心别人是否能永远满足他们的需要。</p>
</blockquote>
<blockquote>
<p>不是所有的“精神贯注”都是爱，那些与心智成熟无关，不能给心灵带来任何滋养的“精神贯注”，都不是真正意义上的爱。</p>
</blockquote>
<blockquote>
<p>爱的唯一目标，乃是促进心智的成熟和人性的进步。</p>
</blockquote>
<blockquote>
<p>我们爱的真正对象应该是人。只有人类的心灵，才有成长与进步的能力。如果我们丧失了爱人类的能力，就可能把情感转移到其他事物上，以为这样也可以培养出真正的爱。</p>
</blockquote>
<blockquote>
<p>对那些寂寞而孤单的人而言，宠物就像他们的生命，是人生的一切，在他们看来，这不是爱又是什么呢？但是，人和人之间的关系，并不同于人和宠物的关系。首先，我们和宠物的沟通相当有限，我们不知道它们每天在想什么，却一厢情愿，把自己的想法和感受投射到它们身上，甚至引之为人生知己。实际上，这只是我们的主观愿望罢了。其次，我们喜欢宠物的原因是，它们表现乖巧，任凭摆弄。如果宠物不听话，破坏家具，随意大小便，甚至咬上我们几口，我们就可能把它们赶出家门。</p>
</blockquote>
<blockquote>
<p>我们豢养宠物，只是希望它们永远都不要长大，可以乖乖地陪伴我们。我们看重的，是宠物对我们的依赖性。</p>
</blockquote>
<h2 id="自我牺牲"><a class="markdownIt-Anchor" href="#自我牺牲"></a> “自我牺牲”</h2>
<blockquote>
<p>很多时候，我们自称为别人着想，可能只是为了逃避责任，满足自己的愿望：我们所做的一切都是出自个人的意愿，核心动机是满足自我的需求；不管为别人做什么事，真正的原因都是为了自己。</p>
</blockquote>
<blockquote>
<p>真正的爱能够使人发生改变，在本质上是一种自我扩展，而非纯粹的自我牺牲。所以，爱在某种意义上是自私的，最终追求的是自我完善。区别爱与非爱的关键不是自私或是无私，而是行为的目的。真爱的目的永远都是促进心智的成熟，出于其他目的的“爱”都不是真爱。</p>
</blockquote>
<h2 id="爱不是感觉"><a class="markdownIt-Anchor" href="#爱不是感觉"></a> 爱，不是感觉</h2>
<blockquote>
<p>真正的爱，需要投入和奉献，需要付出全部的智慧和力量。</p>
</blockquote>
<blockquote>
<p>真正的爱，其价值在于始终如一的行动，这远远大于转瞬即逝的感觉或者精神贯注。真正的爱出自自我意愿，只能依靠实际行动来证明。“爱”与“非爱”的区别，正如善与恶的区别一样，有着客观的标准。爱是行动，不是空想。</p>
</blockquote>
<h2 id="关注的艺术"><a class="markdownIt-Anchor" href="#关注的艺术"></a> 关注的艺术</h2>
<blockquote>
<p>拓展自我界限就如同走路一样，每多走一步或多走一里，都可以逐步对抗与生俱来的惰性，抵御因恐惧而产生的排斥心理。拓展自我界限，意味着摆脱惰性，直面内心的恐惧。而爱则可以给我们勇气，使我们敢于迈向未知的领域，敢于拓展自己和他人的心理界限。</p>
</blockquote>
<blockquote>
<p>爱是为了努力促进自己和他人心智成熟，而表现出来的一种勇气。</p>
</blockquote>
<blockquote>
<p>爱，最重要的体现形式，就是关注。我们爱某个人，一定会关注对方，细心照料对方，进而帮助对方成长。</p>
</blockquote>
<blockquote>
<p>用心倾听是一种耗费精力的过程，必须以爱为出发点，只有基于共同成长、自我拓展和自我完善的意愿，才能够达到倾听的目的。但是，很多人却缺乏用心倾听的能力，不管是在商务活动还是在社交生活中，他们都不会长时间倾听他人讲话，而是采取有选择地倾听，他们的头脑早已被别的事情所占据，一边假装倾听，一边想着怎样使谈话尽早结束，怎样尽快达到目的。</p>
</blockquote>
<h2 id="爱与自律"><a class="markdownIt-Anchor" href="#爱与自律"></a> 爱与自律</h2>
<blockquote>
<p>自律的原动力来自于爱，而爱的本质是一种意愿。自律是将爱转化为实际行动的具体方法。所有的爱，都离不开自律；真正懂得爱的人，必然懂得自我约束，并会以此促进双方心智的成熟。</p>
</blockquote>
<blockquote>
<p>真正的爱，在促进对方心智成熟的同时，也会让你的心灵得到成长，你会体验到莫大的喜悦，幸福感会越发真实和持久。</p>
</blockquote>
]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>读书</tag>
      </tags>
  </entry>
  <entry>
    <title>书摘：《少有人走的路2》-[美]m·斯科特·派克(m.scottPeck)</title>
    <url>/2020/01/11/%E4%B9%A6%E6%91%98_%E5%B0%91%E6%9C%89%E4%BA%BA%E8%B5%B0%E7%9A%84%E8%B7%AF2-%5B%E7%BE%8E%5Dm%C2%B7%E6%96%AF%E7%A7%91%E7%89%B9%C2%B7%E6%B4%BE%E5%85%8B(m.scottPeck).hexo/</url>
    <content><![CDATA[<div class="douban-card-block">
	<a class="douban-card" href="https://book.douban.com/subject/25852589">
		<div class="douban-card-bgimg" style="background-image: url('https://images.weserv.nl/?url=https://img1.doubanio.com/view/subject/s/public/s27993498.jpg');"></div>
		<div class="douban-card-left">
			<div class="douban-card-img" style="background-image: url('https://images.weserv.nl/?url=https://img1.doubanio.com/view/subject/s/public/s27993498.jpg');"></div>
		</div>
		<div class="douban-card-right" style="line-height: 1.7;">
			<div class="douban-card-item"><span>书名: </span><strong>少有人走的路2</strong></div>
			<div class="douban-card-item"><span>作者: </span><span>[美国]斯科特·派克</span></div>
			<div class="douban-card-item"><span>出版年份: </span><span>2013-10-1</span></div>
			<div class="douban-card-item"><span>评分: </span><span>8.2</span></div>
		</div>
	</a>
</div>
<style>
	.douban-card-block {
		display: flex;
		justify-content: center;
		align-items: center;
		width: 100%;
		max-height: 400px;
	}
	.douban-card {
		display: flex;
		margin: 30px 10px;
		padding: 15px;
		border-radius: 10px;
		position: relative;
		justify-content: center;
		align-items: center;
		overflow: hidden;
		color: antiquewhite;
		text-decoration: none;
	}
	.douban-card:hover {
		text-decoration: none;
	}
	.douban-card-bgimg {
		position: absolute;
		width: 115%;
		height: 115%;
		filter: blur(15px) brightness(0.6);
		background-size: 100%;
		background-position: center;
		background-repeat: no-repeat;
	}
	.douban-card-img {
		position: relative;
		height: 130px;
		width: 80px;
		background-size: 100%;
		background-position: center;
		background-repeat: no-repeat;
	}
	.douban-card-img {
		position: relative;
		height: 130px;
		width: 80px;
	}
	.douban-card-left {
		position: relative;
		display: flex;
		flex-direction: column;
		align-items: center;
	}
	.douban-card-right {
		position: relative;
		display: flex;
		flex-direction: column;
		margin-left: 12px;
		font-size: 16px;
		font-family: 'Courier New', Courier, monospace;
		line-height: 1.3;
		color: antiquewhite;
	}
	.douban-card-item {
		margin-top: 4px;
	}
</style>
<a id="more"></a>
<h2 id="中文版序"><a class="markdownIt-Anchor" href="#中文版序"></a> 中文版序</h2>
<blockquote>
<p>真正勇敢的人是敢于面对自己内心的人。只要我们勇敢面对自己的问题和痛苦，不选择逃避，不选择谎言，就一定可以摆脱掉心中那只恶狼的追赶，迎来光明的人生。</p>
</blockquote>
<h2 id="第1章-谎言是心理疾病的根源"><a class="markdownIt-Anchor" href="#第1章-谎言是心理疾病的根源"></a> 第1章  谎言是心理疾病的根源</h2>
<blockquote>
<p>只要接受了人生苦难重重的事实，我们就能从苦难中解脱出来，实现人生的超越。人正是在承受痛苦和解决问题的过程中，心灵才得以成长和成熟</p>
</blockquote>
<blockquote>
<p>如果害怕面对问题，畏惧承受痛苦，一心想要逃避，那么我们虽然能够逃避人生正常的痛苦，却会承受心理疾病这种非正常的痛苦。荣格说：“神经官能症，是人生痛苦常见的替代品。”所以，逃避问题和痛苦是一切心理问题的根源。你不解决问题，你就会成为问题！</p>
</blockquote>
<blockquote>
<p>人是用什么方式在逃避问题和痛苦呢？简单地说，就是谎言。谎言的本质是掩盖真相，颠倒是非，人正是用它来逃避自己面临的问题和需要承受的痛苦。</p>
</blockquote>
<blockquote>
<p>从根本上来说，心理治疗是要让人把曾经逃避的痛苦说出来，它既是一种鼓励说真话的游戏，也是一种揭穿谎言的行为。</p>
</blockquote>
<h2 id="把生命颠倒一下就变成了邪恶"><a class="markdownIt-Anchor" href="#把生命颠倒一下就变成了邪恶"></a> 把生命颠倒一下，就变成了邪恶</h2>
<blockquote>
<p>所谓善，就是从本质上热爱生命，对一切充满生命力的事物都有一种与生俱来的亲近感。这种人拥有正常人具有的情感和意愿，能够努力去获取丰富的人生体验，理解生命的价值和意义。他们发出自己的光，但不会吹熄别人的灯</p>
</blockquote>
<blockquote>
<p>所谓恶，就是对死的东西极度感兴趣。具有“恋尸癖”的人被所有没有生气和死的东西所吸引和狂迷，诸如，死尸、腐物、粪便和污垢。他们对此类事物有一种莫名的亲近感，不管是喜欢还是讨厌，都会被它诱惑，不由自主地注意它，并对其作出反应。这些人发不出生命之光，却会去吹熄别人的灯。</p>
</blockquote>
<blockquote>
<p>恶，是运用一切影响力阻止他人心智成熟与自我完善的行为。</p>
</blockquote>
<h2 id="如何识别伪善之人远离邪恶"><a class="markdownIt-Anchor" href="#如何识别伪善之人远离邪恶"></a> 如何识别伪善之人，远离邪恶</h2>
<blockquote>
<p>伪善之人特别在乎自己的形象，总是衣冠楚楚，他们与普通人没什么两样，有的也许很穷，有的也许很富，有的受过高等教育，有的则目不识丁，表面上看他们都是脚踏实地的公民，看不出有什么不良嗜好。</p>
</blockquote>
<blockquote>
<p>其次，伪善的人对伦理道德十分熟悉，也熟悉法律，因为只有这样，他们才能逃避良心的谴责和法律的制裁。</p>
</blockquote>
<blockquote>
<p>第三，伪善的人努力追名逐利，不怕吃苦，而且还会有超强的心理承受力。</p>
</blockquote>
<blockquote>
<p>第四，伪善之人都是“恶性自恋”的人。</p>
</blockquote>
<blockquote>
<p>最后，也是最重要的一点，识别一个人是不是伪善的恶人，还要听从自己的直觉。</p>
</blockquote>
<h2 id="第3章-压制别人就是邪恶"><a class="markdownIt-Anchor" href="#第3章-压制别人就是邪恶"></a> 第3章  压制别人，就是邪恶</h2>
<blockquote>
<p>罪恶感就像是一盏灯，有了罪恶感，人才能看清自己身上的“恶”，从而走向善；而逃避罪恶感，不愿意承受良心的谴责，心灵就会一片漆黑。这样的心灵不仅无法燃烧出生命的光芒，还会吹熄别人的灯，扼杀别人的生命力。</p>
</blockquote>
<blockquote>
<p>为了逃避罪恶感，人会用谎言来掩盖真相，欺骗自己和别人，进而压制别人的生命力，毁灭别人的人生。</p>
</blockquote>
<h2 id="压制别人就是邪恶"><a class="markdownIt-Anchor" href="#压制别人就是邪恶"></a> 压制别人，就是邪恶</h2>
<blockquote>
<p>杀戮是恶，因为它把鲜活的生命变成了尸体。同样，压制别人的生命力和创造力，限制别人思想自由，阻碍别人心灵成长，一味地控制别人、操纵别人，试图把别人变成行尸走肉，更是一种普遍存在的恶。</p>
</blockquote>
<blockquote>
<p>对于正在成长中的孩子来说，父母最应该给予的是爱。爱的目的，是要帮助孩子确立独立的人格，而不是让他的人格依附于父母；是要让孩子勇敢地去追逐自己的梦想，而不是让孩子替父母圆梦；是要让孩子自己去体验生活，而不是要父母替孩子生活。真正爱孩子的父母都明白，爱孩子，就要尊重孩子，尊重他们的意愿和感受，尊重他们有做决定的权力</p>
</blockquote>
<blockquote>
<p>爱的最终目标，不是要成为孩子生活的中心，而是要从孩子生命的重心中逐渐抽离出来，让孩子去走自己的路。这样的爱不仅能促进孩子的心灵成长，同样也能促进父母的心灵成长。</p>
</blockquote>
<blockquote>
<p>不管父母口口声声说自己多么爱孩子，只要他们不接受孩子的独立性，压制孩子的思想和情感，这都不是爱，而是恶。</p>
</blockquote>
<h2 id="要敞开心灵但不要把心灵交给对方管理"><a class="markdownIt-Anchor" href="#要敞开心灵但不要把心灵交给对方管理"></a> 要敞开心灵，但不要把心灵交给对方管理</h2>
<blockquote>
<p>婚姻不应该成为一个埋葬自我的坟场，而应该成为一个提升自我、拓展自我和完善自我的圣地。同样，婚姻需要彼此坦诚相见，却不需要把自己的心灵出卖给对方。那些试图在婚姻中寻求依赖和控制的人，注定会迷失方向。</p>
</blockquote>
<h2 id="不敢面对自己才会去控制别人"><a class="markdownIt-Anchor" href="#不敢面对自己才会去控制别人"></a> 不敢面对自己，才会去控制别人</h2>
<blockquote>
<p>寻找真实自己的过程，是一个痛苦的过程，需要接纳自己的不完美，承受罪恶感所带来的痛苦。</p>
</blockquote>
<h2 id="爱需要一个空间否则便会感到窒息"><a class="markdownIt-Anchor" href="#爱需要一个空间否则便会感到窒息"></a> 爱需要一个空间，否则便会感到窒息</h2>
<blockquote>
<p>爱，是为了成长，成长需要足够的空间；邪恶的本质是压制，它压制别人的自我，压缩别人的空间。但遗憾的是，有些人偏偏把压制当成了爱。</p>
</blockquote>
<h2 id="第5章-从小缺乏爱长大就容易变坏"><a class="markdownIt-Anchor" href="#第5章-从小缺乏爱长大就容易变坏"></a> 第5章  从小缺乏爱，长大就容易变坏</h2>
<blockquote>
<p>几乎每个人都有一定的自恋倾向。不过，正常的自恋，并不是死死地抱着固有的自我不放，而是能够不断突破自我的界限，获得心灵的成长和心智的成熟。但恶性自恋则与之不同，恶性自恋不愿意放弃固有的自我，顽固坚守陈旧的过去，宁愿牺牲别人，也不愿意改变自己。</p>
</blockquote>
<h2 id="自闭是更高程度的自恋"><a class="markdownIt-Anchor" href="#自闭是更高程度的自恋"></a> 自闭，是更高程度的自恋</h2>
<blockquote>
<p>自闭是自恋的终极形式。彻底的自恋者会认为人与家具没什么两样，都是不具有心理感受和情绪的实物。自恋者心中只认为自己最重要，即布伯所谓的唯我独尊的“自我主义”关系观。</p>
</blockquote>
<h2 id="内心没有安全感就想去控制外面的一切"><a class="markdownIt-Anchor" href="#内心没有安全感就想去控制外面的一切"></a> 内心没有安全感，就想去控制外面的一切</h2>
<blockquote>
<p>所谓病态的自我，就是被谎言包裹着的自我。这个自我不敢面对自己的问题和痛苦，不愿正视自己。说谎的人虽然外表从容淡定，但却始终不敢去正视自己的内心，因为正视内心会让他们感受到极大的痛苦，他们不明白痛苦正是生命力的一种表现，否认痛苦也就否认了生命力。</p>
</blockquote>
<h2 id="没勇气正视过去就不会有未来"><a class="markdownIt-Anchor" href="#没勇气正视过去就不会有未来"></a> 没勇气正视过去，就不会有未来</h2>
<blockquote>
<p>撒谎成性之人不是无药可救的，而每一个人，都应该用心中的爱，给予他们勇气，让他们勇敢地面对过去，走出谎言，获得灵魂的救赎，获得心灵的成长。</p>
</blockquote>
<h2 id="第6章-勇敢地面对谎言"><a class="markdownIt-Anchor" href="#第6章-勇敢地面对谎言"></a> 第6章   勇敢地面对谎言</h2>
<blockquote>
<p>所谓谎言，就是掩盖真相，使自己的认识与实际情况不符。过去的已经过去，你抱着过去的自我不放，与现在的情况不相符，甚至完全脱节，这就是谎言。</p>
</blockquote>
<blockquote>
<p>为什么人会抱着过去的自我不放呢？有两个原因：一是过去的自我被溺爱，自己感觉很舒适，不愿意去改变，这种懒惰的心理注定会阻碍成长的道路；二是过去的自我没有获得父母的爱，甚至还遭到伤害，内心充满了恐惧。</p>
</blockquote>
<blockquote>
<p>回头是岸，意味着勇敢地回到过去，在承认过去自我的基础上，放弃旧我，获得新我，促使自我不断拓展和完善。</p>
</blockquote>
<h2 id="为什么天使会变成魔鬼"><a class="markdownIt-Anchor" href="#为什么天使会变成魔鬼"></a> 为什么天使会变成魔鬼</h2>
<blockquote>
<p>如果我们勇敢面对自己的内心，敢于正视自己的缺陷，敢于承受不完美所带来的痛苦，那么，我们就能在接纳真实自我的基础上拓展自我界限，获得心灵的成长和心智的成熟</p>
</blockquote>
<blockquote>
<p>正视自己的过程，是一个逐步面对真相，逐渐戳穿谎言的过程。由于人性中存在着许许多多的缺陷和弱点，如懒惰、恐惧和骄傲等等，所以人们往往不愿意面对现实，承受痛苦，总是用谎言来逃避。</p>
</blockquote>
<blockquote>
<p>不敢面对真实的自我，人就会选择谎言；选择谎言，意味着失去自我，出卖灵魂；而一个没有灵魂的人则会无恶不作。所以，只有勇敢揭穿谎言，我们才能消除邪恶。</p>
</blockquote>
<h2 id="过分依赖集体个人的心智就会退化"><a class="markdownIt-Anchor" href="#过分依赖集体个人的心智就会退化"></a> 过分依赖集体，个人的心智就会退化</h2>
<blockquote>
<p>首先，选择，意味着放弃。选择一条路，意味着要放弃其他的路；有了一个选择，意味着要放弃其他选择。由于人们不愿意放弃，所以，每当面临选择时，内心总是充满了烦恼和痛苦。其次，选择会产生结果，人们必须为自己的选择负责，并承受选择所带来的结果。当然，好的结果让人欣喜，但坏的结果不仅会招致别人的指责、埋怨，也会让自己陷入懊悔和自责之中，令人痛苦不堪。许多人不愿意承担选择所带来的痛苦，便会把自主选择的权力拱手让给了别人。这就是弗洛姆所说的逃避自由。</p>
</blockquote>
<h2 id="勇敢地面对谎言"><a class="markdownIt-Anchor" href="#勇敢地面对谎言"></a> 勇敢地面对谎言</h2>
<blockquote>
<p>不能勇敢面对自己的问题，就容易产生邪恶。</p>
</blockquote>
<blockquote>
<p>一个人如果心中缺失了爱，他就没有勇气去直面内心的痛苦，就会用谎言来逃避。相反，只要人的心中拥有了足够多的爱的力量，他就能勇敢地去面对人生道路上的任何艰难险阻。</p>
</blockquote>
]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>读书</tag>
      </tags>
  </entry>
  <entry>
    <title>书摘：《成功，动机与目标》-海蒂•格兰特•霍尔沃森(heidiGrantHalvorson)</title>
    <url>/2020/11/25/%E4%B9%A6%E6%91%98_%E6%88%90%E5%8A%9F%EF%BC%8C%E5%8A%A8%E6%9C%BA%E4%B8%8E%E7%9B%AE%E6%A0%87-%E6%B5%B7%E8%92%82%E2%80%A2%E6%A0%BC%E5%85%B0%E7%89%B9%E2%80%A2%E9%9C%8D%E5%B0%94%E6%B2%83%E6%A3%AE(heidiGrantHalvorson).hexo/</url>
    <content><![CDATA[<div class="douban-card-block">
	<a class="douban-card" href="https://book.douban.com/subject/22994632">
		<div class="douban-card-bgimg" style="background-image: url('https://images.weserv.nl/?url=https://img1.doubanio.com/view/subject/s/public/s26039188.jpg');"></div>
		<div class="douban-card-left">
			<div class="douban-card-img" style="background-image: url('https://images.weserv.nl/?url=https://img1.doubanio.com/view/subject/s/public/s26039188.jpg');"></div>
		</div>
		<div class="douban-card-right" style="line-height: 1.7;">
			<div class="douban-card-item"><span>书名: </span><strong>成功，动机与目标</strong></div>
			<div class="douban-card-item"><span>作者: </span><span>[美]海蒂·格兰特·霍尔沃森</span></div>
			<div class="douban-card-item"><span>出版年份: </span><span>2013-3</span></div>
			<div class="douban-card-item"><span>评分: </span><span>8.8</span></div>
		</div>
	</a>
</div>
<style>
	.douban-card-block {
		display: flex;
		justify-content: center;
		align-items: center;
		width: 100%;
		max-height: 400px;
	}
	.douban-card {
		display: flex;
		margin: 30px 10px;
		padding: 15px;
		border-radius: 10px;
		position: relative;
		justify-content: center;
		align-items: center;
		overflow: hidden;
		color: antiquewhite;
		text-decoration: none;
	}
	.douban-card:hover {
		text-decoration: none;
	}
	.douban-card-bgimg {
		position: absolute;
		width: 115%;
		height: 115%;
		filter: blur(15px) brightness(0.6);
		background-size: 100%;
		background-position: center;
		background-repeat: no-repeat;
	}
	.douban-card-img {
		position: relative;
		height: 130px;
		width: 80px;
		background-size: 100%;
		background-position: center;
		background-repeat: no-repeat;
	}
	.douban-card-img {
		position: relative;
		height: 130px;
		width: 80px;
	}
	.douban-card-left {
		position: relative;
		display: flex;
		flex-direction: column;
		align-items: center;
	}
	.douban-card-right {
		position: relative;
		display: flex;
		flex-direction: column;
		margin-left: 12px;
		font-size: 16px;
		font-family: 'Courier New', Courier, monospace;
		line-height: 1.3;
		color: antiquewhite;
	}
	.douban-card-item {
		margin-top: 4px;
	}
</style>
<a id="more"></a>
<h2 id="序言"><a class="markdownIt-Anchor" href="#序言"></a> 序言</h2>
<blockquote>
<p>人是可以改变的。改变不容易，但在正确的动机与方法的引导下便是可能的。</p>
</blockquote>
<h2 id="导言"><a class="markdownIt-Anchor" href="#导言"></a> 导言</h2>
<blockquote>
<p>自制力是依照目标采取行动的能力。它能使你抵制诱惑、专心投入、克服困难，从而坚持不懈。自制力至关重要，它是实现目标最关键的元素之一。</p>
</blockquote>
<p>就我个人感觉而言。自制力这个东西。兽兽影响有两个东西。一个是那个现实的场景。有时候你很累，你自己的都很差，有时候心情很好，自己就上去了。吊哥，是那个量面对的东西。如果你那个。有决心去完成一个东西，自制力真的很强。如果你只是。随便完成而已。那就不一定能完成了。</p>
<h2 id="成功者不会事事成功"><a class="markdownIt-Anchor" href="#成功者不会事事成功"></a> 成功者不会事事成功</h2>
<blockquote>
<p>每个人都知道少吃多运动能够帮我们减轻体重。然而知道是一回事，真正去行动则是彻头彻尾的另一回事。</p>
</blockquote>
<p>这样的例子比比皆是。减肥是一方面吧！其实还有更多领域。我想要找到好的工作就必须复习认真地看书，然后去追寻职场。最新的动态。但现实中我确实没有这么去做。</p>
<h2 id="自制力的真实面目"><a class="markdownIt-Anchor" href="#自制力的真实面目"></a> 自制力的真实面目</h2>
<blockquote>
<p>当你刚做完一件需要很多自制力的事时（比如制作一期电视节目），自制力也会消耗不少。</p>
</blockquote>
<p>那其实这样子看来。人的智力就像一壶水。总会有被倒完的那一刻。又被填满的时候，所以其实是一个动态的变化过程。但是当你在一个市场花卉的知识力太多。你就较少的自制力去应对新的东西。</p>
<blockquote>
<p>那些在一个或多个人生领域里获得巨大成功的人恰恰是把大部分自制力投入到了那些相应的领域中了。如果每天面临很多压力，无论是谁都会感到乏力，无法达到某些目标。</p>
</blockquote>
<p>其实样子也给我提了一个醒。人的自制力是有限度的。我们必须把自制力投放到应对主要的事情上、关键的事情上。这也和一个观点相佐证。不要每天都在瞎忙，其实是在浪费你的自制力</p>
<h2 id="你能做什么"><a class="markdownIt-Anchor" href="#你能做什么"></a> 你能做什么</h2>
<blockquote>
<p>你让自制力歇息一会儿，它的能量就能恢复。消耗只是暂时的，你在刚刚用尽自制力能源时也是最脆弱的。</p>
</blockquote>
<p>这个体会很深切。现实生活中确实有还自制力就开始自暴自弃、看视频、打游戏什么的，反正就是很难约束自己。</p>
<blockquote>
<p>还</p>
</blockquote>
<p>在这一点上，你是有切身体会的。如之前想看抖音。之前还刷了一段时间的抖音，那时候真是着迷一样。然后来。等我多方路径查到抖音实际上是有那个。一定的手段让你一直眯着浪费时间在这app上，而且里面的质量一般，趋向于同化要认识到这个视频，对自己提升不是很大。要对这个视频就产生了厌恶感，然后进了。就没有一直没有用这个视频了。</p>
<blockquote>
<p>以奖励的方法增强动机可以暂时弥补受损的自制力。</p>
</blockquote>
<p>其实就奖励而言。主要分为两种的。第一种是别人给的。他这种就存在外部监督的情况。就比较好完成。第二种就是那个。自己为了完成某种目标而给自己一个未来的奖励。那这种就没有监督所以说我们最后完成那个事情的。概率就下降了。</p>
<blockquote>
<p>增强自制力的方式与增强肌肉性能是一样的——你需要定期锻炼。最近的研究表明，每天坚持锻炼身体、记账或者记录进食，甚至仅仅时不时地提醒自己坐直都能帮助一个人锻炼总体的自制力。</p>
</blockquote>
<p>自制力虽然是一个消耗品。但其实也是属于一个动态的过程。你可以消耗他你也可以那个补充他，锻炼他。</p>
<h2 id="第1章做到最好不够好"><a class="markdownIt-Anchor" href="#第1章做到最好不够好"></a> 第1章“做到最好”不够好</h2>
<blockquote>
<p>给自己立下过不少目标，但当真如此吗？还是你只是想要更开心、更健康或是更成功，却没真正决定过具体做什么？你有欲望，你想做的很多很多，但你把多少个愿望转化成真正的目标过？没有这个转化，我们的欲望就仅仅停留在那个“希望能够实现”的层面。</p>
</blockquote>
<p>确实。定了好多目标，要么就是在准备开始开工的过程中。要么就在想象目标完成之后的美好愿景中。从来没有真正行动起来过。</p>
<blockquote>
<p>当你用正确的方式聚焦于正确的细节时，成功就离你更近一步了。</p>
</blockquote>
<h2 id="别用做到最好"><a class="markdownIt-Anchor" href="#别用做到最好"></a> 别用“做到最好”</h2>
<blockquote>
<p>在全球上千例研究里，科研人员发现具体又有难度的目标比模糊或过于简单的目标更能激发优异的表现，而且差距是明显的。</p>
</blockquote>
<p>对于我个人而言。我现实生活中定了目标都是一个总体的想法。都是想到未来实现这个目标之后的愿景。但具体的目标我没有确定。这也是我们的非常缺乏的一点。</p>
<blockquote>
<p>如果奋斗的目标不明确，人们很容易向疲惫、灰心或无聊妥协，但若建立了具体的目标，你便无法欺骗自己了。达标或非达标，没有中间地带。你若是还没达标，若是还想成功，便只能继续努力。</p>
</blockquote>
<p>我就是没有对自己这么狠。没有留余地的去。实现一个目标。就想这么拖着。有想拖着他就是不想去。具体的规划具体的实施。种子一句话。应该对自己狠咯。</p>
<blockquote>
<p>你不能制定不现实或者不可能实现的目标。艰巨而具可能性才是关键。因为有难度的目标会促使你下更大功夫，更加聚精会神，更加没有二心。</p>
</blockquote>
<p>这个确实。你不能定那些目标，每天都干的。每天都是。唾手可得的都轻易完成了，那个目标完全没挑战性，你迟早会腻的。</p>
<blockquote>
<p>成功完成困难的事更使人愉悦，它能给人更大的满足感和快感，让人整体感觉更幸福。</p>
</blockquote>
<p>这个确实啊！我在研究生之前。也就本科。靠的是。成绩还算可以，水有点信心。研究生之后呢？好论是科研水平有老师的帮助，还算过得去，所以有点信心。其实每个阶段我都是靠着过往一段时间的那个成就经历。有点自信的活下去。</p>
<blockquote>
<p>对工作的满意度使人更致力于为所在机构工作，对自己更有信心，从而会给自己更多的挑战，这又带来更好的表现和更大的满意度，周而复始……制定具体而具挑战性的目标便创造了成功和幸福的无限循环。洛克和莱瑟姆称之为“高绩效循环”。</p>
</blockquote>
<p>这个就是一个比较完美的自我激励模式。在开始新书，我之前。利用已有的那一个。自信。勇敢的做新的东西。</p>
<h2 id="西瓜与芝麻"><a class="markdownIt-Anchor" href="#西瓜与芝麻"></a> 西瓜与芝麻</h2>
<blockquote>
<p>在不同情况下，一种思维方式可能比另一种更能有效地帮助人们实现目标，关键是要懂得针对不同情况而适当地转换思维方式。好消息是，这并不难实现。</p>
</blockquote>
<blockquote>
<p>当人们用“为什么”理解行为时总是会想得更宏观些——那些小的、日常的举动都变成更重大的目标的一部分。他们对长期目标更有概念。所以用“为什么”而不是“是什么”想问题的人更少冲动，更少被诱惑，还更常会为行动提早做准备。</p>
</blockquote>
<p>确实对一件事情来说，使用为什么的方式来思考问题能产生一个比较重大的成就的意义。但是这种意义是短暂的。恐怖的。就容易失去的。</p>
<blockquote>
<p>若要解决一件棘手的事，则用“是什么”思考更为恰当。学习一套新体系时需要把它拆成几个具体步骤。</p>
</blockquote>
<p>这个和前面的当面临困难问题的时候，使用为什么的方式来思考更容易启动问题。信不信矛盾了？你这面对困难的事情的时候，也同样使用一个是什么的方式来理解。应该不是一个意思吧？为什么面对的是一个不确定的困难的目标是什么？面对的是一个复杂的目标。</p>
<h2 id="现在还是未来"><a class="markdownIt-Anchor" href="#现在还是未来"></a> 现在还是未来</h2>
<blockquote>
<p>研究显示，我们偏向于用大而抽象的概念，也就是“为什么”式思维，来理解较久以后才会贯彻的计划。反之，我们理解近期计划时则会侧重于更切实际的想法——我们完成这件事需要做的“是什么”。</p>
</blockquote>
<p>在这一点上。我的体会还是蛮深刻的。我真的是一个只会思考为什么的人可以说几乎每天都在思考为什么？但是却很少用是什么去思考问题，缺少问题的规范性。</p>
<blockquote>
<p>“为什么”式思维会使你更看重心理学家所谓的“合意度”信息，意思就是说，你做成这件事或达到这个目标对你是否有好处，将会多有趣，多愉悦，多有益。</p>
</blockquote>
<blockquote>
<p>更加具体的“是什么”式思维会使你更加重视“可行度”信息——你是否真的能做到你要做的事？有多大把握成功？你面临着什么阻碍？当我们在考虑近期要执行的事时，这些是我们想得更多的问题。</p>
</blockquote>
<blockquote>
<p>我们大多数人都一次次地掉入这样的陷阱里，因为我们习惯于用“为什么”来考虑未来的事，而较少思考究竟如何实现这些目标。于是我们选择了有潜在丰厚报酬的目标，却带来了一场噩梦。</p>
</blockquote>
<p>确实害处很大呢，这样子思考。它相当于给你画了一个饼。然后你每天吃的这个饼感觉很舒服。但是你就没有去实现它。这难道不就是自己给自己下的毒药吗？</p>
<blockquote>
<p>当我们思考比较久远的事时，我们会牺牲实际的考虑而选择潜在的回报；当我们思考近期要做什么时就满脑子官司，放下了愉悦。换言之，说到未来，我们都像探险家；说到当下，就都像会计了。</p>
</blockquote>
<blockquote>
<p>用“是什么”方式思考目标不仅能让你更好地安排时间，还能防止拖延时间。</p>
</blockquote>
<p>我就是一个经常用为什么的方式来思考问题的人。结果到处都是拖延症，都不知道怎么往下走。</p>
<blockquote>
<p>用“是什么”方式看待目标能让你更专注于具体的必要行动，让你能更快地达到目标。太注重“为什么”做一件事则可能会让人行动比较拖拉。</p>
</blockquote>
<blockquote>
<p>具体地说,是视目标而定。对目标采取“为什么”式的大体思维能使你更有动力、备受鼓舞，专注于你能得到的回报，并增强自制力与毅力。而“是什么”的细节式思维在你做困难或生疏的事时最有帮助。它能使你专注于操作性细节，从而完成任务，并且能帮助你防止拖延。大的成就不是采用一种固定的思维方式就能得到的。</p>
</blockquote>
<p>这里就不了解是很好的解释了。什么情况下该用为什么？什么情况下可以用是什么的是个问题。</p>
<h2 id="正面思考"><a class="markdownIt-Anchor" href="#正面思考"></a> 正面思考</h2>
<blockquote>
<p>相信目标艰巨的人会做更多准备，下更大功夫，为目标做出更多行动。他们预料到要努力奋斗，便也是这样做的。</p>
</blockquote>
<p>相信自己成功很重要。但是如果是亲人相信自己亲人轻而易举的成功。确实不一样。</p>
<blockquote>
<p>那么怎样才能最好地树立并实现目标而不是活在白日梦中呢？最佳策略是用乐观的方式看待目标，同时用实际的方式思考具体需要做什么才能实现目标。奥丁根把它叫做“心理对照</p>
</blockquote>
<blockquote>
<p>放弃梦想可能是痛苦并让人失望的，但为你的身心着想也可能是重要和必需的。只有意识到某些目标无法实现我们才能为可实现的理想腾出空间。</p>
</blockquote>
<p>这就意味着他有些目标定的不是很好。有可能不是很好能实现。</p>
<blockquote>
<p>通过无数调查发现，当认为自己能完成目标的人运用了心理对照策略时，他们通常比只幻想美好结局的人表现得更好。心理对照带来了更大的努力、更多的能量和计划以及普遍更高的成就。</p>
</blockquote>
<p>生活之中我经常是只做了第一步。点我完全没做。</p>
]]></content>
  </entry>
  <entry>
    <title>书摘：《机器学习——Python实践》-魏贞原</title>
    <url>/2020/07/11/%E4%B9%A6%E6%91%98_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Python%E5%AE%9E%E8%B7%B5-%E9%AD%8F%E8%B4%9E%E5%8E%9F.hexo/</url>
    <content><![CDATA[<div class="douban-card-block">
	<a class="douban-card" href="https://book.douban.com/subject/27611266">
		<div class="douban-card-bgimg" style="background-image: url('https://images.weserv.nl/?url=https://img1.doubanio.com/view/subject/s/public/s29646619.jpg');"></div>
		<div class="douban-card-left">
			<div class="douban-card-img" style="background-image: url('https://images.weserv.nl/?url=https://img1.doubanio.com/view/subject/s/public/s29646619.jpg');"></div>
		</div>
		<div class="douban-card-right" style="line-height: 1.7;">
			<div class="douban-card-item"><span>书名: </span><strong>机器学习——Python实践</strong></div>
			<div class="douban-card-item"><span>作者: </span><span>魏贞原</span></div>
			<div class="douban-card-item"><span>出版年份: </span><span>2018-1</span></div>
			<div class="douban-card-item"><span>评分: </span><span>6.9</span></div>
		</div>
	</a>
</div>
<style>
	.douban-card-block {
		display: flex;
		justify-content: center;
		align-items: center;
		width: 100%;
		max-height: 400px;
	}
	.douban-card {
		display: flex;
		margin: 30px 10px;
		padding: 15px;
		border-radius: 10px;
		position: relative;
		justify-content: center;
		align-items: center;
		overflow: hidden;
		color: antiquewhite;
		text-decoration: none;
	}
	.douban-card:hover {
		text-decoration: none;
	}
	.douban-card-bgimg {
		position: absolute;
		width: 115%;
		height: 115%;
		filter: blur(15px) brightness(0.6);
		background-size: 100%;
		background-position: center;
		background-repeat: no-repeat;
	}
	.douban-card-img {
		position: relative;
		height: 130px;
		width: 80px;
		background-size: 100%;
		background-position: center;
		background-repeat: no-repeat;
	}
	.douban-card-img {
		position: relative;
		height: 130px;
		width: 80px;
	}
	.douban-card-left {
		position: relative;
		display: flex;
		flex-direction: column;
		align-items: center;
	}
	.douban-card-right {
		position: relative;
		display: flex;
		flex-direction: column;
		margin-left: 12px;
		font-size: 16px;
		font-family: 'Courier New', Courier, monospace;
		line-height: 1.3;
		color: antiquewhite;
	}
	.douban-card-item {
		margin-top: 4px;
	}
</style>
<a id="more"></a>
<h2 id="第一部分初始"><a class="markdownIt-Anchor" href="#第一部分初始"></a> 第一部分初始</h2>
<blockquote>
<p>机器学习（MachineLearning，ML）是一门多领域的交叉学科，涉及概率论、统计学、线性代数、算法等多门学科。</p>
</blockquote>
<blockquote>
<p>监督学习即在机器学习过程中提供对错指示。一般是在数据组中包含最终结果（0，1），通过算法让机器自己减少误差。这一类学习主要应用于分类和预测（Regression&amp;Classify）。</p>
</blockquote>
<blockquote>
<p>非监督学习又称归纳性学习（Clustering），利用K方式（KMean）建立中心（Centriole），通过循环和递减运算（Iteration&amp;Descent）来减小误差，达到分类的目的。</p>
</blockquote>
<blockquote>
<p>下面三个技巧可以有效地帮助你快速提高学习机器学习的能力。·启动一个可以在一个小时内完成的小项目。·通过每周完成一个项目来保持你的学习势头，并建立积累自己的项目工作区。·在微博、微信、Github等社交工具上分享自己的成果，或者随时随地地展示自己的兴趣，增加技能、知识，并获得反馈。</p>
</blockquote>
<blockquote>
<p>Python是一门面向对象的动态解释语言，简单易学，并且具有很好的可读性。</p>
</blockquote>
<blockquote>
<p>Python具有丰富和强大的类库，它常被称为“胶水语言”，能够很轻松地把用其他语言制作的各种模块（尤其是C/C++）联结在一起。</p>
</blockquote>
<blockquote>
<p>Python是一门动态语言，非常适合于交互性开发和大型项目的快速原型开发。</p>
</blockquote>
<blockquote>
<p>SciPy是在数学运算、科学和工程学方面被广泛应用的Python类库。它包括统计、优化、整合、线性代数模块、傅里叶变换、信号和图像处理、常微分方程求解器等，因此被广泛地应用在机器学习项目中。</p>
</blockquote>
<blockquote>
<p>NumPy：是Python的一种开源数值计算扩展。它可用来存储和处理大型矩阵，提供了许多高级的数值编程工具，如矩阵数据类型、矢量处理、精密的运算库。</p>
</blockquote>
<blockquote>
<p>Matplotlib：Python中最著名的2D绘图库，十分适合交互式地进行制图；也可以方便地将它作为绘图控件，嵌入GUI应用程序中。</p>
</blockquote>
<blockquote>
<p>Pandas：是基于NumPy的一种工具，是为了解决数据分析任务而创建的。Pandas纳入了大量库和一些标准的数据模型，提供了高效地操作大型数据集所需的工具，也提供了大量能使我们快速、便捷地处理数据的函数和方法。</p>
</blockquote>
<blockquote>
<p>scikit-learn是Python中开发和实践机器学习的著名类库之一，依赖于SciPy及其相关类库来运行。scikit-learn的基本功能主要分为六大部分：分类、回归、聚类、数据降维、模型选择和数据预处理。</p>
</blockquote>
<blockquote>
<p>使用with语句，简化了对异常的处理。因此，当需要对异常进行处理时，如果对象遵循了上下文管理协议（ContextManagementProtocol），建议使用with语句来实现。</p>
</blockquote>
<h2 id="第二部分数据理解"><a class="markdownIt-Anchor" href="#第二部分数据理解"></a> 第二部分数据理解</h2>
<blockquote>
<p>下面将介绍三种将CSV数据导入到Python中的方法，以便完成对机器学习算法的训练。·通过标准的Python库导入CSV文件。·通过NumPy导入CSV文件。·通过Pandas导入CSV文件。</p>
</blockquote>
<blockquote>
<p>Python提供了一个标准类库CSV，用来处理CSV文件。这个类库中的reader（）函数用来读入CSV文件。</p>
</blockquote>
<blockquote>
<p>也可以使用NumPy的loadtxt（）函数导入数据。使用这个函数处理的数据没有文件头，并且所有的数据结构是一样的，也就是说，数据类型是一样的。</p>
</blockquote>
<blockquote>
<p>通过Pandas来导入CSV文件要使用pandas.read_csv（）函数。这个函数的返回值是DataFrame，可以很方便地进行下一步的处理。</p>
</blockquote>
<blockquote>
<p>介绍七种方法来帮助大家理解数据。·简单地查看数据。·审查数据的维度。·审查数据的类型和属性。·总结查看数据分类的分布情况。·通过描述性统计分析数据。·理解数据属性的相关性。·审查数据的分布状况。</p>
</blockquote>
<blockquote>
<p>在分类算法中，需要知道每个分类的数据大概有多少条记录，以及数据分布是否平衡。如果数据分布的平衡性很差，需要在数据加工阶段进行数据处理，来提高数据分布的平衡性。</p>
</blockquote>
<blockquote>
<p>数据属性的相关性是指数据的两个属性是否互相影响，以及这种影响是什么方式的等。非常通用的计算两个属性的相关性的方法是皮尔逊相关系数，皮尔逊相关系数是度量两个变量间相关程度的方法。它是一个介于1和-1之间的值，其中，1表示变量完全正相关，0表示无关，-1表示完全负相关。</p>
</blockquote>
<blockquote>
<p>通过分析数据的高斯分布情况来确认数据的偏离情况。高斯分布又叫正态分布，是在数据、物理及工程等领域都非常重要的概率分布，在统计学的许多方面有着重大的影响。</p>
</blockquote>
<blockquote>
<p>相关矩阵图主要用来展示两个不同属性相互影响的程度。如果两个属性按照相同的方向变化，说明是正向影响。如果两个属性朝相反方向变化，说明是反向影响。把所有属性两两影响的关系展示出来的图表就叫相关矩阵图。矩阵图法就是从多维问题的事件中找出成对的因素，排列成矩阵图，然后根据矩阵图来分析问题，确定关键点。它是一种通过多因素综合思考来探索问题的好方法。</p>
</blockquote>
<h2 id="第三部分数据准备"><a class="markdownIt-Anchor" href="#第三部分数据准备"></a> 第三部分数据准备</h2>
<blockquote>
<p>特征选择是困难耗时的，也需要对需求的理解和专业知识的掌握。在机器学习的应用开发中，最基础的是特征工程。</p>
</blockquote>
<blockquote>
<p>数据预处理需要根据数据本身的特性进行，有不同的格式和不同的要求，有缺失值的要填，有无效数据的要剔，有冗余维的要选，这些步骤都和数据本身的特性紧密相关。</p>
</blockquote>
<blockquote>
<p>介绍以下几种数据转换方法：·调整数据尺度（RescaleData）。·正态化数据（StandardizeData）。·标准化数据（NormalizeData）。·二值数据（BinarizeData）。</p>
</blockquote>
<blockquote>
<p>在scikit-learn的说明文档中，也有对这两种方法的详细说明：·适合和多重变换（FitandMultipleTransform）。·适合和变换组合（CombinedFit-and-Transform）。推荐优先选择适合和多重变换（FitandMultipleTransform）方法。首先调用fit（）函数来准备数据转换的参数，然后调用transform（）函数来做数据的预处理。适合和变换组合（CombinedFit-and-Transform）对绘图或汇总处理具有非常好的效果。</p>
</blockquote>
<blockquote>
<p>如果数据的各个属性按照不同的方式度量数据，那么通过调整数据的尺度让所有的属性按照相同的尺度来度量数据，就会给机器学习的算法模型训练带来极大的方便。这个方法通常会将数据的所有属性标准化，并将数据转换成0和1之间的值，这对于梯度下降等算法是非常有用的，对于回归算法、神经网络算法和K近邻算法的准确度提高也起到很重要的作用。</p>
</blockquote>
<blockquote>
<p>在统计学中，按照对事物描述的精确度，对所采用的尺度从低级到高级分成四个层次：定类尺度、定序尺度、定距尺度和定比尺度。定类尺度是对事物类别属性的一种测度，按照事物的属性进行分组或分类。定序尺度是对事物之间的等级或顺序的一种测度，可以比较优劣或排序。定距尺度和定比尺度是对事物类别或次序之间间距的测量，定距尺度的特点是其不仅能将事物区分为不同的类型并进行排序，而且可以准确地指出类别之间的差距。而定比尺度则更近一步，它和定距尺度的差别在于它有一个固定的绝对“零”点。由于这两种测量尺度在绝大多数统计分析中没有本质的差别，所以很多时候都没有严格的区分。</p>
</blockquote>
<blockquote>
<p>正态化数据（StandardizeData）是有效的处理符合高斯分布的数据的手段，输出结果以0为中位数，方差为1，并作为假定数据符合高斯分布的算法的输入。</p>
</blockquote>
<blockquote>
<p>标准化数据（NormalizeData）处理是将每一行的数据的距离处理成1（在线性代数中矢量距离为1）的数据又叫作“归一元”处理，适合处理稀疏数据（具有很多为0的数据），归一元处理的数据对使用权重输入的神经网络和使用距离的K近邻算法的准确度的提升有显著作用。</p>
</blockquote>
<blockquote>
<p>二值数据（BinarizeData）是使用值将数据转化为二值，大于阈值设置为1，小于阈值设置为0。这个过程被叫作二分数据或阈值转换。</p>
</blockquote>
<blockquote>
<p>数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已。</p>
</blockquote>
<blockquote>
<p>在开始建立模型之前，执行特征选定有助于：降低数据的拟合度：较少的冗余数据，会使算法得出结论的机会更大。提高算法精度：较少的误导数据，能够提高算法的准确度。减少训练时间：越少的数据，训练模型所需要的时间越少。</p>
</blockquote>
<blockquote>
<p>统计分析可以用来分析选择对结果影响最大的数据特征。在scikit-learn中提供了SelectKBest类，可以使用一系列统计方法来选定数据特征，是对卡方检验的实现。</p>
</blockquote>
<blockquote>
<p>经典的卡方检验是检验定性自变量对定性因变量的相关性的方法。假设自变量有N种取值，因变量有M种取值，考虑自变量等于i且因变量等于j的样本频数的观察值与期望值的差距，构建统计量。卡方检验就是统计样本的实际观测值与理论推断值之间的偏离程度，偏离程度决定了卡方值的大小，卡方值越大，越不符合；卡方值越小，偏差越小，越趋于符合；若两个值完全相等，卡方值就为0，表明理论值完全符合。</p>
</blockquote>
<blockquote>
<p>递归特征消除（RFE）使用一个基模型来进行多轮训练，每轮训练后消除若干权值系数的特征，再基于新的特征集进行下一轮训练。通过每一个基模型的精度，找到对最终的预测结果影响最大的数据特征。在scikit-learn文档中有更多的关于递归特征消除（RFE）的描述。</p>
</blockquote>
<blockquote>
<p>主要成分分析（PCA）是使用线性代数来转换压缩数据，通常被称作数据降维。常见的降维方法除了主要成分分析（PCA），还有线性判别分析（LDA），它本身也是一个分类模型。PCA和LDA有很多的相似之处，其本质是将原始的样本映射到维度更低的样本空间中，但是PCA和LDA的映射目标不一样：PCA是为了让映射后的样本具有最大的发散性；而LDA是为了让映射后的样本有最好的分类性能。所以说，PCA是一种无监督的降维方法，而LDA是一种有监督的降维方法。在聚类算法中，通常会利用PCA对数据进行降维处理，以利于对数据的简化分析和可视化。</p>
</blockquote>
<blockquote>
<p>袋装决策树算法（BaggedDecisionTress）、随机森林算法和极端随机树算法都可以用来计算数据特征的重要性。这三个算法都是集成算法中的袋装算法，</p>
</blockquote>
<h2 id="第四部分选择模型"><a class="markdownIt-Anchor" href="#第四部分选择模型"></a> 第四部分选择模型</h2>
<blockquote>
<p>学习四种不同的分离数据集的方法，用来分离训练数据集和评估数据集，并用其评估算法模型：·分离训练数据集和评估数据集。·K折交叉验证分离。·弃一交叉验证分离。·重复随机评估、训练数据集分离。</p>
</blockquote>
<blockquote>
<p>交叉验证是用来验证分类器的性能的一种统计分析方法，有时也称作循环估计，在统计学上是将数据样本切割成小子集的实用方法。基本思想是按照某种规则将原始数据进行分组，一部分作为训练数据集，另一部分作为评估数据集。</p>
</blockquote>
<blockquote>
<p>K折交叉验证是将原始数据分成K组（一般是均分），将每个子集数据分别做一次验证集，其余的K-1组子集数据作为训练集，这样会得到K个模型，再用这K个模型最终的验证集的分类准确率的平均数，作为此K折交叉验证下分类器的性能指标。K一般大于等于2，实际操作时一般从3开始取值，只有在原始数据集和数据量小的时候才会尝试取2。K折交叉验证可以有效地避免过学习及欠学习状态的发生，最后得到的结果也比较具有说服力。通常情况下，K的取值为3、5、10。</p>
</blockquote>
<blockquote>
<p>如果原始数据有N个样本，那么弃一交叉验证就是N-1个交叉验证，即每个样本单独作为验证集，其余的N-1个样本作为训练集，所以弃一交叉验证会得到N个模型，用这N个模型最终的验证集的分类准确率的平均数作为此次弃一交叉验证分类器的性能指标。</p>
</blockquote>
<blockquote>
<p>较于K折交叉验证，弃一交叉验证有两个显著的优点：·每一回合中几乎所有的样本皆用于训练模型，因此最接近原始样本的分布，这样评估所得的结果比较可靠。·实验过程中没有随机因素会影响实验数据，确保实验过程是可以被复制的。</p>
</blockquote>
<blockquote>
<p>弃一交叉验证的缺点是计算成本高，因为需要建立的模型数量与原始数据样本数量相同，当原始数据样本数量相当多时，弃一交叉验证在实际运行上便有困难，需要花费大量的时间来完成算法的运算与评估，除非每次训练分类器得到模型的速度很快，或者可以用并行化计算减少计算所需的时间。</p>
</blockquote>
<blockquote>
<p>另外一种K折交叉验证的用途是随机分离数据为训练数据集和评估数据集，但是重复这个过程多次，就如同交叉验证分离。</p>
</blockquote>
<blockquote>
<p>分类问题或许是最常见的机器学习问题，并且有多种评估矩阵来评估分类算法。本章将介绍以下几种用来评估分类算法的评估矩阵：·分类准确度。·对数损失函数（Logloss）。·AUC图。·混淆矩阵。·分类报告（ClassificationReport）。</p>
</blockquote>
<blockquote>
<p>在逻辑回归的推导中，它假设样本服从伯努利分布（0～1分布），然后求得满足该分布的似然函数，再取对数、求极值等。而逻辑回归并没有求似然函数的极值，而是把极大化当作一种思想，进而推导出它的经验风险函数为：最小化负的似然函数[maxF（y，f（x））→min-F（y，f（x））]。从损失函数的视角来看，它就成了对数（Log）损失函数了。对数损失函数越小，模型就越好，而且使损失函数尽量是一个凸函数，便于收敛计算。</p>
</blockquote>
<blockquote>
<p>ROC和AUC是评价分类器的指标。ROC是受试者工作特征曲线（ReceiverOperatingCharacteristicCurve）的简写，又称为感受性曲线（SensitivityCurve）。得此名的原因在于曲线上各点反映相同的感受性，它们都是对同一信号刺激的反应，只不过是在几种不同的判定标准下所得的结果而已。ROC是反映敏感性和特异性连续变量的综合指标，用构图法揭示敏感性和特异性的相互关系，通过将连续变量设定出多个不同的临界值计算出一系列敏感性和特异性，再以敏感性为纵坐标、（1-特异性）为横坐标绘制成曲线。AUC是ROC曲线下的面积（AreaUnderROCCurve）的简称，顾名思义，AUC的值就是处于ROCCurve下方的那部分面积的大小。通常，AUC的值介于0.5到1.0之间，AUC的值越大，诊断准确性越高。在ROC曲线上，靠近坐标图左上方的点为敏感性和特异性均较高的临界值。</p>
</blockquote>
<blockquote>
<p>混淆矩阵（CnfusionMatrix）主要用于比较分类结果和实际测得值，可以把分类结果的精度显示在一个混淆矩阵里面。</p>
</blockquote>
<blockquote>
<p>在scikit-learn中提供了一个非常方便的工具，可以给出对分类问题的评估报告，Classification_report（）方法能够给出精确率（precision）、召回率（recall）、F1值（F1-score）和样本数目（support）。在这里简单地介绍一下三个指标数据：精确率、召回率、F1值。</p>
</blockquote>
<blockquote>
<p>介绍三种评估机器学习的回归算法的评估矩阵。·平均绝对误差（MeanAbsoluteError，MAE）。·均方误差（MeanSquaredError，MSE）。·决定系数（R2）。</p>
</blockquote>
<blockquote>
<p>平均绝对误差是所有单个观测值与算术平均值的偏差的绝对值的平均值。与平均误差相比，平均绝对误差由于离差被绝对值化，不会出现正负相抵消的情况，因而，平均绝对误差能更好地反映预测值误差的实际情况。</p>
</blockquote>
<blockquote>
<p>均方误差是衡量平均误差的方法，可以评价数据的变化程度。均方根误差是均方误差的算术平方根。均方误差的值越小，说明用该预测模型描述实验数据的准确度越高。</p>
</blockquote>
<blockquote>
<p>决定系数，反映因变量的全部变异能通过回归关系被自变量解释的比例。拟合优度越大，自变量对因变量的解释程度越高，自变量引起的变动占总变动的百分比越高，观察点在回归直线附近越密集。如R2为0.8，则表示回归关系可以解释因变量80%的变异。换句话说，如果我们能控制自变量不变，则因变量的变异程度会减少80%。</p>
</blockquote>
<blockquote>
<p>决定系数（R2）的特点：·可决系数是非负的统计量。·可决系数的取值范围：0≤R2≤1。·可决系数是样本观测值的函数，是因随机抽样而变动的随机变量。为此，对可决系数的统计的可靠性也应进行检验。</p>
</blockquote>
<blockquote>
<p>审查算法前没有办法判断哪个算法对数据集最有效、能够生成最优模型，必须通过一系列实验判断出哪些算法对问题最有效，然后再进一步来选择算法。这个过程被叫作算法审查。</p>
</blockquote>
<blockquote>
<p>审查算法的几点建议：·尝试多种代表性算法。·尝试多种机器学习的算法。·尝试多种模型。</p>
</blockquote>
<blockquote>
<p>回归是一种极易理解的模型，相当于y=f（x），表明自变量x与因变量y的关系。犹如医生治病时先望、闻、问、切，再判定病人是否生病或生了什么病，此处的“望、闻、问、切”就是获取自变量x，即特征数据；判断是否生病就相当于获取因变量y，即预测分类。逻辑回归其实是一个分类算法而不是回归算法，通常是利用已知的自变量来预测一个离散型因变量的值（如二进制值0/1、是/否、真/假）。简单来说，它就是通过拟合一个逻辑函数（LogitFunction）来预测一个事件发生的概率。所以它预测的是一个概率值，它的输出值应该为0～1，因此非常适合处理二分类问题。</p>
</blockquote>
<blockquote>
<p>线性判别分析（LinearDiscriminantAnalysis，LDA），也叫作Fisher线性判别（</p>
</blockquote>
<blockquote>
<p>线性判别分析的基本思想是将高维的模式样本投影到最佳鉴别矢量空间，以达到抽取分类信息和压缩特征空间维数的效果，投影后保证模式样本在新的子空间有最大的类间距离和最小的类内距离，即模式在该空间中有最佳的可分离性。因此，它是一种有效的特征抽取方法。使用这种方法能够使投影后模式样本的类间散布矩阵最大，并且类内散布矩阵最小。就是说，它能够保证投影后模式样本在新的空间中有最小的类内距离和最大的类间距离，即模式在该空间中有最佳的可分离性。</p>
</blockquote>
<blockquote>
<p>K近邻算法是一种理论上比较成熟的方法，也是最简单的机器学习算法之一。该方法的思路是：如果一个样本在特征空间中的k个最相似（特征空间中最邻近）的样本中的大多数属于某一个类别，则该样本也属于这个类别。在KNN中，通过计算对象间距离来作为各个对象之间的非相似性指标，避免了对象之间的匹配问题，距离一般使用欧氏距离或曼哈顿距离；同时，KNN通过依据k个对象中占优的类别进行决策，而不是通过单一的对象类别决策。这就是KNN算法的优势。在scikit-learn中的实现类是KNeighborsClassifier。</p>
</blockquote>
<blockquote>
<p>贝叶斯分类器的分类原理是通过某对象的先验概率，利用贝叶斯公式计算出其在所有类别上的后验概率，即该对象属于某一类的概率，选择具有最大后验概率的类作为该对象所属的类。</p>
</blockquote>
<blockquote>
<p>分类与回归树的英文缩写是CART，也属于一种决策树，树的构建基于基尼指数。CART假设决策树是二叉树，内部结点特征的取值为“是”和“否”，左分支是取值为“是”的分支，右分支是取值为“否”的分支。这样的决策树等价于递归二分每个特征，将输入空间（特征空间）划分为有限个单元，并在这些单元上确定预测的概率分布，也就是在输入给定的条件下输出的条件概率分布。</p>
</blockquote>
<blockquote>
<p>回归算法是一种专门用于共线性数据分析的有偏估计回归方法，实际上是一种改良的最小二乘估计法，通过放弃最小二乘法的无偏性，以损失部分信息、降低精度为代价，获得回归系数更符合实际、更可靠的回归方法，对病态数据的拟合要强于最小二乘法。</p>
</blockquote>
<blockquote>
<p>套索回归算法和岭回归算法类似，套索回归算法也会惩罚回归系数，在套索回归中会惩罚回归系数的绝对值大小。此外，它能够减少变化程度并提高线性回归模型的精度。套索回归算法和岭回归算法有一点不同，它使用的惩罚函数是绝对值，而不是平方。这导致惩罚（或等于约束估计的绝对值之和）值使一些参数估计结果等于零。使用惩罚值越大，进一步估计会使缩小值越趋近零。</p>
</blockquote>
<blockquote>
<p>弹性网络回归算法是套索回归算法和岭回归算法的混合体，在模型训练时，弹性网络回归算法综合使用L1和L2两种正则化方法。当有多个相关的特征时，弹性网络回归算法是很有用的，套索回归算法会随机挑选算法中的一个，而弹性网络回归算法则会选择两个。与套索回归算法和岭回归算法相比，弹性网络回归算法的优点是，它允许弹性网络回归继承循环状态下岭回归的一些稳定性。另外，在高度相关变量的情况下，它会产生群体效应；选择变量的数目没有限制；可以承受双重收缩。在scikit-learn中的实现类是ElasticNet。</p>
</blockquote>
<blockquote>
<p>K近邻算法是按照距离来预测结果。在scikit-learn中对回归算法的K近邻算法的实现类是KNeighborsRegressor。默认的距离参数为闵式距离，可以指定曼哈顿距离作为距离的计算方式。</p>
</blockquote>
<blockquote>
<p>最合适的算法比较方法是：使用相同的数据、相同的方法来评估不同的算法，以便得到一个准确的结果。</p>
</blockquote>
<blockquote>
<p>在机器学习方面有一些可以采用的标准化流程，这些标准化流程是从共同的问题中提炼出来的，例如评估框架中的数据缺失等。在scikit-learn中提供了自动化运行流程的工具——Pipeline。Pipeline能够将从数据转换到评估模型的整个机器学习流程进行自动化处理。</p>
</blockquote>
<blockquote>
<p>在机器学习的实践中有一个很常见的错误，就是训练数据集与评估数据集之间的数据泄露，这会影响到评估的准确度。要想避免这个问题，需要有一个合适的方式把数据分离成训练数据集和评估数据集，这个过程被包含在数据的准备过程中。</p>
</blockquote>
<blockquote>
<p>Pipeline能够处理训练数据集与评估数据集之间的数据泄露问题，通常会在数据处理过程中对分离出的所有数据子集做同样的数据处理，如正态化处理。</p>
</blockquote>
<blockquote>
<p>特征选择也是一个容易受到数据泄露影响的过程。和数据准备一样，特征选择时也必须确保数据的稳固性，Pipeline也提供了一个工具（FeatureUnion）来保证数据特征选择时数据的稳固性。</p>
</blockquote>
<h2 id="第五部分优化模型"><a class="markdownIt-Anchor" href="#第五部分优化模型"></a> 第五部分优化模型</h2>
<blockquote>
<p>下面是三种流行的集成算法的方法。·装袋（Bagging）算法：先将训练集分离成多个子集，然后通过各个子集训练多个模型。·提升（Boosting）算法：训练多个模型并组成一个序列，序列中的每一个模型都会修正前一个模型的错误。·投票（Voting）算法：训练多个模型，并采用样本统计来提高模型的准确度。</p>
</blockquote>
<blockquote>
<p>装袋算法是一种提高分类准确率的算法，通过给定组合投票的方式获得最优解。比如你生病了，去n个医院看了n个医生，每个医生都给你开了药方，最后哪个药方的出现次数多，就说明这个药方越有可能是最优解，这很好理解，这也是装袋算法的思想。下面将介绍三种装袋模型：·装袋决策树（BaggedDecisionTrees）。·随机森林（RandomForest）。·极端随机树（ExtraTrees）。</p>
</blockquote>
<blockquote>
<p>装袋算法在数据具有很大的方差时非常有效，最常见的例子就是决策树的装袋算法。下面将在scikit-learn中通过BaggingClassifier实现分类与回归树算法。</p>
</blockquote>
<blockquote>
<p>随机森林是用随机的方式建立一个森林，森林由很多的决策树组成，而且每一棵决策树之间是没有关联的。得到森林之后，当有一个新的输入样本进入的时候，就让森林中的每一棵决策树分别进行判断，看看这个样本应该属于哪一类，再看看哪一类被选择最多，就预测这个样本为哪一类。</p>
</blockquote>
<blockquote>
<p>在建立每一棵决策树的过程中，有两点需要注意：采样与完全分裂。首先是两个随机采样的过程，随机森林对输入的数据要进行行、列的采样。对于行采样采用有放回的方式，也就是在采样得到的样本集合中可能有重复的样本。假设输入样本为N个，那么采样的样本也为N个。这样在训练的时候，每一棵树的输入样本都不是全部的样本，就相对不容易出现过拟合。然后进行列采样，从M个feature中选出m个（m＜＜M）。之后再对采样之后的数据使用完全分裂的方式建立决策树，这样决策树的某一个叶子节点要么是无法继续分裂的，要么所有样本都指向同一个分类。一般很多的决策树算法都有一个重要的步骤——剪枝，但是这里不这么做，因为之前的两个随机采样过程保证了随机性，所以不剪枝也不会出现过拟合。</p>
</blockquote>
<blockquote>
<p>随机森林算法：每一棵决策树就是一个精通某一个领域的专家，这样在随机森林中就有了很多个精通不同领域的专家，对于一个新的问题（新的输入数据），可以从不同的角度去看待它，最终由各个专家投票得到结果。</p>
</blockquote>
<blockquote>
<p>极端随机树是由PierreGeurts等人于2006年提出的，它与随机森林十分相似，都是由许多决策树构成。但它与随机森林有两个主要的区别：（1）随机森林应用的是Bagging模型，而极端随机树是使用所有的训练样本得到每棵决策树，也就是每棵决策树应用的是相同的全部训练样本。（2）随机森林是在一个随机子集内得到最优分叉特征属性，而极端随机树是完全随机地选择分叉特征属性，从而实现对决策树进行分叉的。</p>
</blockquote>
<blockquote>
<p>提升算法是一种用来提高弱分类算法准确度的方法，这种方法先构造一个预测函数系列，然后以一定的方式将它们组合成一个预测函数。提升算法也是一种提高任意给定学习算法准确度的方法，它是一种集成算法，主要通过对样本集的操作获得样本子集，然后用弱分类算法在样本子集上训练生成一系列的基分类器。它可以用来提高其他弱分类算法的识别率，也就是将其他的弱分类算法作为基分类算法放于提升框架中，通过提升框架对训练样本集的操作，得到不同的训练样本子集，再用该样本子集去训练生成基分类器。每得到一个样本集就用该基分类算法在该样本集上产生一个基分类器，这样在给定训练轮数n后，就可产生n个基分类器，然后提升算法将这n个基分类器进行加权融合，产生最后的结果分类器。在这n个基分类器中，每个分类器的识别率不一定很高，但它们联合后的结果有很高的识别率，这样便提高了弱分类算法的识别率。</p>
</blockquote>
<blockquote>
<p>两个非常常见的用于机器学习的提升算法：·AdaBoost.·随机梯度提升（StochasticGradientBoosting）。</p>
</blockquote>
<blockquote>
<p>AdaBoost是一种迭代算法，其核心思想是针对同一个训练集训练不同的分类器（弱分类器），然后把这些弱分类器集合起来，构成一个更强的最终分类器（强分类器）。其算法本身是通过改变数据分布来实现的，它根据每次训练集中每个样本的分类是否正确，以及上次的总体分类的准确率，来确定每个样本的权值。它将修改过权值的新数据集送给下层分类器进行训练，再将每次训练得到的分类器融合起来，作为最后的决策分类器。使用AdaBoost分类器可以排除一些不必要的训练数据特征，并放在关键的训练数据上面。在scikit-learn中的实现类是AdaBoostClassifier。</p>
</blockquote>
<blockquote>
<p>随机梯度提升法（GBM）基于的思想是：要找到某个函数的最大值，最好的办法就是沿着该函数的梯度方向探寻。梯度算子总是指向函数值增长最快的方向。由于梯度提升算法在每次更新数据集时都需要遍历整个数据集，计算复杂度较高，于是有了一个改进算法——随机梯度提升算法，该算法一次只用一个样本点来更新回归系数，极大地改善了算法的计算复杂度。在scikit-learn中的实现类是GradientBoostingClassifier。</p>
</blockquote>
<blockquote>
<p>投票算法（Voting）是一个非常简单的多个机器学习算法的集成算法。投票算法是通过创建两个或多个算法模型，利用投票算法将这些算法包装起来，计算各个子模型的平均预测状况。在实际的应用中，可以对每个子模型的预测结果增加权重，以提高算法的准确度。但是，在scikit-learn中不提供加权算法。下面通过一个例子来展示在scikit-learn中如何实现一个投票算法。在scikit-learn中的实现类是VotingClassifier。</p>
</blockquote>
<blockquote>
<p>调整算法参数是采用机器学习解决问题的最后一个步骤，有时也被称为超参数优化。学会调参是进行机器学习项目的前提，但第一次遇到这些算法和模型时，肯定会被其大量的参数吓到。其实，参数可分为两种：一种是影响模型在训练集上的准确度或防止过拟合能力的参数；另一种是不影响这两者的参数。模型在样本总体上的准确度由其在训练集上的准确度及其防止过拟合的能力共同决定，所以在调参时主要针对第一种参数进行调整，最终达到的效果是：模型在训练集上的准确度和防止过拟合能力的大和谐。</p>
</blockquote>
<blockquote>
<p>网格搜索优化参数是一种算法参数优化的方法。它是通过遍历已定义参数的列表，来评估算法的参数，从而找到最优参数。在scikit-learn中使用GridSearchCV来实现对参数的跟踪、调整与评估，从而找到最优参数。网格搜索优化参数适用于三四个（或更少）的超参数（当超参数的数量增加时，网格搜索的计算复杂度会呈现指数型增长，这时要换用随机搜索），由用户列出一个较小的超参数值域，这些超参数值域的笛卡尔集（排列组合）为一组组超参数。网格搜索算法使用每组超参数训练模型，并挑选验证集误差最小的超参数组合。</p>
</blockquote>
<blockquote>
<p>随机搜索优化参数是另一种对算法参数优化的方法。随机搜索优化参数通过固定次数的迭代，采用随机采样分布的方式搜索合适的参数。与网格搜索优化参数相比，随机搜索优化参数提供了一种更高效的解决方法（特别是在参数数量多的情况下），随机搜索优化参数为每个参数定义了一个分布函数，并在该空间中采样。在scikit-learn中通过RandomizedSearchCV类实现。</p>
</blockquote>
<blockquote>
<p>调参是算法模型生成之前很重要的一步，本章介绍了两种选择最优参数的方法：网格搜索优化参数和随机搜索优化参数。如果算法的参数少于三个，推荐使用网格搜索优化参数；如果需要优化的参数超过三个，推荐使用随机搜索优化参数。</p>
</blockquote>
<h2 id="第六部分结果部署"><a class="markdownIt-Anchor" href="#第六部分结果部署"></a> 第六部分结果部署</h2>
<blockquote>
<p>找到一个能够生成高准确度模型的算法不是机器学习最后的步骤，在实际的项目中，需要将生成的模型序列化，并将其发布到生产环境。当有新数据出现时，需要反序列化已保存的模型，然后用其预测新的数据。</p>
</blockquote>
<blockquote>
<p>pickle是标准的Python序列化的方法，可以通过它来序列化机器学习算法生成的模型，并将其保存到文件中。当需要对新数据进行预测时，将保存在文件中的模型反序列化，并用其来预测新数据的结果。</p>
</blockquote>
<blockquote>
<p>joblib是SciPy生态环境的一部分，提供了通用的工具来序列化Python的对象和反序列化Python的对象。通过joblib序列化对象时会采用NumPy的格式保存数据，这对某些保存数据到模型中的算法非常有效，如K近邻算法。</p>
</blockquote>
<h2 id="第七部分项目实践"><a class="markdownIt-Anchor" href="#第七部分项目实践"></a> 第七部分项目实践</h2>
<blockquote>
<p>分类或回归模型的机器学习项目可以分成以下六个步骤：（1）定义问题。（2）理解数据。（3）数据准备。（4）评估算法。（5）优化模型。（6）结果部署。</p>
</blockquote>
<blockquote>
<p>步骤1：定义问题主要是导入在机器学习项目中所需要的类库和数据集等，以便完成机器学习的项目，包括导入Python的类库、类和方法，以及导入数据。同时这也是所有的配置参数的配置模块。当数据集过大时，可以在这里对数据集进行瘦身处理，理想状态是可以在1分钟内，甚至是30秒内完成模型的建立或可视化数据集。</p>
</blockquote>
<blockquote>
<p>步骤2：理解数据这是加强对数据理解的步骤，包括通过描述性统计来分析数据和通过可视化来观察数据。在这一步需要花费时间多问几个问题，设定假设条件并调查分析一下，这对模型的建立会有很大的帮助。</p>
</blockquote>
<blockquote>
<p>步骤3：数据准备数据准备主要是预处理数据，以便让数据可以更好地展示问题，以及熟悉输入与输出结果的关系。包括：·通过删除重复数据、标记错误数值，甚至标记错误的输入数据来清洗数据。·特征选择，包括移除多余的特征属性和增加新的特征属性。·数据转化，对数据尺度进行调整，或者调整数据的分布，以便更好地展示问题。要不断地重复这个步骤和下一个步骤，直到找到足够准确的算法生成模型。</p>
</blockquote>
<blockquote>
<p>步骤4：评估算法评估算法主要是为了寻找最佳的算法子集，包括：·分离出评估数据集，以便于验证模型。·定义模型评估标准，用来评估算法模型。·抽样审查线性算法和非线性算法。·比较算法的准确度。在面对一个机器学习的问题的时候，需要花费大量的时间在评估算法和准备数据上，直到找到3～5种准确度足够的算法为止。</p>
</blockquote>
<blockquote>
<p>步骤5：优化模型当得到一个准确度足够的算法列表后，要从中找出最合适的算法，通常有两种方法可以提高算法的准确度：·对每一种算法进行调参，得到最佳结果。·使用集合算法来提高算法模型的准确度。</p>
</blockquote>
<blockquote>
<p>步骤6：结果部署一旦认为模型的准确度足够高，就可以将这个模型序列化，以便有新数据时使用该模型来预测数据。·通过验证数据集来验证被优化过的模型。·通过整个数据集来生成模型。·将模型序列化，以便于预测新数据。做到这一步的时候，就可以将模型展示并发布给相关人员。当有新数据产生时，就可以采用这个模型来预测新数据。</p>
</blockquote>
]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>读书</tag>
      </tags>
  </entry>
  <entry>
    <title>书摘：《统计学习方法》-李航</title>
    <url>/2020/05/15/%E4%B9%A6%E6%91%98_%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95-%E6%9D%8E%E8%88%AA.hexo/</url>
    <content><![CDATA[<div class="douban-card-block">
	<a class="douban-card" href="https://book.douban.com/subject/10590856">
		<div class="douban-card-bgimg" style="background-image: url('https://images.weserv.nl/?url=https://img2.doubanio.com/view/subject/s/public/s9108113.jpg');"></div>
		<div class="douban-card-left">
			<div class="douban-card-img" style="background-image: url('https://images.weserv.nl/?url=https://img2.doubanio.com/view/subject/s/public/s9108113.jpg');"></div>
		</div>
		<div class="douban-card-right" style="line-height: 1.7;">
			<div class="douban-card-item"><span>书名: </span><strong>统计学习方法</strong></div>
			<div class="douban-card-item"><span>作者: </span><span>李航</span></div>
			<div class="douban-card-item"><span>出版年份: </span><span>2012-3</span></div>
			<div class="douban-card-item"><span>评分: </span><span>9.0</span></div>
		</div>
	</a>
</div>
<style>
	.douban-card-block {
		display: flex;
		justify-content: center;
		align-items: center;
		width: 100%;
		max-height: 400px;
	}
	.douban-card {
		display: flex;
		margin: 30px 10px;
		padding: 15px;
		border-radius: 10px;
		position: relative;
		justify-content: center;
		align-items: center;
		overflow: hidden;
		color: antiquewhite;
		text-decoration: none;
	}
	.douban-card:hover {
		text-decoration: none;
	}
	.douban-card-bgimg {
		position: absolute;
		width: 115%;
		height: 115%;
		filter: blur(15px) brightness(0.6);
		background-size: 100%;
		background-position: center;
		background-repeat: no-repeat;
	}
	.douban-card-img {
		position: relative;
		height: 130px;
		width: 80px;
		background-size: 100%;
		background-position: center;
		background-repeat: no-repeat;
	}
	.douban-card-img {
		position: relative;
		height: 130px;
		width: 80px;
	}
	.douban-card-left {
		position: relative;
		display: flex;
		flex-direction: column;
		align-items: center;
	}
	.douban-card-right {
		position: relative;
		display: flex;
		flex-direction: column;
		margin-left: 12px;
		font-size: 16px;
		font-family: 'Courier New', Courier, monospace;
		line-height: 1.3;
		color: antiquewhite;
	}
	.douban-card-item {
		margin-top: 4px;
	}
</style>
<a id="more"></a>
<h2 id="第1章-统计学习方法概论"><a class="markdownIt-Anchor" href="#第1章-统计学习方法概论"></a> 第1章　统计学习方法概论</h2>
<blockquote>
<p>首先叙述统计学习的定义、研究对象与方法；然后叙述监督学习，这是本书的主要内容；接着提出统计学习方法的三要素：模型、策略和算法；介绍模型选择，包括正则化、交叉验证与学习的泛化能力；介绍生成模型与判别模型；最后介绍监督学习方法的应用：分类问题、标注问题与回归问题。</p>
</blockquote>
<h2 id="11-统计学习"><a class="markdownIt-Anchor" href="#11-统计学习"></a> 1.1　统计学习</h2>
<blockquote>
<p>统计学习（learning）是关于计算机基于数据构建概率统计模型并运用模型对数据进行预测与分析的一门学科。统计学习也称为统计机器学习（machinelearning）。</p>
</blockquote>
<blockquote>
<p>统计学习的对象是数据（data）。它从数据出发，提取数据的特征，抽象出数据的模型，发现数据中的知识，又回到对数据的分析与预测中去。</p>
</blockquote>
<blockquote>
<p>统计学习关于数据的基本假设是同类数据具有一定的统计规律性，这是统计学习的前提。这里的同类数据是指具有某种共同性质的数据，例如英文文章、互联网网页、数据库中的数据等</p>
</blockquote>
<blockquote>
<p>统计学习用于对数据进行预测与分析，特别是对未知新数据进行预测与分析。</p>
</blockquote>
<blockquote>
<p>对数据的预测与分析是通过构建概率统计模型实现的。统计学习总的目标就是考虑学习什么样的模型和如何学习模型，以使模型能对数据进行准确的预测与分析，同时也要考虑尽可能地提高学习效率。</p>
</blockquote>
<blockquote>
<p>统计学习的方法是基于数据构建统计模型从而对数据进行预测与分析。统计学习由监督学习（learning）、非监督学习（learning）、半监督学习（learning）和强化学习（learning）等组成。</p>
</blockquote>
<blockquote>
<p>data）集合出发，假设数据是独立同分布产生的；并且假设要学习的模型属于某个函数的集合，称为假设空间（space）；应用某个评价准则（criterion），从假设空间中选取一个最优的模型，使它对已知训练数据及未知测试数据（data）在给定的评价准则下有最优的预测；最优模型的选取由算法实现。这样，统计学习方法包括模型的假设空间、模型选择的准则以及模型学习的算法，称其为统计学习方法的三要素，简称为模型（model）、策略（strategy）和算法（algorithm）。实现统计学习方法的步骤如下：（1）得到一个有限的训练数据集合；（2）确定包含所有可能的模型的假设空间，即学习模型的集合；（3）确定模型选择的准则，即学习的策略；（4）实现求解最优模型的算法，即学习的算法；（5）通过学习方法选择最优模型；（6）利用学习的最优模型对新数据进行预测或分析。</p>
</blockquote>
<blockquote>
<p>统计学习研究一般包括统计学习方法（learningmethod）、统计学习理论（learningtheory）及统计学习应用（ofstatisticallearning）三个方面。统计学习方法的研究旨在开发新的学习方法；统计学习理论的研究在于探求统计学习方法的有效性与效率，以及统计学习的基本理论问题；统计学习应用的研究主要考虑将统计学习方法应用到实际问题中去，解决实际问题。</p>
</blockquote>
<h2 id="121-基本概念"><a class="markdownIt-Anchor" href="#121-基本概念"></a> 1.2.1　基本概念</h2>
<blockquote>
<p>在监督学习中，将输入与输出所有可能取值的集合分别称为输入空间（space）与输出空间（space）。输入与输出空间可以是有限元素的集合，也可以是整个欧氏空间。输入空间与输出空间可以是同一个空间，也可以是不同的空间；但通常输出空间远远小于输入空间。每个具体的输入是一个实例（instance），通常由特征向量（vector）表示。这时，所有特征向量存在的空间称为特征空间（space）。</p>
</blockquote>
<blockquote>
<p>监督学习从训练数据（data）集合中学习模型，对测试数据（data）进行预测。训练数据由输入（或特征向量）与输出对组成</p>
</blockquote>
<blockquote>
<p>输入与输出对又称为样本（sample）或样本点。</p>
</blockquote>
<blockquote>
<p>根据输入、输出变量的不同类型，对预测任务给予不同的名称：输入变量与输出变量均为连续变量的预测问题称为回归问题；输出变量为有限个离散变量的预测问题称为分类问题；输入变量与输出变量均为变量序列的预测问题称为标注问题。</p>
</blockquote>
<blockquote>
<p>监督学习假设输入与输出的随机变量X和Y遵循联合概率分布P(X,Y)。P(X,Y)表示分布函数，或分布密度函数。注意，在学习过程中，假定这一联合概率分布存在，但对学习系统来说，联合概率分布的具体定义是未知的。训练数据与测试数据被看作是依联合概率分布P(X,Y)独立同分布产生的。统计学习假设数据存在一定的统计规律，X和Y具有联合概率分布的假设就是监督学习关于数据的基本假设。</p>
</blockquote>
<blockquote>
<p>监督学习的目的在于学习一个由输入到输出的映射，这一映射由模型来表示。</p>
</blockquote>
<h2 id="122-问题的形式化"><a class="markdownIt-Anchor" href="#122-问题的形式化"></a> 1.2.2　问题的形式化</h2>
<blockquote>
<p>监督学习利用训练数据集学习一个模型，再用模型对测试样本集进行预测（prediction）。</p>
</blockquote>
<h2 id="131-模型"><a class="markdownIt-Anchor" href="#131-模型"></a> 1.3.1　模型</h2>
<blockquote>
<p>统计学习首要考虑的问题是学习什么样的模型。在监督学习过程中，模型就是所要学习的条件概率分布或决策函数。模型的假设空间（space）包含所有可能的条件概率分布或决策函数。</p>
</blockquote>
<blockquote>
<p>由决策函数表示的模型为非概率模型，由条件概率表示的模型为概率模型。</p>
</blockquote>
<h2 id="132-策略"><a class="markdownIt-Anchor" href="#132-策略"></a> 1.3.2　策略</h2>
<blockquote>
<p>有了模型的假设空间，统计学习接着需要考虑的是按照什么样的准则学习或选择最优的模型。</p>
</blockquote>
<blockquote>
<p>理论上模型f(X)关于联合分布P(X,Y)的平均意义下的损失，称为风险函数（riskfunction）或期望损失（expectedloss）。</p>
</blockquote>
<blockquote>
<p>模型f(X)关于训练数据集的平均损失称为经验风险（risk）或经验损失（loss）</p>
</blockquote>
<blockquote>
<p>期望风险exp(f)是模型关于联合分布的期望损失，经验风险emp(f)是模型关于训练样本集的平均损失。根据大数定律，当样本容量N趋于无穷时，经验风险emp(f)趋于期望风险exp(f)。所以一个很自然的想法是用经验风险估计期望风险。但是，由于现实中训练样本数目有限，甚至很小，所以用经验风险估计期望风险常常并不理想，要对经验风险进行一定的矫正。</p>
</blockquote>
<blockquote>
<p>结构风险最小化（riskminimization，SRM）是为了防止过拟合而提出来的策略。结构风险最小化等价于正则化（regularization）。结构风险在经验风险上加上表示模型复杂度的正则化项（regularizer）或罚项（term）。</p>
</blockquote>
<h2 id="133-算法"><a class="markdownIt-Anchor" href="#133-算法"></a> 1.3.3　算法</h2>
<blockquote>
<p>算法是指学习模型的具体计算方法。</p>
</blockquote>
<h2 id="141-训练误差与测试误差"><a class="markdownIt-Anchor" href="#141-训练误差与测试误差"></a> 1.4.1　训练误差与测试误差</h2>
<blockquote>
<p>通常将学习方法对未知数据的预测能力称为泛化能力（generalizationability）</p>
</blockquote>
<h2 id="142-过拟合与模型选择"><a class="markdownIt-Anchor" href="#142-过拟合与模型选择"></a> 1.4.2　过拟合与模型选择</h2>
<blockquote>
<p>如果一味追求提高对训练数据的预测能力，所选模型的复杂度则往往会比真模型更高。这种现象称为过拟合（over-fitting）</p>
</blockquote>
<h2 id="151-正则化"><a class="markdownIt-Anchor" href="#151-正则化"></a> 1.5.1　正则化</h2>
<blockquote>
<p>模型选择的典型方法是正则化（regularization）。正则化是结构风险最小化策略的实现，是在经验风险上加一个正则化项（regularizer）或罚项term)。正则化项一般是模型复杂度的单调递增函数，模型越复杂，正则化值就越大。</p>
</blockquote>
<blockquote>
<p>在所有可能选择的模型中，能够很好地解释已知数据并且十分简单才是最好的模型，也就是应该选择的模型。</p>
</blockquote>
<h2 id="161-泛化误差"><a class="markdownIt-Anchor" href="#161-泛化误差"></a> 1.6.1　泛化误差</h2>
<blockquote>
<p>学习方法的泛化能力（ability）是指由该方法学习到的模型对未知数据的预测能力，是学习方法本质上重要的性质。</p>
</blockquote>
<h2 id="17-生成模型与判别模型"><a class="markdownIt-Anchor" href="#17-生成模型与判别模型"></a> 1.7　生成模型与判别模型</h2>
<blockquote>
<p>监督学习方法又可以分为生成方法（approach）和判别方法（approach）。所学到的模型分别称为生成模型（model）和判别模型（model）。生成方法由数据学习联合概率分布P(X,Y)，然后求出条件概率分布P(Y|X)作为预测的模型，即生成模型</p>
</blockquote>
<blockquote>
<p>这样的方法之所以称为生成方法，是因为模型表示了给定输入X产生输出Y的生成关系。典型的生成模型有：朴素贝叶斯法和隐马尔可夫模型</p>
</blockquote>
<blockquote>
<p>判别方法由数据直接学习决策函数f(X)或者条件概率分布P(Y|X)作为预测的模型，即判别模型。判别方法关心的是对给定的输入X，应该预测什么样的输出Y。典型的判别模型包括：k近邻法、感知机、决策树、逻辑斯谛回归模型、最大熵模型、支持向量机、提升方法和条件随机场等</p>
</blockquote>
<blockquote>
<p>生成方法的特点：生成方法可以还原出联合概率分布P(X,Y)，而判别方法则不能；生成方法的学习收敛速度更快，即当样本容量增加的时候，学到的模型可以更快地收敛于真实模型；当存在隐变量时，仍可以用生成方法学习，此时判别方法就不能用。判别方法的特点：判别方法直接学习的是条件概率P(Y|X)或决策函数f(X)，直接面对预测，往往学习的准确率更高；由于直接学习P(Y|X)或f(X)，可以对数据进行各种程度上的抽象、定义特征并使用特征，因此可以简化学习问题。</p>
</blockquote>
<h2 id="18-分类问题"><a class="markdownIt-Anchor" href="#18-分类问题"></a> 1.8　分类问题</h2>
<blockquote>
<p>评价分类器性能的指标一般是分类准确率（accuracy），其定义是：对于给定的测试数据集，分类器正确分类的样本数与总样本数之比。</p>
</blockquote>
<blockquote>
<p>对于二类分类问题常用的评价指标是精确率（precision）与召回率（recall）。通常以关注的类为正类，其他类为负类，</p>
</blockquote>
<h2 id="19-标注问题"><a class="markdownIt-Anchor" href="#19-标注问题"></a> 1.9　标注问题</h2>
<blockquote>
<p>标注问题的输入是一个观测序列，输出是一个标记序列或状态序列。标注问题的目标在于学习一个模型，使它能够对观测序列给出标记序列作为预测。</p>
</blockquote>
<blockquote>
<p>评价标注模型的指标与评价分类模型的指标一样，常用的有标注准确率、精确率和召回率。</p>
</blockquote>
<blockquote>
<p>标注常用的统计学习方法有：隐马尔可夫模型、条件随机场。</p>
</blockquote>
<h2 id="110-回归问题"><a class="markdownIt-Anchor" href="#110-回归问题"></a> 1.10　回归问题</h2>
<blockquote>
<p>回归问题的学习等价于函数拟合：选择一条函数曲线使其很好地拟合已知数据且很好地预测未知数据（</p>
</blockquote>
<blockquote>
<p>回归问题按照输入变量的个数，分为一元回归和多元回归；按照输入变量和输出变量之间关系的类型即模型的类型，分为线性回归和非线性回归。</p>
</blockquote>
<h2 id="本章概要"><a class="markdownIt-Anchor" href="#本章概要"></a> 本章概要</h2>
<blockquote>
<p>分类问题、标注问题和回归问题都是监督学习的重要问题。</p>
</blockquote>
<h2 id="第2章-感知机"><a class="markdownIt-Anchor" href="#第2章-感知机"></a> 第2章　感知机</h2>
<blockquote>
<p>感知机（perceptron）是二类分类的线性分类模型，其输入为实例的特征向量，输出为实例的类别，取+1和–1二值</p>
</blockquote>
<h2 id="21-感知机模型"><a class="markdownIt-Anchor" href="#21-感知机模型"></a> 2.1　感知机模型</h2>
<blockquote>
<p>感知机模型的假设空间是定义在特征空间中的所有线性分类模型（linearclassificationmodel）或线性分类器(linearclassifier)，即函数集合{f|f(x)＝w·x+b}。</p>
</blockquote>
<h2 id="222-感知机学习策略"><a class="markdownIt-Anchor" href="#222-感知机学习策略"></a> 2.2.2　感知机学习策略</h2>
<blockquote>
<p>假设训练数据集是线性可分的，感知机学习的目标是求得一个能够将训练集正实例点和负实例点完全正确分开的分离超平面。为了找出这样的超平面，即确定感知机模型参数w,b，需要确定一个学习策略，即定义（经验）损失函数并将损失函数极小化。</p>
</blockquote>
<blockquote>
<p>感知机学习的策略是在假设空间中选取使损失函数式（2.4）最小的模型参数w,b，即感知机模型。</p>
</blockquote>
<h2 id="231-感知机学习算法的原始形式"><a class="markdownIt-Anchor" href="#231-感知机学习算法的原始形式"></a> 2.3.1　感知机学习算法的原始形式</h2>
<blockquote>
<p>感知机学习算法是误分类驱动的，具体采用随机梯度下降法（gradientdescent）。首先，任意选取一个超平面0,b0，然后用梯度下降法不断地极小化目标函数（2.5）。极小化过程中不是一次使M中所有误分类点的梯度下降，而是一次随机选取一个误分类点使其梯度下降。</p>
</blockquote>
<blockquote>
<p>感知机学习算法由于采用不同的初值或选取不同的误分类点，解可以不同。</p>
</blockquote>
<h2 id="232-算法的收敛性"><a class="markdownIt-Anchor" href="#232-算法的收敛性"></a> 2.3.2　算法的收敛性</h2>
<blockquote>
<p>训练数据集线性可分时，感知机学习算法原始形式迭代是收敛的。</p>
</blockquote>
<blockquote>
<p>感知机学习算法存在许多解，这些解既依赖于初值的选择，也依赖于迭代过程中误分类点的选择顺序。为了得到唯一的超平面，需要对分离超平面增加约束条件。</p>
</blockquote>
<blockquote>
<p>训练集线性不可分时，感知机学习算法不收敛，迭代结果会发生震荡。</p>
</blockquote>
<h2 id="第3章-k近邻法"><a class="markdownIt-Anchor" href="#第3章-k近邻法"></a> 第3章　k近邻法</h2>
<blockquote>
<p>近邻法假设给定一个训练数据集，其中的实例类别已定。分类时，对新的实例，根据其k个最近邻的训练实例的类别，通过多数表决等方式进行预测。</p>
</blockquote>
<h2 id="323-k值的选择"><a class="markdownIt-Anchor" href="#323-k值的选择"></a> 3.2.3　k值的选择</h2>
<blockquote>
<p>如果选择较小的k值，就相当于用较小的邻域中的训练实例进行预测，“学习”的近似误差（error）会减小，只有与输入实例较近的（相似的）训练实例才会对预测结果起作用。但缺点是“学习”的估计误差（error）会增大，预测结果会对近邻的实例点非常敏感[2]。如果邻近的实例点恰巧是噪声，预测就会出错。换句话说，k值的减小就意味着整体模型变得复杂，容易发生过拟合。如果选择较大的k值，就相当于用较大邻域中的训练实例进行预测。其优点是可以减少学习的估计误差。但缺点是学习的近似误差会增大。这时与输入实例较远的（不相似的）训练实例也会对预测起作用，使预测发生错误。k值的增大就意味着整体的模型变得简单。</p>
</blockquote>
<h2 id="331-构造kd树"><a class="markdownIt-Anchor" href="#331-构造kd树"></a> 3.3.1　构造kd树</h2>
<blockquote>
<p>kd树是一种对k维空间中的实例点进行存储以便对其进行快速检索的树形数据结构。kd树是二叉树，表示对k维空间的一个划分（partition）。构造kd树相当于不断地用垂直于坐标轴的超平面将k维空间切分，构成一系列的k维超矩形区域。kd树的每个结点对应于一个k维超矩形区域。</p>
</blockquote>
<h2 id="第4章-朴素贝叶斯法"><a class="markdownIt-Anchor" href="#第4章-朴素贝叶斯法"></a> 第4章　朴素贝叶斯法</h2>
<blockquote>
<p>朴素贝叶斯（Bayes）法是基于贝叶斯定理与特征条件独立假设的分类方法[1]。对于给定的训练数据集，首先基于特征条件独立假设学习输入/输出的联合概率分布；然后基于此模型，对给定的输入x，利用贝叶斯定理求出后验概率最大的输出y。</p>
</blockquote>
<h2 id="412-后验概率最大化的含义"><a class="markdownIt-Anchor" href="#412-后验概率最大化的含义"></a> 4.1.2　后验概率最大化的含义</h2>
<blockquote>
<p>朴素贝叶斯法将实例分到后验概率最大的类中。这等价于期望风险最小化。</p>
</blockquote>
<h2 id="513-决策树与条件概率分布"><a class="markdownIt-Anchor" href="#513-决策树与条件概率分布"></a> 5.1.3　决策树与条件概率分布</h2>
<blockquote>
<p>决策树还表示给定特征条件下类的条件概率分布。这一条件概率分布定义在特征空间的一个划分（partition）上。将特征空间划分为互不相交的单元（cell）或区域（region），并在每个单元定义一个类的概率分布就构成了一个条件概率分布。</p>
</blockquote>
<h2 id="522-信息增益"><a class="markdownIt-Anchor" href="#522-信息增益"></a> 5.2.2　信息增益</h2>
<blockquote>
<p>在信息论与概率统计中，熵（entropy）是表示随机变量不确定性的度量。</p>
</blockquote>
<blockquote>
<p>熵越大，随机变量的不确定性就越大。</p>
</blockquote>
<blockquote>
<p>特征A对训练数据集D的信息增益g(D,A)，定义为集合D的经验熵H(D)与特征A给定条件下D的经验条件熵H(D|A)之差</p>
</blockquote>
<h2 id="523-信息增益比"><a class="markdownIt-Anchor" href="#523-信息增益比"></a> 5.2.3　信息增益比</h2>
<blockquote>
<p>特征A对训练数据集D的信息增益比gR(D,A)定义为其信息增益g(D,A)与训练数据集D的经验熵H(D)之比</p>
</blockquote>
<h2 id="552-cart剪枝"><a class="markdownIt-Anchor" href="#552-cart剪枝"></a> 5.5.2　CART剪枝</h2>
<blockquote>
<p>剪枝算法由两步组成：首先从生成算法产生的决策树T0底端开始不断剪枝，直到T0的根结点，形成一个子树序列{T0，T1,…,Tn}；然后通过交叉验证法在独立的验证数据集上对子树序列进行测试，从中选择最优子树。</p>
</blockquote>
<h2 id="第6章-逻辑斯谛回归与最大熵模型"><a class="markdownIt-Anchor" href="#第6章-逻辑斯谛回归与最大熵模型"></a> 第6章　逻辑斯谛回归与最大熵模型</h2>
<blockquote>
<p>逻辑斯谛回归（regression）是统计学习中的经典分类方法。最大熵是概率模型学习的一个准则，将其推广到分类问题得到最大熵模型（entropymodel）。逻辑斯谛回归模型与最大熵模型都属于对数线性模型。</p>
</blockquote>
<h2 id="612-二项逻辑斯谛回归模型"><a class="markdownIt-Anchor" href="#612-二项逻辑斯谛回归模型"></a> 6.1.2　二项逻辑斯谛回归模型</h2>
<blockquote>
<p>二项逻辑斯谛回归模型（logisticregressionmodel）是一种分类模型，由条件概率分布P(Y|X)表示，形式为参数化的逻辑斯谛分布。这里，随机变量X取值为实数，随机变量Y取值为1或0。我们通过监督学习的方法来估计模型参数。</p>
</blockquote>
<h2 id="621-最大熵原理"><a class="markdownIt-Anchor" href="#621-最大熵原理"></a> 6.2.1　最大熵原理</h2>
<blockquote>
<p>最大熵原理是概率模型学习的一个准则。最大熵原理认为，学习概率模型时，在所有可能的概率模型（分布）中，熵最大的模型是最好的模型。通常用约束条件来确定概率模型的集合，所以，最大熵原理也可以表述为在满足约束条件的模型集合中选取熵最大的模型。</p>
</blockquote>
<h2 id="63-模型学习的最优化算法"><a class="markdownIt-Anchor" href="#63-模型学习的最优化算法"></a> 6.3　模型学习的最优化算法</h2>
<blockquote>
<p>逻辑斯谛回归模型、最大熵模型学习归结为以似然函数为目标函数的最优化问题，通常通过迭代算法求解。从最优化的观点看，这时的目标函数具有很好的性质。它是光滑的凸函数，因此多种最优化的方法都适用，保证能找到全局最优解。常用的方法有改进的迭代尺度法、梯度下降法、牛顿法或拟牛顿法。牛顿法或拟牛顿法一般收敛速度更快。</p>
</blockquote>
<h2 id="第7章-支持向量机"><a class="markdownIt-Anchor" href="#第7章-支持向量机"></a> 第7章　支持向量机</h2>
<blockquote>
<p>支持向量机（vectormachines，SVM）是一种二类分类模型。它的基本模型是定义在特征空间上的间隔最大的线性分类器，间隔最大使它有别于感知机</p>
</blockquote>
<blockquote>
<p>支持向量机还包括核技巧，这使它成为实质上的非线性分类器。支持向量机的学习策略就是间隔最大化，可形式化为一个求解凸二次规划（convexquadraticprogramming）的问题，也等价于正则化的合页损失函数的最小化问题</p>
</blockquote>
<blockquote>
<p>支持向量机学习方法包含构建由简至繁的模型：线性可分支持向量机（supportvectormachineinlinearlyseparablecase）、线性支持向量机（supportvectormachine）及非线性支持向量机（supportvectormachine）。</p>
</blockquote>
<blockquote>
<p>当训练数据线性可分时，通过硬间隔最大化（hardmarginmaximization），学习一个线性的分类器，即线性可分支持向量机，又称为硬间隔支持向量机</p>
</blockquote>
<blockquote>
<p>当训练数据近似线性可分时，通过软间隔最大化（softmarginmaximization），也学习一个线性的分类器，即线性支持向量机，又称为软间隔支持向量机</p>
</blockquote>
<blockquote>
<p>当训练数据线性不可分时，通过使用核技巧（kerneltrick）及软间隔最大化，学习非线性支持向量机。</p>
</blockquote>
<blockquote>
<p>通过使用核函数可以学习非线性支持向量机，等价于隐式地在高维的特征空间中学习线性支持向量机。这样的方法称为核技巧。核方法（kernelmethod）是比支持向量机更为一般的机器学习方法。</p>
</blockquote>
<h2 id="711-线性可分支持向量机"><a class="markdownIt-Anchor" href="#711-线性可分支持向量机"></a> 7.1.1　线性可分支持向量机</h2>
<blockquote>
<p>线性可分支持向量机、线性支持向量机假设这两个空间的元素一一对应，并将输入空间中的输入映射为特征空间中的特征向量。</p>
</blockquote>
<blockquote>
<p>输入都由输入空间转换到特征空间，支持向量机的学习是在特征空间进行的。</p>
</blockquote>
<blockquote>
<p>学习的目标是在特征空间中找到一个分离超平面，能将实例分到不同的类。分</p>
</blockquote>
<blockquote>
<p>一般地，当训练数据集线性可分时，存在无穷个分离超平面可将两类数据正确分开。感知机利用误分类最小的策略，求得分离超平面，不过这时的解有无穷多个。线性可分支持向量机利用间隔最大化求最优分离超平面，这时，解是唯一的。</p>
</blockquote>
<h2 id="712-函数间隔和几何间隔"><a class="markdownIt-Anchor" href="#712-函数间隔和几何间隔"></a> 7.1.2　函数间隔和几何间隔</h2>
<blockquote>
<p>一致能够表示分类是否正确。所以可用量y(w·x+b)来表示分类的正确性及确信度，这就是函数间隔（functionalmargin）的概念。</p>
</blockquote>
<blockquote>
<p>对于给定的训练数据集T和超平面(w,b)，定义超平面(w,b)关于样本点(xi，yi)的函数间隔为</p>
</blockquote>
<blockquote>
<p>定义超平面(w,b)关于训练数据集T的函数间隔为超平面(w,b)关于T中所有样本点i，yi)的函数间隔之最小值</p>
</blockquote>
<blockquote>
<p>定义超平面(w,b)关于训练数据集T的几何间隔为超平面(w,b)关于T中所有样本点i，yi)的几何间隔之最小值</p>
</blockquote>
<blockquote>
<p>超平面(w,b)关于样本点i，yi)的几何间隔一般是实例点到超平面的带符号的距离（distance），当样本点被超平面正确分类时就是实例点到超平面的距离。</p>
</blockquote>
<blockquote>
<p>如果||w||＝1，那么函数间隔和几何间隔相等。如果超平面参数w和b成比例地改变（超平面没有改变），函数间隔也按此比例改变，而几何间隔不变。</p>
</blockquote>
<h2 id="713-间隔最大化"><a class="markdownIt-Anchor" href="#713-间隔最大化"></a> 7.1.3　间隔最大化</h2>
<blockquote>
<p>支持向量机学习的基本想法是求解能够正确划分训练数据集并且几何间隔最大的分离超平面。对线性可分的训练数据集而言，线性可分分离超平面有无穷多个（等价于感知机），但是几何间隔最大的分离超平面是唯一的。这里的间隔最大化又称为硬间隔最大化</p>
</blockquote>
<blockquote>
<p>间隔最大化的直观解释是：对训练数据集找到几何间隔最大的超平面意味着以充分大的确信度对训练数据进行分类。也就是说，不仅将正负实例点分开，而且对最难分的实例点（离超平面最近的点）也有足够大的确信度将它们分开。这样的超平面应该对未知的新实例有很好的分类预测能力。</p>
</blockquote>
<blockquote>
<p>若训练数据集T线性可分，则可将训练数据集中的样本点完全正确分开的最大间隔分离超平面存在且唯一。</p>
</blockquote>
<blockquote>
<p>在线性可分情况下，训练数据集的样本点中与分离超平面距离最近的样本点的实例称为支持向量（vector）</p>
</blockquote>
<blockquote>
<p>在决定分离超平面时只有支持向量起作用，而其他实例点并不起作用。如果移动支持向量将改变所求的解；但是如果在间隔边界以外移动其他实例点，甚至去掉这些点，则解是不会改变的。由于支持向量在确定分离超平面中起着决定性作用，所以将这种分类模型称为支持向量机。支持向量的个数一般很少，所以支持向量机由很少的“重要的”训练样本确定。</p>
</blockquote>
<h2 id="714-学习的对偶算法"><a class="markdownIt-Anchor" href="#714-学习的对偶算法"></a> 7.1.4　学习的对偶算法</h2>
<blockquote>
<p>通过求解对偶问题（dualproblem）得到原始问题（primalproblem）的最优解，这就是线性可分支持向量机的对偶算法（dualalgorithm）。这样做的优点，一是对偶问题往往更容易求解；二是自然引入核函数，进而推广到非线性分类问题。</p>
</blockquote>
<blockquote>
<p>对于线性可分问题，上述线性可分支持向量机的学习（硬间隔最大化）算法是完美的。但是，训练数据集线性可分是理想的情形。在现实问题中，训练数据集往往是线性不可分的，即在样本中出现噪声或特异点。</p>
</blockquote>
<h2 id="73-非线性支持向量机与核函数"><a class="markdownIt-Anchor" href="#73-非线性支持向量机与核函数"></a> 7.3　非线性支持向量机与核函数</h2>
<blockquote>
<p>对解线性分类问题，线性分类支持向量机是一种非常有效的方法。但是，有时分类问题是非线性的，这时可以使用非线性支持向量机。</p>
</blockquote>
<h2 id="731-核技巧"><a class="markdownIt-Anchor" href="#731-核技巧"></a> 7.3.1　核技巧</h2>
<blockquote>
<p>非线性问题往往不好求解，所以希望能用解线性分类问题的方法解决这个问题。所采取的方法是进行一个非线性变换，将非线性问题变换为线性问题，通过解变换后的线性问题的方法求解原来的非线性问题。</p>
</blockquote>
<blockquote>
<p>核技巧应用到支持向量机，其基本想法就是通过一个非线性变换将输入空间（欧氏空间n或离散集合）对应于一个特征空间（希尔伯特空间），使得在输入空间n中的超曲面模型对应于特征空间中的超平面模型（支持向量机）。这样，分类问题的学习任务通过在特征空间中求解线性支持向量机就可以完成。</p>
</blockquote>
<blockquote>
<p>在核函数K(x,z)给定的条件下，可以利用解线性分类问题的方法求解非线性分类问题的支持向量机。学习是隐式地在特征空间进行的，不需要显式地定义特征空间和映射函数。这样的技巧称为核技巧，</p>
</blockquote>
<h2 id="74-序列最小最优化算法"><a class="markdownIt-Anchor" href="#74-序列最小最优化算法"></a> 7.4　序列最小最优化算法</h2>
<blockquote>
<p>支持向量机的学习问题可以形式化为求解凸二次规划问题。这样的凸二次规划问题具有全局最优解，并且有许多最优化算法可以用于这一问题的求解。</p>
</blockquote>
<h2 id="811-提升方法的基本思路"><a class="markdownIt-Anchor" href="#811-提升方法的基本思路"></a> 8.1.1　提升方法的基本思路</h2>
<blockquote>
<p>在概率近似正确（probablyapproximatelycorrect，PAC）学习的框架中，一个概念（一个类），如果存在一个多项式的学习算法能够学习它，并且正确率很高，那么就称这个概念是强可学习的</p>
</blockquote>
<blockquote>
<p>一个概念，如果存在一个多项式的学习算法能够学习它，学习的正确率仅比随机猜测略好，那么就称这个概念是弱可学习的。</p>
</blockquote>
<blockquote>
<p>在PAC学习的框架下，一个概念是强可学习的充分必要条件是这个概念是弱可学习的。</p>
</blockquote>
<blockquote>
<p>对于分类问题而言，给定一个训练样本集，求比较粗糙的分类规则（弱分类器）要比求精确的分类规则（强分类器）容易得多。提升方法就是从弱学习算法出发，反复学习，得到一系列弱分类器（又称为基本分类器），然后组合这些弱分类器，构成一个强分类器。大多数的提升方法都是改变训练数据的概率分布（训练数据的权值分布），针对不同的训练数据分布调用弱学习算法学习一系列弱分类器。</p>
</blockquote>
<blockquote>
<p>对提升方法来说，有两个问题需要回答：一是在每一轮如何改变训练数据的权值或概率分布；二是如何将弱分类器组合成一个强分类器。关于第1个问题，AdaBoost的做法是，提高那些被前一轮弱分类器错误分类样本的权值，而降低那些被正确分类样本的权值。这样一来，那些没有得到正确分类的数据，由于其权值的加大而受到后一轮的弱分类器的更大关注。于是，分类问题被一系列的弱分类器“分而治之”。至于第2个问题，即弱分类器的组合，AdaBoost采取加权多数表决的方法。具体地，加大分类误差率小的弱分类器的权值，使其在表决中起较大的作用，减小分类误差率大的弱分类器的权值，使其在表决中起较小的作用。</p>
</blockquote>
<h2 id="83-adaboost算法的解释"><a class="markdownIt-Anchor" href="#83-adaboost算法的解释"></a> 8.3　AdaBoost算法的解释</h2>
<blockquote>
<p>AdaBoost算法还有另一个解释，即可以认为AdaBoost算法是模型为加法模型、损失函数为指数函数、学习算法为前向分步算法时的二类分类学习方法。</p>
</blockquote>
<h2 id="84-提升树"><a class="markdownIt-Anchor" href="#84-提升树"></a> 8.4　提升树</h2>
<blockquote>
<p>提升树是以分类树或回归树为基本分类器的提升方法。提升树被认为是统计学习中性能最好的方法之一。</p>
</blockquote>
<h2 id="841-提升树模型"><a class="markdownIt-Anchor" href="#841-提升树模型"></a> 8.4.1　提升树模型</h2>
<blockquote>
<p>提升方法实际采用加法模型（即基函数的线性组合）与前向分步算法。以决策树为基函数的提升方法称为提升树（tree）。对分类问题决策树是二叉分类树，对回归问题决策树是二叉回归树。</p>
</blockquote>
<h2 id="第10章-隐马尔可夫模型"><a class="markdownIt-Anchor" href="#第10章-隐马尔可夫模型"></a> 第10章　隐马尔可夫模型</h2>
<blockquote>
<p>隐马尔可夫模型（Markovmodel,HMM）是可用于标注问题的统计学习模型，描述由隐藏的马尔可夫链随机生成观测序列的过程，属于生成模型。</p>
</blockquote>
<h2 id="1011-隐马尔可夫模型的定义"><a class="markdownIt-Anchor" href="#1011-隐马尔可夫模型的定义"></a> 10.1.1　隐马尔可夫模型的定义</h2>
<blockquote>
<p>隐马尔可夫模型是关于时序的概率模型，描述由一个隐藏的马尔可夫链随机生成不可观测的状态随机序列，再由各个状态生成一个观测而产生观测随机序列的过程</p>
</blockquote>
<blockquote>
<p>隐藏的马尔可夫链随机生成的状态的序列，称为状态序列（statesequence）；每个状态生成一个观测，而由此产生的观测的随机序列，称为观测序列（observationsequence）。序列的每一个位置又可以看作是一个时刻。</p>
</blockquote>
<h2 id="1013-隐马尔可夫模型的3个基本问题"><a class="markdownIt-Anchor" href="#1013-隐马尔可夫模型的3个基本问题"></a> 10.1.3　隐马尔可夫模型的3个基本问题</h2>
<blockquote>
<p>隐马尔可夫模型有3个基本问题：（1）概率计算问题。</p>
</blockquote>
<blockquote>
<p>（2）学习问题。</p>
</blockquote>
<blockquote>
<p>（3）预测问题，</p>
</blockquote>
<h2 id="103-学习算法"><a class="markdownIt-Anchor" href="#103-学习算法"></a> 10.3　学习算法</h2>
<blockquote>
<p>隐马尔可夫模型的学习，根据训练数据是包括观测序列和对应的状态序列还是只有观测序列，可以分别由监督学习与非监督学习实现。本节首先介绍监督学习算法，而后介绍非监督学习算法——Baum-Welch算法（也就是EM算法）。</p>
</blockquote>
<h2 id="104-预测算法"><a class="markdownIt-Anchor" href="#104-预测算法"></a> 10.4　预测算法</h2>
<blockquote>
<p>隐马尔可夫模型预测的两种算法：近似算法与维特比算法（Viterbialgorithm）。</p>
</blockquote>
<h2 id="1042-维特比算法"><a class="markdownIt-Anchor" href="#1042-维特比算法"></a> 10.4.2　维特比算法</h2>
<blockquote>
<p>维特比算法实际是用动态规划解隐马尔可夫模型预测问题，即用动态规划（programming）求概率最大路径（最优路径）。这时一条路径对应着一个状态序列。</p>
</blockquote>
<h2 id="第11章-条件随机场"><a class="markdownIt-Anchor" href="#第11章-条件随机场"></a> 第11章　条件随机场</h2>
<blockquote>
<p>条件随机场（randomfield,CRF）是给定一组输入随机变量条件下另一组输出随机变量的条件概率分布模型，其特点是假设输出随机变量构成马尔可夫随机场。</p>
</blockquote>
<h2 id="111-概率无向图模型"><a class="markdownIt-Anchor" href="#111-概率无向图模型"></a> 11.1　概率无向图模型</h2>
<blockquote>
<p>概率无向图模型（undirectedgraphicalmodel），又称为马尔可夫随机场（randomfield），是一个可以由无向图表示的联合概率分布。</p>
</blockquote>
<h2 id="1111-模型定义"><a class="markdownIt-Anchor" href="#1111-模型定义"></a> 11.1.1　模型定义</h2>
<blockquote>
<p>设有联合概率分布P(Y)，由无向图G＝(V,E)表示，在图G中，结点表示随机变量，边表示随机变量之间的依赖关系。如果联合概率分布P(Y)满足成对、局部或全局马尔可夫性，就称此联合概率分布为概率无向图模型（probabilityundirectedgraphicalmodel），或马尔可夫随机场（Markovrandomfield）。</p>
</blockquote>
<blockquote>
<p>事实上，概率无向图模型的最大特点就是易于因子分解。下</p>
</blockquote>
<h2 id="1112-概率无向图模型的因子分解"><a class="markdownIt-Anchor" href="#1112-概率无向图模型的因子分解"></a> 11.1.2　概率无向图模型的因子分解</h2>
<blockquote>
<p>将概率无向图模型的联合概率分布表示为其最大团上的随机变量的函数的乘积形式的操作，称为概率无向图模型的因子分解</p>
</blockquote>
<h2 id="1121-条件随机场的定义"><a class="markdownIt-Anchor" href="#1121-条件随机场的定义"></a> 11.2.1　条件随机场的定义</h2>
<blockquote>
<p>条件随机场（randomfield）是给定随机变量X条件下，随机变量Y的马尔可夫随机场。这里主要介绍定义在线性链上的特殊的条件随机场，称为线性链条件随机场（chainconditionalrandomfield）。线性链条件随机场可以用于标注等问题。</p>
</blockquote>
<h2 id="本章概要-2"><a class="markdownIt-Anchor" href="#本章概要-2"></a> 本章概要</h2>
<blockquote>
<p>概率无向图模型或马尔可夫随机场的联合概率分布可以分解为无向图最大团上的正值函数的乘积的形式。</p>
</blockquote>
<blockquote>
<p>条件随机场是给定输入随机变量X条件下，输出随机变量Y的条件概率分布模型，其形式为参数化的对数线性模型。条件随机场的最大特点是假设输出变量之间的联合概率分布构成概率无向图模型，即马尔可夫随机场。条件随机场是判别模型。</p>
</blockquote>
<blockquote>
<p>线性链条件随机场是定义在观测序列与标记序列上的条件随机场。线性链条件随机场一般表示为给定观测序列条件下的标记序列的条件概率分布，由参数化的对数线性模型表示。模型包含特征及相应的权值，特征是定义在线性链的边与结点上的。</p>
</blockquote>
<h2 id="第12章-统计学习方法总结"><a class="markdownIt-Anchor" href="#第12章-统计学习方法总结"></a> 第12章　统计学习方法总结</h2>
<blockquote>
<p>感知机、k近邻法、朴素贝叶斯法、决策树、逻辑斯谛回归与最大熵模型、支持向量机、提升方法是分类方法。原始的感知机、支持向量机以及提升方法是针对二类分类的，可以将它们扩展到多类分类</p>
</blockquote>
<blockquote>
<p>感知机、k近邻法、朴素贝叶斯法、决策树是简单的分类方法，具有模型直观、方法简单、实现容易等特点。逻辑斯谛回归与最大熵模型、支持向量机、提升方法是更复杂但更有效的分类方法，往往分类准确率更高</p>
</blockquote>
<blockquote>
<p>隐马尔可夫模型、条件随机场是主要的标注方法。通常条件随机场的标注准确率更高。</p>
</blockquote>
<blockquote>
<p>分类问题与标注问题的预测模型都可以认为是表示从输入空间到输出空间的映射。它们可以写成条件概率分布P(Y|X)或决策函数Y＝f(X)的形式。前者表示给定输入条件下输出的概率模型，后者表示输入到输出的非概率模型。有时，模型更直接地表示为概率模型，或者非概率模型</p>
</blockquote>
<blockquote>
<p>朴素贝叶斯法、隐马尔可夫模型是概率模型。感知机、k近邻法、支持向量机、提升方法是非概率模型。而决策树、逻辑斯谛回归与最大熵模型、条件随机场既可以看作是概率模型，又可以看作是非概率模型。直接学习条件概率分布P(Y|X)或决策函数Y＝f(X)的方法为判别方法，对应的模型是判别模型。感知机、k近邻法、决策树、逻辑斯谛回归与最大熵模型、支持向量机、提升方法、条件随机场是判别方法</p>
</blockquote>
<blockquote>
<p>首先学习联合概率分布P(X,Y)，从而求得条件概率分布P(Y|X)的方法是生成方法，对应的模型是生成模型。朴素贝叶斯法、隐马尔可夫模型是生成方法。</p>
</blockquote>
<blockquote>
<p>决策树是定义在一般的特征空间上的，可以含有连续变量或离散变量。感知机、支持向量机、k近邻法的特征空间是欧氏空间（更一般地，是希尔伯特空间）</p>
</blockquote>
<blockquote>
<p>提升方法的模型是弱分类器的线性组合，弱分类器的特征空间就是提升方法模型的特征空间。感知机模型是线性模型，而逻辑斯谛回归与最大熵模型、条件随机场是对数线性模型。k近邻法、决策树、支持向量机（包含核函数）、提升方法使用的是非线性模型。</p>
</blockquote>
<blockquote>
<p>在二类分类的监督学习中，支持向量机、逻辑斯谛回归与最大熵模型、提升方法各自使用合页损失函数、逻辑斯谛损失函数、指数损失函数。</p>
</blockquote>
<blockquote>
<p>概率模型的学习可以形式化为极大似然估计或贝叶斯估计的极大后验概率估计。这时，学习的策略是极小化对数似然损失或极小化正则化的对数似然损失。</p>
</blockquote>
<blockquote>
<p>决策树学习的策略是正则化的极大似然估计，损失函数是对数似然损失，正则化项是决策树的复杂度。逻辑斯谛回归与最大熵模型、条件随机场的学习策略既可以看成是极大似然估计（或正则化的极大似然估计），又可以看成是极小化逻辑斯谛损失（或正则化的逻辑斯谛损失）。朴素贝叶斯模型、隐马尔可夫模型的非监督学习也是极大似然估计或极大后验概率估计，但这时模型含有隐变量。</p>
</blockquote>
<blockquote>
<p>朴素贝叶斯法与隐马尔可夫模型的监督学习，最优解即极大似然估计值，可以由概率计算公式直接计算。感知机、逻辑斯谛回归与最大熵模型、条件随机场的学习利用梯度下降法、拟牛顿法等。这些都是一般的无约束最优化问题的解法。支持向量机学习，可以解凸二次规划的对偶问题。有序列最小最优化算法等方法。决策树学习是基于启发式算法的典型例子。可以认为特征选择、生成、剪枝是启发式地进行正则化的极大似然估计。提升方法利用学习的模型是加法模型、损失函数是指数损失函数的特点，启发式地从前向后逐步学习模型，以达到逼近优化目标函数的目的。EM算法是一种迭代的求解含隐变量概率模型参数的方法，它的收敛性可以保证，但是不能保证收敛到全局最优。支持向量机学习、逻辑斯谛回归与最大熵模型学习、条件随机场学习是凸优化问题，全局最优解保证存在。而其他学习问题则不是凸优化问题。</p>
</blockquote>
<h2 id="附录a-梯度下降法"><a class="markdownIt-Anchor" href="#附录a-梯度下降法"></a> 附录A　梯度下降法</h2>
<blockquote>
<p>梯度下降法（descent）或最速下降法（descent）是求解无约束最优化问题的一种最常用的方法，有实现简单的优点。梯度下降法是迭代算法，每一步需要求解目标函数的梯度向量。</p>
</blockquote>
<h2 id="附录b-牛顿法和拟牛顿法"><a class="markdownIt-Anchor" href="#附录b-牛顿法和拟牛顿法"></a> 附录B　牛顿法和拟牛顿法</h2>
<blockquote>
<p>牛顿法（method）和拟牛顿法（Newtonmethod）也是求解无约束最优化问题的常用方法，有收敛速度快的优点。牛顿法是迭代算法，每一步需要求解目标函数的海赛矩阵的逆矩阵，计算比较复杂</p>
</blockquote>
]]></content>
  </entry>
  <entry>
    <title>书摘：《生活需要自律力》-童小言</title>
    <url>/2020/10/23/%E4%B9%A6%E6%91%98_%E7%94%9F%E6%B4%BB%E9%9C%80%E8%A6%81%E8%87%AA%E5%BE%8B%E5%8A%9B-%E7%AB%A5%E5%B0%8F%E8%A8%80.hexo/</url>
    <content><![CDATA[<div class="douban-card-block">
	<a class="douban-card" href="https://book.douban.com/subject/33700841">
		<div class="douban-card-bgimg" style="background-image: url('https://images.weserv.nl/?url=https://img2.doubanio.com/view/subject/s/public/s32567412.jpg');"></div>
		<div class="douban-card-left">
			<div class="douban-card-img" style="background-image: url('https://images.weserv.nl/?url=https://img2.doubanio.com/view/subject/s/public/s32567412.jpg');"></div>
		</div>
		<div class="douban-card-right" style="line-height: 1.7;">
			<div class="douban-card-item"><span>书名: </span><strong>生活需要自律力</strong></div>
			<div class="douban-card-item"><span>作者: </span><span>童小言</span></div>
			<div class="douban-card-item"><span>出版年份: </span><span>2019-6-1</span></div>
			<div class="douban-card-item"><span>评分: </span><span>5.7</span></div>
		</div>
	</a>
</div>
<style>
	.douban-card-block {
		display: flex;
		justify-content: center;
		align-items: center;
		width: 100%;
		max-height: 400px;
	}
	.douban-card {
		display: flex;
		margin: 30px 10px;
		padding: 15px;
		border-radius: 10px;
		position: relative;
		justify-content: center;
		align-items: center;
		overflow: hidden;
		color: antiquewhite;
		text-decoration: none;
	}
	.douban-card:hover {
		text-decoration: none;
	}
	.douban-card-bgimg {
		position: absolute;
		width: 115%;
		height: 115%;
		filter: blur(15px) brightness(0.6);
		background-size: 100%;
		background-position: center;
		background-repeat: no-repeat;
	}
	.douban-card-img {
		position: relative;
		height: 130px;
		width: 80px;
		background-size: 100%;
		background-position: center;
		background-repeat: no-repeat;
	}
	.douban-card-img {
		position: relative;
		height: 130px;
		width: 80px;
	}
	.douban-card-left {
		position: relative;
		display: flex;
		flex-direction: column;
		align-items: center;
	}
	.douban-card-right {
		position: relative;
		display: flex;
		flex-direction: column;
		margin-left: 12px;
		font-size: 16px;
		font-family: 'Courier New', Courier, monospace;
		line-height: 1.3;
		color: antiquewhite;
	}
	.douban-card-item {
		margin-top: 4px;
	}
</style>
<a id="more"></a>
<h2 id="自序"><a class="markdownIt-Anchor" href="#自序"></a> 自序</h2>
<blockquote>
<p>我相信命运在此之前，已为我做好种种铺垫。我的原生家庭、所受的教育、看过的书、行过的路、遇见过的人，塑造了我的性格和观念，它们让我在面临某些选择时做出适合自己的决定。</p>
</blockquote>
<blockquote>
<p>自律是一种选择，也是一种决定，当你决定开始自律时，你的人生也会从此不同。</p>
</blockquote>
<blockquote>
<p>如果你想过自己想要的生活，自律是你一定要坚持锤炼的心性。放纵可以带来短暂的快感，但人生终究是一场马拉松，短暂不能持久，而自律带给你的喜悦与成就，经历岁月，历久弥香。</p>
</blockquote>
<h2 id="那些出人头地都源于自律"><a class="markdownIt-Anchor" href="#那些出人头地都源于自律"></a> 那些出人头地，都源于自律</h2>
<blockquote>
<p>知道自己要什么，思考怎样做，然后专注且高执行力地去实现它，这就是自律的态度！</p>
</blockquote>
<h2 id="自律是管好你的嘴"><a class="markdownIt-Anchor" href="#自律是管好你的嘴"></a> 自律是管好你的嘴</h2>
<blockquote>
<p>我之所以不在乎别人对我的看法，是因为别人看到的我不是真实的我，只是他眼里的我。</p>
</blockquote>
<blockquote>
<p>越长大，“别人眼中的我”越不重要，“我心里的我”越重要。</p>
</blockquote>
<blockquote>
<p>自律的人，都善于管住自己的嘴，不会对任何人、任何事妄加评论。</p>
</blockquote>
<h2 id="自律是不麻烦别人"><a class="markdownIt-Anchor" href="#自律是不麻烦别人"></a> 自律是不麻烦别人</h2>
<blockquote>
<p>我们更愿意帮助那些有能力、肯努力、正直、善良、美好、懂事、有责任感的人，他们知感恩，尽管我们不期待他们回报什么。</p>
</blockquote>
<blockquote>
<p>生活就是，有时你冷了，别人正好为你披上外套，可最终，你得把外套还回去，独自走自己的路，所以，不必贪恋那一时的温度。</p>
</blockquote>
<h2 id="自律是坚持自己接纳不同"><a class="markdownIt-Anchor" href="#自律是坚持自己接纳不同"></a> 自律是坚持自己，接纳不同</h2>
<blockquote>
<p>现代人常常感到无聊，其实是“更高精神满足感的需求”与“远远不足的知识补给”之间的落差。所以，无聊时去啃书，去学习。人生如逆水行舟，不进则退。</p>
</blockquote>
<h2 id="凡事有交代件件有着落事事有回音"><a class="markdownIt-Anchor" href="#凡事有交代件件有着落事事有回音"></a> 凡事有交代，件件有着落，事事有回音</h2>
<blockquote>
<p>明智的人在经历各种沉浮时都始终盯紧稳健的基本面；而轻浮的人跟着感觉走，做出情绪化的反应，对于热门的东西一拥而上，不热的时候又马上放弃。</p>
</blockquote>
<blockquote>
<p>做事没有闭环，不落地，或有始无终，称不靠谱。沟通没有闭环，有些人，你问他问题从来得不到及时回应，甚至你不追到他眼前就永远没有回应，也没有交代，也是不靠谱。</p>
</blockquote>
<blockquote>
<p>大智论道，中智论事，小智论人</p>
</blockquote>
<blockquote>
<p>一个人的人生经验，来自读过的书、走过的路和遇见过的人。经历过的，成功与失败，都是镜子，让我们在拼拼凑凑中找到自己。</p>
</blockquote>
<h2 id="越自律越幸运"><a class="markdownIt-Anchor" href="#越自律越幸运"></a> 越自律，越幸运</h2>
<blockquote>
<p>经历带来经验，经验本就是财富，它使你懂得将来再遇到事情的时候该如何应对。你不会不够强大的，只要你对未来还有憧憬，只要你还在为此努力，挫折会把你摔得更强大。哪怕过去的经验有时会误导你，让你在面对类似的问题时条件反射般地泛起熟悉又久违的害怕，几乎缴械投降。</p>
</blockquote>
<blockquote>
<p>心境得靠自己走出来。也许有人觉得当下的处境糟透了，其实拉长时间轴，你会发现并不是。老天只是觉得你应该最大化地去体验生活，淋漓尽致地品味酸甜苦辣。老天在一个你尚且可以承受、可以转弯、可以选择的阶段安排这一切，包括让你遇见那些崭新的人以及他们的观念和生活方式，让你感受和感触，就足以证明老天对你还是有善意和安排的。</p>
</blockquote>
<blockquote>
<p>任何事都不是容易的，任何所得都不会如外界以为的那么轻易。没那么多矫情的正能量，最好的正能量就是过好自己的生活，然后让别人看到你的生活就充满动力。</p>
</blockquote>
<h2 id="自律是生活里的仪式感"><a class="markdownIt-Anchor" href="#自律是生活里的仪式感"></a> 自律是生活里的仪式感</h2>
<blockquote>
<p>朋友是：听得懂，聊得来，互相看得上。闺蜜是：听得懂，愿意听，聊得来，愿意聊，互相看得上，互相损得起。知己是：知道我为何而来，知道我向往何方，一个眼神的长度，便能把我看穿。</p>
</blockquote>
<blockquote>
<p>仪式是什么？”小王子问道。“这也是经常被遗忘的事情。”狐狸说，“它就是使某一天与其他日子不同，使某一时刻与其他时刻不同。”</p>
</blockquote>
<blockquote>
<p>博尔赫斯在《朋友之树》中所说，我们生命中的每位过客都是独一无二的。他们会留下自己的一些印记，也会带走我们的部分气息。我需要你，我生命之树的叶子，就像需要和平、爱与健康一样，无论现在还是永远。</p>
</blockquote>
<h2 id="自律的人拥有两倍人生"><a class="markdownIt-Anchor" href="#自律的人拥有两倍人生"></a> 自律的人，拥有两倍人生</h2>
<blockquote>
<p>逻辑可以带你从A到B，想象力可以带你到任何地方。</p>
</blockquote>
<blockquote>
<p>人生命的长度终是有限的，但我们可以无限拓宽生命的宽度和厚度。拥有自律，你就拥有了两倍的人生。</p>
</blockquote>
<blockquote>
<p>机会不会主动告诉你去把握它，它会“易容”成其他模样，有时是细节、有时是尊重、有时是大局观……机会靠近你，直到有些人抓住了，有些人不屑地走开，它才找到了自己的主人。而那些当时有太多理由走开的人，他们内心总在抱怨——为什么机会从来没有眷顾过我。</p>
</blockquote>
<h2 id="自律通往优秀优秀吸引人脉"><a class="markdownIt-Anchor" href="#自律通往优秀优秀吸引人脉"></a> 自律通往优秀，优秀吸引人脉</h2>
<blockquote>
<p>人生如品茶，再优秀的人长期和乌合之众在一起，也终将褪去优秀，沦为乌合之众。纵然“优秀”，也只是和乌合之众相比而言的优秀，又能够优秀到哪里去呢？</p>
</blockquote>
<blockquote>
<p>人很重要，到一个能让你施展才华与光芒的优异环境，也很重要。</p>
</blockquote>
<blockquote>
<p>要想真正进入更高级的圈子，人脉是没有用的，还得自己有能力。掌握越多别人所没有的东西，越能创造自己的稀缺性，你的价值才越大，人脉才能被催化。</p>
</blockquote>
<blockquote>
<p>参照性权利是指对拥有理想的资源或个人特质的人的认同而形成的权力。如果景仰一个人到了要模仿他的行为和态度的地步，那么这个人对你就拥有了参照性权利。这就是大家常说的各领域的KOL[关键意见领袖（KeyOpinionLeader）]。</p>
</blockquote>
<blockquote>
<p>人脉若来自你的个人特质，即才华、学识、人品、个人魅力、精神共鸣等等的吸引，则是相对稳固的，是relationship（强连接），欣赏大于利益，可能已上升到友谊了。如果你的资源是基于平台，如家庭、工作，那么也许这些资源会随着变化而自然消失</p>
</blockquote>
<blockquote>
<p>要么够优秀、要么够魅力，资源才是自己的，不是认识就叫人脉。</p>
</blockquote>
<h2 id="优质的环境让自律事半功倍"><a class="markdownIt-Anchor" href="#优质的环境让自律事半功倍"></a> 优质的环境，让自律事半功倍</h2>
<blockquote>
<p>如何获得机会，我给出的建议是：假如你没有慧眼，就多试！</p>
</blockquote>
<blockquote>
<p>一个人的一生就是让自己不断变得值钱的过程，不断变得值钱就意味着自身不断进步。在一个市场化的社会里，每一个人都有自己的定价，如果你值钱了，讨价还价的机会就多，工作的机会就多，升迁的机会就多，让生命自由的机会也就增多。</p>
</blockquote>
<blockquote>
<p>你想要修炼自己，不窝在一寸地里当井底之蛙，想看看世界上的其他人都在干些什么</p>
</blockquote>
<blockquote>
<p>常到陌生圈子走动，会有意外收获。人脉，前提是有人，窝在家里的沙发上，当然不可能认识什么人。你必须走出去，见识多元，开阔视野，寻得同伴，彼此有信念，互相是人脉。</p>
</blockquote>
<h2 id="自律的敌人是明日复明日"><a class="markdownIt-Anchor" href="#自律的敌人是明日复明日"></a> 自律的敌人，是“明日复明日”</h2>
<blockquote>
<p>想到就去做的执行力，是通向成功的起点。自律的敌人，永远是“明日复明日”。</p>
</blockquote>
<h2 id="选择信息社会最重要的能力是删繁就简"><a class="markdownIt-Anchor" href="#选择信息社会最重要的能力是删繁就简"></a> 选择：信息社会，最重要的能力是删繁就简</h2>
<blockquote>
<p>观察一个人，不要听他说了什么，要看他做了什么。因为说话是没有成本的，行动才是有成本的。</p>
</blockquote>
<blockquote>
<p>如果你对未来还有要求，倒推回来，也许你不知道自己现在该做什么，但至少你该知道自己不该做什么。</p>
</blockquote>
<h2 id="从容慢慢来有时比较快"><a class="markdownIt-Anchor" href="#从容慢慢来有时比较快"></a> 从容：慢慢来，有时比较快</h2>
<blockquote>
<p>既紧急又重要的事，放在第一位，优先处理。重要但不紧急的事，早点规划起来，按照计划逐步实行。如果一直搁置，到了临近截止期限，就会成为“既紧急又重要”，拖延症或者时间管理不当的结果就是让自己非常忙碌。紧急但不重要的事，授权别人去做，不要什么事都想自己做，不要抱着“与其花时间跟别人交代不如自己完成”的心态，也许当时你的事情很多，但别人正好有时间。对你来说，此事的优先级很低，要把排在它前面的10件事办完你才会来考虑它，但对别人来说，听完你的交代，可以立刻处理完毕。如果你没交代下去，结果当你处理完第9件事时，突然插进来新的“重要”事项，那件“紧急但不重要”的事就又会被耽搁，而且你明明知道它是“紧急”的。最后，“不紧急不重要”的事，要学会抛弃，尽量不要浪费时间。</p>
</blockquote>
<h2 id="挫折做最坏的打算但拼死找一条生路"><a class="markdownIt-Anchor" href="#挫折做最坏的打算但拼死找一条生路"></a> 挫折：做最坏的打算，但拼死找一条生路</h2>
<blockquote>
<p>成长的烦恼以不同的形状和深浅进入人生的各个阶段，到了30岁，真真切切地感受到烦恼本身，才觉得小时候的烦恼大多是自己想出来的，就跟棉花糖一样，尝过以后，化在嘴里还有点甜。</p>
</blockquote>
<h2 id="格局想当将军就别用兵的思维"><a class="markdownIt-Anchor" href="#格局想当将军就别用兵的思维"></a> 格局：想当将军，就别用兵的思维</h2>
<blockquote>
<p>鸡毛蒜皮”和“细节”不同，细节是对事态有影响的事，虽然微小，但不能被忽略。所以细节很重要，而“鸡毛蒜皮”是“非重点”</p>
</blockquote>
]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>读书</tag>
      </tags>
  </entry>
  <entry>
    <title>书摘：《群体性孤独》-[美] 雪莉·特克尔</title>
    <url>/2021/04/08/%E4%B9%A6%E6%91%98_%E7%BE%A4%E4%BD%93%E6%80%A7%E5%AD%A4%E7%8B%AC-%5B%E7%BE%8E%5D%20%E9%9B%AA%E8%8E%89%C2%B7%E7%89%B9%E5%85%8B%E5%B0%94.hexo/</url>
    <content><![CDATA[<p>这是一本思考人与机器，人与网络关系的书籍，主要认识有：</p>
<ol>
<li>在当今互联网飞速发展下，把越来越多的人联系在一起，人们非但没有感觉更加<code>热闹</code>，而是更加孤独，这就是所谓的群体性孤独！！！</li>
<li>人们越来越期待<code>虚拟世界</code>和<code>弱联系</code>，对面对面的交流越来越抵触，比如如今网上<code>廉价的道歉</code>；</li>
<li>互联网是用来提高工作效率的工具，但是我们却没有被解法，反而被它束缚，要求我们<code>时刻在线</code>；</li>
<li>互联网犹豫荆棘丛林，各种想法、链接、图片缠绕在一起，沉迷其中就会让我们没有办法更加深刻地思考当下，太容易随波逐流；</li>
<li>互联网作为新生事物，完全抛弃肯定不行，但是必须时刻警惕它对我们的影响</li>
</ol>
<p>一个搞IT，搞AI的人，居然去看这类书，我都无法找到当初的原因，或许是前方路太黑，需要灯光，或许是当下被互联网所累，学习如何更加有效利用它！</p>
<a id="more"></a>
<hr />
<p><strong>阅读书摘及笔记：</strong></p>
<blockquote>
<p>哈佛大学心理学教授霍华德·加德纳在30年前提出了著名的多元智能理论，认为人的智能不是简单的一种，而是由8种相互独立的智能构成的。它们分别是：语言智能、音乐智能、逻辑智能、空间智能、身体智能、自省智能、交流智能和自然智能。</p>
</blockquote>
<blockquote>
<p>与森林等自然环境的境遇相反，计算机和互联网正在成为人类赖以生存的新环境。和与自然接触会产生自然智能相同，我们与计算机和互联网接触会产生机器智能（不是传统意义上的能思考的机器，而是人们如何更好地驾驭机器的智能）、网络智能（不是网络里产生的群体智能，而是人们如何更好地利用网络解决问题的智能）。机器智能、网络智能的智商高低，未来在很大程度上会决定一个人的命运。</p>
</blockquote>
<blockquote>
<p>技术是极具诱惑力的，因为它能弥补人性中脆弱的一面。而我们的确是非常脆弱、敏感的物种。我们时常感到孤独，却又害怕被亲密关系所束缚。数字化的社交关系和机器人恰恰为我们制造了一种幻觉：我们有人陪伴，却无须付出友谊。在网络世界中我们彼此连接，同时也可以互相隐身。</p>
</blockquote>
<blockquote>
<p>发现人们不仅十分认真地把机器人视为宠物，还视为潜在的朋友、知己，甚至是虚拟的情人。我们并不关心机器人对人类与他们“分享”的情感能“知道”或“理解”多少。在机器人时代，只要人与机器连接的表演看起来足够多就行了。我们毫无偏见地、泰然自若地与毫无生命的机器连接在一起。这让我想起了一个短语：“技术滥交”</p>
</blockquote>
<blockquote>
<p>一个30岁的男人评论说：“我更愿意和一个机器人说话。和朋友们交往太累，使我筋疲力尽。机器人会一直陪伴着我，而且任何时候只要我想好了，我都可以脱离这段关系。”</p>
</blockquote>
<blockquote>
<p>社交机器人的发明说明人类兜了一个大圈子，还是无法摆脱对亲密关系的渴望。人们看起来很心甘情愿地相信：如果我们疏远或是忽视了彼此，机器人会补偿我们，程序早就设定好了，他们会带来虚拟的爱。当我们逐渐衰老，机器人会伺候我们；当我们的孩子无人照看，机器人会照料他们；当我们在逆境中精疲力竭而不能互相支撑时，机器人会给予我们能量。机器人不会对我们评头论足，我们得到前所未有的接纳和包容。</p>
</blockquote>
<blockquote>
<p>有了技术，我们惊讶于世界之“苍白”，无事表达，无人取悦。当一个化身在网络游戏里与另一个化身整晚交谈之后，在某个时刻，我们感到完全拥有一份真实的社会生活，然后接下来，在与陌生人牵强而脆弱的联系里，莫名地感到孤独无援。</p>
</blockquote>
<blockquote>
<p>用技术来处理亲密关系，人际关系会被弱化成仅仅是联系而已。而在此之后，简单的联系会被重新定义为亲密。换句话说，网络亲密（cyberintimacies）滑向了网络疏离（cybersolitudes）</p>
</blockquote>
<blockquote>
<p>在机器人的陪伴下，人们是孤单的，但也感到与他人连接在一起。在这种孤单的环境中，出现了一种新型的亲密关系。</p>
</blockquote>
<blockquote>
<p>人们通过移动设备把自己牢牢地拴在网络上，从而获得自我的新状态。第一种状态是“逃离现实世界”：也许他们正在你身边，但他们的精神已经游离到了另一个世界；第二种状态是“双重体验”：人们能够体验到“虚拟与现实的双重人生”；第三种状态是“多任务处理”：人们由于可以同时处理多种事情而赢得了更多时间。</p>
</blockquote>
<blockquote>
<p>我开始意识到，获取关于专业问题和需求的新信息并不是开始和结束一天的好方法。</p>
</blockquote>
<blockquote>
<p>人们通过移动设备把自己牢牢地拴在网络上，从而获得一种自我的新状态。从一开始，它就意味着某种授权：它可以从现实环境中脱离——包括其中的人。它能同时体验到现实世界和虚拟世界。而且它能通过多任务处理产生更多时间，这是我们21世纪的魔法。</p>
</blockquote>
<blockquote>
<p>今天的年轻人生活在“永远在线”状态，他们期待着被“打扰”。网络技术改变了人们对“分开”的理解，也让年轻人失去了“独处”的机会</p>
</blockquote>
<blockquote>
<p>现在的年轻人伴随着机器人宠物成长，处在一个完全被网络束缚的环境中。他们认为自己是新兴人类，也是对虚拟化生存没有任何偏见的第一代人。他们看出了网络化生活的巨大力量——毕竟他们冒着生命危险去查看网络上的信息。</p>
</blockquote>
<blockquote>
<p>现在的青少年也要像前辈们一样学会表达情感，去思考人生的价值和自我的意识，他们也需要学会管理和表达自己的情感，需要时间去发现自己，去思考。但是科技的发展带来了永远在线的传播服务以及快餐式的文字和图像，这完全改变了原有的规则。什么时候该停下来？什么时候该寂静无声？文字短消息的快速回复，并非不能让年轻人在人际互动中进行自我反省，但作用的确较小。当人际交互要适应小屏幕、情绪需要通过情感符号表达时，的确存在着简化的必要。</p>
</blockquote>
<blockquote>
<p>根据传统，生活在城市里的孩子在成长的过程中都有一个重要的经历：第一次独自游览这个城市。这个经历是一种成人的仪式，孩子们从此需要对自己负责了。即使感到恐惧，他们也需要独自承担这种感受。而如今手机的存在减轻了这个仪式带来的恐惧感。</p>
</blockquote>
<blockquote>
<p>青少年的独立不仅仅意味着和父母分开，也包括和同龄人分开。他们要体会友谊既是一种支持，也是一种束缚</p>
</blockquote>
<blockquote>
<p>人际关系有着复杂的多面性。网络的虚拟生活为个人提供了足够的空间，同时也让青少年难以从新的群体需求中逃脱。年轻人很自然地期待他的朋友们可以随时在线——这是一种由技术进步引发的社会契约，要求同龄人随传随在。因此，受到束缚的自我也开始习惯于此</p>
</blockquote>
<blockquote>
<p>社会学家大卫·理斯曼（David Riesman）在20世纪50年代中期写道：美国人的自我感觉从内在转向了受人支配。人们没有坚定的内在目标，依赖伙伴寻找对其自身的肯定。如今，随身携带的手机增长了受人支配的态势。在开始有一个想法或一种感觉时，我们向别人证实，几乎是提前证实。人际交流也许是简短的，但是更多的交流大可不必。人们的需求只是希望随时可以保持联系</p>
</blockquote>
<blockquote>
<p>自恋时并不是指那些爱自己的人，而是指脆弱的个性，拥有这种个性的人需要源源不断的外界支持来进行自我确认。这种个性的人不能容忍别人的复杂需求，却试图通过扭曲别人的身份，分离出自身需要的和能用的东西，以此来与他们建立联系。因此，自恋者仅以量身定做的表达来与别人交往</p>
</blockquote>
<blockquote>
<p>一个脆弱的人也可以通过选择性和限制性的与人接触，从而获得支持（也就是通讯录中最受欢迎的人）</p>
</blockquote>
<blockquote>
<p>精神病学家罗伯特·杰伊·利夫顿（Robert Jay Lifton）是埃里克森的学生，他对成熟自我的看法与老师不同。他称成熟自我是千变万化的，强调多面性。这个自我，是“流动的和多面的”，可以接受和修饰不同的思想和观念。当被赋予多元的、彼此毫不相干的、全球性的事物时，这样的自我可以变得活跃起来。</p>
</blockquote>
<blockquote>
<p>在网络空间的不和谐声中形成的自我不是多变的，而是幼稚的。而如今我认为，在这样的文化背景下成长，会让他们以自恋的方式与世界建立联系。</p>
</blockquote>
<blockquote>
<p>当我注册Facebook时，这个网站对我来说还很新鲜，我会把第一感觉记录下来。现在看来，我的第一感觉稀松平常：我在交友计划A和交友计划B之间游离不定。计划A是我只在这个网站上联系我认识的人；计划B是我会接受所有人的好友请求，因为他们都表示很欣赏我的工作。我前几周执行了计划A，转而又选择了更具包容性的计划B，因为我为吸引了众多陌生人的注意力和称赞而沾沾自喜</p>
</blockquote>
<blockquote>
<p>发短信让人有一种安全感，并且可以通过细心斟酌而展现出一个期望的自我。但虚拟空间对“道歉”等现实问题是无能为力的。打电话意味着你在全神贯注地做一件事，也意味着一种“交谈”能力。声音传递情感，我们却巴不得让声音在生活中消失</p>
</blockquote>
<blockquote>
<p>在短信、留言和电子邮件中，我们隐藏的内容不比我们表达的内容少。我们可以把自己更好的一面展示给别人，也可以更快、更容易地处理好一件事。聆听只会使我们节奏放慢。</p>
</blockquote>
<blockquote>
<p>在网络世界中，当你身处多玩家角色扮演网络游戏的时候，你不仅技艺精湛、光芒四射，更重要的是，这种行为使你处在一个新的群体当中，有虚幻的好朋友和一种归属感。人在虚幻的世界里会感到比在现实中更加自在，因为他们觉得在虚拟的世界里可以秀出一个更加优秀、更加真实的自己。随着这一切的发生，谁还愿意身处现实之中呢？</p>
</blockquote>
<blockquote>
<p>对网络生活进行思考的过程有助于区分心理学家所说的“演练”和“实践”。“演练”时，你首先将现实生活中所遇到的冲突提取出来，然后将其在虚拟的世界里一遍又一遍地进行表现。此事重复量很大，却只有微不足道的进步。而在“实践”时，你运用网络上的一些素材来应对现实生活中的矛盾并寻找新的解决方案。</p>
</blockquote>
<blockquote>
<p>有些人会选择去“告白网站”排解孤独。人们宁愿在网上对着陌生人忏悔和释放情感，也不愿意直接面对你所伤害的人给他一个真正的道歉。实际上，网上告白没有想象的那么好，人们只是为了感觉良好而用“分享”避开“孤独”。</p>
</blockquote>
<blockquote>
<p>我们所抱怨的人际关系，也是连接我们和真实生活的纽带。我们的情感宣泄运用了一种极端的手段。人们会善意地对待陌生人。寂寞和孤单是如此难以忍受，以至于和在网络虚拟世界认识的网友结婚，似乎竟然成为了我们最好的希望</p>
</blockquote>
<blockquote>
<p>将负能量释放出来可以减轻它的毒副作用；而这样的情感释放不需要与真人交互即可完成。在两种情况中，告白看上去都越来越像对话，情感宣泄看上去越来越像分享。</p>
</blockquote>
<blockquote>
<p>道歉所包含的基本要素为修补关系打下了重要的心理基础——不仅对于被伤害者，也包括伤害者本身。首先你必须知道你冒犯了别人，你承认自己的行为可能给对方造成伤害，你必须问你自己如何做才能弥补。</p>
</blockquote>
<blockquote>
<p>科技模糊了告白和道歉的界线，很容易让我们忘记道歉的真正含义，不只是因为在线空间提供给他们一个面对其他人的“廉价道歉”的选择，同时也因为我们会认为道歉本身已与他人无关。在这样的情况下，我们忘记了我们的行为可以影响到他人。</p>
</blockquote>
<blockquote>
<p>对不起’这3个字太难。如果你是那个收到道歉的人，你知道对于一个人来说，让他当面说出‘对不起’是很困难的。但是正是如此，才让我们可以原谅一个人，他们亲自说出来，说明他们内心还是有勇气想道歉的</p>
</blockquote>
<blockquote>
<p>像与机器人的交流，在线告白有吸引力是因为某些沉默的人想诉说隐秘的情感。但是如果我们通过这些网站把它们“释放出来”来解除我们的忧虑，我们就不必精确地明白这些情感的背后是什么。我们没有运用我们的感情资源来建立对我们可能有帮助的持久关系。我们不能因为这种状况而责备技术。人们对彼此失望。技术仅仅能使我们创造一个无关紧要的神话。</p>
</blockquote>
<blockquote>
<p>焦虑成了这种新型沟通模式的一部分。然而，当我们谈起移动通信改革的时候，我们习惯对以前的事物进行“尊敬的”贬低，而把新鲜事物理想化。就拿在线阅读来说，因为它可能导入链接和其他一些超文本，所以常常有着一个英雄般必胜的传言，而书本却被蔑称为“孤立的”</p>
</blockquote>
<blockquote>
<p>朱莉娅还是情不自禁地在MySpace上搜索着父亲的大家庭——他的父母、兄弟姐妹、表兄弟姐妹、叔叔及阿姨等。她说她不会跟其中的任何一人联系，至少在她和父亲邮件交流之前不会。她不知道是否MySpace能够缝合幼年时代被撕裂的那份感情。</p>
</blockquote>
<blockquote>
<p>我和我的朋友们都觉得如果没有手机，感觉就像一无所有，毫无防备。”对于一无所有，毫无防备的自己，就仿佛置身于危险处境。失去联系，便如此脆弱。</p>
</blockquote>
<blockquote>
<p>短信是如此有诱惑力。因为它产生了一个附带自己要求的承诺。这个承诺是：你发送短信的那个人会在几秒钟内收到你的短信，而不管他或她是否“空闲”，他都能够看到你的短信。其附带的要求是：当你收到一条短信时，你就要去关注它（也许你正在上课，这意味着你要低头偷偷地瞟一眼静音的手机）并且在第一时间内给予回复。</p>
</blockquote>
<blockquote>
<p>短信这种介质适合快速传达简单的陈述，而对于开始一段蕴含复杂情感的对话则不是那么合适</p>
</blockquote>
<blockquote>
<p>电话交流是如此个人化，是因为在打电话的过程中，你没有时间去坐下来考虑你将要说些什么。你所要说的话都是你真正要表达的东西。如果某人发送给你一条短信，你还有一两分钟时间来考虑你将在回复里写些什么。如果你是在一个现实的谈话中，如果你一两分钟还没有说出一句话，过了几分钟你才回答，那将是非常尴尬的。这就是我喜欢打电话的原因。我更喜欢某人是诚实的，如果你在打电话，你就完全把自己暴露出来，但同时这也比其他方式更好。</p>
</blockquote>
<blockquote>
<p>这些年轻人渴望时间、接触、关注，以及直接的沟通。他们想要生活中少一些伪装，他们怀念面对面打交道，而且每次只专注做一件事的世界。这听起来充满了讽刺的意味，因为他们这一代人最大的、也曾经是最引以为豪的特征就是“一心多用”。</p>
</blockquote>
<blockquote>
<p>斯托尔说，人类的“创造过程”机制奇特，“到目前为止，新的想法产生频率比较高的状态是冥想状态，介于走路和睡眠之间。在冥想的心理状态下，思绪和画面可以自发地组合演变……创造者可以完全放松身心，让大脑内自行产生化学作用”。但是在数字化时代，安静和独处却很难获得。</p>
</blockquote>
<blockquote>
<p>如果你想拥有一个不被打扰的交流和沟通的环境，你最好亲自找那个人面对面地谈。如果没办法直接见面那就打电话。但是如果你是坐在电脑前在网上和别人交谈，那就有很多东西可以打断你的谈话，因为互联网上有如此多的比谈话更有趣的东西在吸引着你</p>
</blockquote>
<blockquote>
<p>梭罗写道：“我步入丛林，因为我希望生活得有意义。我希望活得深刻，吸取生命中所有的精华，把非生命的一切都击溃。以免当我生命终结时，发现自己从没有活过。我不想过一种不能称之为生活的生活，活得太甜蜜，我也不想试着顺从，除非那真的有必要。</p>
</blockquote>
<blockquote>
<p>《连线》杂志创始主编凯文·凯利说，他发现在网络上可以恢复精力。他在网络的树荫下，身心得到休憩：“有时候我进入网络的原因只是为了主动地迷失自己，温柔地向网络的未知世界投降，暂时忘却自己确信的周遭生活。尽管人们设计互联网有着明确的目的性，网络却依然是狂野的，它的边界是未知的，它的神秘数不胜数。荆棘缠绕般的各种想法、链接、图片创造了一片茂密的丛林。网络好像是有生命的。</p>
</blockquote>
<blockquote>
<p>撰写自己在社交网站上的自我简介、用即时聊天工具聊天，没有比这种“艰苦”的劳动更为“深刻”的了。人们在线的大多数时间都是在潜水漫游、跟随链接、伸出随机的“触须”。一个人在朋友的网络相册里晃来晃去，然后又到其他朋友的相册里面，在一个几乎不认识的人发布的信息下面留下评论。梭罗抱怨人们总是太过于急着和别人分享观点。而在虚拟世界中，Facebook总是鼓励我们随时分享“我们大脑里面存在的东西”，无论这些思想是多么的无知，或者多么浅薄，然后它会帮助我们传播给最广的听众。每天，我们被其他人“随机”的想法所轰炸。我们已经对这种“宣泻”司空见惯。所以尽管网络身份以及个人简介都是经过了深思熟虑的设计，但是人们最终感觉唯一深思熟虑的东西只是自己投身网络的决定。做完这个决定之后，人们开始在网络的洪流中随波逐流了</p>
</blockquote>
<blockquote>
<p>对于那些一直保持在线的人来说，尽管有很多问题（比如像表演一样的生活，比如失去了面对面察言观色的能力），但随时有人陪伴也带来了许多欢乐。而对于那些没有连网的人来说，即使是在自己家乡的大街上，他们也会有一种怪异的孤独感。</p>
</blockquote>
<blockquote>
<p>神圣空间”这个词语成为了我关注的重要概念。他们中的每一个人都保持着自己的专业生活，纯洁而不受污染。他们之所以这样做，是因为他们想要和虚拟保持距离。在那个空间里，他们能最大化地感觉到他们最完整的自己。</p>
</blockquote>
<blockquote>
<p>一个神圣的空间不是为了躲藏自己，而是一个我们认识自己和责任的地方</p>
</blockquote>
<blockquote>
<p>我们对科技的期待越来越多，对彼此的期待却越来越少。我们正处于一个完美风暴的静止中心，浑然不觉已成了科技的奴仆。我们不会放弃互联网，也不可能一下子 “戒掉”手机。我们自己才是决定怎样利用科技的那个人，记住这一点，我们就一定能够拥有美好的未来。</p>
</blockquote>
<blockquote>
<p>我们已经变成了电脑的“杀手级”应用程序</p>
</blockquote>
<blockquote>
<p>我们在网络上很容易找“同伴”，但是我们却被“自我表演”的压力搞得疲惫不堪。我们虽然享受着不间断的联系，却极少给予彼此全部的注意力。我们可以随时获得关注，却为不断出现的新缩略语所累。我们很喜欢网络“懂”我们，但是这只有在个人隐私问题上做了妥协才会有可能</p>
</blockquote>
<blockquote>
<p>网络生活留下了大量的“电子面包屑”，一些公司可以为了商业或政治目的而进行开发。我们在网络上会有很多新的邂逅，但是这种关系都是短暂的，如果有新的或者更好的邂逅出现，那些以前的都将被尘封。事实上，新的邂逅并不一定是更好的，因为我们仅仅是喜新厌旧。我们随时连线，对新鲜事保持积极地回应。我们可以在家里办公，但是工作也同时渗入到私人生活中，直到我们几乎不能分辨出它们之间的界限。我们能够瞬间连接彼此，但是我们有时却不得不藏起我们的电话，强迫自己去享受片刻的安宁</p>
</blockquote>
<blockquote>
<p>科技带来的高生活节奏让我们疲惫不堪，我们考虑通过更新、更高效的技术把我们从中解救出来。但是新的技术设备却带来更大的信息量和传播速率。在这种速率递增的需求的背景下，其中一件让我们感到满意的事情就是用技术来连接远方的人们，或者更为精确地说，是连接很多来自远方的人</p>
</blockquote>
<blockquote>
<p>通过互联网所形成的连接并没有把我们联系得更紧密，这些连接却让我们沉迷其中无法自拔。我们会在晚餐的时候忙于发短信。当我们慢跑散步的时候，当我们开车的时候，当我们在公园陪孩子荡秋千的时候，我们都在发信息。我们不想打扰别人，因此我们不停地打扰别人，只是非“实时”罢了</p>
</blockquote>
<blockquote>
<p>当这些情感聚集在一起时，可能就形成了“后家庭主义时代的家庭”。家庭成员很孤独地待在一起，每个人都在自己的房间里，每个人都在用电脑或者手机等移动设备上网。我们因为忙碌而使用网络，但是却和技术一起花费了更多的时间，而与现实生活中的人们之间花费的时间越来越少。我们坚信网络连接是接近彼此的方法，即使它也是同样有效地躲避和隐藏彼此的方法。在这个限度内，如果必须要减少与现实中人们相处的时间，我们会满足于这种无生命的东西</p>
</blockquote>
<blockquote>
<p>我们，创造和赋予了机器人生命，并且开始谈论机器人的情感，甚至它们的“真实性”。如果我们关注的是机器人能够唤起我们自己内心的情感，那么这么做是可以的。但是我们常常忽略的问题是：“机器人的感受是什么？”我们知道机器人不能感受：他们不能感知到人的感情变化，或者人类关系的流动性。事实上，机器人什么也感受不到。而我们关心这个吗？或者它们表现出有感觉的样子，对于我们来说足够了吗？为什么我们情愿和那些既不能理解、又不能关心我们的机器人交谈？</p>
</blockquote>
<blockquote>
<p>理解ELIZA受欢迎不仅是因为人们愿意和机器交谈，它也说明人们变得不愿意和彼此交流。机器人保姆提供了一种新的可能，那就是我们可以逃离彼此，也可以很好地生活下去。当我们期待着电脑法官、电脑顾问、电脑老师或者电脑牧师时，我们事实上是对那些根本不关心我们、带着偏见对待、甚至虐待我们的人表达了失望。正是对于这些人的失望让机器人的“关心”看上去足够真实。我们心甘情愿地忽略机器人缺乏理解力的弱点，对这一点置若罔闻，转而去努力地让它看上去似乎更加善解人意。所有的这一切是为了创造一个假象—— 一个可以替代人类存在的东西。这就是更深层次的ELIZA效应。对于ELIZA的信任不仅说明了我们认为ELIZA程序可以理解我们，更说明了我们对彼此缺乏信任。</p>
</blockquote>
<blockquote>
<p>我们生活在繁荣的社交媒介文化里，我们梦想着社交机器人。尽管彼此连接，我们却依旧孤独，只能送给自己科技情人。如果网络生活太过严苛，那么机器人则总和我们在一起。想拥有机器人伴侣既是病症，也是梦想</p>
</blockquote>
<blockquote>
<p>就像其他心理学病症一样，它 “解决”问题但却未阐明问题。我们将会获得机器人的陪伴，却不必承担类似于人与人之间亲密关系所带来的风险。机器人暴露了我们希望能够控制社交关系的愿望，这正是我们的梦想</p>
</blockquote>
<blockquote>
<p>这种病症常常携带着大量的信息，以至于让人难以承受。为了承受这种恐惧，病症会把这些信息伪装起来，人们就不必每天都面对这些恐惧。所以，感觉持续的饥饿要比明白你的妈妈没有养育你更加“简单”。被超市排的长队弄得满心怒火，比处理你的配偶没有给予你所需要的关注更“容易”。当科技变成了一种病症，它就切断了表面现象和挣扎背后的真正原因之间的关联</p>
</blockquote>
<blockquote>
<p>俄狄浦斯（Oedipus）的神话故事。作为一个传统的、广为人知的故事，人们通常会认为俄狄浦斯因为追求知识而被惩罚——尤其是关于他出身的知识。卡珀说俄狄浦斯被惩罚另有原因——他拒绝承认知识的局限性。类似的问题也出现在我们对科技的态度上。我们失职并非因为我们试图建设一个新的东西，而是因为我们不允许自己去考虑新科技瓦解了什么。我们并不是因为发明和创造而陷入麻烦，而是因为我们认为它可以解决一切问题</p>
</blockquote>
<blockquote>
<p>我发现自己对网络充满了感激。它是一位坚定的施恩者，永远都在那里。我用不安分的手指爱抚它，它挑起了我的欲望，就像一个爱人一样……我想一直沉浸在它深不可测的广度之中。停留在那里，醉心于它梦幻般的怀抱里。向网络投降就像去土著丛林徒步旅行。不合逻辑的梦慰藉着你。在这个梦里，你在不同的页面和想法中穿梭跳跃。网络的白日梦已经深深地触动了我，让我感动并且搅动着我的心。</p>
</blockquote>
<blockquote>
<p>网络的连接性可以平复我们心灵最深处对孤独、失去和死亡的恐惧。这是一种令人欣喜的东西。但是连接也破坏了与原本维系我们的东西之间的联系，比如面对面的人际交流的价值</p>
</blockquote>
<blockquote>
<p>科技给了越来越多我们认为自己想要的东西。如今我们可以很容易地找到社交机器人和数字化的朋友。有人或许认为我们需要什么，它总在我们的所及范围内，我们永远也不会感到孤独。还有人假定我们想要的是大量的弱联系，支撑在线熟人关系的、非正式的网络关系。但是倘若我们真正思考我们认为自己想要东西的后果，我们才会了解我们真正想要的是什么。我们也许想要一些安静和独处的时光</p>
</blockquote>
<blockquote>
<p>正如梭罗提出的那样，我们也许想要生活少一些“拥挤”，等待更多不常发生的、但是很有意义的面对面邂逅。因为我们把很多时间花费在打字上面——用所有的手指或者只用拇指，我们会怀念人的声音。我们也许觉得和一个机器人下象棋也不算太坏，但是机器人却无法代替任何关于家庭或者朋友之间的谈话。一个机器人或许有需求，但是倘若要理解人的欲望，则需要语言和有血有肉的身体。因此，要进行这样的谈话，我们必须有一个真正的朋友，首先重要的是，他可以明白生命的真正含义，理解父母和家庭的含义，理解成年人之间爱的含义，理解对于子女的渴望，并且可以理解生老病死是不可避免的事情</p>
</blockquote>
<blockquote>
<p>现实生活中的人做事遵循一致性原则，所以当我们的关系进展顺利时，改变是逐步的，作用是缓慢的。但是在虚拟的网络生活里，所有关系的节奏加快了很多。一个人会很快从迷恋到幻灭，然后又回来，并在这个过程中来回穿梭。一个人如果在现实生活中感到有些无聊，很容易就能和一些新朋友联系上。一个人匆忙地阅读一长串邮件，并学会如何抓住“亮点”。夸张的标题往往能吸引注意力。在网络游戏里面，人物的动作总是被精简到一个从惊恐到安全、然后如此反复的模式。一个令人恐惧的邂逅自动完成，处理完了一个之后你可以重新组队，然后又用一个新的人物。我们的肾上腺素不停地向上冲，在这里没有所谓的“空闲时间”</p>
</blockquote>
<blockquote>
<p>通过对网络生活的研究，我认为，亲密行为是人和人之间的行为，听到他们的声音，看到他们的脸和试着读懂他们的内心。这些研究也让我想到，从某种角度来说，独处是刷新自己的状态，恢复精力。而孤独是失败的独处。去体验独处，你必须有自我振作、自我鼓励的能力，要不然你只能明白如何变得孤独。</p>
</blockquote>
<blockquote>
<p>今天的“回归”首要表现在进行无网络生活的实验。但是网络已经成为我们获得教育、获取新闻、找工作等不可或缺的必然途径。它已经成为我们生活的一部分。因此，我们只能退而求其次，要求自己重塑在屏幕上的生活。寻找新的平衡不仅仅是“放慢节奏”，而是“我们该如何为自我反思腾出空间？”</p>
</blockquote>
<blockquote>
<p>为了和这种上瘾作斗争，你必须抛弃这些令人上瘾的物质。但是，我们是不会放弃使用互联网的。我们也不会“突然完全戒掉”手机，或者禁止孩子们使用手机。我们不会停止听音乐或是回到以电视为中心的家庭生活方式</p>
</blockquote>
<blockquote>
<p>我相信，我们会找到一种全新的方式来沟通和连接彼此。但是，如果只考虑我们是有害物质（比如互联网技术）的受害者，并不是一个解决问题的好的开始。这种上瘾，是因为我们知道，我们不会让自己感到绝望。我们不得不找到一种方法使自己与这种让人上瘾的科技和平相处，并且让它按照我们的意愿来发挥作用。这确实是非常困难的，但却很有效果。出于对技术的简单热爱，或是出于反对技术进步的冲动，都是无济于事的</p>
</blockquote>
<blockquote>
<p>如今，我们和网络之间存在的问题让人困惑，无法忽略。最极端的情况是，我们有可能深陷网络连接不能自拔而忽略了彼此的存在。我们没有必要抛弃科技，或是贬低它的价值。我们需要的是把科技放回到它应处的位置。</p>
</blockquote>
<blockquote>
<p>群体性孤独》这本书描述了一对矛盾：我们对科技的期盼越来越多，却对彼此的期盼越来越少。我们处于一个完美风暴的静止中心。我们被科技打败了，被吸引到一个低风险并且唾手可得的联系上：Facebook上的朋友，虚拟化身，在线聊天等。如果“方便”和“可控”仍然是我们生活的首选，那么我们可能还被社交机器人诱惑而沉迷其中。就像是一个赌徒在老虎机的卡槽边上，那些令人兴奋的程序向我们许诺，让我们沉迷于游戏里而不能自拔。在机器人时代，我们必须注意到这一点，我们不再抱怨，而是期望甚至渴望简化和减少联系</p>
</blockquote>
<blockquote>
<p>一个耸肩是有助于缓和僵局的。但这还不是我们所处的阶段，我们距离山穷水尽的僵局还为时尚早。然而，我相信我们已经到达了一个反思的转折点，我们可以看到我们为科技进步付出的代价，并开始采取一些行动</p>
</blockquote>
]]></content>
  </entry>
  <entry>
    <title>使用Keras训练神经网络备忘录</title>
    <url>/2018/06/04/%E4%BD%BF%E7%94%A8Keras%E8%AE%AD%E7%BB%83%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%A4%87%E5%BF%98%E5%BD%95/</url>
    <content><![CDATA[<p>本文总结了keras使用过程中常见的操作进行汇总</p>
<a id="more"></a>
<h1 id="1优化函数的选择"><a class="markdownIt-Anchor" href="#1优化函数的选择"></a> 1.优化函数的选择</h1>
<p>先写结论,后面再补上每个优化函数的详细解释:</p>
<blockquote>
<p>如果你的数据很稀疏，那应该选择有自适应性的优化函数。并且你还可以减少调参的时间，用默认参数取得好的结果。<br />
RMSprop是adagrad的一个拓展，旨在解决它提前结束的问题。<br />
而RMSprop和Adadelta类似，只是adadelta采用了RMS的方法更新参数。<br />
在RMSprop基础上增加了偏差校正和momentum，形成了Adam。<br />
综上，RMSprop、Adadelta、Adam都是类似的。<br />
Kingma【Kingma, D. P., &amp; Ba, J. L. (2015). Adam: a Method for Stochastic Optimization. International Conference on Learning Representations, 1–13.】的实验表示，偏差校正使得Adam在优化到后面梯度变的稀疏的时候使得其优化性能最好。<br />
所以，可能Adam是最好的优化函数。<br />
所以，如果你希望你的训练能变的更快，或者你要训练的是一个复杂的深度的网络，尽量选择自适应的优化函数。</p>
</blockquote>
<p>摘自:<a href="https://blog.csdn.net/qq_21460525/article/details/70146665">深度学习各种优化函数详解</a></p>
<h1 id="2损失函数的选择"><a class="markdownIt-Anchor" href="#2损失函数的选择"></a> 2.损失函数的选择</h1>
<p>编译模型必须的两个参数之一:</p>
<blockquote>
<p>model.compile(loss=‘mean_squared_error’, optimizer=‘sgd’)</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> losses</span><br><span class="line">model.<span class="built_in">compile</span>(loss=losses.mean_squared_error, optimizer=<span class="string">&#x27;sgd&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="22常用的损失函数"><a class="markdownIt-Anchor" href="#22常用的损失函数"></a> 2.2常用的损失函数</h2>
<p><strong>mean_squared_error或mse</strong><br />
<strong>mean_absolute_error或mae</strong><br />
<strong>mean_absolute_percentage_error或mape</strong><br />
<strong>mean_squared_logarithmic_error或msle</strong><br />
<strong>squared_hinge</strong><br />
<strong>hinge</strong><br />
<strong>categorical_hinge</strong><br />
<strong>logcosh</strong><br />
<strong>categorical_crossentropy</strong>:亦称作多类的对数损失，注意使用该目标函数时，需要将标签转化为形如(nb_samples, nb_classes)的二值序列<br />
<strong>sparse_categorical_crossentropy</strong>:如上，但接受稀疏标签。注意，使用该函数时仍然需要你的标签与输出值的维度相同，你可能需要在标签数据上增加一个维度：np.expand_dims(y,-1)<br />
<strong>binary_crossentropy</strong>:（亦称作对数损失，logloss）<br />
<strong>kullback_leibler_divergence</strong>:从预测值概率分布Q到真值概率分布P的信息增益,用以度量两个分布的差异<br />
<strong>poisson</strong>:即(predictions - targets * log(predictions))的均值<br />
<strong>cosine_proximity</strong>:即预测值与真实标签的余弦距离平均值的相反数</p>
<p>注:当使用”categorical_crossentropy”作为目标函数时,标签应该为多类模式,即one-hot编码的向量,而不是单个数值. 可以使用工具中的to_categorical函数完成该转换.示例如下:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.utils.np_utils <span class="keyword">import</span> to_categorical</span><br><span class="line">categorical_labels = to_categorical(int_labels, num_classes=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>摘自:<a href="http://keras-cn.readthedocs.io/en/latest/other/objectives/">目标函数objectives</a></p>
</blockquote>
<h2 id="22自定义函数"><a class="markdownIt-Anchor" href="#22自定义函数"></a> 2.2自定义函数</h2>
<p>keras的Losses部分的源码是这样的:</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613533510116.png" alt="部分losses" /></p>
<p>可以看出,每次计算loss时,会传给损失函数两个值,一个是正确的标签(y_true),一是模型预测的标签(y_pred),这两个值是shape相同的Theano/TensorFlow张量,根据这一规则,可以设计自己的损失函数.</p>
<h3 id="21实践"><a class="markdownIt-Anchor" href="#21实践"></a> 2.1实践</h3>
<p>(1)基本用法<br />
自定义一个,对真实和预测的差距求4次方的损失函数:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#自定义损失函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">myloss</span>(<span class="params">pred,true</span>):</span></span><br><span class="line">    result = np.power(pred-true,<span class="number">4</span>)</span><br><span class="line">    <span class="keyword">return</span> result.mean()</span><br><span class="line"><span class="comment">#编译模型</span></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>,loss=myloss)</span><br></pre></td></tr></table></figure>
<p>(2)实际例子<br />
使用one hot分类时,拟合one hot分布的同时,还你拟合均匀分布<br />
自定义的函数是:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$$loss&#x3D;-(1-e)log&#123;e^&#123;Z_1&#125; \over Z&#125;-e\sum_&#123;i&#x3D;1&#125;^n&#123;&#123;1 \over 3&#125;log&#123;e^&#123;Z_1&#125; \over Z&#125;&#125;$$</span><br><span class="line">$$Z&#x3D;e^&#123;Z_1&#125;+e^&#123;Z_2&#125;+e^&#123;Z_3&#125;$$</span><br></pre></td></tr></table></figure>
<p>实际用keras是这样的:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#自定义损失函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mycrossentropy</span>(<span class="params">y_true, y_pred, e=<span class="number">0.1</span></span>):</span></span><br><span class="line">    <span class="keyword">return</span> (<span class="number">1</span>-e)*K.categorical_crossentropy(y_pred,y_true) + e*K.categorical_crossentropy(y_pred, K.ones_like(y_pred)/nb_classes)</span><br><span class="line"><span class="comment">#编译模型	</span></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>, loss=mycrossentropy)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>例子来源<a href="https://kexue.fm/archives/4493">Keras中自定义复杂的loss函数</a></p>
</blockquote>
<h3 id="22将损失函数自定义为网络层"><a class="markdownIt-Anchor" href="#22将损失函数自定义为网络层"></a> 2.2将损失函数自定义为网络层</h3>
<p>使用均方差和KL散度定义损失函数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CustomVariationalLayer</span>(<span class="params">Layer</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, **kwargs</span>):</span></span><br><span class="line">        self.is_placeholder = <span class="literal">True</span></span><br><span class="line">        <span class="built_in">super</span>(CustomVariationalLayer, self).__init__(**kwargs)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">vae_loss</span>(<span class="params">self, x, x_decoded_mean</span>):</span></span><br><span class="line">        xent_loss = original_dim * metrics.binary_crossentropy(x, x_decoded_mean)<span class="comment">#Square Loss</span></span><br><span class="line">        kl_loss = - <span class="number">0.5</span> * K.<span class="built_in">sum</span>(<span class="number">1</span> + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-<span class="number">1</span>)<span class="comment"># KL-Divergence Loss</span></span><br><span class="line">        <span class="keyword">return</span> K.mean(xent_loss + kl_loss)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, inputs</span>):</span></span><br><span class="line">        x = inputs[<span class="number">0</span>]</span><br><span class="line">        x_decoded_mean = inputs[<span class="number">1</span>]</span><br><span class="line">        loss = self.vae_loss(x, x_decoded_mean)</span><br><span class="line">        self.add_loss(loss, inputs=inputs)</span><br><span class="line">        <span class="comment"># We won&#x27;t actually use the output.</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">		</span><br><span class="line">y = CustomVariationalLayer()([x, x_decoded_mean])</span><br><span class="line">vae = Model(x, y)</span><br><span class="line">vae.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;rmsprop&#x27;</span>, loss=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>例子来源<a href="https://blog.csdn.net/A_a_ron/article/details/79050204">Keras自定义Loss函数</a></p>
</blockquote>
<h1 id="3模型的保存"><a class="markdownIt-Anchor" href="#3模型的保存"></a> 3.模型的保存</h1>
<h2 id="31同时保存结构和权重"><a class="markdownIt-Anchor" href="#31同时保存结构和权重"></a> 3.1同时保存结构和权重</h2>
<p>官方保持模型的API是这样的:</p>
<blockquote>
<p>def save_model(model, filepath, overwrite=True, include_optimizer=True)</p>
</blockquote>
<p>调用这个函数保持的内容包括:</p>
<ul>
<li>模型的结构</li>
<li>模型的权重</li>
<li>优化器的状态(即保存时优化器的状态,一遍后面从该状态出发继续训练)</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> load_model</span><br><span class="line"></span><br><span class="line"><span class="comment">#保持模型</span></span><br><span class="line">model.save(<span class="string">&#x27;my_model.h5&#x27;</span>) </span><br><span class="line"></span><br><span class="line"><span class="comment">#载入模型</span></span><br><span class="line">model = load_model(<span class="string">&#x27;my_model.h5&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="32模型结构的保存"><a class="markdownIt-Anchor" href="#32模型结构的保存"></a> 3.2模型结构的保存</h2>
<p>如果只希望保持模型结构,可以使用以下方法保存和重建.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># save as JSON</span></span><br><span class="line">json_string = model.to_json()</span><br><span class="line"></span><br><span class="line"><span class="comment"># save as YAML</span></span><br><span class="line">yaml_string = model.to_yaml()</span><br><span class="line"></span><br><span class="line"><span class="comment"># model reconstruction from JSON:</span></span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> model_from_json</span><br><span class="line">model = model_from_json(json_string)</span><br><span class="line"></span><br><span class="line"><span class="comment"># model reconstruction from YAML</span></span><br><span class="line">model = model_from_yaml(yaml_string)</span><br></pre></td></tr></table></figure>
<h2 id="33模型权重的保存"><a class="markdownIt-Anchor" href="#33模型权重的保存"></a> 3.3模型权重的保存</h2>
<p>如果只希望保持权重,可以使用以下方法保持和载入.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.save_weights(<span class="string">&#x27;my_model_weights.h5&#x27;</span>)</span><br><span class="line">model.load_weights(<span class="string">&#x27;my_model_weights.h5&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="35选择网络层载入"><a class="markdownIt-Anchor" href="#35选择网络层载入"></a> 3.5选择网络层载入</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">假如原模型为：</span></span><br><span class="line"><span class="string">    model = Sequential()</span></span><br><span class="line"><span class="string">    model.add(Dense(2, input_dim=3, name=&quot;dense_1&quot;))</span></span><br><span class="line"><span class="string">    model.add(Dense(3, name=&quot;dense_2&quot;))</span></span><br><span class="line"><span class="string">    ...</span></span><br><span class="line"><span class="string">    model.save_weights(fname)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># new model</span></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Dense(<span class="number">2</span>, input_dim=<span class="number">3</span>, name=<span class="string">&quot;dense_1&quot;</span>))  <span class="comment"># will be loaded</span></span><br><span class="line">model.add(Dense(<span class="number">10</span>, name=<span class="string">&quot;new_dense&quot;</span>))  <span class="comment"># will not be loaded</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># load weights from first model; will only affect the first layer, dense_1.</span></span><br><span class="line">model.load_weights(fname, by_name=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>摘自:<a href="https://blog.csdn.net/u010159842/article/details/54407745">如何保存Keras模型</a></p>
</blockquote>
<h1 id="4训练历史的保存"><a class="markdownIt-Anchor" href="#4训练历史的保存"></a> 4.训练历史的保存</h1>
<h2 id="41检测运行过程的参数"><a class="markdownIt-Anchor" href="#41检测运行过程的参数"></a> 4.1检测运行过程的参数</h2>
<p>深度学习像<code>炼丹</code>一样,有时候看见出现了<code>仙丹</code>(非常好的训练结果),但是忘记保持了,之后再怎么训练也找不回曾经的那个	<code>点</code>.有没有有一种机制,检测训练过程中的参数,如果结果比前一次好,我就保存模型权重下来呢?<br />
有的,官方提供<code>回调函数</code>检测训练参数.<br />
定义好检测的参数和保存的格式,就可以将回调函数写到训练函数的callbacks即可:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Checkpoint = keras.callbacks.ModelCheckpoint(</span><br><span class="line">    <span class="string">&#x27;Train_record/&#123;epoch:02d&#125;.&#123;val_acc:.2f&#125;.V0.hdf5&#x27;</span>,</span><br><span class="line">    monitor=<span class="string">&#x27;val_loss&#x27;</span>,</span><br><span class="line">    verbose=<span class="number">1</span>,</span><br><span class="line">    save_best_only=<span class="literal">True</span>,</span><br><span class="line">    save_weights_only=<span class="literal">False</span>,</span><br><span class="line">    mode=<span class="string">&#x27;auto&#x27;</span>,</span><br><span class="line">    period=<span class="number">1</span>)</span><br><span class="line">	</span><br><span class="line">history = model.fit([train_X_lstm,train_X_resnet],train_y,verbose=<span class="number">1</span>,epochs=<span class="number">150</span>,batch_size=<span class="number">256</span>,validation_data=([vali_X_lstm,vali_X_resnet],vali_y),shuffle=<span class="literal">True</span>,callbacks=[Checkpoint])	</span><br></pre></td></tr></table></figure>
<p>回调函数<code>Checkpoint</code>设置:</p>
<blockquote>
<p>filepath:保存模型的路径,你可以按照上面的方式自定义你的文件名,很直观<br />
monitor: 被监测的数据,训练历史必须包含改值,比如:如果你的训练过程没有设置验证集,就无法检测val_acc<br />
save_best_only:每次是否保存当前的最佳模型<br />
mode:auto, min, max} 的其中之一。 如果 save_best_only=True，那么是否覆盖保存文件的决定就取决于被监测数据的最大或者最小值。 对于 val_acc，模式就会是 max，而对于 val_loss，模式就需要是 min.<br />
save_weights_only: 如果 True，那么只有模型的权重会被保存 (model.save_weights(filepath))， 否则的话，整个模型会被保存 (model.save(filepath))。<br />
period: 每个检查点之间的间隔（训练轮数</p>
</blockquote>
<h2 id="42保持训练过程得到的所有数据"><a class="markdownIt-Anchor" href="#42保持训练过程得到的所有数据"></a> 4.2保持训练过程得到的所有数据</h2>
<p>这里的所有数据是指<code>model.fit()</code>返回的所有数据,包括acc(训练准确度),loss(训练损失),如果指定了验证集,还会有val_acc(验证集准确度),val_loss(训练集损失).保持方法是在训练完成后写入到文件中:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">history=model.fit(train_set_x,train_set_y,batch_size=<span class="number">256</span>,shuffle=<span class="literal">True</span>,nb_epoch=nb_epoch,validation_split=<span class="number">0.1</span>)</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;train_history.txt&#x27;</span>,<span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(<span class="built_in">str</span>(history.history))</span><br></pre></td></tr></table></figure>
<h1 id="5陷阱validation_split与shuffle"><a class="markdownIt-Anchor" href="#5陷阱validation_split与shuffle"></a> 5.陷阱:validation_split与shuffle</h1>
<p>模型训练时,有一个参数可以从训练集抽取一定比例的数据做验证,这个参数是<code>validation_split</code>.</p>
<blockquote>
<p>训练过程抽取训练数据的10%作验证</p>
<blockquote>
<p>history = model.fit([train_X_lstm,train_X_resnet],train_y,verbose=1,epochs=150,batch_size=256,validation_split=0.1,shuffle=True,callbacks=[Checkpoint])</p>
</blockquote>
</blockquote>
<p>但是使用这个参数时,必须注意先对数据Shuffle,据说是因为validation_split只抽取训练集的后面10%数据作验证,如果你前面的数据没有打乱,这样抽取是可能只抽取到一个类别的样本,这样的验证集将没有意义.</p>
<p>所以,使用这个参数前,先将训练数据(标签同步)打乱.</p>
<p>例外需要关注的是:validation_split划分出来的验证集是固定的,不随每次epoch变化</p>
<p><a href="https://keras.io/zh/losses/">官方文档-Losses</a></p>
]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>Keras</tag>
      </tags>
  </entry>
  <entry>
    <title>书摘：《青春大丈夫（谁的青春不迷茫，一本从人生、职场、情感角度，深入浅出地解答了众多疑问的年轻人的书）》-吴主任</title>
    <url>/2019/04/11/%E4%B9%A6%E6%91%98_%E9%9D%92%E6%98%A5%E5%A4%A7%E4%B8%88%E5%A4%AB%EF%BC%88%E8%B0%81%E7%9A%84%E9%9D%92%E6%98%A5%E4%B8%8D%E8%BF%B7%E8%8C%AB%EF%BC%8C%E4%B8%80%E6%9C%AC%E4%BB%8E%E4%BA%BA%E7%94%9F%E3%80%81%E8%81%8C%E5%9C%BA%E3%80%81%E6%83%85%E6%84%9F%E8%A7%92%E5%BA%A6%EF%BC%8C%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E5%9C%B0%E8%A7%A3%E7%AD%94%E4%BA%86%E4%BC%97%E5%A4%9A%E7%96%91%E9%97%AE%E7%9A%84%E5%B9%B4%E8%BD%BB%E4%BA%BA%E7%9A%84%E4%B9%A6%EF%BC%89-%E5%90%B4%E4%B8%BB%E4%BB%BB.hexo/</url>
    <content><![CDATA[<div class="douban-card-block">
	<a class="douban-card" href="https://book.douban.com/subject/27196540">
		<div class="douban-card-bgimg" style="background-image: url('https://images.weserv.nl/?url=https://img2.doubanio.com/view/subject/s/public/s29606971.jpg');"></div>
		<div class="douban-card-left">
			<div class="douban-card-img" style="background-image: url('https://images.weserv.nl/?url=https://img2.doubanio.com/view/subject/s/public/s29606971.jpg');"></div>
		</div>
		<div class="douban-card-right" style="line-height: 1.7;">
			<div class="douban-card-item"><span>书名: </span><strong>青春大丈夫</strong></div>
			<div class="douban-card-item"><span>作者: </span><span>吴主任</span></div>
			<div class="douban-card-item"><span>出版年份: </span><span>2017-11</span></div>
			<div class="douban-card-item"><span>评分: </span><span>7.5</span></div>
		</div>
	</a>
</div>
<style>
	.douban-card-block {
		display: flex;
		justify-content: center;
		align-items: center;
		width: 100%;
		max-height: 400px;
	}
	.douban-card {
		display: flex;
		margin: 30px 10px;
		padding: 15px;
		border-radius: 10px;
		position: relative;
		justify-content: center;
		align-items: center;
		overflow: hidden;
		color: antiquewhite;
		text-decoration: none;
	}
	.douban-card:hover {
		text-decoration: none;
	}
	.douban-card-bgimg {
		position: absolute;
		width: 115%;
		height: 115%;
		filter: blur(15px) brightness(0.6);
		background-size: 100%;
		background-position: center;
		background-repeat: no-repeat;
	}
	.douban-card-img {
		position: relative;
		height: 130px;
		width: 80px;
		background-size: 100%;
		background-position: center;
		background-repeat: no-repeat;
	}
	.douban-card-img {
		position: relative;
		height: 130px;
		width: 80px;
	}
	.douban-card-left {
		position: relative;
		display: flex;
		flex-direction: column;
		align-items: center;
	}
	.douban-card-right {
		position: relative;
		display: flex;
		flex-direction: column;
		margin-left: 12px;
		font-size: 16px;
		font-family: 'Courier New', Courier, monospace;
		line-height: 1.3;
		color: antiquewhite;
	}
	.douban-card-item {
		margin-top: 4px;
	}
</style>
<a id="more"></a>
<h2 id="part1人生不容易愿你不虚此行"><a class="markdownIt-Anchor" href="#part1人生不容易愿你不虚此行"></a> PART1人生不容易，愿你不虚此行</h2>
<blockquote>
<p>最后想对那些犹犹豫豫的人说一句，不要去跟同龄人瞎比较，徒增焦虑，觉得一切都晚了。没有这种事，最重要的是你做出了选择，开启了新生活，起步再晚，也比就地腐烂好。</p>
</blockquote>
<blockquote>
<p>要我说，学什么学，这一代人，所有有野心的优秀年轻人都毁在了学习如何变强大的技巧上。由于这种轻松阅读即可掌握技能的感觉太过良好，人们纷纷上瘾，浪费了大量时间去学习如何学习，到头来什么也不会。你倒是干起来啊！</p>
</blockquote>
<blockquote>
<p>是的，人们并不怕辛苦，人们希望的是立刻见效的回报。</p>
</blockquote>
<blockquote>
<p>实际上坚持需要的并不是毅力，而依然是观念。你需要赋予自己重复的意义，寻找过程的乐趣，并强化坚持下去的美好动机，为了能力更强，为了生活更好，或别的随便什么吧。</p>
</blockquote>
<blockquote>
<p>每个行业里的从业者90%都很平庸，这其中还有至少50%都是在混日子。这听起来对新人来说是非常好的消息，但这些人也都是从新人过来的啊。想想真是伤感。</p>
</blockquote>
<blockquote>
<p>历经几个城市的工作生活，我可能比较有资格说，年轻人，可以大胆地去大城市尝试。大城市有更多的资源、更多的工作机会、更多有意思的人，相对自由和包容……或许一开始的日子不易，但能让一个人迅速成长，这里竞争激烈，同样也充满更多可能。</p>
</blockquote>
<blockquote>
<p>别傻了，那也得是你才华足够出众，才会有人不计较你的外貌。</p>
</blockquote>
<blockquote>
<p>满足要求不是一个下结论的过程，是一个论证的过程。任何投递简历过来的人都被默认为有热情并且向往这份工作，即使人们只是在广撒网，但这并不矛盾。这就意味着，所有有关热情的表态都显得无足轻重。换句话说，如果连工作激情都没有，那么，对即将毕业的年轻人而言，可能真的是一无是处了。</p>
</blockquote>
<blockquote>
<p>做一份自己热爱或至少是喜欢的工作，否则，要么整天闷闷不乐，要么自我催眠告诉自己这份工作意义深远，或者学会挖掘它的正面意义——这也是积极心理学家推荐过的一种方法。</p>
</blockquote>
<blockquote>
<p>多数人在学校里接受的教育，致使其毕业后对世界和未来的认知都是狭隘的，即使如今人人都在用手机阅读和社交，好像世界早就被微信打通了。天真如过去的我就是这么想的。</p>
</blockquote>
<blockquote>
<p>能做到立即行动就已经打败了90%的人。但人们不，人们需要一些更“科学”、更“有效率”的学习方法。花大量的时间沉迷于他人以更高级的包装输出的如何更容易成功的秘籍。</p>
</blockquote>
<blockquote>
<p>如何进步成长的方法早就了然于胸了，好像一个健身爱好者已经把装备都堆满房间了，剩下的就简单了，无非是动起来。故事的结局也很合理，后来这个胖子成了一个装备搜集爱好者。</p>
</blockquote>
<blockquote>
<p>听再多再好的建议都没用，而且如果万一人家的方法看起来特别科学有用，你看得如痴如醉，书一本没看，却修炼成了一个“如何阅读”爱好者，“学会学习”大师，也不是什么坏事，有点像深谙房中术的太监，也是可以去各种公司给人培训赚点钱的。市场前景不能说不广阔。</p>
</blockquote>
<blockquote>
<p>只需要回答自己，跟对方在一起开心吗，以及是否愿意长期跟对方这样开心地生活下去？能沟通交流，在一起有话说，共同成长一起进步，有较好的经济基础，不至于让日子过得狼狈，其他的都不重要，或者说都是可以克服的。</p>
</blockquote>
<h2 id="part2不想当个猪头总可以吧"><a class="markdownIt-Anchor" href="#part2不想当个猪头总可以吧"></a> PART2不想当个猪头总可以吧</h2>
<blockquote>
<p>1.找一份工作的前期功课准备。</p>
</blockquote>
]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>读书</tag>
      </tags>
  </entry>
  <entry>
    <title>使用oracle VM vitualbox安装windows10系统</title>
    <url>/2021/03/09/%E4%BD%BF%E7%94%A8oracle-VM-vitualbox%E5%AE%89%E8%A3%85windows10%E7%B3%BB%E7%BB%9F/</url>
    <content><![CDATA[<p>由于工作需要，在windows10工作机编译的代码需要在干净的windows中测试代码运行效果，所以本文介绍如何使用oracle VM vitualbox安装windows10系统，已经配置主机与虚拟机之间的文件传输过程</p>
<a id="more"></a>
<p>为避免大段文字及节省时间，以下简单描述安装步骤：</p>
<h2 id="前期准备"><a class="markdownIt-Anchor" href="#前期准备"></a> 前期准备</h2>
<ol>
<li>
<p><a href="https://msdn.itellyou.cn/">到此选择</a>合适的系统，获得下载连接<code>ed2k://|file|xxxxxxx</code>，然后使用迅雷下载该文件</p>
</li>
<li>
<p><a href="https://www.virtualbox.org/wiki/Downloads">到此下载</a>并安装oracle VM vitualbox</p>
</li>
</ol>
<h2 id="安装windows10"><a class="markdownIt-Anchor" href="#安装windows10"></a> 安装windows10</h2>
<ol>
<li>启动oracle VM vitualbox，并选择<code>新建</code>按钮</li>
<li>命名虚拟机，选择<code>类型</code>及<code>版本</code>，然后点击<code>下一步</code>，注意和第一步下载的系统对应</li>
<li>配置虚拟机使用内存，点击<code>下一步</code></li>
<li>点击<code>现在创建虚拟硬盘</code>虚拟硬盘，然后点击<code>下一步</code></li>
<li>选择虚拟硬盘类型为<code>VDI</code>，然后点击<code>下一步</code></li>
<li>选择虚拟硬盘大小为<code>动态分配</code>，然后点击<code>下一步</code></li>
<li>选择虚拟硬盘的<code>文件大小及大小</code>，然后点击<code>创建</code></li>
<li>至此完成虚拟机的创建，后面的将第一步下载的文件挂载至虚拟机硬盘上，才能启动虚拟机</li>
<li>右键点击新建的虚拟机，依次选择<code>设置-&gt;存储</code>，点击选择虚拟盘，选择第一步下载的系统，操作看下图</li>
<li>退出设置后，启动虚拟机，并安装windows10系统</li>
</ol>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/PicGo/image-20210309171724366.png" alt="image-20210309171724366" /></p>
<h2 id="配置虚拟机"><a class="markdownIt-Anchor" href="#配置虚拟机"></a> 配置虚拟机</h2>
<p>通过以下两种方式配置虚拟机与主机之间的文件传输</p>
<p><strong>双向拷贝及拖放</strong></p>
<ol>
<li>完成系统安装后，右键点击虚拟机，选择依次点击<code>设置-&gt;常规-&gt;高级</code>，将<code>共享粘贴板</code>及<code>拖放</code>都改为<mark>双向</mark></li>
<li>启动虚拟机，在新窗口的菜单中选择<code>设备-&gt;安装增强功能</code>，然后到系统中找到CD驱动器挂载的安装程序，双击该驱动安装程序，具体操作看下图</li>
</ol>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/PicGo/image-20210309172743941.png" alt="image-20210309172743941" /></p>
<p><strong>共享文件夹</strong></p>
<p>通过文件共享的方式，将主机的某个文件夹共享给虚拟机</p>
<ol>
<li>在虚拟机窗口中菜单，选择<code>设备-&gt;共享文件夹-&gt;共享文件夹</code></li>
<li>双击<code>固定分配</code>下的选项，选择主机的<code>共享文件夹路径</code>，设置共享文件夹名称，设置<code>只读</code>与<code>自动挂载</code>，最后点击OK</li>
<li>主机的共享文件夹被挂载到文件系统，打开我的电脑即可访问</li>
</ol>
]]></content>
      <categories>
        <category>软件工具</category>
      </categories>
      <tags>
        <tag>windows10</tag>
        <tag>虚拟机</tag>
      </tags>
  </entry>
  <entry>
    <title>使用LSTM预测航班人数</title>
    <url>/2018/05/17/%E4%BD%BF%E7%94%A8LSTM%E9%A2%84%E6%B5%8B%E8%88%AA%E7%8F%AD%E4%BA%BA%E6%95%B0/</url>
    <content><![CDATA[<p>郑重声明，文章大部分翻译自: <a href="https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/"><br />
Time Series Prediction with LSTM Recurrent Neural Networks in Python with Keras</a></p>
<p><strong>数据:</strong> 1949到1960共12年,每年12个月的数据,一共 144 个数据,单位是 1000, 原文数据下载在<a href="https://datamarket.com/data/set/22u3/international-airline-passengers-monthly-totals-in-thousands-jan-49-dec-60#!ds=22u3&amp;display=line">这里</a></p>
<p><strong>目标:</strong> 预测国际航班未来 1 个月的乘客数</p>
<a id="more"></a>
<h2 id="1导入相应库文件及数据情况"><a class="markdownIt-Anchor" href="#1导入相应库文件及数据情况"></a> 1.导入相应库文件及数据情况</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#导入相应的库</span></span><br><span class="line"><span class="keyword">import</span> numpy</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> read_csv</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> LSTM</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> plot_model</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> SVG</span><br><span class="line"><span class="keyword">from</span> keras.utils.vis_utils <span class="keyword">import</span> model_to_dot</span><br><span class="line"></span><br><span class="line"><span class="comment">#将数据存储为两个矩阵，一个矩阵的ind位置存储t时刻的值，另一个矩阵存储t+1时刻的值</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_dataset</span>(<span class="params">dataset, look_back=<span class="number">1</span></span>):</span></span><br><span class="line">    dataX, dataY = [], []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(dataset)-look_back-<span class="number">1</span>):</span><br><span class="line">        a = dataset[i:(i+look_back), <span class="number">0</span>]</span><br><span class="line">        dataX.append(a)</span><br><span class="line">        dataY.append(dataset[i + look_back, <span class="number">0</span>])</span><br><span class="line">    <span class="keyword">return</span> numpy.array(dataX), numpy.array(dataY)</span><br><span class="line"></span><br><span class="line"><span class="comment"># fix random seed for reproducibility</span></span><br><span class="line">numpy.random.seed(<span class="number">7</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#读取数据</span></span><br><span class="line">dataframe = read_csv(<span class="string">&#x27;international-airline-passengers.csv&#x27;</span>, usecols=[<span class="number">1</span>], engine=<span class="string">&#x27;python&#x27;</span>, skipfooter=<span class="number">3</span>)</span><br><span class="line">dataset = dataframe.values</span><br><span class="line">dataset = dataset.astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#查看数据集</span></span><br><span class="line">print(<span class="string">&#x27;样本中的前面两个数据: \n&#x27;</span>,dataset[<span class="number">0</span>:<span class="number">2</span>])</span><br><span class="line">print(<span class="string">&#x27;整个样本的规模: &#x27;</span>,<span class="built_in">len</span>(dataset))</span><br><span class="line"></span><br><span class="line">plt.plot(dataset)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><strong>输出:</strong></p>
<blockquote>
<p>样本中的前面两个数据:<br />
[[112.]  [118.]]<br />
整个样本的规模:  144</p>
</blockquote>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613528044762.jpg" alt="数据" title="真实数据在月份上的分布" /></p>
<hr />
<h2 id="2标准化数据划分数据"><a class="markdownIt-Anchor" href="#2标准化数据划分数据"></a> 2.标准化数据,划分数据</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#LSTM对输入数据的规模很敏感，特别是在使用sigmoid（默认）或tanh激活函数时。</span></span><br><span class="line"><span class="comment">#将数据重新调整到0到1的范围（也称为标准化）可能是一种很好的做法。</span></span><br><span class="line"></span><br><span class="line">scaler = MinMaxScaler(feature_range=(<span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line">dataset = scaler.fit_transform(dataset)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分训练集与测试集,这里使用67%的原始数据作为训练数据,剩下33%作为测试数据</span></span><br><span class="line">train_size = <span class="built_in">int</span>(<span class="built_in">len</span>(dataset) * <span class="number">0.67</span>)</span><br><span class="line">test_size = <span class="built_in">len</span>(dataset) - train_size</span><br><span class="line">train, test = dataset[<span class="number">0</span>:train_size,:], dataset[train_size:<span class="built_in">len</span>(dataset),:]</span><br><span class="line">print(<span class="string">&#x27;划分数据集后的得到的训练数据和测试数据(训练数据未有标签): &#x27;</span>,train.shape,test.shape)</span><br></pre></td></tr></table></figure>
<p><strong>输出</strong>:</p>
<blockquote>
<p>划分数据集后的得到的训练数据和测试数据(训练数据未有标签):  (96, 1) (48, 1)</p>
</blockquote>
<hr />
<h2 id="3生成样本"><a class="markdownIt-Anchor" href="#3生成样本"></a> 3.生成样本</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 生成[t,t+look_back]时间间隔和t+look_back时刻的两个矩阵</span></span><br><span class="line">look_back = <span class="number">1</span></span><br><span class="line">trainX, trainY = create_dataset(train, look_back)</span><br><span class="line">testX, testY = create_dataset(test, look_back)</span><br><span class="line"></span><br><span class="line">print(trainX[:<span class="number">2</span>], trainY[:<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据被Reshape成 [samples, time steps, features]，这是放入LSTM的shape</span></span><br><span class="line">trainX = numpy.reshape(trainX, (trainX.shape[<span class="number">0</span>], <span class="number">1</span>, trainX.shape[<span class="number">1</span>]))</span><br><span class="line">testX = numpy.reshape(testX, (testX.shape[<span class="number">0</span>], <span class="number">1</span>, testX.shape[<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;构造得到模型的输入数据(训练数据已有标签trainY): &#x27;</span>,trainX.shape,testX.shape)</span><br></pre></td></tr></table></figure>
<p><strong>输出:</strong></p>
<blockquote>
<p>[[0.01544401] #第一个月份数据<br />
[0.02702703]] #第二个月份数据<br />
[0.02702703 0.05405405]  #每个样本在模型上的应该得到的输出</p>
</blockquote>
<blockquote>
<p>构造得到模型的输入数据(训练数据已有标签trainY):  (95, 1, 1) (47, 1, 1)</p>
</blockquote>
<hr />
<p><strong>这里解释下数据为什么这样划分?</strong><br />
前面我们已经说明了,我们是基于历史数据预测下一时刻的数据,但是每次依赖多少历史数据,我们没有说.这个例子的参数<code>look_back=1</code>设置说明历史数据是1,也就是基于前一个月份数据预测下一个月份数据.下面我以第一年的数据说明数据划分情况.</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613528044763.png" alt="enter description here" title="第一年的数据情况" /></p>
<p>当我们基于1个历史数据预测下一个值时,样本划分就像图示的蓝,红框,蓝色框表示输入模型的数据,红色表示<code>希望</code>模型输出的数据(当然只是希望,会有偏差,后面我们用均方根误差来衡量模型真实输出和这个值的差距).蓝,红框在所有的数据上滑动,得到类似上面的数据划分情况.</p>
<p><mark>当然 #007480</mark>,你也可以改动这个<code>look_back</code>这个值,基于历史多少数据来预测下一个数据可以自己设定.</p>
<p><mark>注意:本来训练数据和测试数据分别有96,48个,但是经过这样划分后都减少1个,分别为95,47.这是因为最后一个数据没有标签.但是测试数据没有必要这样分,因为他不需要标签,这里分的意思是利用分到的标签用于计算模型在测试数据上的均方根误差. #800014</mark></p>
<hr />
<h2 id="4构建lstm网络"><a class="markdownIt-Anchor" href="#4构建lstm网络"></a> 4.构建LSTM网络</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#构建LSTM网络</span></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(LSTM(<span class="number">4</span>, input_shape=(<span class="number">1</span>, look_back)))</span><br><span class="line">model.add(Dense(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">#编译训练LSTM网络</span></span><br><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;mean_squared_error&#x27;</span>, optimizer=<span class="string">&#x27;adam&#x27;</span>)</span><br><span class="line">model.fit(trainX, trainY, epochs=<span class="number">50</span>, batch_size=<span class="number">1</span>, verbose=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#打印模型</span></span><br><span class="line">model.summary()</span><br><span class="line"></span><br><span class="line"><span class="comment">#保存模型</span></span><br><span class="line">SVG(model_to_dot(model,show_shapes=<span class="literal">True</span>).create(prog=<span class="string">&#x27;dot&#x27;</span>, <span class="built_in">format</span>=<span class="string">&#x27;svg&#x27;</span>))</span><br></pre></td></tr></table></figure>
<p><strong>输出:</strong></p>
 <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Epoch <span class="number">1</span>/<span class="number">50</span></span><br><span class="line"><span class="number">95</span>/<span class="number">95</span> [==============================] - 2s 18ms/step - loss: <span class="number">0.0406</span></span><br><span class="line">Epoch <span class="number">2</span>/<span class="number">50</span></span><br><span class="line"><span class="number">95</span>/<span class="number">95</span> [==============================] - 1s 6ms/step - loss: <span class="number">0.0199</span></span><br><span class="line">Epoch <span class="number">3</span>/<span class="number">50</span></span><br><span class="line"><span class="number">95</span>/<span class="number">95</span> [==============================] - 1s 6ms/step - loss: <span class="number">0.0147</span></span><br><span class="line">........后面直到<span class="number">50</span>次省略</span><br><span class="line"></span><br><span class="line"> ______________________________________________________________________________________</span><br><span class="line"> Layer (<span class="built_in">type</span>)                 Output Shape              Param <span class="comment">#   </span></span><br><span class="line"> ======================================================================================</span><br><span class="line"> lstm_7 (LSTM)                (<span class="literal">None</span>, <span class="number">4</span>)                 <span class="number">96</span>        </span><br><span class="line"> ______________________________________________________________________________________</span><br><span class="line"> dense_7 (Dense)              (<span class="literal">None</span>, <span class="number">1</span>)                 <span class="number">5</span>         </span><br><span class="line"> ======================================================================================</span><br><span class="line"> Total params: <span class="number">101</span></span><br><span class="line"> Trainable params: <span class="number">101</span></span><br><span class="line"> Non-trainable params: <span class="number">0</span></span><br><span class="line"> ______________________________________________________________________________________</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613528044764.png" alt="enter description here" title="模型图示" /></p>
<hr />
<h2 id="5查看模型效果"><a class="markdownIt-Anchor" href="#5查看模型效果"></a> 5.查看模型效果</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 使用已训练的模型进行预测</span></span><br><span class="line">trainPredict = model.predict(trainX)</span><br><span class="line">testPredict = model.predict(testX)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测的值是[0,1]这样的标准化数据，需要将该值转换回原始值</span></span><br><span class="line">trainPredict = scaler.inverse_transform(trainPredict)</span><br><span class="line">trainY = scaler.inverse_transform([trainY])</span><br><span class="line">testPredict = scaler.inverse_transform(testPredict)</span><br><span class="line">testY = scaler.inverse_transform([testY])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算预测的均方根误差</span></span><br><span class="line">trainScore = math.sqrt(mean_squared_error(trainY[<span class="number">0</span>], trainPredict[:,<span class="number">0</span>]))</span><br><span class="line">print(<span class="string">&#x27;Train Score: %.2f RMSE&#x27;</span> % (trainScore))</span><br><span class="line">testScore = math.sqrt(mean_squared_error(testY[<span class="number">0</span>], testPredict[:,<span class="number">0</span>]))</span><br><span class="line">print(<span class="string">&#x27;Test Score: %.2f RMSE&#x27;</span> % (testScore))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 画图：对训练数据的预测</span></span><br><span class="line">trainPredictPlot = numpy.empty_like(dataset)</span><br><span class="line">trainPredictPlot[:, :] = numpy.nan</span><br><span class="line">trainPredictPlot[look_back:<span class="built_in">len</span>(trainPredict)+look_back, :] = trainPredict</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 画图：对测试数据的预测</span></span><br><span class="line">testPredictPlot = numpy.empty_like(dataset)</span><br><span class="line">testPredictPlot[:, :] = numpy.nan</span><br><span class="line"><span class="comment">#testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict</span></span><br><span class="line">testPredictPlot[<span class="built_in">len</span>(trainPredict)+look_back:<span class="built_in">len</span>(dataset)-<span class="number">1</span>, :] = testPredict</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示图片</span></span><br><span class="line">plt.plot(scaler.inverse_transform(dataset),color=<span class="string">&#x27;blue&#x27;</span>,label=<span class="string">&#x27;Raw data&#x27;</span>)</span><br><span class="line">plt.plot(trainPredictPlot,color=<span class="string">&#x27;red&#x27;</span>,label=<span class="string">&#x27;Train process&#x27;</span>)</span><br><span class="line">plt.plot(testPredictPlot,color=<span class="string">&#x27;green&#x27;</span>,label=<span class="string">&#x27;Test process&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#在折线图上显示标签</span></span><br><span class="line">leg = plt.legend(loc=<span class="string">&#x27;best&#x27;</span>, ncol=<span class="number">1</span>, fancybox=<span class="literal">True</span>)</span><br><span class="line">leg.get_frame().set_alpha(<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><strong>输出:</strong></p>
<blockquote>
<p>Train Score: 23.39 RMSE   #训练数据的均方根误差<br />
Test Score: 46.92  RMSE  #测试数据的均方根误差</p>
</blockquote>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613528044767.png" alt="enter description here" title="模型效果图示" /></p>
<p><mark>蓝色 #0e0080</mark>线是<code>原始数据</code>,<mark>红色 #800028</mark>是<code>训练数据的预测情况</code>,<mark>绿色</mark>是<code>测试数据的预测情况</code>,红色和绿色线越靠近蓝色线,表示模型对数据拟合能力越好.</p>
<hr />
<h2 id="6预测未来的数据"><a class="markdownIt-Anchor" href="#6预测未来的数据"></a> 6.预测未来的数据</h2>
<p>最后一个数据集的下一个月情况没有被预测,现把它拿到后进行预测.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#测试数据的最后一个数据没有预测,这里补上</span></span><br><span class="line">finalX = numpy.reshape(test[-<span class="number">1</span>], (<span class="number">1</span>, <span class="number">1</span>, testX.shape[<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment">#预测得到标准化数据</span></span><br><span class="line">featruePredict = model.predict(finalX)</span><br><span class="line"></span><br><span class="line"><span class="comment">#将标准化数据转换为人数</span></span><br><span class="line">featruePredict = scaler.inverse_transform(featruePredict)</span><br><span class="line"></span><br><span class="line"><span class="comment">#原始数据是1949-1960年的数据,下一个月是1961年1月份</span></span><br><span class="line">print(<span class="string">&#x27;模型预测1961年1月份的国际航班人数是: &#x27;</span>,featruePredict)</span><br></pre></td></tr></table></figure>
<p><strong>输出</strong>:</p>
<blockquote>
<p>模型预测1961年1月份的国际航班人数是:  [[430.27188]]</p>
</blockquote>
<hr />
<h2 id="7扩展"><a class="markdownIt-Anchor" href="#7扩展"></a> 7.扩展</h2>
<p>模型有些参数可以自己手动调一下,看看模型在不同参数下的效果(虽然我估计数据量太少,可能调参带来的变化不是很大,但是可以体验调参的过程),下面我就可以调的参数说明:</p>
<blockquote>
<p>(1)损失函数现在使用的是<code>mean_squared_error</code>,可以调成别的<br />
(2)优化器是<code>adam</code>,也可以调,甚至对优化器内的参数进行调整(比如学习率)<br />
(3)训练次数是50,可以调低点(因为我看后面模型的损失不下降了)<br />
(4)基于历史多少数据的参数<code>look_back</code>可调,你可以设置为3,5…</p>
</blockquote>
<p>全部代码可以在<a href="https://files.cnblogs.com/files/wushaogui/%E5%9F%BA%E4%BA%8ELSTM%E7%9A%84%E8%88%AA%E7%8F%AD%E4%B9%98%E5%AE%A2%E9%A2%84%E6%B5%8B.zip">这里</a>找到.</p>
]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>LSTM</tag>
      </tags>
  </entry>
  <entry>
    <title>分析LSTM中的神经元个数</title>
    <url>/2017/09/22/%E5%88%86%E6%9E%90LSTM%E4%B8%AD%E7%9A%84%E7%A5%9E%E7%BB%8F%E5%85%83%E4%B8%AA%E6%95%B0/</url>
    <content><![CDATA[<p>本文通过拆解LSTM，并通过统计几个模块的参数量来分析各个模块的原理</p>
<a id="more"></a>
<h2 id="1lstm简单介绍"><a class="markdownIt-Anchor" href="#1lstm简单介绍"></a> 1.LSTM简单介绍</h2>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613540825355.png" alt="LSTM在时间上展开" /></p>
<p>红框从左到右,依次是:<br />
<strong>忘记门层:</strong> 决定从细胞状态中丢弃什么信息,通过当前时刻输入和前一个时刻输出决定<br />
<strong>细胞状态:</strong>  确定并更新<code>新信息</code>到当前时刻的细胞状态中<br />
<strong>输出门层:</strong> 基于目前的细胞状态决定该时刻的输出</p>
<h2 id="2简单假设样例"><a class="markdownIt-Anchor" href="#2简单假设样例"></a> 2.简单假设样例</h2>
<p>假设现有一个样本,Shape=(13,5),时间步是13,每个时间步的特征长度是5.形象点,我把一个样本画了出来:</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo fence="true">(</mo><mtable rowspacing="0.15999999999999992em" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>a</mi><mn>1</mn><mn>1</mn></msubsup></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>a</mi><mn>1</mn><mn>2</mn></msubsup></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mo>⋯</mo></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>a</mi><mn>1</mn><mn>5</mn></msubsup></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>a</mi><mn>2</mn><mn>1</mn></msubsup></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>a</mi><mn>2</mn><mn>2</mn></msubsup></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mo>⋯</mo></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>a</mi><mn>2</mn><mn>5</mn></msubsup></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mi mathvariant="normal">⋮</mi><mpadded height="+0em" voffset="0em"><mspace mathbackground="black" width="0em" height="1.5em"></mspace></mpadded></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mi mathvariant="normal">⋮</mi><mpadded height="+0em" voffset="0em"><mspace mathbackground="black" width="0em" height="1.5em"></mspace></mpadded></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mo>⋱</mo></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mi mathvariant="normal">⋮</mi><mpadded height="+0em" voffset="0em"><mspace mathbackground="black" width="0em" height="1.5em"></mspace></mpadded></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>a</mi><mn>13</mn><mn>1</mn></msubsup></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>a</mi><mn>13</mn><mn>2</mn></msubsup></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mo>⋯</mo></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>a</mi><mn>13</mn><mn>5</mn></msubsup></mstyle></mtd></mtr></mtable><mo fence="true">)</mo></mrow><annotation encoding="application/x-tex">\begin{pmatrix}
    a_1^1 &amp; a_1^2 &amp; \cdots &amp; a_1^{5} \\
    a_2^1 &amp; a_2^2 &amp; \cdots &amp; a_2^{5} \\
    \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
    a_{13}^1 &amp; a_{13}^2 &amp; \cdots &amp; a_{13}^{5} \\
\end{pmatrix}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:5.459999999999999em;vertical-align:-2.4799999999999995em;"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.9500349999999997em;"><span style="top:-1.3499850000000007em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎝</span></span></span><span style="top:-2.5049950000000005em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-3.1050050000000007em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-3.7050150000000004em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-4.950035em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎛</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.4500349999999997em;"><span></span></span></span></span></span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.9799999999999995em;"><span style="top:-5.8275em;"><span class="pstrut" style="height:3.6875em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.4518920000000004em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.24810799999999997em;"><span></span></span></span></span></span></span></span></span><span style="top:-4.6275em;"><span class="pstrut" style="height:3.6875em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.4518920000000004em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.24810799999999997em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.7674999999999996em;"><span class="pstrut" style="height:3.6875em;"></span><span class="mord"><span class="mord"><span class="mord">⋮</span><span class="mord rule" style="border-right-width:0em;border-top-width:1.5em;bottom:0em;"></span></span></span></span><span style="top:-1.5675000000000006em;"><span class="pstrut" style="height:3.6875em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.4518920000000004em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">3</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.24810799999999997em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.4799999999999995em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.9799999999999995em;"><span style="top:-5.8275em;"><span class="pstrut" style="height:3.6875em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.4518920000000004em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.24810799999999997em;"><span></span></span></span></span></span></span></span></span><span style="top:-4.6275em;"><span class="pstrut" style="height:3.6875em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.4518920000000004em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.24810799999999997em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.7674999999999996em;"><span class="pstrut" style="height:3.6875em;"></span><span class="mord"><span class="mord"><span class="mord">⋮</span><span class="mord rule" style="border-right-width:0em;border-top-width:1.5em;bottom:0em;"></span></span></span></span><span style="top:-1.5675000000000006em;"><span class="pstrut" style="height:3.6875em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.4518920000000004em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">3</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.24810799999999997em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.4799999999999995em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.9799999999999995em;"><span style="top:-5.64em;"><span class="pstrut" style="height:3.5em;"></span><span class="mord"><span class="minner">⋯</span></span></span><span style="top:-4.44em;"><span class="pstrut" style="height:3.5em;"></span><span class="mord"><span class="minner">⋯</span></span></span><span style="top:-2.5799999999999996em;"><span class="pstrut" style="height:3.5em;"></span><span class="mord"><span class="minner">⋱</span></span></span><span style="top:-1.3800000000000006em;"><span class="pstrut" style="height:3.5em;"></span><span class="mord"><span class="minner">⋯</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.4799999999999995em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.9799999999999995em;"><span style="top:-5.8275em;"><span class="pstrut" style="height:3.6875em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.4518920000000004em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">5</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.24810799999999997em;"><span></span></span></span></span></span></span></span></span><span style="top:-4.6275em;"><span class="pstrut" style="height:3.6875em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.4518920000000004em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">5</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.24810799999999997em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.7674999999999996em;"><span class="pstrut" style="height:3.6875em;"></span><span class="mord"><span class="mord"><span class="mord">⋮</span><span class="mord rule" style="border-right-width:0em;border-top-width:1.5em;bottom:0em;"></span></span></span></span><span style="top:-1.5675000000000006em;"><span class="pstrut" style="height:3.6875em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.4518920000000004em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">3</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">5</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.24810799999999997em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.4799999999999995em;"><span></span></span></span></span></span></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.9500349999999997em;"><span style="top:-1.3499850000000007em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎠</span></span></span><span style="top:-2.5049950000000005em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-3.1050050000000007em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-3.7050150000000004em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-4.950035em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎞</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.4500349999999997em;"><span></span></span></span></span></span></span></span></span></span></span></span></p>
<p>使用Keras框架添加LSTM层时,我的设置是这样的<code>keras.layers.LSTM(10)</code>,也就是我现在设定,<mark>每个时间</mark>步经过LSTM后,得到的中间隐向量是10维(意思是5-&gt;10维),13个时间步的数据进去得到的是(13*10)的数据.</p>
<p>每个时间步对应神经元个数(参数个数)一样.也就是算一个LSTM中神经元个数,算一个时间步中参与的神经元个数即可.下面将对LSTM每个计算部分进行神经元分析.</p>
<h2 id="3神经元分析"><a class="markdownIt-Anchor" href="#3神经元分析"></a> 3.神经元分析</h2>
<h3 id="31忘记门层"><a class="markdownIt-Anchor" href="#31忘记门层"></a> 3.1忘记门层</h3>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613540825356.png" alt="忘记门层" /></p>
<p>图中公式的<code>!$h_&#123;t-1&#125;$</code>是上一个状态的隐向量(已设定隐向量长度为10),<code>!$x_t$</code>为当前状态的输入(长度为5),那么<code>!$[h_&#123;t-1&#125;,x_t]$</code>的长度就是10+5=15了.<code>!$W_f$</code>和<code>!$b_f$</code>为该层的参数.</p>
<p>该层输出是中间隐向量的长度(10),经过<code>!$\sigma$</code>激活前后的长度不变.只需要考虑<code>!$\sigma$</code>里面的操作得到10维特征即可.</p>
<p><code>!$[h_&#123;t-1&#125;,x_t]$</code>是(1,15)的向量,与<code>!$W_f$</code>相乘得到(1,10)的向量,根据矩阵相乘规律,得到<code>!$W_f$</code>是(15,10)的矩阵,得到(1,10)矩阵后,与该门层偏置相加,偏置也应该有相同的形状,即<code>!$b_f$</code>是(1,10)的矩阵.</p>
<p>即:该层神经元为:</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><mi>N</mi><mi>e</mi><mi>u</mi><mi>r</mi><mi>o</mi><mi>n</mi><msub><mi>s</mi><mn>1</mn></msub><mo>=</mo><mn>15</mn><mo>×</mo><mn>10</mn><mo>+</mo><mn>10</mn><mo>=</mo><mn>160</mn></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(1)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">Neurons_{1} =15 \times 10 + 10 =160 \tag{1}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mord mathdefault">e</span><span class="mord mathdefault">u</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">o</span><span class="mord mathdefault">n</span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">1</span><span class="mord">5</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">1</span><span class="mord">0</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">0</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">6</span><span class="mord">0</span></span><span class="tag"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">1</span></span><span class="mord">)</span></span></span></span></span></span></p>
<h3 id="32细胞状态"><a class="markdownIt-Anchor" href="#32细胞状态"></a> 3.2细胞状态</h3>
<p>(1)确定更新信息过程</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613540825365.png" alt="确定该时刻细胞要更新的内容" /></p>
<p>可以看到,这里公式和前面的一样的,<code>!$\sigma$</code>和<code>!$\tanh$</code>都是激活函数,不影响参数个数.</p>
<p>同理这过程的神经元个数是:</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><mi>N</mi><mi>e</mi><mi>u</mi><mi>r</mi><mi>o</mi><mi>n</mi><msub><mi>s</mi><mn>2</mn></msub><mo>=</mo><mn>2</mn><mo>×</mo><mo stretchy="false">(</mo><mn>15</mn><mo>×</mo><mn>10</mn><mo>+</mo><mn>10</mn><mo stretchy="false">)</mo><mo>=</mo><mn>320</mn></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(2)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">Neurons_{2} =2 \times (15 \times 10 + 10) =320 \tag{2}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mord mathdefault">e</span><span class="mord mathdefault">u</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">o</span><span class="mord mathdefault">n</span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mord">5</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">1</span><span class="mord">0</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mord">0</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">3</span><span class="mord">2</span><span class="mord">0</span></span><span class="tag"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">2</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p>(2)更新过程</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613540825378.png" alt="细胞状态更新" /></p>
<p>公式中的四个值,均是前面计算得到的结果,因此该过程没有参数需要学习.</p>
<h3 id="33输出层"><a class="markdownIt-Anchor" href="#33输出层"></a> 3.3输出层</h3>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613540825379.png" alt="输出门层" /></p>
<p>一样的公式,神经元个数一样.即个数为:</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><mi>N</mi><mi>e</mi><mi>u</mi><mi>r</mi><mi>o</mi><mi>n</mi><msub><mi>s</mi><mn>3</mn></msub><mo>=</mo><mn>15</mn><mo>×</mo><mn>10</mn><mo>+</mo><mn>10</mn><mo>=</mo><mn>160</mn></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(3)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">Neurons_{3} =15 \times 10 + 10 =160 \tag{3}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mord mathdefault">e</span><span class="mord mathdefault">u</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">o</span><span class="mord mathdefault">n</span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">1</span><span class="mord">5</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">1</span><span class="mord">0</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">0</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">6</span><span class="mord">0</span></span><span class="tag"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">3</span></span><span class="mord">)</span></span></span></span></span></span></p>
<h3 id="34总结"><a class="markdownIt-Anchor" href="#34总结"></a> 3.4总结</h3>
<p>把公式(1),(2),(3)的神经元加起来,就是该LSTM的神经元个数了.</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>N</mi><mi>e</mi><mi>u</mi><mi>r</mi><mi>o</mi><mi>n</mi><msub><mi>s</mi><mrow><mi>a</mi><mi>l</mi><mi>l</mi></mrow></msub><mo>=</mo><mi>N</mi><mi>e</mi><mi>u</mi><mi>r</mi><mi>o</mi><mi>n</mi><msub><mi>s</mi><mn>1</mn></msub><mo>+</mo><mi>N</mi><mi>e</mi><mi>u</mi><mi>r</mi><mi>o</mi><mi>n</mi><msub><mi>s</mi><mn>2</mn></msub><mo>+</mo><mi>N</mi><mi>e</mi><mi>u</mi><mi>r</mi><mi>o</mi><mi>n</mi><msub><mi>s</mi><mn>3</mn></msub><mo>=</mo><mn>160</mn><mo>+</mo><mn>320</mn><mo>+</mo><mn>160</mn><mo>=</mo><mn>640</mn></mrow><annotation encoding="application/x-tex">Neurons_{all} =Neurons_{1}+Neurons_{2}+Neurons_{3}=160+320+160 =640 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mord mathdefault">e</span><span class="mord mathdefault">u</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">o</span><span class="mord mathdefault">n</span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mord mathdefault">e</span><span class="mord mathdefault">u</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">o</span><span class="mord mathdefault">n</span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mord mathdefault">e</span><span class="mord mathdefault">u</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">o</span><span class="mord mathdefault">n</span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mord mathdefault">e</span><span class="mord mathdefault">u</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">o</span><span class="mord mathdefault">n</span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">1</span><span class="mord">6</span><span class="mord">0</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">3</span><span class="mord">2</span><span class="mord">0</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">6</span><span class="mord">0</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">6</span><span class="mord">4</span><span class="mord">0</span></span></span></span></span></p>
<p>其实,我们可以把这个问题一般化,不看这个例子,<mark>假设你一个时间步的特征长度是n,经过该LSTM得到的长度是m #800028</mark>,这样就可以算出该LSTM层的神经元个数为:</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>N</mi><mi>e</mi><mi>u</mi><mi>r</mi><mi>o</mi><mi>n</mi><msub><mi>s</mi><mrow><mi>a</mi><mi>l</mi><mi>l</mi></mrow></msub><mo>=</mo><mn>4</mn><mo>×</mo><mrow><mo stretchy="false">(</mo><mo stretchy="false">(</mo><mi>n</mi><mo>+</mo><mi>m</mi><mo stretchy="false">)</mo><mo>×</mo><mi>m</mi><mo>+</mo><mi>m</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">Neurons_{all} =4 \times {((n+m)\times m + m )}  
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mord mathdefault">e</span><span class="mord mathdefault">u</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">o</span><span class="mord mathdefault">n</span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mopen">(</span><span class="mopen">(</span><span class="mord mathdefault">n</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault">m</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault">m</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault">m</span><span class="mclose">)</span></span></span></span></span></span></p>
<h2 id="4测试"><a class="markdownIt-Anchor" href="#4测试"></a> 4.测试</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> LSTM</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"></span><br><span class="line">time_step=<span class="number">13</span></span><br><span class="line">featrue=<span class="number">5</span></span><br><span class="line">hidenfeatrue=<span class="number">10</span></span><br><span class="line"></span><br><span class="line">model=Sequential()</span><br><span class="line">model.add( LSTM(hidenfeatrue,input_shape=(time_step,featrue)))</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>
<p>输出是:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">_________________________________________________________________________________</span><br><span class="line">Layer (<span class="built_in">type</span>)                 Output Shape              Param <span class="comment">#   </span></span><br><span class="line">=================================================================================</span><br><span class="line">lstm_8 (LSTM)                (<span class="literal">None</span>, <span class="number">10</span>)                <span class="number">640</span>       </span><br><span class="line">=================================================================================</span><br><span class="line">Total params: <span class="number">640</span></span><br><span class="line">Trainable params: <span class="number">640</span></span><br><span class="line">Non-trainable params: <span class="number">0</span></span><br><span class="line">_________________________________________________________________________________</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>参考:<br />
<a href="https://www.jianshu.com/p/9dc9f41f0b29">理解 LSTM 网络</a><br />
<a href="https://blog.csdn.net/roslei/article/details/61912618">推荐给初学LSTM或者懂个大概却不完全懂的人</a></p>
]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>LSTM</tag>
      </tags>
  </entry>
  <entry>
    <title>卷积核的理解-多通道的卷积过程</title>
    <url>/2017/03/15/%E5%8D%B7%E7%A7%AF%E6%A0%B8%E7%9A%84%E7%90%86%E8%A7%A3-%E5%A4%9A%E9%80%9A%E9%81%93%E7%9A%84%E5%8D%B7%E7%A7%AF%E8%BF%87%E7%A8%8B/</url>
    <content><![CDATA[<p><strong>问题</strong><br />
1.对一个通道进行卷积时，10个卷积核得到10个featrue map;那么10个卷积核对多个通道（比如RGB三个通道）进行卷积时，得到多少个featrue map?是10*3=30个吗？<br />
2.多个卷积核对一个通道进行卷积是，其参数计算方法为：<br />
（卷积核-宽×卷积核-高）×通道数+通道数（通道数即偏置）</p>
<a id="more"></a>
<p>例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Conv2D</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"></span><br><span class="line">model=Sequential()</span><br><span class="line">model.add(Conv2D(<span class="number">2</span>, (<span class="number">2</span>,<span class="number">3</span>),input_shape=(<span class="number">3</span>,<span class="number">3</span>,<span class="number">1</span>)))</span><br><span class="line"></span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Layer (<span class="built_in">type</span>)                 Output Shape              Param <span class="comment">#   </span></span><br><span class="line">=================================================================</span><br><span class="line">conv2d_3 (Conv2D)            (<span class="literal">None</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>)           <span class="number">14</span>        </span><br><span class="line">=================================================================</span><br><span class="line">Total params: <span class="number">14</span></span><br><span class="line">Trainable params: <span class="number">14</span></span><br><span class="line">Non-trainable params: <span class="number">0</span></span><br><span class="line">_________________________________________________________________</span><br></pre></td></tr></table></figure>
<p>那么多个卷积核对多个通道操作时，使用的参数个数为多少？？？</p>
<hr />
<p>下文思路来源于博客：</p>
<ul>
<li>[<a href="https://blog.csdn.net/u014114990/article/details/51125776">https://blog.csdn.net/u014114990/article/details/51125776</a>]</li>
<li>[<a href="https://blog.csdn.net/yudiemiaomiao/article/details/72466402">https://blog.csdn.net/yudiemiaomiao/article/details/72466402</a>]</li>
</ul>
<p>例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Conv2D</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"></span><br><span class="line">model=Sequential()</span><br><span class="line">model.add(Conv2D(<span class="number">2</span>, (<span class="number">2</span>,<span class="number">3</span>),input_shape=(<span class="number">3</span>,<span class="number">3</span>,<span class="number">2</span>)))</span><br><span class="line">p</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Layer (<span class="built_in">type</span>)                 Output Shape              Param <span class="comment">#   </span></span><br><span class="line">=================================================================</span><br><span class="line">conv2d_5 (Conv2D)            (<span class="literal">None</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>)           <span class="number">26</span>        </span><br><span class="line">=================================================================</span><br><span class="line">Total params: <span class="number">26</span></span><br><span class="line">Trainable params: <span class="number">26</span></span><br><span class="line">Non-trainable params: <span class="number">0</span></span><br><span class="line">_________________________________________________________________</span><br></pre></td></tr></table></figure>
<p>该例子卷积核的计算公式为：<code>!$输入通道数*输出通道数*卷积核宽*卷积核高$</code><br />
即2*2*2*3</p>
<p><mark>caffe实现卷积的过程</mark></p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613529748060.png" alt="enter description here" title="Caffe卷积过程" /></p>
<blockquote>
<p>Caffe中的卷积计算是将卷积核矩阵和输入图像矩阵变换为两个大的矩阵A与B，然后A与B进行矩阵相乘得到结果C（利用GPU进行矩阵相乘的高效性），三个矩阵的说明如下：<br />
（1）在矩阵A中<br />
M为卷积核个数，K=k*k，等于卷积核大小，即第一个矩阵每行为一个卷积核向量（是将二维的卷积核转化为一维），总共有M行，表示有M个卷积核。<br />
（2）在矩阵B中     		$$ N=（（image_h + 2<em>pad_h – kernel_h）/stride_h+<br />
1）</em>（（image_w +2<em>pad_w – kernel_w）/stride_w + 1）$$<br />
image_h：输入图像的高度<br />
image_w：输入图像的宽度<br />
pad_h：在输入图像的高度方向两边各增加pad_h个单位长度（因为有两边，所以乘以2）<br />
pad_w：在输入图像的宽度方向两边各增加pad_w个单位长度（因为有两边，所以乘以2）<br />
kernel_h：卷积核的高度<br />
kernel_w：卷积核的宽度<br />
stride_h：高度方向的滑动步长；<br />
stride_w：宽度方向的滑动步长。<br />
因此，N为输出图像大小的长宽乘积，也是卷积核在输入图像上滑动可截取的最大特征数。<br />
K=k</em>k，表示利用卷积核大小的框在输入图像上滑动所截取的数据大小，与卷积核大小一样大。 （3）在矩阵C中<br />
矩阵C为矩阵A和矩阵B相乘的结果，得到一个M*N的矩阵，其中每行表示一个输出图像即feature map，共有M个输出图像（输出图像数目等于卷积核数目）<br />
（在Caffe中是使用src/caffe/util/im2col.cu中的im2col和col2im来完成矩阵的变形和还原操作）</p>
</blockquote>
<hr />
<p>其实多个卷积核对多个通道进行卷积的过程是：<br />
1.每个输入通道对应一个卷积核（相互之间不同）<br />
2.某个输入通道与对应卷积核乘积，然后所有输出加起来，即代表一个输出通道；每个输出通道都这样计算而来。</p>
<p><strong>例子</strong></p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613529748240.gif" alt="enter description here" title="多通道卷积过程" /></p>
]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>卷积</tag>
      </tags>
  </entry>
  <entry>
    <title>图论---算法篇</title>
    <url>/2018/07/03/%E5%9B%BE%E8%AE%BA---%E7%AE%97%E6%B3%95%E7%AF%87/</url>
    <content><![CDATA[<p>图论中的算法基本都是提出后,经过检验的.我就不讨论算法很基础的原理,只是从看懂一个算法的角度去学习.本着不花时间去重复别人优秀工作的原则,本文中很多部分引用了别人的工作,甚至是照搬过来,因为我觉得算法这东西已经类似<code>真理</code>,证明不需要你,你可以看得懂,别人也可以,只是表达方式不同,别人有优秀的表达方式,我为什么不用呢!</p>
<a id="more"></a>
<h1 id="算法类"><a class="markdownIt-Anchor" href="#算法类"></a> 算法类</h1>
<h2 id="戴克斯特拉算法da"><a class="markdownIt-Anchor" href="#戴克斯特拉算法da"></a> 戴克斯特拉算法(D.A)</h2>
<p><strong>描述:</strong> 又译<strong>迪杰斯特拉算法</strong>,使用了<code>广度优先搜索</code>解决赋权有向图或者无向图的单源最短路径问题，算法最终得到一个最短路径树。</p>
<p><strong>原理:</strong> 迪杰斯特拉算法主要特点是以起始点为中心向外层层扩展，直到扩展到终点为止.</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613548263619.jpg" alt="迪杰斯特拉算法算法图示" /></p>
<p>结合上图,详细解释迪杰斯特拉算法:<br />
通过维护一个两个集合来实现:</p>
<blockquote>
<p>1.一个集合内存储已经找到的最短距离及其路径(假设为D)<br />
2.另一个是未找到的最短距离的点到起始顶点的路径(假设为U)<br />
下面更新U的过程也是如此</p>
</blockquote>
<p>图示目标:寻找顶点1到所有顶点的最短路径.</p>
<p><strong>第一步:初始化D,U</strong><br />
初始节点到自身距离为0,直接初初始化到D集合,U集合维护顶点到初始节点1的距离和长度,根据上图,可初始化为以下两个集合.</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613548263622.png" alt="enter description here" title="初始化" /></p>
<p>注:  图中表示节点名称,每个集合记录距离和路径,路径中的数字也表示节点名称,空间不够,不标单引号了.</p>
<p>以下步骤是不断更新两个集合的过程:</p>
<blockquote>
<p>1.D根据U更新当前最短路径到自己(扩张过程)<br />
2.U根据新加入的节点更新自己(松弛过程)<br />
3.迭代以上过程,直到所有路径遍历完</p>
</blockquote>
<p>下面是各个迭代过程图示:</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613548263625.png" alt="第二步" /><br />
由前面的初始情况可知,与节点1直接相连接一共3个点,最近的点是2.把1与2的当前最短距离和路径加到集合D中,然后根据新的集合D,更新集合U的信息,更新的过程是:</p>
<blockquote>
<p>1.首先看看2节点的出边有那些,图中可以看到是:3,4<br />
2.节点1经过2节点到达上面两个节点与直接到达上面两个节点的距离比较,那个距离小就把信息更新到U集合中</p>
</blockquote>
<hr />
<!-- ![Diagram](./attachments/1529908444491.drawio.html) --->
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613548263629.png" alt="第三步" /></p>
<p>上一次迭代完成后,集合D有1,2两个点,这两个点能到达的点是6,3,4;广度遍历路径得到1到3个节点的3最近,将节点3填到D中,然后更新U.<br />
此时的广度遍历就是从1开始,可以经过2,最终到达3,4,6其中一个节点的路径.具体包括:</p>
<blockquote>
<p>a. 1-&gt;3<br />
b. 1-&gt;6<br />
c. 1-&gt;2-&gt;4</p>
</blockquote>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613548263632.png" alt="第四步" /><br />
上一次迭代完成后,集合D有1,2,3三个点,这三个点能到达的点是6,4;广度遍历路径得到<code>1-&gt;3-&gt;6</code>这路径最短,将6更新到D后,更新U.</p>
<hr />
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613548263636.png" alt="第五步" /><br />
上一次迭代完成后,集合D有1,2,3,6四个点,这四个点能到达的点是5,4;广度遍历路径得到<code>1-&gt;3-&gt;4</code>这路径最短,将4更新到D后,更新U.</p>
<hr />
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613548263640.png" alt="第六步" /><br />
上一次迭代完成后,集合D有1,2,3,6,4五个点,这五个点能到达的点是5;广度遍历路径得到<code>1-&gt;3-&gt;6-&gt;5</code>这路径最短,将4更新到D后,更新U.</p>
<p>最终,节点1到各个节点的最短路径及其长度都保存在集合D中.</p>
<blockquote>
<p>注:迪杰斯特拉算法也可用于有向图最短路径查找,还有一个迪杰斯特拉的优化算法<code>双向的迪杰斯特拉</code>,改进的地方是从源点和终点同时广度优先搜索最短路径,总的来说双向的迪杰斯特拉比一般迪杰斯特拉更快.</p>
</blockquote>
<hr />
<h2 id="最短路径快速算法spfa"><a class="markdownIt-Anchor" href="#最短路径快速算法spfa"></a> 最短路径快速算法(SPFA)</h2>
<p><strong>描述:</strong><br />
SPFA算法是西南交通大学段凡丁于1994年发表的,是一个用于求解<mark>有向带权图单源最短路径</mark>的改良的贝尔曼-福特算法。这一算法被认为在随机的稀疏图上表现出色，并且<mark>极其适合带有负边权的图</mark>。 然而SPFA在最坏情况的时间复杂度与贝尔曼-福特算法相同，因此在非负边权的图中仍然最好使用戴克斯特拉算法。</p>
<p><strong>原理:</strong></p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613548263732.png" alt="" /></p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613548263846.png" alt="最短路径快速算法图示" /></p>
<p>声明:<br />
图片来源于:<a href="https://blog.csdn.net/xunalove/article/details/70045815">最快最好用的——spfa算法</a></p>
<hr />
<h2 id="弗洛伊德算法floyd-warshall"><a class="markdownIt-Anchor" href="#弗洛伊德算法floyd-warshall"></a> 弗洛伊德算法(Floyd-Warshall)</h2>
<p><strong>描述:</strong><br />
是解决任意两点间的最短路径的一种算法，可以正确处理有向图或负权（但不可存在负权回路）的最短路径问题，同时也被用于计算有向图的传递闭包.</p>
<p><strong>原理:</strong><br />
假设我有以下graph:</p>
<!-- ![Diagram](./attachments/1529980535179.drawio.html) -->
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613548263735.png" alt="演示graph" /></p>
<p>可以得到以下的邻接矩阵:</p>
<!--![Diagram](./attachments/1529981065032.drawio.html)-->
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613548263764.png" alt="graph的邻接矩阵" /></p>
<p>该邻接矩阵D记录了有向图中,直接可达节点之间的距离.<br />
下面就1-&gt;3的最短路径进行分析:</p>
<p>直接可达的路径权重为:9<br />
比这短的路径可能是1-&gt;X-&gt;3 (X是除1,3外的所有点中的一个或多个)</p>
<p><strong>假设X长度为1</strong>,X就是2,4,5其中一个值,1-&gt;X-&gt;3的路径长度小于9,在矩阵中就是D[1][x]+D[x][3]&lt;9(为了理解,假设矩阵从1开始编号).<br />
D[1][2]+D[2][3]=5+3=8&lt;9  更新最短路径长度<br />
D[1][4]+D[4][3]=∞+∞=∞<br />
D[1][5]+D[5][3]=∞+∞=∞</p>
<p><strong>假设X长度是2</strong>,X就是考虑顺序在2,4,5中任取两个.有以下情况<br />
D[1][2]+D[2][4]+D[4][3]=5+2+∞=∞<br />
D[1][4]+D[4][2]+D[2][3]=∞+∞+3=∞<br />
…剩下组合省略</p>
<p><strong>同理X长度为3时</strong>,有以下情况<br />
D[1][2]+D[2][4]+D[4][5]+D[5][3]=2+2+1+2=7&lt;8  更新<br />
…剩下组合省略</p>
<p>最后找到,1到3的最短路径是,1-&gt;2-&gt;4-&gt;5-&gt;3,最短距离为8,更新D矩阵得到:</p>
<!-- ![Diagram](./attachments/1530004137360.drawio.html) -->
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613548263765.png" alt="更新后D矩阵" /></p>
<p>在这个新的D上继续算其他节点之间的最短路径.当然,这在程序中就是简单遍历,其实这里X的长度就是1到3中间需要经过多少节点.所有节点遍历完成,得到graph内两两节点之间的最短距离.</p>
<hr />
<h2 id="克鲁斯卡尔算法ka"><a class="markdownIt-Anchor" href="#克鲁斯卡尔算法ka"></a> 克鲁斯卡尔算法(K.A)</h2>
<p><strong>描述:</strong><br />
一种用来查找最小生成树的算法，由Joseph Kruskal在1956年发表。用来解决同样问题的还有Prim算法和Boruvka算法等。三种算法都是贪心算法的应用。和Boruvka算法不同的地方是，Kruskal算法在图中存在相同权值的边时也有效。</p>
<p><strong>原理:</strong></p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613548263848.gif" alt="克鲁斯卡尔算法算法图示" /></p>
<p>把所有边选出来,并按照权重进行排序,从权重最小边开始选择,每次选择一条边,每次选择的边不能与原来的边构成环,知道选择的边包含所有的节点.</p>
<hr />
<h2 id="普里姆算法pa"><a class="markdownIt-Anchor" href="#普里姆算法pa"></a> 普里姆算法(P.A)</h2>
<p><strong>描述:</strong><br />
图论中的一种算法，可在加权连通图里搜索最小生成树。意即由此算法搜索到的边子集所构成的树中，不但包括了连通图里的所有顶点，且其所有边的权值之和亦为最小。</p>
<p><strong>原理:</strong><br />
从单一顶点开始，普里姆算法按照以下步骤逐步扩大树中所含顶点的数目，直到遍及连通图的所有顶点。</p>
<blockquote>
<pre><code>输入：一个加权连通图，其中顶点集合为V，边集合为E；
初始化：Vnew = &#123;x&#125;，其中x为集合V中的任一节点（起始点），Enew = &#123;&#125;；
重复下列操作，直到Vnew = V：
    在集合E中选取权值最小的边（u, v），其中u为集合Vnew中的元素，而v则是V中没有加入Vnew的顶点（如果存在有多条满足前述条件即具有相同权值的边，则可任意选取其中之一）；
    将v加入集合Vnew中，将（u, v）加入集合Enew中；
输出：使用集合Vnew和Enew来描述所得到的最小生成树。
</code></pre>
</blockquote>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1222446-20200514094835156-1076198969.png" alt="原图" /></p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1.png" alt="1" /><br />
(1)顶点D被任意选为起始点。顶点A、B、E和F通过单条边与D相连。A是距离D最近的顶点，因此将A及对应边AD以高亮表示。</p>
<hr />
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/2.png" alt="2" /><br />
(2)下一个顶点为距离D或A最近的顶点。B距D为9，距A为7，E为15，F为6。因此，F距D或A最近，因此将顶点F与相应边DF以高亮表示。</p>
<hr />
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/3.png" alt="3" /><br />
(3)算法继续重复上面的步骤。距离A为7的顶点B被高亮表示。</p>
<hr />
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/4.png" alt="4" /><br />
(4)在当前情况下，可以在C、E与G间进行选择。C距B为8，E距B为7，G距F为11。E最近，因此将顶点E与相应边BE高亮表示。</p>
<hr />
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/5.png" alt="5" /><br />
(5)这里，可供选择的顶点只有C和G。C距E为5，G距E为9，故选取C，并与边EC一同高亮表示。</p>
<hr />
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/6.png" alt="6" /><br />
(6)顶点G是唯一剩下的顶点，它距F为11，距E为9，E最近，故高亮表示G及相应边EG。</p>
<hr />
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/7.png" alt="7" /><br />
(7)现在，所有顶点均已被选取，图中绿色部分即为连通图的最小生成树。在此例中，最小生成树的权值之和为39。</p>
<hr />
<h2 id="拓扑排序算法tsa"><a class="markdownIt-Anchor" href="#拓扑排序算法tsa"></a> 拓扑排序算法(TSA)</h2>
<p><strong>描述:</strong><br />
对一个有向无环图(Directed Acyclic Graph简称DAG)G进行拓扑排序，是将G中所有顶点排成一个线性序列，使得图中任意一对顶点u和v，若边(u,v)∈E(G)，则u在线性序列中出现在v之前。</p>
<p>图形的顶点可以表示要执行的任务，并且边缘可以表示一个任务必须在另一个任务之前执行的约束; 在这个应用中，拓扑排序只是一个有效的任务顺序。通常，我们把这种顶点表示活动、边表示活动间先后关系的有向图称做顶点活动网(Activity On Vertex network)，简称<strong>AOV网</strong>。</p>
<p>一个AOV网应该是一个有向无环图，即不应该带有回路，因为若带有回路，则回路上的所有活动都无法进行.在AOV网中，若不存在回路，则所有活动可排列成一个线性序列，使得每个活动的所有前驱活动都排在该活动的前面，我们把此序列叫做拓扑序列(Topological order)，由AOV网构造拓扑序列的过程叫做拓扑排序(Topological sort)。AOV网的拓扑序列不是唯一的，满足上述定义的任一线性序列都称作它的拓扑序列。</p>
<p><strong>原理:</strong><br />
重复以下两个步骤,即可以得到拓扑序列.</p>
<blockquote>
<p>1.在有向图中任意选择一个无前驱的节点,并且作为当前的拓扑序列输出<br />
2.删除与 前面选择的无前驱节点 的所有关联的边</p>
</blockquote>
<p>例子:</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613548263766.png" alt="e拓扑排序算法例子" /></p>
<p>下面是得到其中一个拓扑序列的过程:</p>
<blockquote>
<p>第一步:a是无前驱的节点,选择<br />
第二步:a去掉后,b,c为无前驱节点,任选一个,假设选择c<br />
第三步:a,c去掉,只有b为无前驱节点,选择<br />
第四步:a,c,b去掉后,d,e为无前驱节点,任选一个,假设选择d<br />
第五步:a,c,b,d去掉后,e,f为无前驱节点,任选一个,假设选择f<br />
第六步:a,c,b,d,f去掉后,只有e为无前驱节点,选择<br />
第六步:a,c,b,d,f,e去掉后,只有g为无前驱节点,选择<br />
第七步:所有节点遍历完成,得到拓扑序列</p>
</blockquote>
<p>最终得到的拓扑序列为<code>a-&gt;c-&gt;b-&gt;d-&gt;f-&gt;e-&gt;g</code></p>
<hr />
<h2 id="关键路径算法cpa"><a class="markdownIt-Anchor" href="#关键路径算法cpa"></a> 关键路径算法(CPA)</h2>
<p><strong>描述:</strong><br />
关键路径：在AOE网中，从始点到终点具有最大路径长度（该路径上的各个活动所持续的时间之和）的路径称为关键路径,一个AOE网中不一定只有一条关键路径，可能会有多条。<br />
关键活动：关键路径上的活动（边）。<br />
由于AOE网中的某些活动能够同时进行，故完成整个工程所必须花费的时间应该为始点到终点的最大路径长度。关键路径长度是整个工程所需的最短工期。</p>
<p><strong>原理:</strong><br />
现有无向有权图</p>
<!--![Diagram](./attachments/1530005452480.drawio.html) -->
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613548263767.png" alt="无向有权图" /></p>
<p>根据这个graph定义四个值：前两个针对顶点，后两个针对边</p>
<p>(1)事件最早开始时间：顶点最早发生的时间。<br />
节点B只有A指向,所以其最早开始时间是1,对于节点E,需要等待B,C,D完成才能开始,缺一不可,所以其最早时间是A-&gt;D-&gt;E:8</p>
<p>(2)事件最晚开始时间：顶点最晚发生的时间，超出则会延误整个工期。<br />
从右往左推,假设求得关键路径是A-&gt;D-&gt;E-&gt;H-&gt;J:18,以H为例,J-&gt;H:18-7=11表示J最晚开始时间,超过这个时间J无法在18内完成.J-&gt;I-&gt;H为例,18-5-1=12,也是H的最迟开始时间,但是11比12靠前,所以11为H的最迟开始时间.</p>
<p>(3)活动的最早开始时间：边最早发生时间。<br />
求某一点的最早开始时间就是计算该节点前所有几点完成的时刻.比如E开始时,必须等待A-&gt;C-&gt;E(4);A-&gt;B-&gt;E(4);A-&gt;D-&gt;E(8)上的边必须先完成,取最长时间8为E的最早开始时间,比如上图各节点的最早开始时间如下:</p>
<!---  可编辑文件:   ![Diagram](./attachments/1530145603750.drawio.html) --->
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613548263768.png" alt="最早发生时间" /></p>
<p>图中所标数字是每个节点的最早开始时间,假设源点(A)从0开始算起,汇点不需要时间处理.那么整个网络,最长的路径就是18(A-&gt;D-&gt;E-&gt;H-&gt;J).各个点的最迟发生时间从后往前推,取较小的,比如H这个点J-&gt;H(18-7=11),J-&gt;I-&gt;H(18-5-1=12),就取11.</p>
<p>(4)活动的最晚开始时间：边最晚发生时间。不推迟工期的最晚开工时间。</p>
<p>以上数字均是时间点,从<code>源点</code>算起.<br />
假设起点是vo，则我们称从v0到vi的最长路径的长度为vi的最早发生时间，同时，vi的最早发生时间也是所有以vi为尾的弧所表示的活动的最早开始时间，使用e（i）表示活动ai最早发生时间，除此之外，我们还定义了一个活动最迟发生时间，使用l（i）表示，不推迟工期的最晚开工时间。我们把e（i）=l（i）的活动ai称为关键活动.</p>
<p>下面是算法的推理过程:<br />
1.构建graph网络<br />
2.从源点开始求graph的拓扑排序序列,如果序列个数小于graph节点个数,则graph存储环,程序退出,否则根据拓扑序列求各个节点的<code>最早开始时间ve(j)</code>,计算公式为:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$$</span><br><span class="line">ve(j)&#x3D;Max(ve(i)+Dur(i,j))</span><br><span class="line">$$</span><br></pre></td></tr></table></figure>
<p>3.从汇点求graph的逆拓扑序列,然后根据该序列求各个节点的<code>最晚开始时间vl(j)</code>,计算公式为:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$$</span><br><span class="line">vl(j)&#x3D;Min(vl(i)-Dur(i,j))</span><br><span class="line">$$</span><br></pre></td></tr></table></figure>
<p>4.如果ve(j)=vl(j),则i-.j是关键路径,否则不是.</p>
<hr />
<h2 id="广度优先搜索算法bfs"><a class="markdownIt-Anchor" href="#广度优先搜索算法bfs"></a> 广度优先搜索算法(BFS)</h2>
<p><strong>描述:</strong><br />
又译作宽度优先搜索，或横向优先搜索，是一种图形搜索算法。简单的说，BFS是从根节点开始，沿着树的宽度遍历树的节点。如果所有节点均被访问，则算法中止。广度优先搜索的实现一般采用open-closed表。</p>
<p><strong>原理:</strong><br />
优先搜索同以层次的节点,和优先往纵深搜索不同,过程如下图,代码过程不描述.</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613548263769.gif" alt="广度优先搜索算法" /></p>
<hr />
<h2 id="深度优先搜索算法dfs"><a class="markdownIt-Anchor" href="#深度优先搜索算法dfs"></a> 深度优先搜索算法(DFS)</h2>
<p><strong>描述:</strong><br />
是一种用于遍历或搜索树或图的算法。沿着树的深度遍历树的节点，尽可能深的搜索树的分支。当节点v的所在边都己被探寻过，搜索将回溯到发现节点v的那条边的起始节点。这一过程一直进行到已发现从源节点可达的所有节点为止。如果还存在未被发现的节点，则选择其中一个作为源节点并重复以上过程，整个进程反复进行直到所有节点都被访问为止。属于盲目搜索。</p>
<p><strong>原理:</strong><br />
过程如下图,代码过程不描述.</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613548263770.gif" alt="深度优先搜索算法" /></p>
<p>参考:<br />
<a href="https://zh.wikipedia.org/wiki/%E5%9B%BE%E8%AE%BA">维基百科-图论</a><br />
<a href="https://baike.baidu.com/item/%E8%BF%AA%E6%9D%B0%E6%96%AF%E7%89%B9%E6%8B%89%E7%AE%97%E6%B3%95/4049057?fr=aladdin">百度百科-迪杰斯特拉算法</a><br />
<a href="https://blog.csdn.net/qq_35644234/article/details/60870719">最短路径问题—Dijkstra算法详解</a><br />
<a href="https://blog.csdn.net/qq_35644234/article/details/60578189">数据结构—拓扑排序详解</a><br />
<a href="https://blog.csdn.net/qq_34374664/article/details/52261672">傻子也能看懂的弗洛伊德算法</a><br />
<a href="https://www.cnblogs.com/jsgnadsj/p/3432820.html">算法学习记录-图——应用之关键路径</a><br />
<a href="https://blog.csdn.net/qq_35644234/article/details/52664108">数据结构----关键路径详解</a></p>
]]></content>
      <categories>
        <category>图论</category>
      </categories>
      <tags>
        <tag>图论</tag>
      </tags>
  </entry>
  <entry>
    <title>图论---问题篇</title>
    <url>/2018/06/28/%E5%9B%BE%E8%AE%BA---%E9%97%AE%E9%A2%98%E7%AF%87/</url>
    <content><![CDATA[<p>图论中的算法基本都是提出后,经过检验的.我就不讨论算法很基础的原理,只是从看懂一个算法的角度去学习.本着不花时间去重复别人优秀工作的原则,本文中很多部分引用了别人的工作,甚至是照搬过来,因为我觉得算法这东西已经类似<code>真理</code>,证明不需要你,你可以看得懂,别人也可以,只是表达方式不同,别人有优秀的表达方式,我为什么不用呢!</p>
<a id="more"></a>
<h1 id="问题类"><a class="markdownIt-Anchor" href="#问题类"></a> 问题类</h1>
<h2 id="路径问题"><a class="markdownIt-Anchor" href="#路径问题"></a> 路径问题</h2>
<h3 id="柯尼斯堡七桥问题"><a class="markdownIt-Anchor" href="#柯尼斯堡七桥问题"></a> 柯尼斯堡七桥问题</h3>
<p>这个问题是基于一个现实生活中的事例：当时东普鲁士柯尼斯堡（今日俄罗斯加里宁格勒）市区跨普列戈利亚河两岸，河中心有两个小岛。小岛与河的两岸有七条桥连接。在所有桥都只能走一遍的前提下，如何才能把这个地方所有的桥都走遍？</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613547720478.png" alt="柯尼斯堡七桥问题" /></p>
<p>摘自:</p>
<blockquote>
<p><a href="https://zh.wikipedia.org/wiki/%E6%9F%AF%E5%B0%BC%E6%96%AF%E5%A0%A1%E4%B8%83%E6%A1%A5%E9%97%AE%E9%A2%98">维基百科-柯尼斯堡七桥问题</a></p>
</blockquote>
<hr />
<h3 id="哈密顿回路问题"><a class="markdownIt-Anchor" href="#哈密顿回路问题"></a> 哈密顿回路问题</h3>
<p>哈密顿图是一个无向图,由指定的起点前往指定的终点，途中经过所有其他节点且只经过一次</p>
<p><strong>哈密顿回路:</strong> 闭合的哈密顿路径称作哈密顿回路<br />
<strong>哈密顿路径:</strong> 含有图中所有顶点的路径称作哈密顿路径。</p>
<p>摘自:</p>
<blockquote>
<p><a href="https://baike.baidu.com/item/%E5%93%88%E5%AF%86%E9%A1%BF%E5%9B%9E%E8%B7%AF/5575399">百度百科-哈密顿回路</a></p>
</blockquote>
<hr />
<h3 id="最小生成树问题"><a class="markdownIt-Anchor" href="#最小生成树问题"></a> 最小生成树问题</h3>
<p><strong>最小生成树</strong>是一副连通加权无向图中一棵权值最小的生成树。具体定义为: 在一给定的无向图 G = (V, E) 中，(u, v) 代表连接顶点 u 与顶点 v 的边（即 ( u , v ) ∈ E ，而 w(u, v) 代表此边的权重，若存在 T 为 E 的子集（即 T ⊆ E 且 (V, T) 为树，使得下面的值最小.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$$</span><br><span class="line">w(T)&#x3D;\sum_&#123;(u,v)\subseteq E&#125;&#123;w(u,v)&#125;</span><br><span class="line">$$</span><br></pre></td></tr></table></figure>
<p>可以描述为以下问题,有一个有权无向图,找到路径把所有顶点连起来,并保证边上权重和最小. 所以最小生成树也称为:<strong>最小权重生成树</strong></p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613547720443.png" alt="enter description here" title="最小生成树" /></p>
<p>一个连通图可能有多个生成树。当图中的边具有权值时，总会有一个生成树的边的权值之和小于或者等于其它生成树的边的权值之和。广义上而言，对于非连通无向图来说，它的每一连通分量同样有最小生成树，它们的并被称为<strong>最小生成森林</strong>。</p>
<p>以有线电视电缆的架设为例，若只能沿着街道布线，则以街道为边，而路口为顶点，其中必然有一最小生成树能使布线成本最低。</p>
<p>摘自:</p>
<blockquote>
<p><a href="https://zh.wikipedia.org/wiki/%E6%9C%80%E5%B0%8F%E7%94%9F%E6%88%90%E6%A0%91">维基百科-最小生成树</a></p>
</blockquote>
<hr />
<h3 id="中国邮路问题"><a class="markdownIt-Anchor" href="#中国邮路问题"></a> 中国邮路问题</h3>
<p>也称<strong>中国邮递员问题</strong>,此问题为在一个连通的无向图中找到一最短的封闭路径，且此路径需通过所有<em>边</em>至少一次。</p>
<p>注意:下面有一个<code>旅行商问题</code>是经过所有<em>点</em>一次,和这个<em>边</em>不同.</p>
<p>简单来说，邮递员问题就是在一个已知的地区，邮差要设法找到一条最短路径，可以走过此地区所有的街道，且最后要回到出发点.</p>
<p>摘自:</p>
<blockquote>
<p><a href="https://zh.wikipedia.org/wiki/%E9%82%AE%E9%80%92%E5%91%98%E9%97%AE%E9%A2%98">维基百科-邮递员问题</a></p>
</blockquote>
<hr />
<h3 id="最短路问题"><a class="markdownIt-Anchor" href="#最短路问题"></a> 最短路问题</h3>
<p>最短路径问题是图论研究中的一个经典算法问题，旨在寻找图（由结点和路径组成的）中两结点之间的最短路径。算法具体的形式包括：</p>
<blockquote>
<p><strong>确定起点的最短路径问题</strong> - 即已知起始结点，求最短路径的问题。适合使用Dijkstra算法。<br />
<strong>确定终点的最短路径问题</strong> - 与确定起点的问题相反，该问题是已知终结结点，求最短路径的问题。在无向图中该问题与确定起点的问题完全等同，在有向图中该问题等同于把所有路径方向反转的确定起点的问题。<br />
<strong>确定起点终点的最短路径问题</strong> - 即已知起点和终点，求两结点之间的最短路径。<br />
<strong>全局最短路径问题</strong> - 求图中所有的最短路径。适合使用Floyd-Warshall算法。</p>
</blockquote>
<p>用于解决最短路径问题的算法被称做“最短路径算法”，有时被简称作“路径算法”。最常用的路径算法有：</p>
<blockquote>
<p>Dijkstra算法<br />
A*算法<br />
Bellman-Ford算法<br />
SPFA算法（Bellman-Ford算法的改进版本）<br />
Floyd-Warshall算法<br />
Johnson算法<br />
Bi-Direction BFS算法</p>
</blockquote>
<p>摘自:</p>
<blockquote>
<p><a href="https://zh.wikipedia.org/wiki/%E6%9C%80%E7%9F%AD%E8%B7%AF%E9%97%AE%E9%A2%98">维基百科-最短路问题</a></p>
</blockquote>
<hr />
<h3 id="斯坦纳树"><a class="markdownIt-Anchor" href="#斯坦纳树"></a> 斯坦纳树</h3>
<p>斯坦纳树问题是组合优化问题，与最小生成树相似，是最短网络的一种。最小生成树是在给定的点集和边中寻求最短网络使所有点连通。而最小斯坦纳树允许在给定点外增加额外的点，使生成的最短网络开销最小。</p>
<p><strong>展示问题,以供理解:</strong></p>
<blockquote>
<p>1.平原上的三个城镇间要兴建一个公用的煤气供应站，在选址问题上，要考虑的主要问题是使由供应站到三个城镇的输送管道的总长最短。如何去寻找合适地点？<br />
2.假若要建的是一个垃圾处理站，要修建三条公路将垃圾站与三个城镇连起来。这时，因为三个城镇的居民的数目或工业性质等的不同，每天运送垃圾使用的车辆数目各不相同，运输的费用也就各异。因此，选取地点时，如果仍考虑使三条公路的总长最小，就不合理了。这时应该考虑：先计算出三个城镇单位时间内生产的垃圾数量的百分比（或每日运输费用的百分比），如何选取地点，使得每个城镇垃圾运输数量与公路里程的乘积之和为最小。</p>
</blockquote>
<p>摘自:</p>
<blockquote>
<p><a href="https://baike.baidu.com/item/%E6%96%AF%E5%9D%A6%E7%BA%B3%E6%A0%91/12796694?fr=aladdin">百度百科-斯坦纳树</a></p>
</blockquote>
<hr />
<h3 id="旅行商问题np困难"><a class="markdownIt-Anchor" href="#旅行商问题np困难"></a> 旅行商问题（NP困难）</h3>
<p>假设有一个旅行商人要拜访n个城市，他必须选择所要走的路径，路径的限制是每个城市只能拜访一次，而且最后要回到原来出发的城市。路径的选择目标是要求得的路径路程为所有路径之中的最小值。</p>
<p>注意 ：上面有一个<code>中国邮路问题</code>是经过所有<em>边</em>一次,和这个<em>点</em>不同.</p>
<p>摘自:</p>
<blockquote>
<p><a href="https://baike.baidu.com/item/TSP%E9%97%AE%E9%A2%98/840008?fromtitle=%E6%97%85%E8%A1%8C%E6%8E%A8%E9%94%80%E5%91%98%E9%97%AE%E9%A2%98&amp;fromid=10675002&amp;fr=aladdin">百度百科-TSP问题</a></p>
</blockquote>
<hr />
<h2 id="网络流与匹配"><a class="markdownIt-Anchor" href="#网络流与匹配"></a> 网络流与匹配</h2>
<h3 id="最大流问题"><a class="markdownIt-Anchor" href="#最大流问题"></a> 最大流问题</h3>
<p>在优化理论中,最大流问题涉及到在一个单源点、单汇点的网络流中找到一条最大的流。<br />
最大流问题可以被看作是一个更复杂的网络流问题的特殊情况,。s-t流（从源点s到汇点t）的最大值等于s-t割的最小容量，这被称为最大流最小割定理。</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613547720444.png" alt="最大流问题" /></p>
<p><strong>最小费用最大流问题:</strong> 在一个网络中每段路径都有“容量”和“费用”两个限制的条件下，此类问题的研究试图寻找出：流量从A到B，如何选择路径、分配经过路径的流量，可以达到所用的费用最小的要求。<br />
在实际中：n辆卡车要运送物品，从A地到B地。由于每条路段都有不同的路费要缴纳，每条路能容纳的车的数量有限制，如何分配卡车的出发路径可以达到费用最低，物品又能全部送到。</p>
<p>摘自:</p>
<blockquote>
<p><a href="https://zh.wikipedia.org/wiki/%E6%9C%80%E5%A4%A7%E6%B5%81%E9%97%AE%E9%A2%98">维基百科-最大流问题</a><br />
<a href="https://zh.wikipedia.org/wiki/%E6%9C%80%E5%B0%8F%E8%B4%B9%E7%94%A8%E6%9C%80%E5%A4%A7%E6%B5%81%E9%97%AE%E9%A2%98">维基百科-最小费用最大流问题</a></p>
</blockquote>
<hr />
<h2 id="染色"><a class="markdownIt-Anchor" href="#染色"></a> 染色</h2>
<h3 id="四色问题"><a class="markdownIt-Anchor" href="#四色问题"></a> 四色问题</h3>
<p>每个无外飞地的地图都可以用不多于四种颜色来染色，而且不会有两个邻接的区域颜色相同</p>
<blockquote>
<p>外飞地：某国家拥有一块与本国分离开来的领土，该领土被其他国家包围，则该领土称为某国的外飞地。</p>
</blockquote>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613547720479.png" alt="四色问题示意图" /></p>
<p>摘自:</p>
<blockquote>
<p><a href="https://zh.wikipedia.org/wiki/%E5%9B%9B%E8%89%B2%E5%AE%9A%E7%90%86">维基百科-四色定理</a></p>
</blockquote>
<hr />
]]></content>
      <categories>
        <category>图论</category>
      </categories>
      <tags>
        <tag>图论</tag>
      </tags>
  </entry>
  <entry>
    <title>在Windows上编译带CUDA(GPU)的OpenCV</title>
    <url>/2021/03/08/%E5%9C%A8Windows%E4%B8%8A%E7%BC%96%E8%AF%91%E5%B8%A6CUDA(GPU)%E7%9A%84opencv/</url>
    <content><![CDATA[<p>本文一步一步地介绍如何在windows上编译带CUDA模块（GPU）支持的OpenCV，为避免长篇大论，截图过多，尽可能简单地描述</p>
<a id="more"></a>
<p><strong>本次安装说明：</strong></p>
<p>本次在windows10上、RTX2060S编译OpenCV4.5.0，其他相关软件安装情况如下：</p>
<ul>
<li>NVIDIA Diver 461</li>
<li>CUDA 11.1</li>
<li>CUDNN 8.0.4</li>
<li>Cmake 3.19.3</li>
<li>Visual studio 2017</li>
</ul>
<h2 id="第一步安装前准备"><a class="markdownIt-Anchor" href="#第一步安装前准备"></a> 第一步：安装前准备</h2>
<ol>
<li>确认系统显卡牌子为：NVIDIA，并<a href="https://developer.nvidia.com/zh-cn/cuda-gpus">在此</a>查看是否支持CUDA ，在列表中找到即是支持显卡</li>
<li><a href="https://www.nvidia.cn/geforce/drivers/">下载</a>并安装显卡驱动</li>
<li><a href="https://developer.nvidia.com/zh-cn/cuda-toolkit">下载</a>并安装CUDA，<a href="https://developer.nvidia.com/zh-cn/cudnn">下载</a>CUDNN，安装过程参考<a href=""></a></li>
<li><a href="https://cmake.org/download/">下载</a>并安装CmakeGUI</li>
<li><a href="https://visualstudio.microsoft.com/downloads/">下载</a>并安装VIsual sudio 2017</li>
<li><a href="https://opencv.org/releases/">下载</a>OpenCV</li>
<li><a href="https://github.com/opencv/opencv_contrib/">下载</a>OpenCV contrib，需跟OpenCV同版本</li>
<li>解压OpenCV及OpenCV contrib</li>
<li>在OpenCV解压目录下创建build</li>
</ol>
<h2 id="第二步使用cmake-gui构建opencv"><a class="markdownIt-Anchor" href="#第二步使用cmake-gui构建opencv"></a> 第二步：使用Cmake-gui构建opencv</h2>
<ol>
<li>**启动Cmake：**为编译OpenCV的Python接口，需在在终端激活某个conda虚拟环境，并运行<code>cmake-gui</code>程序，如不需要使用Python接口，直接运行<code>cmake-gui</code>即可</li>
<li><strong>配置Cmake：</strong>（1）<code>source code</code>选择OpenCV解压后的源码；（2）<code>build binaries</code>选择第一步创建的build目录；（3）点击<code>Configure</code>，在弹窗中依次选<code>VIsual sudio 15 2017</code> 、 <code>x64</code>，点击<code>Finish</code></li>
<li>**配置CUDA模块：**Cmake完成初始编译编译后，在出现的红色新选项中勾选<code>WITH_CUDA</code>，<code>OPENCV_DNN_CUDA</code>，<code>ENABLE_FAST_MATH</code></li>
<li>**配置OpenCV contrib：**在出现的红色新选项中找到<code>OPENCV_EXTRA_MODULES_PATH</code>，并将Value配置为第一步解压的OpenCV contrib目录下的<code>modules</code>目录路径</li>
<li><strong>配置OpenCV的Python接口</strong>：（1）点击<code>Add Entry</code>新增BUILD_opencv_python3和BUILD_opencv_python2两项，其中BUILD_opencv_python3设置value为true，另一个设置为false；（2）搜索并配置<code>PYTHON3_EXECUTABLE</code>、<code>PYTHON3_INCLUDE_DIR</code>、<code>PYTHON3_LIBRARY</code>、<code>PYTHON3_NUMPY_INCLUDE_DIRS</code>、<code>PYTHON3_PACKAGES_PATH</code>，配置结果看下图<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup></li>
<li>**其他配置项：**搜索并勾选<code>OPENCV_ENABLE_NONFREE</code>，<code>build_opencv_world</code></li>
<li>再次点击<code>COnfigure</code>，在新增红色配置项中找到<code>CUDA_ARCH_BIN</code>，删除小于显卡计算能力的数值，计算能力可以在<a href="https://developer.nvidia.com/zh-cn/cuda-gpus"></a>找到。</li>
<li>再次点击<code>COnfigure</code>，确认日志中出现<em>Configuring done</em>后，点击<code>Generate</code></li>
</ol>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/PicGo/image-20210306160653041.png" alt="image-20210306160653041" /></p>
<h2 id="第三步使用visual-studio编译opencv"><a class="markdownIt-Anchor" href="#第三步使用visual-studio编译opencv"></a> 第三步：使用Visual studio编译opencv</h2>
<ol>
<li>点击<code>Open Project</code>或者使用<code>Visual studio</code>打开<strong><a href="http://OpenCV.sh">OpenCV.sh</a></strong></li>
<li>打开后，更改<strong>Debug</strong>模式为<strong>Release</strong>模式</li>
<li>右键点击<code>Cmake Targets</code>下的<code>ALL_BUILD</code>，并点击<code>build</code>，此步编译文件需要较长时间</li>
<li>一旦完成，右键点击<code>Install</code>，并点击<code>build</code></li>
</ol>
<p>到此，已经成功在windows10上编译了带CUDA模块的OpenCV，编译得到的文件位于<code>build\install</code>下</p>
<h2 id="第四步python及c使用"><a class="markdownIt-Anchor" href="#第四步python及c使用"></a> 第四步：Python及C++使用</h2>
<p><strong>Python端使用</strong></p>
<ol>
<li>安装OpenCV到Python，</li>
<li>新建Python文件，写入以下内容，并在终端运行，如果无误则运行成功</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line"><span class="comment">#查看opencv信息</span></span><br><span class="line">print(cv2.getBuildInformation())</span><br><span class="line"></span><br><span class="line"><span class="comment">#读取图片</span></span><br><span class="line">frame=cv2.imread(<span class="string">&#x27;test.jpg&#x27;</span>)</span><br><span class="line">print(frame.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment">#上传图片到GPU</span></span><br><span class="line">gpu_frame=cv2.cuda_GpuMat()</span><br><span class="line">gpu_frame.upload(frame)</span><br><span class="line"></span><br><span class="line"><span class="comment">#resize</span></span><br><span class="line">gpu_resframe=cv2.cuda.resize(gpu_frame,(<span class="number">1024</span>,<span class="number">512</span>))</span><br><span class="line">cpu_resfram=gpu_resframe.download()</span><br><span class="line">print(cpu_resfram.shape)</span><br></pre></td></tr></table></figure>
<p><strong>C++端使用</strong></p>
<ol>
<li>配置系统环境，将编译目录下的<code>install\x64\vc15\bin</code>完整路径配置到系统路径下，<mark>并重启系统</mark></li>
<li>打开visual studio，新建<code>Visual C++</code>空项目，新建文件<code>main.cpp</code>，写入下面内容</li>
<li>点击<code>生成-&gt;生成解决方案</code>，不出现错误后，运行程序，无错误即可使用OpenCV的cuda模块</li>
<li>配置OpenCV开发环境，依次点击<code>视图-&gt;其他窗口-&gt;属性窗口</code>，右键点击<code>Release | x64</code>，新建项目属性表，新建完成后双击项目该文件，进行以下配置。</li>
</ol>
<ul>
<li><strong>VC++目录-&gt;包含目录</strong>：E:\opencv-4.5.0\build_test\install\include;E:\opencv-4.5.0\build_test\install\include\opencv2;$(IncludePath)</li>
<li>**VC++目录-&gt;库目录：**E:\opencv-4.5.0\build_test\install\x64\vc15\lib;$(LibraryPath)</li>
<li>**链接器-&gt;输入：**opencv_world450.dll;%(AdditionalDependencies)</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sstream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;opencv2/core.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;opencv2/dnn.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;opencv2/dnn/all_layers.hpp&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;opencv2/imgproc.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;opencv2/highgui.hpp&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">	<span class="comment">//读取图片</span></span><br><span class="line">	<span class="keyword">const</span> <span class="built_in">std</span>::<span class="built_in">string</span> image_path = <span class="string">&quot;C:\\Users\\wushaogui\\Desktop\\CCP_REPOS\\SegementModule\\SegementModule\\test.jpg&quot;</span>;</span><br><span class="line">	cv::Mat rgb_image = cv::imread(image_path, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">	cv::cuda::GpuMat gpu_frame, gpu_resized;</span><br><span class="line">	<span class="comment">//上传图片到GPU</span></span><br><span class="line">	gpu_frame.upload(rgb_image);</span><br><span class="line"></span><br><span class="line">	<span class="comment">//Resize</span></span><br><span class="line">	<span class="keyword">auto</span> input_size = cv::Size(<span class="number">1024</span>,<span class="number">512</span>);</span><br><span class="line">	cv::cuda::resize(gpu_frame, resized, input_size, <span class="number">0</span>, <span class="number">0</span>, cv::INTER_NEAREST);</span><br><span class="line"></span><br><span class="line">	<span class="comment">//下载并保存图片</span></span><br><span class="line">	cv::Mat cpu_resized;</span><br><span class="line">	gpu_resized.download(cpu_resized);</span><br><span class="line">	cv::imwrite(<span class="string">&quot;resized_test.jpg&quot;</span>, cpu_resized);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="第四步解决问题及其他需了解信息"><a class="markdownIt-Anchor" href="#第四步解决问题及其他需了解信息"></a> 第四步：解决问题及其他需了解信息</h2>
<h3 id="资源无法下载"><a class="markdownIt-Anchor" href="#资源无法下载"></a> 资源无法下载<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup></h3>
<p>在此次编译中，无法下载的资源有：ADE、face_landmark_model.dat、ffmpeg、ippicv、nvidia_optical_flow、xfeatures2d</p>
<p>**解决方法：**网络下载，这些文件，计算文件md5进行文件重命名后，将文件放置在编译目录下的<code>.cache</code>目录下，此次编译放置情况如下：</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/PicGo/image-20210306150042380.png" alt="image-20210306150042380" /></p>
<p><strong>参考资料<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup><sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup>：</strong></p>
<hr class="footnotes-sep" />
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p><a href="https://blog.csdn.net/qq_37781464/article/details/110078370">win10使用vs2019从源码编译OpenCV4.5+cuda10.2+cudnn8.0的C++环境和Python环境</a> <a href="#fnref1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn2" class="footnote-item"><p><a href="https://blog.csdn.net/fengxinzioo/article/details/104919888">windows安装opencv4.1.1过程中ffmpeg、ippicv、face_landmark_model下载出错解决办法</a> <a href="#fnref2" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn3" class="footnote-item"><p><a href="https://haroonshakeel.medium.com/build-opencv-4-4-0-with-cuda-gpu-support-on-windows-10-without-tears-aa85d470bcd0">Build OpenCV 4.4.0 with CUDA (GPU) Support on Windows 10 (Without Tears) | by M. Haroon Shakeel | Medium</a> <a href="#fnref3" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn4" class="footnote-item"><p><a href="https://blog.csdn.net/hitpisces/article/details/104266030">Win10下编译同时支持CUDA以及Python3的OpenCV 4.2教程_吃白兔的小青菜的博客-CSDN博客</a> <a href="#fnref4" class="footnote-backref">↩︎</a></p>
</li>
</ol>
</section>
]]></content>
      <categories>
        <category>软件工具</category>
      </categories>
      <tags>
        <tag>cuda</tag>
        <tag>opencv</tag>
        <tag>windows</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo博客环境搭建</title>
    <url>/2021/02/18/%E5%9C%A8Linux%E4%B8%8A%E5%AE%8C%E6%88%90Hexo%E5%8D%9A%E5%AE%A2%E7%9A%84%E6%90%AD%E5%BB%BA/</url>
    <content><![CDATA[<p>本文介绍在Linux、Windows完成Hexo博客的搭建，包括安装和配置Hexo，将博客部署到github，使得可以通过github page的方式进行访问博客</p>
<a id="more"></a>
<h2 id="系统环境"><a class="markdownIt-Anchor" href="#系统环境"></a> 系统环境</h2>
<p>本系列文章所有操作在系统<code>Linux Mint 20 Cinnamon</code>及windows上完成，其他关联应用版本为：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">node</span><br><span class="line">npm</span><br><span class="line">hexo</span><br><span class="line">git</span><br></pre></td></tr></table></figure>
<h2 id="安装hexo"><a class="markdownIt-Anchor" href="#安装hexo"></a> 安装Hexo</h2>
<h3 id="安装nodejs"><a class="markdownIt-Anchor" href="#安装nodejs"></a> 安装nodejs</h3>
<p>Hexo是基于nodeJS编写的，所以需要安装nodeJs，npm是nodejs的包管理工具，新版本的nodejs包含该工具，不需要单独安装</p>
<p><strong>Linux安装</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo apt install nodejs</span><br><span class="line">sudo apt install git</span><br></pre></td></tr></table></figure>
<p><strong>Windows安装</strong></p>
<ol>
<li><strong>安装nodejs</strong>:从https://nodejs.org/en/下载nodejs的msi安装文件，双击默认选项安装</li>
<li><strong>安装git</strong>:从https://git-scm.com/download/win下载git的exe安装文件，双击默认选项安装</li>
</ol>
<h3 id="配置npm镜像"><a class="markdownIt-Anchor" href="#配置npm镜像"></a> 配置npm镜像<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup><sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup></h3>
<p>npm是nodeJs的包管理工具，用于从NPM服务器下载第三方包到本地使用或上传自己编写的包，但是国内直接使用npm的官方镜像往往较慢，因此建议使用<code>淘宝镜像</code>，可以通过两种方式达到这个目地：</p>
<ul>
<li><strong>更改npm的默认镜像</strong></li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#查看当前镜像地址</span></span><br><span class="line">npm get registry</span><br><span class="line"></span><br><span class="line"><span class="comment">#设置为淘宝镜像</span></span><br><span class="line">npm config <span class="built_in">set</span> registry http://registry.npm.taobao.org/</span><br><span class="line"></span><br><span class="line"><span class="comment">#还原为原始配置</span></span><br><span class="line">npm config <span class="built_in">set</span> registry https://registry.npmjs.org/</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>安装淘宝定制的cnpm工具</strong></li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 安装cnpm工具</span></span><br><span class="line">npm install -g cnpm --registry=https://registry.npm.taobao.org</span><br><span class="line"></span><br><span class="line"><span class="comment">#使用cnpm工具</span></span><br><span class="line">cnpm install [name]</span><br></pre></td></tr></table></figure>
<h2 id="博客初始化"><a class="markdownIt-Anchor" href="#博客初始化"></a> 博客初始化</h2>
<h3 id="安装hexo-2"><a class="markdownIt-Anchor" href="#安装hexo-2"></a> 安装hexo</h3>
<p>通过npm工具安装hexo，使用命令</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install -g hexo</span><br></pre></td></tr></table></figure>
<h3 id="博客初始化-2"><a class="markdownIt-Anchor" href="#博客初始化-2"></a> 博客初始化</h3>
<p>使用hexo初始化博客，初始化文件夹为空或不存在</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#初始化+安装npm</span></span><br><span class="line">hexo init myblog;<span class="built_in">cd</span> myblog;sudo npm install</span><br></pre></td></tr></table></figure>
<p>安装完成后，得到以下文件结构</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/PicGo/20210221170032.png" alt="" /></p>
<h3 id="测试博客"><a class="markdownIt-Anchor" href="#测试博客"></a> 测试博客</h3>
<p>在新建的博客目录下，使用以下命令测试博客是否初始化完成</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo server</span><br></pre></td></tr></table></figure>
<p>浏览器打开：<a href="http://localhost:4000/%E5%90%8E%EF%BC%8C%E5%BE%97%E5%88%B0%E4%BB%A5%E4%B8%8B%E9%A1%B5%E9%9D%A2%EF%BC%8C%E8%A1%A8%E9%9D%A2%E5%8D%9A%E5%AE%A2%E5%88%9D%E5%A7%8B%E5%8C%96%E6%88%90%E5%8A%9F">http://localhost:4000/后，得到以下页面，表面博客初始化成功</a></p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/PicGo/20210221170324.png" alt="" /></p>
<h2 id="发布博客到github-page"><a class="markdownIt-Anchor" href="#发布博客到github-page"></a> 发布博客到Github Page</h2>
<h3 id="配置本地及github"><a class="markdownIt-Anchor" href="#配置本地及github"></a> 配置本地及github</h3>
<p>为了将博客部署到github，需要在本地生成SSH key，并将公钥配置到github</p>
<h5 id="本地生成公钥及密钥"><a class="markdownIt-Anchor" href="#本地生成公钥及密钥"></a> 本地生成公钥及密钥</h5>
<p>使用以下命令，一直回车生成公钥和密钥</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ssh-kengen -t rsa -C <span class="string">&quot;yourmail&quot;</span></span><br></pre></td></tr></table></figure>
<p>生成之后的公钥及密钥保存在目录<code>~/.ssh</code>内，其中<code>id_rsa</code>为私钥，不可泄漏，id_rsa.pub为公钥，将配置到github上，上传代码时，公钥和私钥相互匹配，才能顺利上传代码。</p>
<h5 id="公钥配置到github"><a class="markdownIt-Anchor" href="#公钥配置到github"></a> 公钥配置到github</h5>
<p>登录github后，依次进入<code>Settings</code>-&gt;<code>SSH and GPG keys</code>，然后点击<code>New SSH key</code>，将公钥文件id_rsa.pub里面的内容全部填到<code>Key</code>上</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/PicGo/20210221170419.png" alt="" /></p>
<h5 id="测试是否配置成功"><a class="markdownIt-Anchor" href="#测试是否配置成功"></a> 测试是否配置成功</h5>
<p>使用以下命令检查，配置是否成功</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ssh -T git@github.com</span><br></pre></td></tr></table></figure>
<h3 id="安装部署插件"><a class="markdownIt-Anchor" href="#安装部署插件"></a> 安装部署插件</h3>
<p>通过npm安装git插件，以便进行github部署</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install hexo-deployer-git --save</span><br></pre></td></tr></table></figure>
<h3 id="新建github-pages仓库"><a class="markdownIt-Anchor" href="#新建github-pages仓库"></a> 新建github pages仓库</h3>
<p>推送前需先新建一个用于存储博客的仓库，该仓库为用户的github page（GitHub Pages is a static site hosting service designed to host your  personal, organization, or project pages directly from a GitHub  repository）<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup>，以下两个操作完成此步骤：</p>
<ol>
<li>新建一个公开（Public）仓库，仓库名为<code>你的用户名.github.io</code>；</li>
<li>进入仓库的<code>Settings</code>，找到Github Page，在<code>Source</code>选择分支，并保存</li>
<li>浏览器访问<code>https://[YourUserName].github.io/</code>，成功访问即配置成功（这可能需要科学上网）</li>
</ol>
<h3 id="设置博客部署仓库"><a class="markdownIt-Anchor" href="#设置博客部署仓库"></a> 设置博客部署仓库</h3>
<p>将远程仓库地址配置到博客配置文件中，部署时往此仓库推送，打开<code>_config.yml</code>文件，在最后找到Deployment配置项，按以下方式配置：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Deployment</span></span><br><span class="line"><span class="comment">## Docs: https://hexo.io/docs/one-command-deployment</span></span><br><span class="line">deploy:</span><br><span class="line">  <span class="built_in">type</span>: git</span><br><span class="line">  repo: https://github.com/[YourUserName]/[YourUserName].github.io.git</span><br><span class="line">  branch: master</span><br></pre></td></tr></table></figure>
<h3 id="推送博客到github-pages仓库"><a class="markdownIt-Anchor" href="#推送博客到github-pages仓库"></a> 推送博客到github pages仓库</h3>
<p>使用以下命令推送hexo博客到github page仓库上</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo clean;hexo generate;hexo deploy</span><br></pre></td></tr></table></figure>
<p>在浏览器上再次访问<code>https://[YourUserName].github.io/</code>，出现以下画面表示成功</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/PicGo/20210221170324.png" alt="" /></p>
<h2 id="绑定域名"><a class="markdownIt-Anchor" href="#绑定域名"></a> 绑定域名</h2>
<p>每次访问博客，均需使用<code>https://[YourUserName].github.io/</code>打开，本着<s>装逼</s>的原则，申请一个个人使用的域名，即可以便于记忆/宣传，又隐藏博客在github page的行为，代价是需要RMB（一年几十）。</p>
<h3 id="申请域名"><a class="markdownIt-Anchor" href="#申请域名"></a> 申请域名</h3>
<p>我是在腾讯云申请的域名，阿里云也可以通过申请，访问：<a href="https://dnspod.cloud.tencent.com/%EF%BC%8C%E6%90%9C%E7%B4%A2%E8%87%AA%E5%B7%B1%E8%AE%A1%E5%88%92%E4%BD%BF%E7%94%A8%E7%9A%84%E5%9F%9F%E5%90%8D%EF%BC%8C%E9%80%89%E6%8B%A9%E5%AE%8C%E6%88%90%E5%90%8E%E4%BB%98%E8%B4%B9%EF%BC%8C%E5%AE%8C%E6%88%90%E5%AE%9E%E5%90%8D%E8%AE%A4%E8%AF%81%EF%BC%8B%E5%A4%87%E6%A1%88%EF%BC%8C%E5%8D%B3%E5%8F%AF%E4%BD%BF%E7%94%A8%E3%80%82">https://dnspod.cloud.tencent.com/，搜索自己计划使用的域名，选择完成后付费，完成实名认证＋备案，即可使用。</a></p>
<p>完成域名申请后，需配置域名的解析地址，按照以下方式添加两个记录</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/PicGo/image-20210218163454662.png" alt="image-20210218163454662" /></p>
<h3 id="绑定域名-2"><a class="markdownIt-Anchor" href="#绑定域名-2"></a> 绑定域名</h3>
<p>通过以下两个步骤完成域名的绑定</p>
<p><strong>1.配置Hexo博客</strong></p>
<p>在hexo/source目录下新建一个名为<code>CNAME</code>的文件，然后将申请的域名填写到里面</p>
<p><strong>2.配置Github Pages</strong></p>
<p>到仓库的Github Pages页面，在<code>Custom domain</code>配置申请的域名（注意：配置成功后不会立马生效）</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/PicGo/image-20210218165026184.png" alt="image-20210218165026184" /></p>
<p>在浏览器上通过申请的域名访问博客，如果成功，则配置成功！！！</p>
<h2 id="发文流程"><a class="markdownIt-Anchor" href="#发文流程"></a> 发文流程</h2>
<p>使用以下命令新建一个博文，然后使用markdwn格式写博文，再然后部署到github pages上</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo new <span class="string">&quot;文件名.md&quot;</span></span><br></pre></td></tr></table></figure>
<h2 id="遇到的问题"><a class="markdownIt-Anchor" href="#遇到的问题"></a> 遇到的问题</h2>
<p>1.<code>sudo npm install -g hexo</code>遇到rollbackFailedOptional: verb npm-session<sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup></p>
<p>原因：（1）网络原因；（2）未配置国内镜像服务器；</p>
<p>解决：配置npm使用淘宝镜像服务器</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">npm config set registry http:&#x2F;&#x2F;registry.npm.taobao.org</span><br></pre></td></tr></table></figure>
<p>参考资料<sup class="footnote-ref"><a href="#fn5" id="fnref5">[5]</a></sup><sup class="footnote-ref"><a href="#fn6" id="fnref6">[6]</a></sup><sup class="footnote-ref"><a href="#fn7" id="fnref7">[7]</a></sup><sup class="footnote-ref"><a href="#fn8" id="fnref8">[8]</a></sup>：</p>
<hr class="footnotes-sep" />
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p><a href="https://www.runoob.com/nodejs/nodejs-npm.html">NPM 使用介绍</a> <a href="#fnref1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn2" class="footnote-item"><p><a href="https://blog.csdn.net/shangrila_kun/article/details/89633374">npm的镜像替换成淘宝</a> <a href="#fnref2" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn3" class="footnote-item"><p><a href="https://docs.github.com/en/enterprise/2.14/user/articles/what-is-github-pages">What is GitHub Pages?</a> <a href="#fnref3" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn4" class="footnote-item"><p><a href="https://blog.csdn.net/qq_34458791/article/details/82705345">npm install rollbackFailedOptional: verb npm-session</a> <a href="#fnref4" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn5" class="footnote-item"><p><a href="http://blog.haoji.me/build-blog-website-by-hexo-github.html">使用hexo+github搭建免费个人博客详细教程</a> <a href="#fnref5" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn6" class="footnote-item"><p><a href="https://segmentfault.com/a/1190000017986794">超详细Hexo+Github Page搭建技术博客教程【持续更新】</a> <a href="#fnref6" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn7" class="footnote-item"><p><a href="https://blog.csdn.net/sinat_37781304/article/details/82729029">hexo史上最全搭建教程</a> <a href="#fnref7" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn8" class="footnote-item"><p><a href="https://cloud.tencent.com/developer/article/1520557">这可能是迄今为止最全的hexo博客搭建教程</a> <a href="#fnref8" class="footnote-backref">↩︎</a></p>
</li>
</ol>
</section>
]]></content>
      <categories>
        <category>软件工具</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>博客</tag>
      </tags>
  </entry>
  <entry>
    <title>如何理解皮尔逊相关系数</title>
    <url>/2017/03/18/%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3%E7%9A%AE%E5%B0%94%E9%80%8A%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0/</url>
    <content><![CDATA[<p>本文介绍机器学习中的皮尔逊相关系数</p>
<a id="more"></a>
<h1 id="1是什么"><a class="markdownIt-Anchor" href="#1是什么"></a> 1.是什么？</h1>
<blockquote>
<p>在统计学中，皮尔逊相关系数( Pearson correlation coefficient），又称皮尔逊积矩相关系数（Pearson product-moment correlation coefficient，简称 PPMCC或PCCs），是用于度量两个变量X和Y之间的相关（线性相关），其值介于-1与1之间。</p>
</blockquote>
<h1 id="2怎么算"><a class="markdownIt-Anchor" href="#2怎么算"></a> 2.怎么算？</h1>
<blockquote>
<p>Pearson相关系数是用协方差除以两个变量的标准差得到的，虽然协方差能反映两个随机变量的相关程度（协方差大于0的时候表示两者正相关，小于0的时候表示两者负相关），但其数值上受量纲的影响很大，不能简单地从协方差的数值大小给出变量相关程度的判断。为了消除这种量纲的影响，于是就有了相关系数的概念。</p>
</blockquote>
<h1 id="3适用范围"><a class="markdownIt-Anchor" href="#3适用范围"></a> 3.适用范围</h1>
<blockquote>
<p>当两个变量的标准差都不为零时，相关系数才有定义，皮尔逊相关系数适用于：<br />
(1)、两个变量之间是线性关系，都是连续数据。<br />
(2)、两个变量的总体是正态分布，或接近正态的单峰分布。<br />
(3)、两个变量的观测值是成对的，每对观测值之间相互独立。</p>
</blockquote>
<h1 id="4皮尔逊相关系数和余弦相似度"><a class="markdownIt-Anchor" href="#4皮尔逊相关系数和余弦相似度"></a> 4.皮尔逊相关系数和余弦相似度</h1>
<blockquote>
<p>皮尔逊相关系数的计算是先对向量每一分量减去分量均值，再求余弦相似度，这一操作称为中心化。</p>
</blockquote>
<h1 id="5皮尔逊相关系数和检验p值"><a class="markdownIt-Anchor" href="#5皮尔逊相关系数和检验p值"></a> 5.皮尔逊相关系数和检验P值</h1>
<blockquote>
<p>（1）显著水平,就是P值,这是首要的,因为如果不显著,相关系数再高也没用,可能只是因为偶然因素引起的,那么多少才算显著,一般p值小于0.05就是显著了；如果小于0.01就更显著；例如p值=0.001,就是很高的显著水平了,只要显著,就可以下结论说：拒绝原假设无关,两组数据显著相关也说两者间确实有明显关系.通常需要p值小于0.1,最好小于0.05设甚至0.01,才可得出结论：两组数据有明显关系,如果p=0.5,远大于0.1,只能说明相关程度不明显甚至不相关.起码不是线性相关.</p>
<p>（2）相关系数,也就是Pearson Correlation(皮尔逊相关系数),通常也称为R值,在确认上面指标显著情况下,再来看这个指标,一般相关系数越高表明两者间关系越密切.<br />
R&gt;0 代表连个变量正相关,即一个变大另一个随之变大</p>
</blockquote>
<h1 id="6统计学三大相关系数"><a class="markdownIt-Anchor" href="#6统计学三大相关系数"></a> 6.统计学三大相关系数</h1>
<h2 id="a斯皮尔曼等级相关系数"><a class="markdownIt-Anchor" href="#a斯皮尔曼等级相关系数"></a> a.斯皮尔曼等级相关系数</h2>
<blockquote>
<p>定义：主要用于解决称名数据和顺序数据相关的问题。适用于两列变量，而且具有等级变量性质具有线性关系的资料。</p>
<p>区别1:斯皮尔曼等级相关系数对数据条件的要求没有皮尔逊相关系数严格，只要两个变量的观测值是成对的等级评定资料，或者是由连续变量观测资料转化得到的等级资料，不论两个变量的总体分布形态、样本容量的大小如何，都可以用斯皮尔曼等级相关系数来进行研究。</p>
<p>区别2:相对于皮尔森相关系数，斯皮尔曼相关系数对于数据错误和极端值的反应不敏感。但是一组能用积差相关计算的数据，如果改用等级相关，精确度会低于积差相关。凡符合积差相关条件的，最好不要用等级相关计算。</p>
</blockquote>
<h2 id="b肯德尔相关系数"><a class="markdownIt-Anchor" href="#b肯德尔相关系数"></a> b.肯德尔相关系数</h2>
<blockquote>
<p>定义：Kendall(肯德尔)系数的定义：n个同类的统计对象按特定属性排序，其他属性通常是乱序的。同序对（concordant pairs）和异序对（discordant pairs）之差与总对数（n*(n-1)/2)的比值定义为Kendall(肯德尔)系数。</p>
</blockquote>
<h2 id="c选择那种相关系数"><a class="markdownIt-Anchor" href="#c选择那种相关系数"></a> c.选择那种相关系数</h2>
<blockquote>
<p>适用情况1：计算积距pearson相关系数，连续性变量才可采用;计算Spearman秩相关系数，适合于定序变量或不满足正态分布假设的等间隔数据;计算Kendall秩相关系数，适合于定序变量或不满足正态分布假设的等间隔数据。</p>
<p>适用情况2：当资料不服从双变量正态分布或总体分布未知，或原始数据用等级表示时，宜用 spearman或kendall相关。</p>
</blockquote>
<h1 id="7相关系数的简单分类"><a class="markdownIt-Anchor" href="#7相关系数的简单分类"></a> 7.相关系数的简单分类</h1>
<blockquote>
<p>|r|&gt;0.95 显著性相关<br />
|r|&gt;=0.8 高度相关<br />
0.5&lt;=|r|&lt;0.8 中度相关<br />
0.3&lt;=|r|&lt;0.5 低度相关<br />
|r|&lt;0.3 关系极弱，认为不相关</p>
</blockquote>
<p>参考：<br />
<a href="https://baike.baidu.com/item/%E7%9A%AE%E5%B0%94%E9%80%8A%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0/12712835?fr=aladdin">皮尔逊相关系数</a><br />
<a href="https://blog.csdn.net/huangfei711/article/details/78456165?utm_source=gold_browser_extension">如何通俗易懂地理解皮尔逊相关系数？</a><br />
<a href="https://blog.csdn.net/sujinhehehe/article/details/83380303">皮尔逊相关系数和余弦相似度</a><br />
<a href="https://blog.csdn.net/xiaocong1990/article/details/71267144">皮尔逊相关系数和检验P值</a><br />
<a href="https://blog.csdn.net/lambsnow/article/details/79972145">皮尔森Pearson相关系数 VS 斯皮尔曼Spearman相关系数</a><br />
<a href="https://blog.csdn.net/ruthywei/article/details/82533595">统计学三大相关系数之肯德尔(kendall)相关性系数</a><br />
<a href="https://www.cnblogs.com/quietwalk/p/8288205.html">Kendall’s tau-b（肯德尔）等级相关系数</a><br />
<a href="https://blog.csdn.net/zhaozhn5/article/details/78392220">三大统计相关系数：Pearson、Spearman秩相关系数、kendall等级相关系数</a><br />
<a href="https://baike.baidu.com/item/%E6%96%AF%E7%9A%AE%E5%B0%94%E6%9B%BC%E7%AD%89%E7%BA%A7%E7%9B%B8%E5%85%B3/1858796?fr=aladdin">斯皮尔曼等级相关</a><br />
<a href="https://baike.baidu.com/item/kendall%E7%A7%A9%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0/6246854?fr=aladdin">kendall秩相关系数</a></p>
]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>评价指标</tag>
      </tags>
  </entry>
  <entry>
    <title>如何使用tensorflowServing进行模型部署</title>
    <url>/2021/02/22/%E5%A6%82%E4%BD%95%E7%94%A8tensorflowServing%E8%BF%9B%E8%A1%8C%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/</url>
    <content><![CDATA[<p>TensorFlow Serving是用于机器学习的灵活，高性能的服务系统，针对生产环境而设计。 TensorFlow服务 可以轻松部署新算法和实验，同时保持不变服务器体系结构和API。TensorFlow Serving开箱即用 与TensorFlow模型集成，但可以轻松扩展以服务于其他  模型类型</p>
<a id="more"></a>
<h1 id="关键概念"><a class="markdownIt-Anchor" href="#关键概念"></a> 关键概念</h1>
<h2 id="key-conception"><a class="markdownIt-Anchor" href="#key-conception"></a> Key Conception</h2>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/PicGo/serving_architecture.svg" alt="serving_architecture" /></p>
<h3 id="loaders"><a class="markdownIt-Anchor" href="#loaders"></a> Loaders</h3>
<p>Loaders管理Servables的生命周期。Loader API 是一种支持独立于特定算法，数据或产品用例的通用基础架构。具体来说，Loaders标准化了用于加载和卸载Servable的API。</p>
<h3 id="sources"><a class="markdownIt-Anchor" href="#sources"></a> Sources</h3>
<p>Sources 是可以寻找和提供 Servables 的模块，每个 Source 提供了0个或者多个Servable streams，对于每个Servable stream，Source 都会提供一个Loader实例。</p>
<h3 id="managers"><a class="markdownIt-Anchor" href="#managers"></a> Managers</h3>
<p>管理 Servable 的整个的生命周期，包括：</p>
<ul>
<li>loading Servables</li>
<li>serving Servables</li>
<li>unloading Servables</li>
</ul>
<p>Managers监听Sources并跟踪所有版本。Managers尝试满足、响应Sources的请求，但是如果所请求的资源不可用，可能会拒绝加载相应版本。Managers也可以推迟“卸载”。例如，Managers可能会等待到较新的版本完成加载之后再卸载（基于保证始终至少加载一个版本的策略）。</p>
<h3 id="servables"><a class="markdownIt-Anchor" href="#servables"></a> Servables</h3>
<p>Servable是Tensorflow Serving的核心抽象，是客户端用于执行计算的基础对象,其大小和粒度是灵活的。Tensorflow  serving可以在单个实例的生命周期内处理一个或多个版本的Servable，这样既可以随时加载新的算法配置，权重或其他数据；也能够同时加载多个版本的Servable，支持逐步发布和实验。由此产生另外一个概念：Servable stream，即是指Servable的版本序列，按版本号递增排序。Tensorflow Serving 将 model  表示为一个或者多个Servables，一个Servable可能对应着模型的一部分，例如，a large lookup table 可以被许多  Tensorflow Serving 共享。另外，Servable不管理自己的生命周期</p>
<h3 id="core"><a class="markdownIt-Anchor" href="#core"></a> Core</h3>
<p>Tensorflow Serving core 负责管理Servables的Lifecycle和metrics，将Servables和loaders看作黑箱(opaque objects)。</p>
<p>广义地说：</p>
<ol>
<li>Sources create Loaders for Servable Versions.</li>
<li>Loaders are sent as Aspired Versions to the Manager, which loads and serves them to client requests.</li>
</ol>
<p>例子：</p>
<ol>
<li>Source 为指定的服务(磁盘中检测模型权重的新版本)创建Loader，Loader里包含了服务所需要的元数据（模型）；</li>
<li>Source 使用回调函数通知 Manager 的 Aspired Version(Servable version的集合);</li>
<li>Manager 根据配置的Version Policy决定下一步的操作（是否 unload 之前的Servable，或者 load 新的Servable）；</li>
<li>如果 Manager 判定是操作安全的，就会给 Loader 要求的resource并让 Loader 加载新的版本;</li>
<li>客户端向 Manager 请求服务，可以指定服务版本或者只是请求最新的版本。Manager 返回服务端的处理结果;</li>
</ol>
<h2 id="extensibility"><a class="markdownIt-Anchor" href="#extensibility"></a> Extensibility</h2>
<p>Tensorflow Serving提供了几个可扩展的entry point，用户可以在其中添加自定义功能。</p>
<h3 id="version-policy"><a class="markdownIt-Anchor" href="#version-policy"></a> Version Policy</h3>
<p>Version Policy(版本策略)可以指定单个Servable stream中的版本加载和卸载顺序。它包括Availability Preserving Policy（在卸载旧版本之前加载并准备好新版本）和Resource Preserving Policy（在加载新版本之前先卸载旧版本）。</p>
<h3 id="source"><a class="markdownIt-Anchor" href="#source"></a> Source</h3>
<p>New Sources可以支持新的文件系统，云产品和算法后端，这主要和创建自定义Source有关。</p>
<h3 id="loaders-2"><a class="markdownIt-Anchor" href="#loaders-2"></a> Loaders</h3>
<p>Loaers是添加算法、数据后端的扩展点。Tensorflow就是这样一种算法后端。例如，用户将实现一个新的Loader，以便对新的Servable机器学习模型实例的访问和卸载。</p>
<h3 id="batcher"><a class="markdownIt-Anchor" href="#batcher"></a> Batcher</h3>
<p>将多个请求批处理为单个请求可以显着降低计算成本，尤其是在存在诸如GPU的硬件加速器的情况下。Tensorflow Serving包括一个请求批处理小部件，它允许客户端轻松地将请求中特定类型的计算进行批量处理。</p>
<h1 id="系统环境搭建"><a class="markdownIt-Anchor" href="#系统环境搭建"></a> 系统环境搭建</h1>
<h2 id="系统及软硬件说明"><a class="markdownIt-Anchor" href="#系统及软硬件说明"></a> 系统及软硬件说明</h2>
<p><strong>系统</strong>：Ubuntu16.04</p>
<p><strong>软件</strong></p>
<ul>
<li>驱动 450.23.05</li>
<li>cuda 11.1</li>
<li>cudnn 8.0.5</li>
<li>tensorflow nightly-gpu(2.4)</li>
<li>python 3.7.9</li>
</ul>
<p>硬件</p>
<ul>
<li>RTX 3090</li>
</ul>
<h2 id="导出keras模型"><a class="markdownIt-Anchor" href="#导出keras模型"></a> 导出Keras模型</h2>
<p>将keras中以<code>model.save(filepath)</code>保存的模型h5文件，转为tensorflow的xx格式，加载模型时，使用✔️<code>tf.keras.models.load_model</code>而不是❌<code>keras.models.load_model</code>，</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> load_model</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 首先使用tf.keras的load_model来导入模型h5文件</span></span><br><span class="line">model_path = <span class="string">&#x27;v3_resnet50_unet.h5&#x27;</span></span><br><span class="line">model = tf.keras.models.load_model(model_path, custom_objects=dependencies)</span><br><span class="line">model.save(<span class="string">&#x27;deploy/tfs/0&#x27;</span>, save_format=<span class="string">&#x27;tf&#x27;</span>)  <span class="comment"># 导出tf格式的模型文件</span></span><br></pre></td></tr></table></figure>
<p>导出之后，有以下目录结构</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/PicGo/image-20210205165552193.png" alt="image-20210205165552193" /></p>
<p>导出之后，使用以下命令查看模型的signature、input、output，后续客户端调用需要这些信息。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">saved_model_cli show --dir tfs/0/ --all</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">signature_def[&#39;serving_default&#39;]:</span><br><span class="line">  The given SavedModel SignatureDef contains the following input(s):</span><br><span class="line">    inputs[&#39;input_1&#39;] tensor_info:</span><br><span class="line">        dtype: DT_FLOAT</span><br><span class="line">        shape: (-1, 512, 1024, 3)</span><br><span class="line">        name: serving_default_input_1:0</span><br><span class="line">  The given SavedModel SignatureDef contains the following output(s):</span><br><span class="line">    outputs[&#39;activation_49&#39;] tensor_info:</span><br><span class="line">        dtype: DT_FLOAT</span><br><span class="line">        shape: (-1, 524288, 1)</span><br><span class="line">        name: StatefulPartitionedCall:0</span><br><span class="line">  Method name is: tensorflow&#x2F;serving&#x2F;predict</span><br></pre></td></tr></table></figure>
<p>以上可以确定，signature、input、output分别为：serving_default，input_1，activation_49</p>
<p><strong>saved_model_cli</strong>为tensorflow的python工具包，位于<code>tensorflow/python/tools/saved_model_cli.py</code>下，一般安装了tensorflow，可以直接找到该命令。</p>
<h2 id="docker部署模型"><a class="markdownIt-Anchor" href="#docker部署模型"></a> Docker部署模型</h2>
<h3 id="拉取tfs的docker镜像"><a class="markdownIt-Anchor" href="#拉取tfs的docker镜像"></a> 拉取tfs的docker镜像</h3>
<p><strong>1.安装docker</strong></p>
<p>安装过程参考官方安装文档<a href="https://docs.docker.com/engine/install/ubuntu/">Install Docker Engine on Ubuntu</a></p>
<p><strong>2.安装nvidia-docker</strong></p>
<p>在docker上安装nvidia插件，以便使得应用在GPU上运行，安装过程参考：<a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#docker">Installation Guide</a></p>
<p><strong>3.拉取tfs镜像</strong></p>
<p><a href="https://hub.docker.com/r/tensorflow/serving/tags/?page=1&amp;ordering=last_updated">docker官网</a>上包含不同版本的tfs镜像，根据需求需要版本，使用以下命令拉取tfs镜像</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo docker pull tensorflow/serving:nightly-gpu</span><br></pre></td></tr></table></figure>
<h3 id="启动tfs容器"><a class="markdownIt-Anchor" href="#启动tfs容器"></a> 启动tfs容器</h3>
<p>使用以下命令启动tfs容器</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo nvidia-docker run -p 8500:8500  \</span><br><span class="line">  -v <span class="string">&quot;[path]/tfs:/models/resnet50_unet&quot;</span> \</span><br><span class="line">  -e MODEL_NAME=resnet50_unet \</span><br><span class="line">  -e CUDA_VISIBLE_DEVICES=1 \</span><br><span class="line">  -t 9e73a1470b72&amp;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>其中9e73a1470b72为tfs镜像的id，可通过docker image ls查看</p>
</blockquote>
<p>tfs容器可用参数解释：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">--port &#x3D; 8500                     用于侦听gRPC API的端口</span><br><span class="line">--rest_api_port &#x3D; 0               用于侦听HTTP &#x2F; REST API的端口。如果设置为零，将不会导出HTTP </span><br><span class="line">                                    &#x2F; REST API。此端口必须与--port中指定的端口不同。</span><br><span class="line">--rest_api_num_threads &#x3D; 160      用于HTTP &#x2F; REST API处理的线程数。如果未设置，</span><br><span class="line">                                    将根据CPU数量自动设置。</span><br><span class="line">--rest_api_timeout_in_ms &#x3D; 30000  HTTP &#x2F; REST API调用超时。</span><br><span class="line">--enable_batching &#x3D; false bool    启用批处理</span><br><span class="line">--batching_parameters_file &#x3D;“”    字符串如果非空，请从提供的文件名读取ascii BatchingParameters </span><br><span class="line">                                    protobuf，并使用包含的值代替默认值。</span><br><span class="line">--model_config_file &#x3D;“”           字符串如果非空，请从提供的文件名读取ascii ModelServerConfig</span><br><span class="line">                                    协议，然后在该文件中提供模型。此配置文件可用于指定要使用的</span><br><span class="line">                                    多个模型以及其他高级参数，包括非默认版本策略。 </span><br><span class="line">                                   （如果使用了--model_name和--model_base_path，则将被忽略。）</span><br><span class="line">--model_name &#x3D;“ default”          模型的字符串名称（如果设置了--model_config_file标志，则忽略</span><br><span class="line">--model_base_path &#x3D;“”             导出的字符串路径（如果设置了--model_config_file标志，</span><br><span class="line">                                    则忽略该字符串，否则为必需）</span><br><span class="line">--file_system_poll_wait_seconds &#x3D; 1 以秒为单位的两次新模型版本的文件系统每次轮询之间的间隔</span><br><span class="line">--flush_filesystem_caches&#x3D;true bool 如果为true（默认值），则在所有可服务对象的初始加载之后以及</span><br><span class="line">                                      随后的每个可服务对象重新加载之后（如果加载线程数为1），</span><br><span class="line">                                      将刷新文件系统缓存。如果在加载可服务对象之后访问模型文件，</span><br><span class="line">                                      则可以减少模型服务器的内存消耗，并以潜在的高速缓存未命中为                                       代价。</span><br><span class="line">--tensorflow_session_parallelism&#x3D;0  用于运行Tensorflow会话的线程数。默认情况下自动配置。请注意，</span><br><span class="line">                                      如果--platform_config_file为非空，则将忽略此选项。</span><br><span class="line">--ssl_config_file &#x3D;“”               字符串如果非空，请从提供的文件名读取ascii SSLConfig协议</span><br><span class="line">                                      并设置安全的gRPC通道</span><br><span class="line">--platform_config_file &#x3D;“”         字符串如果非空，请从提供的文件名读取ascii PlatformConfigMap </span><br><span class="line">                                      protobuf，然后使用该平台配置而不是Tensorflow平台。 </span><br><span class="line">                                      （如果使用，则--enable_batching将被忽略。）</span><br><span class="line">--per_process_gpu_memory_fraction&#x3D;0.00 float每个进程占用GPU内存空间的分数，</span><br><span class="line">                                         该值介于0.0和1.0之间（默认值为0.0）。如果为1.0，则服务</span><br><span class="line">                                         器将在服务器启动时分配所有内存;如果为0.0，</span><br><span class="line">                                         则Tensorflow将自动选择一个值。</span><br><span class="line">--saved_model_tags &#x3D;“ serve”        字符串对应于要从SavedModel加载的元图def的逗号分隔的标记集。</span><br><span class="line">--grpc_channel_arguments &#x3D;“”        字符串要传递给grpc服务器的参数的逗号分隔列表。 </span><br><span class="line">                                     （例如grpc.max_connection_age_ms &#x3D; 2000）</span><br><span class="line">--enable_model_warmup &#x3D; true bool   启用模型预热，该预热在加载时触发延迟初始化（例如TF优化），</span><br><span class="line">                                      以减少第一个请求的延迟。</span><br><span class="line">--version &#x3D; false bool              显示版本</span><br></pre></td></tr></table></figure>
<p><strong>客户端的编写</strong></p>
<p>基于Python编写客户端时，需要安装tensorflow_serving、grpc库包</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> grpc</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os.path <span class="keyword">as</span> ops</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorflow_serving.apis <span class="keyword">import</span> predict_pb2, prediction_service_pb2_grpc</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">request_server_grpc</span>(<span class="params">img_resized, server_url</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    用于向TensorFlow Serving服务请求推理结果的函数。</span></span><br><span class="line"><span class="string">    :param img_resized: 经过预处理的待推理图片数组，numpy array，shape：(h, w, 3)</span></span><br><span class="line"><span class="string">    :param server_url: TensorFlow Serving的地址加端口，str，如：&#x27;0.0.0.0:8500&#x27; </span></span><br><span class="line"><span class="string">    :return: 模型返回的结果数组，numpy array</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># Request.</span></span><br><span class="line">    channel = grpc.insecure_channel(server_url)</span><br><span class="line">    stub = prediction_service_pb2_grpc.PredictionServiceStub(channel)</span><br><span class="line">    request = predict_pb2.PredictRequest()</span><br><span class="line">    request.model_spec.name = <span class="string">&quot;resnet50_unet&quot;</span>  <span class="comment"># 模型名称，启动容器命令的model_name参数</span></span><br><span class="line">    request.model_spec.signature_name = <span class="string">&quot;serving_default&quot;</span>  <span class="comment"># 签名名称，刚才叫你记下来的</span></span><br><span class="line">    <span class="comment"># &quot;input_1&quot;是你导出模型时设置的输入名称，刚才叫你记下来的</span></span><br><span class="line">    request.inputs[<span class="string">&quot;input_1&quot;</span>].CopyFrom(</span><br><span class="line">        tf.make_tensor_proto(img_resized, shape=[<span class="number">1</span>, ] + <span class="built_in">list</span>(img_resized.shape)))</span><br><span class="line">    <span class="comment"># print(request)</span></span><br><span class="line">    </span><br><span class="line">    response = stub.Predict(request, <span class="number">5.0</span>)  <span class="comment"># 5 secs timeout</span></span><br><span class="line">    <span class="keyword">return</span> np.asarray(response.outputs[<span class="string">&quot;activation_49&quot;</span>].float_val) <span class="comment"># fc2为输出名称，刚才叫你记下来的</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    img=cv2.imread([imgpath_xx],cv2.COLOR_BGR2RGB)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#预处理</span></span><br><span class="line">    res_image=cv2.resize(img,(<span class="number">1024</span>,<span class="number">512</span>))</span><br><span class="line">    res_image = res_image / <span class="number">255</span></span><br><span class="line">    res_image=res_image.astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#向tfs发送请求</span></span><br><span class="line">    port=<span class="string">&#x27;8500&#x27;</span></span><br><span class="line">    server_url = <span class="string">r&#x27;0.0.0.0:&#x27;</span>+port</span><br><span class="line">    response=request_server_grpc(res_image, server_url) <span class="comment">#调用服务端</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#处理返回结果</span></span><br><span class="line">    predict=response.copy()</span><br><span class="line">    <span class="comment">#....后处理</span></span><br></pre></td></tr></table></figure>
<h3 id="web服务"><a class="markdownIt-Anchor" href="#web服务"></a> Web服务</h3>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">TensorFlow模型的计算图，一般输入的类型都是张量，你需要提前把你的图像、文本或者其它数据先进行预处理，转换成张量才能输入到模型当中。而一般来说，这个数据预处理过程不会写进计算图里面，因此当你想使用TensorFlow Serving的时候，需要在客户端上写一大堆数据预处理代码，然后把张量通过gRPC发送到serving，最后接收结果。现实情况是你不可能要求每一个用户都要写一大堆预处理和后处理代码，用户只需使用简单POST一个请求，然后接收最终结果即可。因此，这些预处理和后处理代码必须由一个“中间人”来处理，这个“中间人”就是Web服务。</span><br></pre></td></tr></table></figure>
<p>可以使用Tornado来搭建web服务</p>
<h3 id="版本管理"><a class="markdownIt-Anchor" href="#版本管理"></a> 版本管理</h3>
<p><em>待完善</em></p>
<h2 id="应用例子"><a class="markdownIt-Anchor" href="#应用例子"></a> 应用例子</h2>
<blockquote>
<p>例子来源于美团技术团队<a href="https://tech.meituan.com/2018/10/11/tfserving-improve.html">基于TensorFlow Serving的深度学习在线预估</a></p>
</blockquote>
<p>该例子针对广告精排的业务场景，使用tfs进行模型部署，针对高速的推断进行逐步的优化，并突破现有tfs的束缚，解决模型切换的毛刺问题，使得tfs部署后在性能上满足业务场景</p>
<p><strong>性能优化措施</strong></p>
<ul>
<li>
<p>请求端优化：使用OpenMP多线程并行处理请求，时间从5ms降低到2ms</p>
</li>
<li>
<p>构建模型的ops优化：分析构建模型的ops中的耗时操作，将其分离出去，或者使用低阶API替代高阶API</p>
</li>
<li>
<p>XLA,JIT优化：优化Tensorflow的计算图，剪除荣誉的计算</p>
</li>
</ul>
<p><strong>模型切换毛刺问题</strong></p>
<p>模型切换时，大量的请求超时，原因有两个：一是更新、加载模型和处理请求的线程共用线程池，切换模型时无法处理请求；二是模型采用Lazy Initialization加载，第一次请求需要等待计算图初始化。</p>
<p>问题一的解决办法：</p>
<p>将<code>uint32 num_load_threads = 0; uint32 num_unload_threads = 0;</code>设置为1，</p>
<p>问题2的解决办法：</p>
<p>模型加载后进行一次预热</p>
<p><strong>参考资料</strong></p>
<p><a href="://blog.csdn.net/jeffery0207/article/details/86072456">Tensorflow Serving部署tensorflow、keras模型详解_jeffery0207的博客-CSDN博客</a><br />
<a href="://zhuanlan.zhihu.com/p/52096200">TensorFlow Serving + Docker + Tornado机器学习模型生产级快速部署 - 知乎</a><br />
<a href="://tensorflow.google.cn/tfx/serving/signature_defs?hl=en">SignatureDefs in SavedModel for TensorFlow Serving  |  TFX</a><br />
<a href="://zhuanlan.zhihu.com/p/96917543">使用tensorflow serving部署keras模型（tensorflow 2.0.0） - 知乎</a><br />
<a href="://tech.meituan.com/2018/10/11/tfserving-improve.html">基于TensorFlow Serving的深度学习在线预估 - 美团技术团队</a><br />
<a href="://www.jianshu.com/p/afe80b2ed7f0">TensorFlow Serving入门 - 简书</a><br />
<a href="://blog.csdn.net/weixin_40922744/article/details/102872607">TensorFlow Serving 入门教程（Windows）_I’m George 的博客-CSDN博客</a><br />
<a href="://blog.csdn.net/leiflyy/article/details/110003671">TensorFlow Serving 使用 及 部署_Eric’s Blog-CSDN博客</a></p>
]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title>在Linux上编译带CUDA(GPU)的OpenCV</title>
    <url>/2021/02/05/%E5%A6%82%E4%BD%95%E7%BC%96%E8%AF%91opencv%EF%BC%88%E5%B8%A6cuda%E6%A8%A1%E5%9D%97%EF%BC%89/</url>
    <content><![CDATA[<p>本文介绍编译包含cuda模块的opencv，可以在GPU上完成opencv的操作，加速opencv的处理速度，本文用于记录在Linux上编译opencv的过程、问题</p>
<a id="more"></a>
<p><strong>编译环境</strong>：</p>
<ul>
<li>
<p>系统：Ubuntu 16.04</p>
</li>
<li>
<p>显卡：RTX3090</p>
</li>
<li>
<p>cmake：3.19.3</p>
</li>
<li>
<p>gcc：6.5.0</p>
</li>
</ul>
<blockquote>
<p>注：cmake、gcc系统自带版本不是3.19.3、6.5.0，为解决cmake过程中文件下载问题，升级cmake到3.19.3，但是感觉没有作用；gcc原始是5.x.x，升级之后避免了一些错误，是有效的</p>
</blockquote>
<p><strong>软件依赖</strong>：</p>
<ul>
<li>cuda    11.1</li>
<li>cudnn  8.0.5</li>
</ul>
<p>默认在以上环境下，编译<code>opencv4.4.0</code>，包括C++和Python3的接口。（编译v4.4.0之前，使用v4.2.0进行编译，一直无法找到cudnn，可能是cuda及cudnn版本较高，较低版本的opencv还未适配，所以建议对opencv4.4.0及以上版本进行编译，类似经历出现在<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>）</p>
<h2 id="下载源码"><a class="markdownIt-Anchor" href="#下载源码"></a> 下载源码</h2>
<p>从<a href="https://github.com/opencv/opencv/tags">github</a>下载opencv4.4.0及opencv_contrib-4.4.0</p>
<p>解压后，将opencv_contrib-4.4.0放进opencv4.4.0目录下，并新建编译文件夹（build），文件目录结构如下：</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/PicGo/image-20210205104342803.png" alt="image-20210205104342803" /></p>
<h2 id="安装依赖"><a class="markdownIt-Anchor" href="#安装依赖"></a> 安装依赖</h2>
<blockquote>
<p>以下参考：<a href="https://medium.com/@sb.jaduniv/how-to-install-opencv-4-2-0-with-cuda-10-1-on-ubuntu-20-04-lts-focal-fossa-bdc034109df3">How to install OpenCV 4.2.0 with CUDA 10.1 on Ubuntu 20.04 LTS (Focal Fossa)</a></p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#更新系统</span></span><br><span class="line">sudo apt update</span><br><span class="line">sudo apt upgrade</span><br><span class="line"></span><br><span class="line"><span class="comment">#编译工具</span></span><br><span class="line">sudo apt install build-essential cmake pkg-config unzip yasm git checkinstall</span><br><span class="line"></span><br><span class="line"><span class="comment">#Image I/O libs</span></span><br><span class="line">sudo apt install libjpeg-dev libpng-dev libtiff-dev</span><br><span class="line"></span><br><span class="line"><span class="comment">#Video/Audio Libs — FFMPEG, GSTREAMER, x264 and so on.</span></span><br><span class="line">sudo apt install libavcodec-dev libavformat-dev libswscale-dev libavresample-dev </span><br><span class="line">sudo apt install libgstreamer1.0-dev libgstreamer-plugins-base1.0-dev </span><br><span class="line">sudo apt install libxvidcore-dev x264 libx264-dev libfaac-dev libmp3lame-dev libtheora-dev  </span><br><span class="line">sudo apt install libfaac-dev libmp3lame-dev libvorbis-dev</span><br><span class="line"></span><br><span class="line"><span class="comment">#OpenCore — Adaptive Multi Rate Narrow Band (AMRNB) and Wide Band (AMRWB) speech codec</span></span><br><span class="line">sudo apt install libopencore-amrnb-dev libopencore-amrwb-dev</span><br><span class="line"></span><br><span class="line"><span class="comment">#Cameras programming interface libs</span></span><br><span class="line">sudo apt-get install libdc1394-22 libdc1394-22-dev libxine2-dev libv4l-dev v4l-utils </span><br><span class="line"><span class="built_in">cd</span> /usr/include/linux </span><br><span class="line">sudo ln -s -f ../libv4l1-videodev.h videodev.h </span><br><span class="line"></span><br><span class="line"><span class="comment">#GTK lib for the graphical user functionalites coming from OpenCV highghui module</span></span><br><span class="line">sudo apt-get install libgtk-3-dev</span><br><span class="line"></span><br><span class="line"><span class="comment">#Python libraries for python3（本文安装至conda下，无次步骤）</span></span><br><span class="line">sudo apt-get install python3-dev python3-pip</span><br><span class="line">sudo -H pip3 install -U pip numpy</span><br><span class="line">sudo apt install python3-testresources</span><br><span class="line"></span><br><span class="line"><span class="comment">#Parallelism library C++ for CPU</span></span><br><span class="line">sudo apt-get install libtbb-dev</span><br><span class="line"></span><br><span class="line"><span class="comment">#Optimization libraries for OpenCV</span></span><br><span class="line">sudo apt-get install libatlas-base-dev gfortran</span><br><span class="line"></span><br><span class="line"><span class="comment">#Optional libraries</span></span><br><span class="line">sudo apt-get install libprotobuf-dev protobuf-compiler </span><br><span class="line">sudo apt-get install libgoogle-glog-dev libgflags-dev </span><br><span class="line">sudo apt-get install libgphoto2-dev libeigen3-dev libhdf5-dev doxygen</span><br></pre></td></tr></table></figure>
<h2 id="cmake生成待编译文件"><a class="markdownIt-Anchor" href="#cmake生成待编译文件"></a> cmake生成待编译文件</h2>
<p>进入build目录下，执行以下命令</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cmake -D CMAKE_BUILD_TYPE=RELEASE \</span><br><span class="line">-D CMAKE_INSTALL_PREFIX=/usr/<span class="built_in">local</span> \</span><br><span class="line">-D CMAKE_C_COMPILER=/usr/bin/gcc-6 \</span><br><span class="line">-D INSTALL_PYTHON_EXAMPLES=ON \</span><br><span class="line">-D INSTALL_C_EXAMPLES=ON \</span><br><span class="line">-D OPENCV_ENABLE_NONFREE=ON \</span><br><span class="line">-D BUILD_opencv_python3=ON \</span><br><span class="line">-D WITH_CUDA=ON \</span><br><span class="line">-D WITH_CUDNN=ON \</span><br><span class="line">-D WITH_TBB=ON \</span><br><span class="line">-D OPENCV_DNN_CUDA=ON \</span><br><span class="line">-D ENABLE_FAST_MATH=1 \</span><br><span class="line">-D CUDA_FAST_MATH=1 \</span><br><span class="line">-D CUDA_ARCH_BIN=8.6 \</span><br><span class="line">-D WITH_CUBLAS=1 \</span><br><span class="line">-D OPENCV_GENERATE_PKGCONFIG=ON \</span><br><span class="line">-D OPENCV_EXTRA_MODULES_PATH=/home/xx/soft/opencv_gpu/opencv-4.4.0/opencv_contrib-4.4.0/modules \</span><br><span class="line">-D PYTHON3_EXECUTABLE=/home/xx/anaconda3/envs/py37/bin/python3.7m \</span><br><span class="line">-D PYTHON3_INCLUDE_DIR=/home/xx/anaconda3/envs/py37/include/python3.7m \</span><br><span class="line">-D PYTHON3_LIBRARY=/home/xx/anaconda3/envs/py37/lib/libpython3.7m.so \</span><br><span class="line">-D PYTHON3_NUMPY_INCLUDE_DIRS=/home/xx/anaconda3/envs/py37/lib/python3.7/site-packages/numpy/core/include \</span><br><span class="line">-D PYTHON3_PACKAGES_PATH=/home/xx/anaconda3/envs/py37/lib/python3.7/site-packages \</span><br><span class="line">-D PYTHON_DEFAULT_EXECUTABLE=/home/xx/anaconda3/envs/py37/bin/python3.7m \</span><br><span class="line">-D CUDNN_LIBRARY=/usr/<span class="built_in">local</span>/cuda/lib64/libcudnn.so.8.0.5 \</span><br><span class="line">-D CUDNN_INCLUDE_DIR=/usr/<span class="built_in">local</span>/cuda/include  \</span><br><span class="line">-D CUDA_CUDA_LIBRARY=/usr/<span class="built_in">local</span>/cuda/lib64/stubs/libcuda.so \</span><br><span class="line">-D OPENCV_PYTHON3_INSTALL_PATH=/home/xx/anaconda3/envs/py37/lib/python3.7/site-packages \</span><br><span class="line">-D WITH_WEBP=OFF \</span><br><span class="line">-D WITH_OPENCL=OFF \</span><br><span class="line">-D ETHASHLCL=OFF \</span><br><span class="line">-D ENABLE_CXX11=ON \</span><br><span class="line">-D BUILD_EXAMPLES=OFF \</span><br><span class="line">-D OPENCV_ENABLE_NONFREE=ON \</span><br><span class="line">-D WITH_OPENGL=ON \</span><br><span class="line">-D WITH_GSTREAMER=ON \</span><br><span class="line">-D WITH_V4L=ON \</span><br><span class="line">-D WITH_QT=OFF \</span><br><span class="line">-D BUILD_opencv_python3=ON \</span><br><span class="line">-D BUILD_opencv_python2=OFF \</span><br><span class="line">-D HAVE_opencv_python3=ON   ..</span><br></pre></td></tr></table></figure>
<p><strong>关键参数说明</strong>：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">BUILD_opencv_python3：</span><br><span class="line">CUDA_ARCH_BIN:显卡算力,Nvidia官网查询，RTX3090对应8.6</span><br><span class="line">OPENCV_GENERATE_PKGCONFIG：生成pkg-config，这个务必打开，不然安装成功找不到opencv</span><br></pre></td></tr></table></figure>
<p>cmake后最终确认得到以下输出：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">-- General configuration <span class="keyword">for</span> OpenCV 4.4.0 =====================================</span><br><span class="line">Version control:               unknown</span><br><span class="line">-- </span><br><span class="line">Extra modules:</span><br><span class="line">  Location (extra):            /home/xx/soft/opencv_gpu/opencv-4.4.0/opencv_contrib-4.4.0/modules</span><br><span class="line">  Version control (extra):     unknown</span><br><span class="line">-- </span><br><span class="line">Platform:</span><br><span class="line">  Timestamp:                   2021-02-05T02:31:19Z</span><br><span class="line">  Host:                        Linux 4.15.0-133-generic x86_64</span><br><span class="line">  CMake:                       3.19.3</span><br><span class="line">  CMake generator:             Unix Makefiles</span><br><span class="line">  CMake build tool:            /usr/bin/make</span><br><span class="line">  Configuration:               RELEASE</span><br><span class="line">-- </span><br><span class="line">CPU/HW features:</span><br><span class="line">  Baseline:                    SSE SSE2 SSE3</span><br><span class="line">    requested:                 SSE3</span><br><span class="line">  Dispatched code generation:  SSE4_1 SSE4_2 FP16 AVX AVX2 AVX512_SKX</span><br><span class="line">    requested:                 SSE4_1 SSE4_2 AVX FP16 AVX2 AVX512_SKX</span><br><span class="line">    SSE4_1 (17 files):         + SSSE3 SSE4_1</span><br><span class="line">    SSE4_2 (2 files):          + SSSE3 SSE4_1 POPCNT SSE4_2</span><br><span class="line">    FP16 (1 files):            + SSSE3 SSE4_1 POPCNT SSE4_2 FP16 AVX</span><br><span class="line">    AVX (5 files):             + SSSE3 SSE4_1 POPCNT SSE4_2 AVX</span><br><span class="line">    AVX2 (31 files):           + SSSE3 SSE4_1 POPCNT SSE4_2 FP16 FMA3 AVX AVX2</span><br><span class="line">    AVX512_SKX (7 files):      + SSSE3 SSE4_1 POPCNT SSE4_2 FP16 FMA3 AVX AVX2 AVX_512F AVX512_COMMON AVX512_SKX</span><br><span class="line">-- </span><br><span class="line">C/C++:</span><br><span class="line">  Built as dynamic libs?:      YES</span><br><span class="line">  C++ standard:                11</span><br><span class="line">  C++ Compiler:                /usr/bin/c++  (ver 6.5.0)</span><br><span class="line">  C++ flags (Release):         -fsigned-char -ffast-math -W -Wall -Werror=return-type -Werror=non-virtual-dtor -Werror=address -Werror=sequence-point -Wformat -Werror=format-security -Wmissing-declarations -Wundef -Winit-self -Wpointer-arith -Wshadow -Wsign-promo -Wuninitialized -Winit-self -Wno-psabi -Wsuggest-override -Wno-delete-non-virtual-dtor -Wno-comment -fdiagnostics-show-option -Wno-long-long -pthread -fomit-frame-pointer -ffunction-sections -fdata-sections  -msse -msse2 -msse3 -fvisibility=hidden -fvisibility-inlines-hidden -O3 -DNDEBUG  -DNDEBUG</span><br><span class="line">  C++ flags (Debug):           -fsigned-char -ffast-math -W -Wall -Werror=return-type -Werror=non-virtual-dtor -Werror=address -Werror=sequence-point -Wformat -Werror=format-security -Wmissing-declarations -Wundef -Winit-self -Wpointer-arith -Wshadow -Wsign-promo -Wuninitialized -Winit-self -Wno-psabi -Wsuggest-override -Wno-delete-non-virtual-dtor -Wno-comment -fdiagnostics-show-option -Wno-long-long -pthread -fomit-frame-pointer -ffunction-sections -fdata-sections  -msse -msse2 -msse3 -fvisibility=hidden -fvisibility-inlines-hidden -g  -O0 -DDEBUG -D_DEBUG</span><br><span class="line">  C Compiler:                  /usr/bin/gcc-6</span><br><span class="line">  C flags (Release):           -fsigned-char -ffast-math -W -Wall -Werror=return-type -Werror=non-virtual-dtor -Werror=address -Werror=sequence-point -Wformat -Werror=format-security -Wmissing-declarations -Wmissing-prototypes -Wstrict-prototypes -Wundef -Winit-self -Wpointer-arith -Wshadow -Wuninitialized -Winit-self -Wno-psabi -Wno-comment -fdiagnostics-show-option -Wno-long-long -pthread -fomit-frame-pointer -ffunction-sections -fdata-sections  -msse -msse2 -msse3 -fvisibility=hidden -O3 -DNDEBUG  -DNDEBUG</span><br><span class="line">  C flags (Debug):             -fsigned-char -ffast-math -W -Wall -Werror=return-type -Werror=non-virtual-dtor -Werror=address -Werror=sequence-point -Wformat -Werror=format-security -Wmissing-declarations -Wmissing-prototypes -Wstrict-prototypes -Wundef -Winit-self -Wpointer-arith -Wshadow -Wuninitialized -Winit-self -Wno-psabi -Wno-comment -fdiagnostics-show-option -Wno-long-long -pthread -fomit-frame-pointer -ffunction-sections -fdata-sections  -msse -msse2 -msse3 -fvisibility=hidden -g  -O0 -DDEBUG -D_DEBUG</span><br><span class="line">  Linker flags (Release):      -Wl,--gc-sections -Wl,--as-needed  </span><br><span class="line">  Linker flags (Debug):        -Wl,--gc-sections -Wl,--as-needed  </span><br><span class="line">  ccache:                      NO</span><br><span class="line">  Precompiled headers:         NO</span><br><span class="line">  Extra dependencies:          m pthread cudart_static dl rt nppc nppial nppicc nppidei nppif nppig nppim nppist nppisu nppitc npps cublas cudnn cufft -L/usr/<span class="built_in">local</span>/cuda/lib64 -L/usr/lib/x86_64-linux-gnu</span><br><span class="line">  3rdparty dependencies:</span><br><span class="line">-- </span><br><span class="line">OpenCV modules:</span><br><span class="line">  To be built:                 alphamat aruco bgsegm bioinspired calib3d ccalib core cudaarithm cudabgsegm cudacodec cudafeatures2d cudafilters cudaimgproc cudalegacy cudaobjdetect cudaoptflow cudastereo cudawarping cudev datasets dnn dnn_objdetect dnn_superres dpm face features2d flann freetype fuzzy gapi hdf hfs highgui img_hash imgcodecs imgproc intensity_transform line_descriptor ml objdetect optflow phase_unwrapping photo plot python3 quality rapid reg rgbd saliency sfm shape stereo stitching structured_light superres surface_matching text tracking ts video videoio videostab xfeatures2d ximgproc xobjdetect xphoto</span><br><span class="line">  Disabled:                    python2 world</span><br><span class="line">  Disabled by dependency:      -</span><br><span class="line">  Unavailable:                 cnn_3dobj cvv java js julia matlab ovis viz</span><br><span class="line">  Applications:                tests perf_tests apps</span><br><span class="line">  Documentation:               NO</span><br><span class="line">  Non-free algorithms:         YES</span><br><span class="line">-- </span><br><span class="line">GUI: </span><br><span class="line">  GTK+:                        YES (ver 3.18.9)</span><br><span class="line">    GThread :                  YES (ver 2.48.2)</span><br><span class="line">    GtkGlExt:                  NO</span><br><span class="line">  OpenGL support:              NO</span><br><span class="line">  VTK support:                 NO</span><br><span class="line">-- </span><br><span class="line">Media I/O: </span><br><span class="line">  ZLib:                        /usr/lib/x86_64-linux-gnu/libz.so (ver 1.2.8)</span><br><span class="line">  JPEG:                        /usr/lib/x86_64-linux-gnu/libjpeg.so (ver 80)</span><br><span class="line">  PNG:                         /usr/lib/x86_64-linux-gnu/libpng.so (ver 1.2.54)</span><br><span class="line">  TIFF:                        /usr/lib/x86_64-linux-gnu/libtiff.so (ver 42 / 4.0.6)</span><br><span class="line">  JPEG 2000:                   OpenJPEG (ver 2.4.0)</span><br><span class="line">  OpenEXR:                     build (ver 2.3.0)</span><br><span class="line">  HDR:                         YES</span><br><span class="line">  SUNRASTER:                   YES</span><br><span class="line">  PXM:                         YES</span><br><span class="line">  PFM:                         YES</span><br><span class="line">-- </span><br><span class="line">Video I/O:</span><br><span class="line">  DC1394:                      YES (2.2.4)</span><br><span class="line">  FFMPEG:                      YES</span><br><span class="line">    avcodec:                   YES (56.60.100)</span><br><span class="line">    avformat:                  YES (56.40.101)</span><br><span class="line">    avutil:                    YES (54.31.100)</span><br><span class="line">    swscale:                   YES (3.1.101)</span><br><span class="line">    avresample:                YES (2.1.0)</span><br><span class="line">  GStreamer:                   YES (1.8.3)</span><br><span class="line">  v4l/v4l2:                    YES (linux/videodev2.h)</span><br><span class="line">-- </span><br><span class="line">Parallel framework:            TBB (ver 4.4 interface 9002)</span><br><span class="line">-- </span><br><span class="line">Trace:                         YES (with Intel ITT)</span><br><span class="line">-- </span><br><span class="line">Other third-party libraries:</span><br><span class="line">  Lapack:                      YES (/usr/lib/libopenblas.so)</span><br><span class="line">  Eigen:                       YES (ver 3.2.92)</span><br><span class="line">  Custom HAL:                  NO</span><br><span class="line">  Protobuf:                    build (3.5.1)</span><br><span class="line">-- </span><br><span class="line">NVIDIA CUDA:                   YES (ver 11.1, CUFFT CUBLAS FAST_MATH)</span><br><span class="line">  NVIDIA GPU arch:             86</span><br><span class="line">  NVIDIA PTX archs:</span><br><span class="line">-- </span><br><span class="line">cuDNN:                         YES (ver 8.0.5)</span><br><span class="line">-- </span><br><span class="line">Python 3:</span><br><span class="line">  Interpreter:                 /home/xx/anaconda3/envs/py37/bin/python3.7m (ver 3.7.9)</span><br><span class="line">  Libraries:                   /home/xx/anaconda3/envs/py37/lib/libpython3.7m.so (ver 3.7.9)</span><br><span class="line">  numpy:                       /home/xx/anaconda3/envs/py37/lib/python3.7/site-packages/numpy/core/include (ver 1.19.2)</span><br><span class="line">  install path:                /home/xx/anaconda3/envs/py37/lib/python3.7/site-packages/cv2/python-3.7</span><br><span class="line">-- </span><br><span class="line">Python (<span class="keyword">for</span> build):            /home/xx/anaconda3/envs/py37/bin/python3.7m</span><br><span class="line">-- </span><br><span class="line">Java:                          </span><br><span class="line">  ant:                         NO</span><br><span class="line">  JNI:                         NO</span><br><span class="line">  Java wrappers:               NO</span><br><span class="line">  Java tests:                  NO</span><br><span class="line">-- </span><br><span class="line">Install to:                    /usr/<span class="built_in">local</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<blockquote>
<p>注：系统用户名使用<code>xx</code>替代</p>
</blockquote>
<h2 id="gcc编译"><a class="markdownIt-Anchor" href="#gcc编译"></a> gcc编译</h2>
<p>在build目录下执行以下命令</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">make -j16</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注：虽然直接make出问题的概率更小，但是为了加速编译速度，这里指使用16个多线程进行编译，这里多线程数量一般不大于CPU核心数，可以通过<code>nproc</code>命令查看CPU核心数。<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup></p>
</blockquote>
<h2 id="安装到系统"><a class="markdownIt-Anchor" href="#安装到系统"></a> 安装到系统</h2>
<p>在build目录下执行以下命令</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo make install</span><br></pre></td></tr></table></figure>
<h2 id="配置环境变量"><a class="markdownIt-Anchor" href="#配置环境变量"></a> 配置环境变量</h2>
<p>执行以下命令</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo /bin/bash -c <span class="string">&#x27;echo &quot;/usr/local/lib&quot; &gt;&gt; /etc/ld.so.conf.d/opencv.conf&#x27;</span></span><br><span class="line">sudo ldconfig</span><br></pre></td></tr></table></figure>
<p>如果想将opencv安装到Python，建议在cmake编译参数中使用<code>-D OPENCV_PYTHON3_INSTALL_PATH</code>指定安装目录</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">-D OPENCV_PYTHON3_INSTALL_PATH=/home/xx/anaconda3/envs/py37/lib/python3.7/site-packages \</span><br></pre></td></tr></table></figure>
<h2 id="查看opencv是否安装成功"><a class="markdownIt-Anchor" href="#查看opencv是否安装成功"></a> 查看opencv是否安装成功</h2>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pkg-config --modversion opencv</span><br><span class="line">pkg-config --libs opencv4</span><br></pre></td></tr></table></figure>
<h2 id="编译过程遇到的问题"><a class="markdownIt-Anchor" href="#编译过程遇到的问题"></a> 编译过程遇到的问题</h2>
<p>编译opencv主要有两个过程，cmake和make，错误主要出现在cmake阶段，根据出现的错误情况，主要分为以下几类</p>
<h3 id="下载失败"><a class="markdownIt-Anchor" href="#下载失败"></a> 下载失败</h3>
<p>cmake过程中，需要下载的文件会放在opencv4.4.0下的隐藏目录<code>.cache</code>下，如果下载失败，可以手动下载，放入相应目录解决。</p>
<p><strong>xfeatures2d</strong><sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">boostdesc_bgm.i</span><br><span class="line">boostdesc_bgm_bi.i</span><br><span class="line">boostdesc_bgm_hd.i</span><br><span class="line">boostdesc_lbgm.i</span><br><span class="line">boostdesc_binboost_064.i</span><br><span class="line">boostdesc_binboost_128.i</span><br><span class="line">boostdesc_binboost_256.i</span><br><span class="line">vgg_generated_120.i</span><br><span class="line">vgg_generated_64.i</span><br><span class="line">vgg_generated_80.i</span><br><span class="line">vgg_generated_48.i</span><br></pre></td></tr></table></figure>
<p>进入opencv4.4.0下的隐藏目录<code>.cache/xfeatures2d</code>，执行以下命令解决：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> boostdesc</span><br><span class="line">curl https://raw.githubusercontent.com/opencv/opencv_3rdparty/34e4206aef44d50e6bbcd0ab06354b52e7466d26/boostdesc_lbgm.i &gt; 0ae0675534aa318d9668f2a179c2a052-boostdesc_lbgm.i</span><br><span class="line">curl https://raw.githubusercontent.com/opencv/opencv_3rdparty/34e4206aef44d50e6bbcd0ab06354b52e7466d26/boostdesc_binboost_256.i &gt; e6dcfa9f647779eb1ce446a8d759b6ea-boostdesc_binboost_256.i</span><br><span class="line">curl https://raw.githubusercontent.com/opencv/opencv_3rdparty/34e4206aef44d50e6bbcd0ab06354b52e7466d26/boostdesc_binboost_128.i &gt; 98ea99d399965c03d555cef3ea502a0b-boostdesc_binboost_128.i</span><br><span class="line">curl https://raw.githubusercontent.com/opencv/opencv_3rdparty/34e4206aef44d50e6bbcd0ab06354b52e7466d26/boostdesc_binboost_064.i &gt; 202e1b3e9fec871b04da31f7f016679f-boostdesc_binboost_064.i</span><br><span class="line">curl https://raw.githubusercontent.com/opencv/opencv_3rdparty/34e4206aef44d50e6bbcd0ab06354b52e7466d26/boostdesc_bgm_hd.i &gt; 324426a24fa56ad9c5b8e3e0b3e5303e-boostdesc_bgm_hd.i</span><br><span class="line">curl https://raw.githubusercontent.com/opencv/opencv_3rdparty/34e4206aef44d50e6bbcd0ab06354b52e7466d26/boostdesc_bgm_bi.i &gt; 232c966b13651bd0e46a1497b0852191-boostdesc_bgm_bi.i</span><br><span class="line">curl https://raw.githubusercontent.com/opencv/opencv_3rdparty/34e4206aef44d50e6bbcd0ab06354b52e7466d26/boostdesc_bgm.i &gt; 0ea90e7a8f3f7876d450e4149c97c74f-boostdesc_bgm.i</span><br><span class="line"><span class="built_in">cd</span> vgg</span><br><span class="line">curl https://raw.githubusercontent.com/opencv/opencv_3rdparty/fccf7cd6a4b12079f73bbfb21745f9babcd4eb1d/vgg_generated_120.i &gt; 151805e03568c9f490a5e3a872777b75-vgg_generated_120.i</span><br><span class="line">curl https://raw.githubusercontent.com/opencv/opencv_3rdparty/fccf7cd6a4b12079f73bbfb21745f9babcd4eb1d/vgg_generated_64.i &gt; 7126a5d9a8884ebca5aea5d63d677225-vgg_generated_64.i</span><br><span class="line">curl https://raw.githubusercontent.com/opencv/opencv_3rdparty/fccf7cd6a4b12079f73bbfb21745f9babcd4eb1d/vgg_generated_48.i &gt; e8d0dcd54d1bcfdc29203d011a797179-vgg_generated_48.i</span><br><span class="line">curl https://raw.githubusercontent.com/opencv/opencv_3rdparty/fccf7cd6a4b12079f73bbfb21745f9babcd4eb1d/vgg_generated_80.i &gt; 7cd47228edec52b6d82f46511af325c5-vgg_generated_80.i</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注：如何curl无法下载，可以通过浏览器挨个下载，并按照以上进行命名各文件</p>
</blockquote>
<p><strong>ippicv</strong></p>
<p>手动从<a href="https://link.jianshu.com/?t=https%3A%2F%2Fraw.githubusercontent.com%2FItseez%2Fopencv_3rdparty%2F81a676001ca8075ada498583e4166079e5744668%2Fippicv%2Fippicv_linux_20151201.tgz">github</a>下载，放入<code>.cache/ppicv</code>目录下</p>
<p>**face_landmark_model.dat **</p>
<p>手动从<a href="https://raw.githubusercontent.com/opencv/opencv_3rdparty/8afa57abc8229d611c4937165d20e2a2d9fc5a12/face_landmark_model.dat">github</a>下载，放入<code>.cache/data</code>目录下，注意文件名前部是该文件的md5值，可以通过命令<code>md5sum file</code>计算该值</p>
<h3 id="软件未安装not-found"><a class="markdownIt-Anchor" href="#软件未安装not-found"></a> 软件未安装（Not Found）</h3>
<p>此类错误比较简单，缺什么安装什么，比如安装过程中遇到以下缺失软件的解决办法</p>
<p><strong>tesserocr安装失败</strong><sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo apt-get install libleptonica-dev libtesseract-dev</span><br><span class="line">python -m pip install tesserocr</span><br></pre></td></tr></table></figure>
<p><strong>lapacke.h缺失</strong><sup class="footnote-ref"><a href="#fn5" id="fnref5">[5]</a></sup></p>
<p>明明已经按照该软件，但是OpenBLAS一致没找到该文件，但是搜索文件发现该文件在<code>/usr/include/</code>下，只能手动拷贝<code>ls /usr/include/lapacke*</code>文件至<code>/usr/include/openblas/</code>目录下</p>
<p><strong>Could NOT find CUDNN: Found unsuitable version “…”, but required is at least “7.5” (found /usr/local/cuda-10.2/lib64/libcudnn.so)</strong></p>
<p>这是在编译opencv4.2.0时出现的错误，实际已经安装cudnn，也满足7.5以上的要求，但是就是找不，可以在cmake中加入参数：<code>-D CUDNN_VERSION='8.0'</code>解决<sup class="footnote-ref"><a href="#fn1" id="fnref1:1">[1:1]</a></sup>，但是后续还会遇到其他问题，编译opencv4.4.0时，该问题不再出现</p>
<p><strong>No package ‘gtk±3.0’ found</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo apt-get install libgtk-3-dev</span><br></pre></td></tr></table></figure>
<h2 id="卸载opencv"><a class="markdownIt-Anchor" href="#卸载opencv"></a> 卸载opencv</h2>
<p>通过源码安装的opencv，可以进入编译目录下（build）执行以下命令，卸载opencv</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo make uninstall</span><br></pre></td></tr></table></figure>
<h2 id="使用cuda模块的简单例子"><a class="markdownIt-Anchor" href="#使用cuda模块的简单例子"></a> 使用cuda模块的简单例子</h2>
<p>查看opencv的cuda模块支持的功能，进入python终端，输入以下命令</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="built_in">dir</span>(cv2.cuda)</span><br><span class="line"><span class="built_in">dir</span>(cv2.cuda_GpuMat())</span><br></pre></td></tr></table></figure>
<p>例子：在GPU做resize</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#读取图片</span></span><br><span class="line">frame=cv2.imread(<span class="string">&#x27;test.jpg&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#上传到gpu进行处理</span></span><br><span class="line">gpu_frame=cv2.cuda_GpuMat()</span><br><span class="line">gpu_frame.upload(frame)</span><br><span class="line">print(gpu_frame.cudaPtr())</span><br><span class="line"></span><br><span class="line"><span class="comment">#resize</span></span><br><span class="line">gpu_resframe=cv2.cuda.resize(gpu_frame,(<span class="number">1024</span>,<span class="number">512</span>))</span><br><span class="line">cpu_resfram=gpu_resframe.download()</span><br><span class="line">print(cpu_resfram.shape)</span><br></pre></td></tr></table></figure>
<hr class="footnotes-sep" />
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p><a href="https://blog.csdn.net/qq_33475105/article/details/111659692">Jetson Nano编译安装opencv4.3.0并使能cuDNN加速</a> <a href="#fnref1" class="footnote-backref">↩︎</a> <a href="#fnref1:1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn2" class="footnote-item"><p><a href="https://www.codenong.com/cs109055604/">Ubuntu20.04+GeForce RTX 2080 SUPER+cuda11.1+cudnn8.0.4+openCV4.4.0编译</a> <a href="#fnref2" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn3" class="footnote-item"><p><a href="https://blog.csdn.net/zhongqli/article/details/112212072">Opencv-3.4.0编译时报错缺少boostdesc_bgm.i等文件</a> <a href="#fnref3" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn4" class="footnote-item"><p><a href="https://stackoverflow.com/questions/43486636/error-while-trying-to-install-tesserocr/">error while trying to install tesserocr</a> <a href="#fnref4" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn5" class="footnote-item"><p><a href="https://github.com/opencv/opencv/issues/9953">Building against OpenBLAS complains about missing lapacke.h</a> <a href="#fnref5" class="footnote-backref">↩︎</a></p>
</li>
</ol>
</section>
]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>cuda</tag>
        <tag>opencv</tag>
        <tag>机器视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>如何释放Linux存储空间</title>
    <url>/2021/02/06/%E5%A6%82%E4%BD%95%E9%87%8A%E6%94%BELinux%E5%AD%98%E5%82%A8%E7%A9%BA%E9%97%B4/</url>
    <content><![CDATA[<p>由于服务器上存储空间即将用完，不得不需要释放新的空间，及挂载新的硬盘，本文展示如何在Linux查看硬盘情况，释放硬盘空间及挂载新的硬盘</p>
<a id="more"></a>
<h2 id="查看当前硬盘情况"><a class="markdownIt-Anchor" href="#查看当前硬盘情况"></a> 查看当前硬盘情况<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup></h2>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">df -lh</span><br></pre></td></tr></table></figure>
<p>查看当前挂载的硬盘</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">fdisk -l</span><br></pre></td></tr></table></figure>
<p><strong>释放空间</strong></p>
<p>通过以下命令逐级搜索Linux目录，找出占用空间的最大的文件，将其删除或移除</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">du --max-depth&#x3D;1 -lh</span><br></pre></td></tr></table></figure>
<h2 id="格式化分区"><a class="markdownIt-Anchor" href="#格式化分区"></a> 格式化分区</h2>
<p>在linux上挂载新硬盘前，尽量使用ext4格式，所以不是该格式的建议提前先格式化（格式化时需提前卸载硬盘）</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkfs.ext4 /dev/sda1</span><br></pre></td></tr></table></figure>
<p>ext4格式的硬盘下，经常能看见 系统创建的lost+found的文件夹<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup></p>
<ul>
<li>通常是未链接的文件（名字已经被删除），但是这些文件还被一些进程使用（数据没有删除），在突然关机时（内核panic或者突然断电）出现，这些文件系统会自动删除。</li>
<li>当因为软件或者硬件出现错误，导致文件系统不一致，也有可能把有问题的文件放到lost+found目录。它提供了恢复丢失文件的一种方法</li>
<li>如果你不小心删除了lost+found目录，不能使用mkdir命令创建lost+found目录，应该使用mklost+found命令创建它</li>
</ul>
<h2 id="挂载硬盘"><a class="markdownIt-Anchor" href="#挂载硬盘"></a> 挂载硬盘</h2>
<p>使用以下命令将新硬盘挂载到系统上</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mount /dev/sda1 /mnt</span><br></pre></td></tr></table></figure>
<p><strong>开机挂载硬盘</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim /etc/fatab</span><br></pre></td></tr></table></figure>
<p>在该文件内添加一行，指明待加载的硬盘<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup></p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/PicGo/image-20210205155011394.png" alt="image-20210205155011394" /></p>
<p>参数解释：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">要挂载的设备或伪文件系统：设备文件、LABEL(LABEL&#x3D;&quot;&quot;)、UUID(UUID&#x3D;&quot;&quot;)、伪文件系统名称(proc, sysfs)</span><br><span class="line">挂载点：指定的文件夹</span><br><span class="line">挂载选项：defaults</span><br><span class="line">转储频率：0：不做备份;1：每天转储;2：每隔一天转储</span><br><span class="line">自检次序：0：不自检；1：首先自检；一般只有rootfs才用1；</span><br></pre></td></tr></table></figure>
<h2 id="卸载磁盘"><a class="markdownIt-Anchor" href="#卸载磁盘"></a> 卸载磁盘</h2>
<p>通过以下命令卸载磁盘</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">umount /dev/sda1或/mnt</span><br></pre></td></tr></table></figure>
<p>查看分区的uuid<sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">blkid</span><br></pre></td></tr></table></figure>
<p><strong>对挂载及挂载点的理解</strong><sup class="footnote-ref"><a href="#fn3" id="fnref3:1">[3:1]</a></sup></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">根文件系统之外的其他文件要想能够被访问，都必须通过“关联”至根文件系统上的某个目录来实现，此关联操作即为“挂载”，此目录即为“挂载点”,解除此关联关系的过程称之为“卸载”</span><br></pre></td></tr></table></figure>
<ol>
<li>挂载：根文件系统外通过关联至根文件系统上的某个目录来实现访问</li>
<li>挂载点：mount_point，用于作为另一个文件系统的访问入口</li>
</ol>
<p>挂载点必须满足以下要求：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">(1) 事先存在；</span><br><span class="line">(2) 应该使用未被或不会被其它进程使用到的目录；</span><br><span class="line">(3) 挂载点下原有的文件将会被隐藏；</span><br></pre></td></tr></table></figure>
<hr class="footnotes-sep" />
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p>Linux下挂载机械硬盘(<a href="https://blog.csdn.net/m0_37407756/article/details/79529399">https://blog.csdn.net/m0_37407756/article/details/79529399</a>) <a href="#fnref1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn2" class="footnote-item"><p><a href="https://www.cnblogs.com/cheyunhua/p/14158174.html">Linux系统中根目录下或者新挂载的磁盘目录下有一个叫lost+found，它的作用是什么？</a> <a href="#fnref2" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn3" class="footnote-item"><p><a href="https://www.linuxidc.com/linux/2016-08/134666.htm">Linux基础知识之挂载详解（mount,umount及开机自动挂载）</a> <a href="#fnref3" class="footnote-backref">↩︎</a> <a href="#fnref3:1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn4" class="footnote-item"><p><a href="https://www.linuxprobe.com/partition-file-system.html">Linux查看分区文件系统类型的几种方法</a> <a href="#fnref4" class="footnote-backref">↩︎</a></p>
</li>
</ol>
</section>
]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>安装windows和linux双系统备忘录</title>
    <url>/2016/06/01/%E5%AE%89%E8%A3%85windows%E5%92%8Clinux%E5%8F%8C%E7%B3%BB%E7%BB%9F%E5%A4%87%E5%BF%98%E5%BD%95/</url>
    <content><![CDATA[<p>本文针对安装windows和linux双系统的流程进行梳理，汇集两个系统上常用的软件，并针对出错的问题进行记录</p>
<a id="more"></a>
<h2 id="安装过程"><a class="markdownIt-Anchor" href="#安装过程"></a> 安装过程</h2>
<p>略</p>
<h2 id="使用软件"><a class="markdownIt-Anchor" href="#使用软件"></a> 使用软件</h2>
<table>
<thead>
<tr>
<th>Windows</th>
<th>Ubuntu</th>
</tr>
</thead>
<tbody>
<tr>
<td>备份数据-》清理硬盘-》安装系统-》卸载多余的东西-》升级win10-》安装软件-》登录各软件帐号-》拷贝数据回本机</td>
<td>刻录U盘-》安装系统-》更新源-》安装软件-》美化</td>
</tr>
</tbody>
</table>
<p>Windows:</p>
<blockquote>
<p>必装：<br />
上网：校园网（<a href="http://dr.com">dr.com</a>)<br />
杀毒软件：电脑管家<br />
笔记：印象笔记<br />
社交：QQ轻聊版<br />
办公：word 2016(破解工具：KMSpico Install)<br />
浏览器：谷歌(<a href="mailto:wushaogui123@gmail.com">wushaogui123@gmail.com</a>)/360极速(15878192524)<br />
网盘：百度网盘<br />
解压工具：闪电压缩<br />
编辑工具：sublime/notepad++<br />
音乐：网易云音乐(<a href="mailto:wushaogui2014@126.com">wushaogui2014@126.com</a>)<br />
截图：Fast stone<br />
翻墙：lantern<br />
驱动：驱动人生<br />
虚拟镜像：Daemon_Tools_Lite<br />
英语词典：有道<br />
选装：<br />
视频：腾讯视频/优酷<br />
购物：阿里旺旺<br />
模拟器：VMwareworkstation_full<br />
U盘刻录工具：UltraISO_cn<br />
思维导图：mini8/visio<br />
画网络图：Cytoscape<br />
Markdown:马克飞象/小书匠<br />
修图工具：Adobe CC 2015 64位<br />
数学工具：Matlab R2016b<br />
游戏和软件：stream<br />
系统工具：CPU-Z<br />
编程类：<br />
C:C-free<br />
R:R+R studio<br />
python:pycham<br />
java:jdk+eclipse<br />
scala:ideaIC</p>
</blockquote>
<p>Ubuntu:<br />
每次安装完Ubuntu后都到网上找别人的“ubuntu安装后需要做的事情”，麻烦得很，现状结合自己的需求将安装完ubuntu后，还原之前工作状态的过程记录下来，以备不时之需！</p>
<p>系统语言的更换-&gt;源的更换与系统的更新-&gt;输入法的安装-&gt;应用的安装-&gt;其他配置</p>
<blockquote>
<p>输入法：搜狗输入法</p>
<p>浏览器：火狐浏览器/Vivaldi<br />
办公：wps</p>
<p>思维导图：Xmind8<br />
音乐：网易云音乐<br />
翻墙：lantern(<a href="https://raw.githubusercontent.com/getlantern/lantern-binaries/master/lantern-installer-beta-64-bit.deb">https://raw.githubusercontent.com/getlantern/lantern-binaries/master/lantern-installer-beta-64-bit.deb</a>) / Shadowsocks-Qt5<br />
画网络图：Cytoscape<br />
英语词典：有道<br />
备份：坚果云<br />
壁纸：variety<br />
天气:gis-weather<br />
截图工具：shutter<br />
系统清理：stacer<br />
屏幕录制工具(gif):peek<br />
屏幕录制:kazam<br />
makedown:typroa/小书匠<br />
文档管理：Zotero/mendeley</p>
<p>PDF阅读器：Foxit Reader</p>
<p>相册管理：Pix相册</p>
<p>邮件：雷鸟邮件</p>
<p>Windows软件模拟工具：crossover（QQ/微信）  独立的Wine-QQ与Wechat<br />
服务器文档编辑：vim/notepadqq<br />
编程类：VS/sublime3/git</p>
<p>远程桌面工具：TeamViewer</p>
<p>视频播放器：VLC</p>
<p>終端：zsh</p>
</blockquote>
<blockquote>
<p><strong>升级Ubuntu系统</strong>：<br />
ubuntu14…10怎么升级到ubuntu15.04_百度经验</p>
<p>安装Ubuntu要做的事：<br />
安装Ubuntu 16.04后要做的事 - skykingf的专栏 - 博客频道 - <a href="http://CSDN.NET">CSDN.NET</a></p>
<p><strong>美化：</strong><br />
ubuntu16.04主题美化和软件推荐 - ZeeCoder - 博客频道 - <a href="http://CSDN.NET">CSDN.NET</a></p>
<p><strong>其他问题：</strong></p>
<ul>
<li>
<p>升级过程遇到boot空间不足：<br />
Ubuntu升级出现/boot空间不足解决 - 海涛的CSDN博客 - 博客频道 - <a href="http://CSDN.NET">CSDN.NET</a></p>
</li>
<li>
<p>更换控制台语言：</p>
</li>
<li>
<p>改变ubuntu终端显示语言（桌面系统是中文，终端提示是英文） - Linux系统教程<br />
字体安装：</p>
</li>
<li>
<p>linux终端中最漂亮的几款字体介绍及安装 - 郭大侠的专栏 - 博客频道 - <a href="http://CSDN.NET">CSDN.NET</a></p>
</li>
<li>
<p>网易云音乐无法启动：</p>
</li>
<li>
<p>zsh-通配符问题<br />
-&gt;在~/.zshrc文件中加入下面的设置<br />
setopt nonomatch</p>
</li>
<li>
<p>WPS for Linux提示“系统缺失字体symbol、wingdings、wingdings dinphy - 孜_行 | 小知识，大家享，你也行</p>
</li>
<li>
<p>设置开机启动:<br />
<a href="http://os.51cto.com/art/201508/487326.htm">http://os.51cto.com/art/201508/487326.htm</a><br />
<a href="http://blog.csdn.net/ocgcn2010/article/details/43260705">http://blog.csdn.net/ocgcn2010/article/details/43260705</a></p>
</li>
</ul>
</blockquote>
]]></content>
      <categories>
        <category>软件工具</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Windows</tag>
      </tags>
  </entry>
  <entry>
    <title>对中国身份证的了解（大陆、香港、澳门、台湾）</title>
    <url>/2019/12/15/%E5%AF%B9%E4%B8%AD%E5%9B%BD%E8%BA%AB%E4%BB%BD%E8%AF%81%E7%9A%84%E4%BA%86%E8%A7%A3%EF%BC%88%E5%A4%A7%E9%99%86%E3%80%81%E9%A6%99%E6%B8%AF%E3%80%81%E6%BE%B3%E9%97%A8%E3%80%81%E5%8F%B0%E6%B9%BE%EF%BC%89/</url>
    <content><![CDATA[<p>本文在了解较多资料的情况下，总结中国现行的四类身份证（祖国大陆、香港、澳门、台湾）相关知识，包括身份证图解、编码规则、编码匹配校验、编码正确性校验等知识。</p>
<p>注：由于政策的改变，本文总结的身份证编码规则可能失效，查看时请留意当时政策变化。</p>
<a id="more"></a>
<h1 id="身份证图解"><a class="markdownIt-Anchor" href="#身份证图解"></a> 身份证图解</h1>
<h2 id="大陆身份证号码"><a class="markdownIt-Anchor" href="#大陆身份证号码"></a> 大陆身份证号码</h2>
<h3 id="号码构成"><a class="markdownIt-Anchor" href="#号码构成"></a> 号码构成</h3>
<blockquote>
<p>身份证号码共18位，由17位本体码和1位校验码组成:<br />
1.前1、2位数字表示：所在省份的代码；<br />
2.第3、4位数字表示：所在城市的代码；<br />
3.第5、6位数字表示：所在区县的代码；<br />
4.第7~14位数字表示：出生年、月、日；<br />
5.第15、16位数字表示：所在地的派出所的代码；<br />
6.第17位数字表示性别：奇数表示男性，偶数表示女性；<br />
7.第18位数字是校检码：也有的说是个人信息码，一般是随计算机的随机产生，用来检验身份证的正确性。校检码可以是0~9的数字，有时也用x表示。</p>
</blockquote>
<h3 id="一代身份证与二代身份证差别"><a class="markdownIt-Anchor" href="#一代身份证与二代身份证差别"></a> 一代身份证与二代身份证差别</h3>
<blockquote>
<p>1.一代身份证是15位，二代身份证是18位；<br />
2.一代身份证出生年月日采用YYMMDD格式，二代身份证出生年月日采用YYYYMMDD格式；</p>
</blockquote>
<ol start="3">
<li>一代身份证无校验码，二代身份证有校验码。</li>
</ol>
<h2 id="香港身份证号码"><a class="markdownIt-Anchor" href="#香港身份证号码"></a> 香港身份证号码</h2>
<h3 id="号码构成-2"><a class="markdownIt-Anchor" href="#号码构成-2"></a> 号码构成</h3>
<blockquote>
<p>由三部分组成：一个英文字母；6个数字；括号及0-9中的任一个数字，或者字母A。括号中的数字或字母A，是校验码，用于检验括号前面的号码的逻辑正确性，如：A123456(7)</p>
</blockquote>
<h3 id="其他香港身份证知识"><a class="markdownIt-Anchor" href="#其他香港身份证知识"></a> 其他香港身份证知识</h3>
<blockquote>
<p>1.香港人在中国大陆的公民身份号码地址码使用810000开头。大陆发给他们的居住证与大陆人的身份证外观相同，使用功能相同<br />
2.香港身份证由香港特别行政区入境事务处签发，为香港居民的主要身份证明文件。凡年满11岁或在香港逗留多于180天人士，必须于年满11岁后或抵港30天内登记领取身份证。</p>
</blockquote>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613546736791.png" alt="香港身份证样卡" /></p>
<p><strong>身份证上的符号解释：</strong></p>
<blockquote>
<p>1.在姓名下方的数字串，是姓名的中文电报号码，代表中文姓名，比如2621 =李，2535=智，5174=能。<br />
2.在出生日期右边是性别：女F，男M。F代表女，M代表男。<br />
3.在签发日期的下方，分别为第一次领取身份证的时间和本证的签发（换发）时间。如上例：（01-79），表示第一次领取身份证的时间是1979年1月；<br />
4.在出生日期之下，会印有一串符号及英文字母（例如***AZ），意思如下：持证人年龄为18岁或以上及有资格申领香港特别行政区回港证，* 持证人年龄为11岁至17岁及有资格申领香港特别行政区回港证。</p>
<ul>
<li>A 持证人拥有香港居留权</li>
<li>B 持证人所报称的出生日期或地点自首次登记以后，曾作出更改</li>
<li>C 持证人登记领证时在香港的居留受到入境事务处处长的限制</li>
<li>N 持证人所报的姓名自首次登记以后，曾作出更改</li>
<li>O 持证人报称在香港、澳门及中国以外其他地区或国家出生</li>
<li>R 持证人拥有香港入境权</li>
<li>U 持证人登记领证时在香港的居留不受入境事务处处长的限制</li>
<li>W 持证人报称在澳门地区出生</li>
<li>X 持证人报称在中国大陆出生</li>
<li>Z 持证人报称在香港出生</li>
</ul>
</blockquote>
<h2 id="澳门居民身份证"><a class="markdownIt-Anchor" href="#澳门居民身份证"></a> 澳门居民身份证</h2>
<h3 id="号码构成-3"><a class="markdownIt-Anchor" href="#号码构成-3"></a> 号码构成</h3>
<p>澳门居民身份证号码由8个拉丁数字组成格式为“X/NNNNNN/Y”或“XNNNNNN(Y)”，智能身份证将原有格式（X/NNNNNN/Y）改为XNNNNNN(Y)</p>
<blockquote>
<blockquote>
<p>1.在“/”符号前加上一个拉丁数字1、5或7以代表其取证时代，可能是1、5、7。绝大多数人以1字开首；以5字开首的身份证号码代表持有或曾经持有葡萄牙国民身份证或葡萄牙给外国人身份证之人士；以7字开首代表曾经取得蓝卡之人士，大多都是在1970年代至1980年代期间从中国大陆持合法证件到澳门的人士。<br />
2.在“/”符号后加上的拉丁数字则为查核用数码，是为方便电脑处理资料及检查号码输入的正确性而设</p>
</blockquote>
</blockquote>
<h3 id="其他香港身份证知识-2"><a class="markdownIt-Anchor" href="#其他香港身份证知识-2"></a> 其他香港身份证知识</h3>
<p>澳门居民身份证由澳门特别行政区身份证明局签发，种类分为“澳门特别行政区永久性居民身份证”和“澳门特别行政区非永久性居民身份证”,前者有居留权，后者没有居留权。</p>
<p>每张澳门身份证均有持证人的姓名、出生日期等个人资料，并把持证人的黑白照片和签名印在证上。年满18周岁者，当局会发出一张有效期为十年的身份证；而未满18岁者，其身份证有效期则为五年；年界60岁者则其居民身份证为终身。</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613546736807.png" alt="澳门居民身份证样卡" /></p>
<blockquote>
<p>在澳门身份证的照片下面，会印有葡萄牙文字母（例如ASM），它代表的意思如下：<br />
A 持证人于澳门出生<br />
B 持证人于香港出生<br />
C 持证人于中国大陆、台湾出生<br />
D 持证人于其他国家及地区出生<br />
N 持证人出生地不明，不知道自己在何处出生<br />
S 持证人有出生证明文件。如无出生证明文件则会漏空。<br />
M 持证人为男性（Masculino）<br />
F 持证人为女性（Feminino）</p>
</blockquote>
<h2 id="台湾居民身份证"><a class="markdownIt-Anchor" href="#台湾居民身份证"></a> 台湾居民身份证</h2>
<h3 id="号码构成-4"><a class="markdownIt-Anchor" href="#号码构成-4"></a> 号码构成</h3>
<p>台湾居民身份证号码由字母+9为数字组成，如：eg:A123456789</p>
<blockquote>
<p>1.第一位数出生的县市，是用英文字母26个字母来分的，如：台北市为A、台北线为B，以此类推；<br />
2.第二位是男性或女性，男性为1、女性为2；<br />
3.后面的8位数字都为随机数</p>
</blockquote>
<h1 id="身份证号匹配规则"><a class="markdownIt-Anchor" href="#身份证号匹配规则"></a> 身份证号匹配规则</h1>
<p><strong>大陆身份证</strong><br />
分为两种情况，18位：</p>
 <figure class="highlight text"><table><tr><td class="code"><pre><span class="line">^[1-9]\d&#123;5&#125;(18|19|([23]\d))\d&#123;2&#125;((0[1-9])|(10|11|12))(([0-2][1-9])|10|20|30|31)\d&#123;3&#125;[0-9X]$</span><br></pre></td></tr></table></figure>
<p>15位：</p>
 <figure class="highlight text"><table><tr><td class="code"><pre><span class="line">^[1-9]\d&#123;5&#125;\d&#123;2&#125;((0[1-9])|(10|11|12))(([0-2][1-9])|10|20|30|31)\d&#123;3&#125;$</span><br></pre></td></tr></table></figure>
<p><strong>香港身份证</strong></p>
 <figure class="highlight text"><table><tr><td class="code"><pre><span class="line">^((\s?[A-Za-z])|([A-Za-z]&#123;2&#125;))\d&#123;6&#125;(\([0−9aA]\)|[0-9aA])$</span><br></pre></td></tr></table></figure>
<p><strong>澳门身份证</strong></p>
 <figure class="highlight text"><table><tr><td class="code"><pre><span class="line">^[1|5|7][0-9]&#123;6&#125;(\([0-9Aa]\)$</span><br></pre></td></tr></table></figure>
<p><strong>台湾身份证</strong></p>
 <figure class="highlight text"><table><tr><td class="code"><pre><span class="line">^[a-zA-ZＡ-Ｘ][0-9]&#123;9&#125;$</span><br></pre></td></tr></table></figure>
<p>注：以上规则在身份证格式无误的情况下可以校验出来，实际使用留意特殊字符，如18位身份证号码最后一位可以是X,也可能是x,还可能是半角状态的Ｘ；香港和澳门身份证前面可能加上香港、香港居民身份证等字眼。</p>
<h1 id="身份证号校验规则"><a class="markdownIt-Anchor" href="#身份证号校验规则"></a> 身份证号校验规则</h1>
<p><strong>大陆身份证</strong><br />
可对18位大陆身份证进行校验，其中校验码为第18位，以下为计算方法：</p>
<blockquote>
<p>1.将前面的身份证号码17位数分别乘以不同的系数。从第一位到第十七位的系数分 别为：7 9 10 5 8 4 2 1 6 3 7 9 10 5 8 4 2<br />
2.将这17位数字和系数相乘的结果相加。<br />
3.用加出来和除以11，看余数是多少？<br />
4.余数只可能有0 1 2 3 4 5 6 7 8 9 10这11个数字。其分别对应的最后一位身份证的号码为1 0 X 9 8 7 6 5 4 3 2。<br />
5.通过上面得知如果余数是2，就会在身份证的第18位数字上出现罗马数字的Ⅹ。如果余数是10，身份证的最后一位号码就是2。</p>
</blockquote>
<p><strong>香港身份证</strong><br />
最后一位为校验码，计算规则如下：</p>
<blockquote>
<p>1.首位字母改为数字代表，即A以1代表，B以2代表…Z以26代表，可以得到8个数字，之后第一个数字乘以8，第二个数字乘以7，依此类推，第七个数字乘以2<br />
2.将以上所有乘积相加，得到一个数，再将这个数除以11，得到余数。如果整除，校验码为0，如果余数为1，则校验码为A，如果余数为2～10，则用11减去这个余数，则为校验码。</p>
</blockquote>
<p><strong>澳门身份证</strong></p>
<blockquote>
<p>暂未找到相关资料</p>
</blockquote>
<p><strong>台湾身份证</strong><br />
最后一位为校验码，计算规则如下：</p>
<blockquote>
<p>1.第一位字符转为数字，(ABCDEFGHJKLMNPQRSTUVXYWZIO)对应一组数(10——35)。 令其十位数为X1，个位数为X2； D2到D9分别代表身份证号码的第二至第九位数，分别乘上8、7、6、…1。<br />
2.将乘积相加除以10得出的余数结果。 再用10来减去这个余数结果。就得出身份证上的最后一位数字。 例如R123456783，R=25，检查公式是：<code>2+5*9+1*8+2*7+3*6+4*5+5*4+6*3+7*2+8*1=167</code>， 其167再除以10求余数结果。 其余数结果的个位数为7以10减去得3(检查码)。</p>
</blockquote>
]]></content>
      <categories>
        <category>通识</category>
      </categories>
      <tags>
        <tag>身份证</tag>
      </tags>
  </entry>
  <entry>
    <title>对正则化的理解</title>
    <url>/2017/10/25/%E5%AF%B9%E6%AD%A3%E5%88%99%E5%8C%96%E7%9A%84%E7%90%86%E8%A7%A3/</url>
    <content><![CDATA[<p>本文介绍深度学习中的正则化操作</p>
<a id="more"></a>
<h2 id="1为什么要使用正则化"><a class="markdownIt-Anchor" href="#1为什么要使用正则化"></a> 1.为什么要使用正则化</h2>
<p>训练机器学习模型的要点之一是避免过拟合。如果发生过拟合，模型的精确度会下降。这是由于模型过度尝试捕获训练数据集的噪声。噪声，是指那些不能代表数据真实特性的数据点，它们的生成是随机的。学习和捕捉这些数据点让你的模型复杂度增大，有过拟合的风险。</p>
<h2 id="2什么是正则化"><a class="markdownIt-Anchor" href="#2什么是正则化"></a> 2.什么是正则化</h2>
<p>正则化是一种回归的形式，它将系数估计（coefficient estimate）朝零的方向进行约束、调整或缩小。也就是说，正则化可以在学习过程中降低模型复杂度和不稳定程度，从而避免过拟合的危险。正则化将模型学习后的参数估计朝零缩小调整。</p>
<p>机器学习中几乎都可以看到损失函数后面会添加一个额外项，常用的额外项一般有两种， L1正则化 和 L2正则化，或者 L1范数 和 L2范数。</p>
<p>L1正则化是指权值向量w ww中各个元素的绝对值之和<br />
L2正则化是指权值向量w ww中各个元素的平方和然后再求平方根<br />
一般都会在正则化项之前添加一个系数，Python中用α \alphaα表示，一些文章也用λ \lambdaλ表示。这个系数需要用户指定。<br />
L1正则化可以产生稀疏权值矩阵，即产生一个稀疏模型，可以用于特征选择<br />
L2正则化可以防止模型过拟合（overfitting）；一定程度上，L1也可以防止过拟合</p>
<h2 id="3正则化超参的选择"><a class="markdownIt-Anchor" href="#3正则化超参的选择"></a> 3.正则化超参的选择</h2>
<p>L1正则：越大的λ 越容易使F(x)在x=0时取到最小值<br />
L2正则：λ越大，代价函数最值时各参数也会变得很小</p>
<h2 id="4注意事项"><a class="markdownIt-Anchor" href="#4注意事项"></a> 4.注意事项</h2>
<p>标准的最小二乘模型常常产生方差。即对于与训练集不同的数据集，模型可能不能很好地泛化。正则化能在不显著增大偏差的的同时，显著减小模型的方差。因此，正则化技术中使用的调整因子 λ，能控制对方差和偏差的影响。当 λ 的值开始上升时，它减小了系数的值，从而降低了方差。直到上升到某个值之前，λ 的增大很有利，因为它只是减少方差（避免过拟合），而不会丢失数据的任何重要特性。但是在某个特定值之后，模型就会失去重要的性质，导致偏差上升产生欠拟合。因此，要仔细选择 λ 的值。</p>
<p>除了上面提到的额正则化策略，其实还有挺多，比如CNN中的参数共享，对抗训练等。不过从本质上看，正则化策略要做的事情其实是一样的，就是将先验信息以不同方式加入到网络中去，达到限制模型有效容量的效果，从而减小过拟合的风险。</p>
<p>参考：<br />
<a href="https://www.jiqizhixin.com/articles/2017-11-23-4">初学者如何学习机器学习中的L1和L2正则化</a><br />
<a href="https://blog.csdn.net/jinping_shi/article/details/52433975">机器学习中正则化项L1和L2的直观理解</a><br />
<a href="https://blog.csdn.net/qq_16137569/article/details/81584165">小结深度学习中的正则化（超详细分析）</a><br />
<a href="https://www.jianshu.com/p/ae7c2322167e">深度学习中的正则化</a></p>
]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>正则化</tag>
      </tags>
  </entry>
  <entry>
    <title>对流媒体传输关键指标作简单预测</title>
    <url>/2019/04/01/%E5%AF%B9%E6%B5%81%E5%AA%92%E4%BD%93%E4%BC%A0%E8%BE%93%E5%85%B3%E9%94%AE%E6%8C%87%E6%A0%87%E4%BD%9C%E7%AE%80%E5%8D%95%E9%A2%84%E6%B5%8B/</url>
    <content><![CDATA[<p>本文使用LSTM对流媒体的6个关键指标进行预测</p>
<a id="more"></a>
<p>现收集有流媒体传输过程中的６个指标，这些指标分别是：</p>
<blockquote>
<ul>
<li>PDCCH信道CCE可用个数    AvaPdcch</li>
<li>PDCCH信道CCE占用个数    OccPdcch</li>
<li>RRC连接最大数        ConRrc</li>
<li>上行PRB平均利用率       UpPrb</li>
<li>下行PRB平均利用率       DownPrb</li>
<li>有效RRC连接最大数     EffConRrc</li>
</ul>
</blockquote>
<h1 id="1数据情况"><a class="markdownIt-Anchor" href="#1数据情况"></a> 1.数据情况</h1>
<p>每个指标的数据格式为：<code>Data-Time-Value</code>，本文首先对数据进行预处理，然后使用LSTM对这６个指标作简单预测。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">filenames=[<span class="string">&#x27;AvaPdcch&#x27;</span>,<span class="string">&#x27;OccPdcch&#x27;</span>,<span class="string">&#x27;ConRrc&#x27;</span>,<span class="string">&#x27;UpPrb&#x27;</span>,<span class="string">&#x27;DownPrb&#x27;</span>,<span class="string">&#x27;EffConRrc&#x27;</span>]  <span class="comment">#属性列表</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#读取数据</span></span><br><span class="line">dataset=[]</span><br><span class="line"><span class="keyword">for</span> filename <span class="keyword">in</span> filenames:</span><br><span class="line">    df=pd.read_csv(filename+<span class="string">&#x27;.csv&#x27;</span>,delimiter=<span class="string">&#x27;,&#x27;</span>)</span><br><span class="line">    partfea=np.array(df)[:,-<span class="number">1</span>]</span><br><span class="line">    dataset.append(partfea)</span><br><span class="line"></span><br><span class="line">dataset=np.array(dataset)</span><br><span class="line">dataset=dataset.T</span><br><span class="line"></span><br><span class="line">print(dataset.shape,dataset[<span class="number">1302</span>])</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<blockquote>
<p>(1378, 6) [nan nan 18.0 nan nan 8.0]</p>
</blockquote>
<p>从这输出可以看出，数据量就是1378个，每个数据量是前文的６个指标。并且数据中包含缺失值，为了简单，这里使用均值进行填充，实际上还可以更加灵活处理缺失值，比如整行/列去掉，进行插值等。</p>
<h1 id="2数据预处理"><a class="markdownIt-Anchor" href="#2数据预处理"></a> 2.数据预处理</h1>
<ul>
<li><strong>缺失值填充</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</span><br><span class="line"></span><br><span class="line">impute = preprocessing.Imputer()</span><br><span class="line">dataset = impute.fit_transform(dataset)</span><br><span class="line"></span><br><span class="line">print(dataset.shape,dataset[<span class="number">1302</span>])</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<blockquote>
<p>(1378, 6) [  7.31026325e+07   9.40476974e+06   1.80000000e+01   3.38872727e-02<br />
1.92543953e-01   8.00000000e+00]</p>
</blockquote>
<ul>
<li><strong>数据归一化</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line"></span><br><span class="line">scaler = MinMaxScaler(feature_range=(<span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line">dataset = scaler.fit_transform(dataset)</span><br><span class="line"></span><br><span class="line">print(dataset.shape,dataset[<span class="number">1302</span>])</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<blockquote>
<p>(1378, 6) [ 0.5072962   0.23767169  0.22222222  0.17733455  0.21859107  0.23809524]</p>
</blockquote>
<h1 id="3样本划分及标签处理"><a class="markdownIt-Anchor" href="#3样本划分及标签处理"></a> 3.样本划分及标签处理</h1>
<p>后一个数据作为前一个数据的标签，模型最终是基于当前的数据预测下一状态数据。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_size=<span class="built_in">int</span>(<span class="number">0.8</span>*<span class="built_in">len</span>(dataset))</span><br><span class="line"><span class="comment">#训练集</span></span><br><span class="line">train_X=dataset[<span class="number">0</span>:train_size,:]</span><br><span class="line">train_y=dataset[<span class="number">1</span>:train_size+<span class="number">1</span>,:]</span><br><span class="line"><span class="comment">#验证集</span></span><br><span class="line">vali_X=dataset[train_size:,:]</span><br><span class="line">vali_y=dataset[train_size+<span class="number">1</span>:,:]</span><br><span class="line"> </span><br><span class="line">train_X=train_X.reshape(train_X.shape[<span class="number">0</span>],<span class="number">1</span>,train_X.shape[<span class="number">1</span>])</span><br><span class="line">vali_X=vali_X.reshape(vali_X.shape[<span class="number">0</span>],<span class="number">1</span>,vali_X.shape[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">print(train_X.shape,train_y.shape,vali_X.shape,vali_y.shape)</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<blockquote>
<p>(1102, 1, 6) (1102, 6) (276, 1, 6) (275, 6)</p>
</blockquote>
<h1 id="4模型训练"><a class="markdownIt-Anchor" href="#4模型训练"></a> 4.模型训练</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> LSTM</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> plot_model</span><br><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> SVG</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> keras.utils.vis_utils <span class="keyword">import</span> model_to_dot</span><br><span class="line"></span><br><span class="line"><span class="comment">#构建LSTM网络</span></span><br><span class="line">model=Sequential()</span><br><span class="line">model.add(LSTM(<span class="number">32</span>,input_shape=(<span class="number">1</span>,<span class="number">6</span>)))</span><br><span class="line">model.add(Dense(<span class="number">6</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">#编译模型</span></span><br><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;mean_squared_error&#x27;</span>, optimizer=<span class="string">&#x27;adam&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#打印模型</span></span><br><span class="line">model.summary()</span><br><span class="line"></span><br><span class="line"><span class="comment">#保存模型</span></span><br><span class="line">SVG(model_to_dot(model,show_shapes=<span class="literal">True</span>).create(prog=<span class="string">&#x27;dot&#x27;</span>, <span class="built_in">format</span>=<span class="string">&#x27;svg&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">#训练LSTM网络</span></span><br><span class="line">model.fit(train_X, train_y, epochs=<span class="number">10</span>, batch_size=<span class="number">1</span>, verbose=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h1 id="5模型评估"><a class="markdownIt-Anchor" href="#5模型评估"></a> 5.模型评估</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#预测数据</span></span><br><span class="line">valipredict=model.predict(vali_X)</span><br><span class="line">print(valipredict.shape,vali_y.shape)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#画图模型预测显示</span></span><br><span class="line">finalypredict=[]</span><br><span class="line"><span class="comment">#归一化后的数据画图,有6列</span></span><br><span class="line">plt.subplots(<span class="number">2</span>,<span class="number">3</span>,figsize=(<span class="number">18</span>,<span class="number">6</span>)) </span><br><span class="line"><span class="keyword">for</span> ind <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">6</span>):</span><br><span class="line">    <span class="comment">#归一化数据转换为真实数据</span></span><br><span class="line">    valipredict_real=valipredict[:,ind]*(scaler.data_max_[ind]-scaler.data_min_[ind])+scaler.data_min_[ind]</span><br><span class="line">    vali_y_real=vali_y[:,ind]*(scaler.data_max_[ind]-scaler.data_min_[ind])+scaler.data_min_[ind]</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#未来的6个真实值</span></span><br><span class="line">    finalypredict.append(valipredict_real[-<span class="number">1</span>])</span><br><span class="line">    </span><br><span class="line">    plt.subplot(<span class="number">2</span>, <span class="number">3</span>,ind+<span class="number">1</span>)</span><br><span class="line">    plt.title(filenames[ind]) </span><br><span class="line">    plt.plot(valipredict_real,color=<span class="string">&#x27;red&#x27;</span>,label=<span class="string">&#x27;valipredict&#x27;</span>)</span><br><span class="line">    plt.plot(vali_y_real,color=<span class="string">&#x27;green&#x27;</span>,label=<span class="string">&#x27;vali_y&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613533169656.png" alt="模型在验证数据上的预测效果" /></p>
<p>由图可以看出，６个指标基本的趋势被正确预测，但是某个时刻的准确度不是很高，我认为原因有几个：</p>
<blockquote>
<ol>
<li>数据量太少，导致模型无法学习足够的特征</li>
<li>特征太简单，某个指标的预测仅仅依赖于包括自身在内的历史时刻的６个值，这明显不够，可以考虑加入更多特征。比如这几个值明显对”时间“敏感，不同的时间区间内，流媒体的传输需要不同，将时间考虑进去将使得模型学习到更加丰富的特征</li>
<li>模型太简单，在数据量少，特征不多的情况下，我只用了一层的LSTM。</li>
</ol>
</blockquote>
<h1 id="6预测未来下一个6个指标"><a class="markdownIt-Anchor" href="#6预测未来下一个6个指标"></a> 6.预测未来下一个６个指标</h1>
<p>将数据中的最后的６个指标输入已经训练好的模型，模型输出６个值，该６个值作为模型预测到的未来下一个６个指标值。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#前文已经存储，直接输出</span></span><br><span class="line">print(finalypredict)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>[93690488.0, 25693568.0, 40.356155, 0.088783175, 0.64066094, 17.614025]</p>
</blockquote>
]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>LSTM</tag>
      </tags>
  </entry>
  <entry>
    <title>对深度学习dropout机制的理解</title>
    <url>/2017/11/10/%E5%AF%B9%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0dropout%E6%9C%BA%E5%88%B6%E7%9A%84%E7%90%86%E8%A7%A3/</url>
    <content><![CDATA[<p>本文介绍深度学习中的dropout机制</p>
<a id="more"></a>
<h1 id="1定义"><a class="markdownIt-Anchor" href="#1定义"></a> 1.定义</h1>
<p>随机失活（dropout）是对具有深度结构的人工神经网络进行优化的方法，在学习过程中通过将隐含层的部分权重或输出随机归零，降低节点间的相互依赖性（co-dependence ）从而实现神经网络的正则化（regularization），降低其结构风险（structural risk）</p>
<h1 id="2过程"><a class="markdownIt-Anchor" href="#2过程"></a> 2.过程</h1>
<ol>
<li>由于每次用输入网络的样本进行权值更新时，隐含节点都是以一定概率随机出现，因此不能保证每2个隐含节点每次都同时出现，这样权值的更新不再依赖于有固定关系隐含节点的共同作用，阻止了某些特征仅仅在其它特定特征下才有效果的情况。</li>
<li>可以将dropout看作是模型平均的一种。对于每次输入到网络中的样本（可能是一个样本，也可能是一个batch的样本），其对应的网络结构都是不同的，但所有的这些不同的网络结构又同时share隐含节点的权值。这样不同的样本就对应不同的模型，是bagging的一种极端情况。个人感觉这个解释稍微靠谱些，和bagging，boosting理论有点像，但又不完全相同。</li>
<li>native bayes是dropout的一个特例。Native bayes有个错误的前提，即假设各个特征之间相互独立，这样在训练样本比较少的情况下，单独对每个特征进行学习，测试时将所有的特征都相乘，且在实际应用时效果还不错。而Droput每次不是训练一个特征，而是一部分隐含层特征。</li>
<li>还有一个比较有意思的解释是，Dropout类似于性别在生物进化中的角色，物种为了使适应不断变化的环境，性别的出现有效的阻止了过拟合，即避免环境改变时物种可能面临的灭亡。</li>
</ol>
<p>Dropout是指在模型训练时随机让网络某些隐含层节点的权重不工作，不工作的那些节点可以暂时认为不是网络结构的一部分，但是它的权重得保留下来（只是暂时不更新而已），因为下次样本输入时它可能又得工作了。</p>
<h1 id="3过拟合"><a class="markdownIt-Anchor" href="#3过拟合"></a> ３.过拟合</h1>
<p>（1）取平均的作用：先回到标准的模型即没有dropout，我们用相同的训练数据去训练5个不同的神经网络，一般会得到5个不同的结果，此时我们可以采用 “5个结果取均值”或者“多数取胜的投票策略”去决定最终结果。例如3个网络判断结果为数字9,那么很有可能真正的结果就是数字9，其它两个网络给出了错误结果。这种“综合起来取平均”的策略通常可以有效防止过拟合问题。因为不同的网络可能产生不同的过拟合，取平均则有可能让一些“相反的”拟合互相抵消。dropout掉不同的隐藏神经元就类似在训练不同的网络，随机删掉一半隐藏神经元导致网络结构已经不同，整个dropout过程就相当于对很多个不同的神经网络取平均。而不同的网络产生不同的过拟合，一些互为“反向”的拟合相互抵消就可以达到整体上减少过拟合。</p>
<p>（2）减少神经元之间复杂的共适应关系：因为dropout程序导致两个神经元不一定每次都在一个dropout网络中出现。这样权值的更新不再依赖于有固定关系的隐含节点的共同作用，阻止了某些特征仅仅在其它特定特征下才有效果的情况 。迫使网络去学习更加鲁棒的特征 ，这些特征在其它的神经元的随机子集中也存在。换句话说假如我们的神经网络是在做出某种预测，它不应该对一些特定的线索片段太过敏感，即使丢失特定的线索，它也应该可以从众多其它线索中学习一些共同的特征。从这个角度看dropout就有点像L1，L2正则，减少权重使得网络对丢失特定神经元连接的鲁棒性提高。</p>
<p>（3）Dropout类似于性别在生物进化中的角色：物种为了生存往往会倾向于适应这种环境，环境突变则会导致物种难以做出及时反应，性别的出现可以繁衍出适应新环境的变种，有效的阻止过拟合，即避免环境改变时物种可能面临的灭绝。</p>
<h1 id="4理解"><a class="markdownIt-Anchor" href="#4理解"></a> ４.理解</h1>
<p>当前Dropout被大量利用于全连接网络，而且一般认为设置为0.5或者0.3，而在卷积网络隐藏层中由于卷积自身的稀疏化以及稀疏化的ReLu函数的大量使用等原因，Dropout策略在卷积网络隐藏层中使用较少。</p>
<p>Dropout是一种Bagging的近似：Bagging定义k个不同的模型，从training set采样出k个不同的数据集，在第i个模型上用第i个数据集进行训练，最后综合k个模型的结果，获得最终的模型。但是需要的空间、时间都很大，在DNN中并不现实。Dropout的目的是在指数级子网络的深度神经网络中近似Bagging。也就是说，在训练时，每次Dropout后，训练的网络是整个深度神经网络的其中一个子网络。在测试时，将dropout层取消，这样得到的前向传播结果其实就是若干个子网络前向传播综合结果的一种近似。dropout,以0.5的概率将每个隐藏神经元的输出设置为0，以这种方式被抑制的神经元既不参与前向也不参与反向传播。每次输入一个样本，相当于该神经网络尝试一个新结构，但是这些结构之间的共享权值，因为神经元不能依赖其他的神经元而存在，所以这种技术降低了神经元复杂的互适应性，因此，网络需要被迫学习更加健壮的特征，这些特征结合其他神经元的一些不同随机子集时很有用，如果没有dropout网络会出现大量的过拟合，dropout使收敛所需的迭代次数增加一倍。</p>
<p>参考资料：<br />
<a href="https://cloud.tencent.com/developer/news/246964">深度学习中Dropout原理解析</a><br />
<a href="https://www.cnblogs.com/tornadomeet/p/3258122.html">Deep learning：四十一(Dropout简单理解)</a><br />
<a href="https://baike.baidu.com/item/%E9%9A%8F%E6%9C%BA%E5%A4%B1%E6%B4%BB/23293814?fromtitle=dropout&amp;fromid=23294126&amp;fr=aladdin">随机失活</a><br />
<a href="https://blog.csdn.net/weixin_41108334/article/details/83827332">深度学习：经典网络模型lenet,alexnet,vggnet,googlenet,Resnet,densenet可解释性</a></p>
]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>dropout</tag>
      </tags>
  </entry>
  <entry>
    <title>对深度学习优化函数的理解</title>
    <url>/2017/11/12/%E5%AF%B9%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%BC%98%E5%8C%96%E5%87%BD%E6%95%B0%E7%9A%84%E7%90%86%E8%A7%A3/</url>
    <content><![CDATA[<p>本文介绍深度学习中如何使用优化函数</p>
<a id="more"></a>
<h1 id="深度学习常用优化方法"><a class="markdownIt-Anchor" href="#深度学习常用优化方法"></a> 深度学习常用优化方法</h1>
<blockquote>
<p>1.对于稀疏数据，尽量使用学习率可自适应的优化方法，不用手动调节，而且最好采用默认值<br />
2.SGD通常训练时间更长，但是在好的初始化和学习率调度方案的情况下，结果更可靠<br />
3.如果在意更快的收敛，并且需要训练较深较复杂的网络时，推荐使用学习率自适应的优化方法。<br />
4.Adadelta，RMSprop，Adam是比较相近的算法，在相似的情况下表现差不多。<br />
5.在想使用带动量的RMSprop，或者Adam的地方，大多可以使用Nadam取得更好的效果</p>
</blockquote>
<h2 id="sgd"><a class="markdownIt-Anchor" href="#sgd"></a> SGD</h2>
<blockquote>
<p>随机梯度下降,算法在每读入一个数据都会立刻区计算loss function的梯度来update参数．</p>
<p>优点：:收敛的速度快；可以实现在线更新；能够跳出局部最优<br />
缺点：很容易陷入到局部最优，困在马鞍点</p>
</blockquote>
<h2 id="bgd"><a class="markdownIt-Anchor" href="#bgd"></a> BGD</h2>
<blockquote>
<p>批量梯度下降，算法在读取整个数据集后累加来计算损失函数的的梯度<br />
优点：如果loss function为convex，则基本可以找到全局最优解<br />
缺点：数据处理量大，导致梯度下降慢;不能实时增加实例，在线更新；训练占内存</p>
</blockquote>
<h2 id="mini-bgd"><a class="markdownIt-Anchor" href="#mini-bgd"></a> Mini-BGD</h2>
<blockquote>
<p>小批量数据进行梯度下降，这个优化方法用的也是比较多的，计算效率高而且收敛稳定，是现在深度学习的主流方法</p>
</blockquote>
<h2 id="带动量"><a class="markdownIt-Anchor" href="#带动量"></a> 带动量</h2>
<h3 id="momentum"><a class="markdownIt-Anchor" href="#momentum"></a> Momentum</h3>
<blockquote>
<p>在更新方向的时候保留之前的方向，增加稳定性而且还有摆脱局部最优的能力</p>
</blockquote>
<h3 id="nesterov"><a class="markdownIt-Anchor" href="#nesterov"></a> Nesterov</h3>
<blockquote>
<p>nesterov项在梯度更新时做一个校正，避免前进太快，同时提高灵敏度，滚雪球游戏中，我们希望有一个智能的雪球，它能够预知运动的方向，以至于当它再次遇到斜坡的时候会减慢速度。</p>
</blockquote>
<h2 id="自适应学习率算法"><a class="markdownIt-Anchor" href="#自适应学习率算法"></a> 自适应学习率算法</h2>
<h3 id="adagrad"><a class="markdownIt-Anchor" href="#adagrad"></a> Adagrad</h3>
<blockquote>
<p>自适应梯度算法,是一种改进的随机梯度下降算法<br />
以前的算法中，每一个参数都使用相同的学习率α. Adagrad算法能够在训练中自动对learning_rate进行调整，出现频率较低参数采用较大的α更新．出现频率较高的参数采用较小的α更新．根据描述这个优化方法很适合处理稀疏数据．<br />
Adagrad算法主要的缺点在于，其分母梯度平方的累加和。因为每次加入的都是一个正数，随着训练的进行，学习率将会变得无限小，此时算法将不能进行参数的迭代更新。</p>
</blockquote>
<h3 id="adadelta"><a class="markdownIt-Anchor" href="#adadelta"></a> Adadelta</h3>
<blockquote>
<p>Adadelta算法是adagrad算法的改进版，它主要解决了adagrad算法单调递减学习率的问题。通过约束历史梯度累加来替代累加所有历史梯度平方。这里通过在历史梯度上添加衰减因子，并通过迭代的方式来对当前的梯度进行计算，最终距离较远的梯度对当前的影响较小，而距离当前时刻较近的梯度对当前梯度的计算影响较大</p>
</blockquote>
<h3 id="rmsprop"><a class="markdownIt-Anchor" href="#rmsprop"></a> RMSprop</h3>
<blockquote>
<p>一种自适应学习率方法．不同之处在于，Adagrad会累加之前所有的梯度平方，RMProp仅仅是计算对应的平均值．可以缓解Adagrad算法学习率下降较快的问题．<br />
RMSPprop算法和adadelta算法都是adagrad算法的优化版，用于解决adagrad算法学习率消失的问题，从最终的计算公式来看，RMSProp算法和Adadelta算法有相似的计算表达式</p>
</blockquote>
<h3 id="adam"><a class="markdownIt-Anchor" href="#adam"></a> Adam</h3>
<blockquote>
<p>Adam是对RMSProp优化器的更新.它利用梯度的一阶矩估计和二阶矩估计动态调整每个参数的学习率。Adam的优点主要在于经过偏置校正后，每一次迭代学习率都有个确定范围，使得参数比较平稳。Adam算法可以看作是RMSProp算法和Momentum的结合版。RMSProp算法通过对历史梯度平方乘上衰减因子来计算v(t)，动量则计算历史梯度。</p>
</blockquote>
<h3 id="adamax"><a class="markdownIt-Anchor" href="#adamax"></a> Adamax</h3>
<blockquote>
<p>Adamax是Adam的一种变体，此方法对学习率的上限提供了一个更简单的范围</p>
</blockquote>
<h3 id="nadam"><a class="markdownIt-Anchor" href="#nadam"></a> Nadam</h3>
<blockquote>
<p>Nadam类似于带有Nesterov动量项的Adam</p>
</blockquote>
<p>概要: 上面的方法都存在一个问题，就是update更新的方向完全依赖于计算出来的梯度．很容易陷入局部最优的马鞍点．能不能改变其走向，又保证原来的梯度方向．就像向量变换一样，我们模拟物理中物体流动的动量概念(惯性).引入Momentum的概念</p>
]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>优化函数</tag>
      </tags>
  </entry>
  <entry>
    <title>对深度学习梯度的理解</title>
    <url>/2017/11/10/%E5%AF%B9%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A2%AF%E5%BA%A6%E7%9A%84%E7%90%86%E8%A7%A3/</url>
    <content><![CDATA[<p>本文介绍深度学习中的梯度及其问题</p>
<a id="more"></a>
<h1 id="1梯度"><a class="markdownIt-Anchor" href="#1梯度"></a> 1.梯度</h1>
<p>梯度的本意是一个向量（矢量），表示某一函数在该点处的方向导数沿着该方向取得最大值，即函数在该点处沿着该方向（此梯度的方向）变化最快，变化率最大（为该梯度的模），梯度的反方向是f降低最快的方向。</p>
<p>在单变量的实值函数的情况，梯度只是导数，或者，对于一个线性函数，也就是线的斜率。<br />
在多变量的实值函数的情况，梯度只是各个变量的偏导数，并把这些偏导数写成向量的形式。</p>
<h1 id="2梯度消失"><a class="markdownIt-Anchor" href="#2梯度消失"></a> 2.梯度消失</h1>
<p>许多激活函数将输出值挤压在很小的区间内，在激活函数两端较大范围的定义域内梯度为0，导致权重更新的缓慢训练难度增加，造成学习停止。前面层上的梯度是来自后面的层上项的乘积，当层数过多时，随着乘积的累积，将越来越小。</p>
<p>从深层网络角度来讲，不同的层学习的速度差异很大，表现为网络中靠近输出的层学习的情况很好，靠近输入的层学习的很慢，有时甚至训练了很久，前几层的权值和刚开始随机初始化的值差不多。</p>
<p>具体来说，我们常常使用sigmoid作为神经元的输入输出函数。对于幅度为1的信号，在BP反向传播梯度时，每传递一层，梯度衰减为原来的0.25。</p>
<h1 id="3梯度爆炸"><a class="markdownIt-Anchor" href="#3梯度爆炸"></a> 3.梯度爆炸</h1>
<p>训练过程中表现为loss为Nan，使得学习过程难以继续。当网络过深，如果连乘的因子大部分小于1，最后乘积可能趋于0；另一方面，如果连乘的因子大部分大于1，最后乘积可能趋于无穷。这就是所谓的梯度消失与梯度爆炸。</p>
<h1 id="4解决思路"><a class="markdownIt-Anchor" href="#4解决思路"></a> ４.解决思路：</h1>
<h2 id="1pre-training-fine-tuning"><a class="markdownIt-Anchor" href="#1pre-training-fine-tuning"></a> 1.Pre-training + fine-tuning</h2>
<p>每次训练一层，训练完成BP所有层</p>
<h2 id="2合理的初始化权重"><a class="markdownIt-Anchor" href="#2合理的初始化权重"></a> 2.合理的初始化权重</h2>
<p>为了防止梯度爆炸或者梯度消失,我们希望wi尽可能小,最合理的方法就是设置W方差为k/n表示神经元的输入特征数量,k根据选择的激活函数不同而不同。为什么不初始化为0或者随机初始化呢？理由如下：<br />
<strong>将所有权重初始化为零</strong>会使模型相当于是一个线性模型，因为如果将权重初始化为零，那么损失函数对每个 w 的梯度都会是一样的，这样在接下来的迭代中，同一层内所有神经元的梯度相同，梯度更新也相同，所有的权重也都会具有相同的值，这样的神经网络和一个线性模型的效果差不多。（将 biases 设为零不会引起多大的麻烦，即使 bias 为 0，每个神经元的值也是不同的。）<br />
<strong>随机初始化</strong>将权重进行随机初始化，使其服从标准正态分布 （ np.random.randn(size_l, size_l-1) ）<br />
在训练深度神经网络时可能会造成两个问题，梯度消失和梯度爆炸。</p>
<h2 id="2梯度剪切-正则"><a class="markdownIt-Anchor" href="#2梯度剪切-正则"></a> 2.梯度剪切、正则</h2>
<p>梯度剪切这个方案主要是针对梯度爆炸提出的，其思想是设置一个梯度剪切阈值，然后更新梯度的时候，如果梯度超过这个阈值，那么就将其强制限制在这个范围之内。这可以防止梯度爆炸。另外一种解决梯度爆炸的手段是采用权重正则化（weithts regularization）比较常见的是l1 l1l1正则，和l2 l2l2正则,正则化是通过对网络权重做正则限制过拟合。</p>
<h2 id="3relu-leakyrelu-elu等激活函数缓解梯度消失"><a class="markdownIt-Anchor" href="#3relu-leakyrelu-elu等激活函数缓解梯度消失"></a> 3.Relu、leakyReLu、Elu等激活函数缓解梯度消失</h2>
<p>Relu思想也很简单，如果激活函数的导数为1，那么就不存在梯度消失爆炸的问题了，每层的网络都可以得到相同的更新速度，relu就这样应运而生。</p>
<h2 id="4batchnorm"><a class="markdownIt-Anchor" href="#4batchnorm"></a> 4.batchnorm</h2>
<p>BN反向传播式子中有权重w 的存在，所以w 的大小影响了梯度的消失和爆炸，batchnorm就是通过对每一层的输出规范为均值和方差一致的方法，消除了w带来的放大缩小的影响，进而解决梯度消失和爆炸的问题，或者可以理解为BN将输出从饱和区拉倒了非饱和区。</p>
<h2 id="5残差机制"><a class="markdownIt-Anchor" href="#5残差机制"></a> 5.残差机制</h2>
<p>残差机制短路机制可以无损地传播梯度，而另外一项残差梯度则需要经过带有weights的层，梯度不是直接传递过来的。残差梯度不会那么巧全为-1，而且就算其比较小，有1的存在也不会导致梯度消失。所以残差学习会更容易。</p>
<h2 id="6lstm"><a class="markdownIt-Anchor" href="#6lstm"></a> 6.LSTM</h2>
<p>LSTM不那么容易发生梯度消失的，主要原因在于LSTM内部复杂的“门”，LSTM通过它内部的“门”可以接下来更新的时候“记住”前几次训练的”残留记忆“</p>
<p>参考：<br />
<a href="https://baike.baidu.com/item/%E6%A2%AF%E5%BA%A6/13014729">梯度</a><br />
<a href="https://blog.csdn.net/zhaomengszu/article/details/77834845">大白话讲解BP算法</a><br />
<a href="https://www.cnblogs.com/mengnan/p/9480804.html">神经网络中的梯度消失</a><br />
<a href="https://www.jianshu.com/p/b4739a40004d">梯度消失，梯度爆炸</a><br />
<a href="https://blog.csdn.net/u013555719/article/details/78319568">改善深层神经网络_深度学习的实用层面1.10_1.12/梯度消失/梯度爆炸/权重初始化</a><br />
<a href="https://blog.csdn.net/u013250416/article/details/81410693">梯度消失与梯度爆炸、Loss为Nan的原因</a><br />
<a href="https://www.jianshu.com/p/332c5cb15933">权重初始化的几个方法</a><br />
<a href="https://blog.csdn.net/qq_25737169/article/details/78847691">详解机器学习中的梯度消失、爆炸原因及其解决方法</a></p>
]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>梯度</tag>
      </tags>
  </entry>
  <entry>
    <title>对深度学习池化的理解</title>
    <url>/2017/11/05/%E5%AF%B9%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%B1%A0%E5%8C%96%E7%9A%84%E7%90%86%E8%A7%A3/</url>
    <content><![CDATA[<p>本文从原理及使用方法，介绍深度学习中的池化操作</p>
<a id="more"></a>
<h2 id="1为什么要池化"><a class="markdownIt-Anchor" href="#1为什么要池化"></a> １．为什么要池化？</h2>
<ol>
<li>invariance(不变性)，这种不变性包括translation(平移)，rotation(旋转)，scale(尺度)</li>
<li>保留主要的特征同时减少参数(降维，效果类似PCA)和计算量，防止过拟合，提高模型泛化能力</li>
</ol>
<h2 id="2怎么池化"><a class="markdownIt-Anchor" href="#2怎么池化"></a> ２．怎么池化？</h2>
<p>最常见的池化操作为平均池化mean pooling和最大池化max pooling：<br />
平均池化：计算图像区域的平均值作为该区域池化后的值。<br />
最大池化：选图像区域的最大值作为该区域池化后的值。<br />
随机池化：只需对feature map中的元素按照其概率值大小随机选择，即元素值大的被选中的概率也大</p>
<p>在提取信息的时候，在池化的时候，如果取区域均值（mean-pooling），往往能保留整体数据的特征，能凸出背景的信息，而如果取区域最大值（max-pooling），则能更好保留纹理上的特征，但这些应该都不如小波变换那样，可以保留更多的细节特征，整体上也应该更加细微。</p>
<p>在ICLR2013上，Zeiler提出了stochastic pooling，元素值大的被选中的概率也大，但不是像max-pooling那样总是取最大值，这种方法的优势是，一方面最大化保证了Max值的取值，一方面又部分确保不会所有元素都被max值给忽悠住，造成过度失真。</p>
<p>这种方式想来还是有缺陷的，因为这种随机行挑选尽管有概率倾向，但它是人为叠加上的，无法总是保证一定随机的概率选择中能够选择到更好的结果，所以也会出现更糟糕的结果的时候，不过加入概率算法好处是，它为产生更好的结果产生了可能，所以总的来说，还是有可能得到更好的结果的。</p>
<p>假设目标总是容易被命中的，而有那么个正态分布与目标的分布是近似重合的，如何保证这种分布比较能吻合目标？平均值与最大值都会产生偏移，因为毕竟太暴力了，而概率算法加入无疑是比较理想的，能减少这种偏移的可能，如果运气足够好，收敛会非常好，那么还有可能得到更加贴近的结果，于是这个又扯到了运气上来了。</p>
<p>只是，术数里的收敛为何能那么准确，这个从数学角度实在是难解，究竟是什么没有考虑到？目前有一种隐隐地思路，需要探索以术数的模型套上去，只是还是没有找到桥梁在哪里，第一是要找出，信息是如何演算并折叠在卦中的，第二是要找出如何还能够把信息进行还原。</p>
<p>在尝试计算了近十万个图形与随机起卦之间的联系后，发现要建立这个联系，是极难完成的任务，制作自动编码器运算到一定程度收敛越来越慢，随便估计也是要花上个几个月的（还不一定最后算得出来），想来还是思路有问题。</p>
<p>至于max与average效果是否一样，还是要看需要识别的图像细节特征情况，这个不一定的，不过据说差异不会超过2%。</p>
<p>不过仔细点说的话，评估特征提取的误差主要来自两个方面：<br />
（1）邻域大小受限造成的估计值方差增大，average能减小这种误差。<br />
（2）卷积层参数误差造成估计均值的偏移，max能减小这种误差。</p>
<p>也就是说，average对背景保留更好，max对纹理提取更好，如果是识别字体什么的，应该考虑max.</p>
<h2 id="4反池化"><a class="markdownIt-Anchor" href="#4反池化"></a> ４．反池化</h2>
<p>反池化是池化的逆操作，是无法通过池化的结果还原出全部的原始数据。因为池化的过程就只保留了主要信息，舍去部分信息。<br />
如果想从池化后的这些主要信息恢复出全部信息，则存在信息缺失，这时只能通过补位来实现最大程度的信息完整。<br />
池化有两种：最大池化和平均池化，其反池化也需要与其对应。</p>
<h2 id="3注意事项"><a class="markdownIt-Anchor" href="#3注意事项"></a> ３．注意事项</h2>
<p>最大池化只是计算神经网络某一层的静态属性，没有什么需要模型进行学习的，它只是一个静态属性。<br />
池化还有重叠池化和空金字塔池化，空间金字塔池化的思想来自于Spatial Pyramid Model，它一个pooling变成了多个scale的pooling。用不同大小池化窗口作用于卷积特征，我们可以得到1X1,2X2,4X4的池化结果，由于conv5中共有256个过滤器，所以得到1个256维的特征，4个256个特征，以及16个256维的特征，然后把这21个256维特征链接起来输入全连接层，通过这种方式把不同大小的图像转化成相同维度的特征。</p>
<p>参考：<br />
<a href="https://blog.csdn.net/zxyhhjs2017/article/details/78607469">深度学习—之pooling层的作用与缺陷</a><br />
<a href="https://blog.csdn.net/denghuanhuandeng/article/details/76601778">深度学习之-池化操作</a><br />
<a href="https://www.cnblogs.com/DOMLX/p/9579108.html">深度学习（一）神经网络中的池化与反池化原理</a><br />
<a href="https://blog.csdn.net/woxincd/article/details/85199928">深度学习 池化的概念</a><br />
<a href="https://www.cnblogs.com/eilearn/p/9282902.html">深度学习—池化、padding的理解</a><br />
<a href="https://www.jianshu.com/p/b742c8c92b26">吴恩达深度学习笔记(79)-池化层讲解（Pooling layers）</a></p>
]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>正则化</tag>
      </tags>
  </entry>
  <entry>
    <title>对深度学习激活函数的理解</title>
    <url>/2017/11/08/%E5%AF%B9%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E7%9A%84%E7%90%86%E8%A7%A3/</url>
    <content><![CDATA[<p>激活函数是深度学习中重要的构件，本文从深度学习的激活函数的使用及类型来解析</p>
<a id="more"></a>
<h1 id="深度学习-激活函数"><a class="markdownIt-Anchor" href="#深度学习-激活函数"></a> 深度学习－激活函数</h1>
<h2 id="激活函数"><a class="markdownIt-Anchor" href="#激活函数"></a> 激活函数</h2>
<blockquote>
<p>当没有神经网络的时候，神经元对数据的处理就是基于权重和偏移做线性变换。线性变换很简单，但是限制了对复杂任务的处理能力。没有激活函数的神经网络就是一个线性回归模型。激活函数做的非线性变换可以使得神经网络处理非常复杂的任务。例如，我们希望我们的神经网络可以对语言翻译和图像分类做操作，这就需要非线性转换。</p>
<p>同时，激活函数也使得反向传播算法变的可能。因为，这时候梯度和误差会被同时用来更新权重和偏移。没有可微分的线性函数(wx+b导数为w,每次更新只是二维图中直线的旋转)，这就不可能了。</p>
</blockquote>
<h2 id="激活函数类型"><a class="markdownIt-Anchor" href="#激活函数类型"></a> 激活函数类型</h2>
<h3 id="linear"><a class="markdownIt-Anchor" href="#linear"></a> linear</h3>
<blockquote>
<p>线性激活函数</p>
</blockquote>
<h3 id="sigmoid"><a class="markdownIt-Anchor" href="#sigmoid"></a> sigmoid</h3>
<blockquote>
<p>sigmoid函数也叫 Logistic 函数，用于隐层神经元输出，取值范围为(0,1)，它可以将一个实数映射到(0,1)的区间，可以用来做二分类。<br />
在特征相差比较复杂或是相差不是特别大时效果比较好。</p>
<p>sigmoid缺点：<br />
激活函数计算量大，反向传播求误差梯度时，求导涉及除法<br />
反向传播时，很容易就会出现梯度消失的情况，从而无法完成深层网络的训练<br />
Sigmoids函数饱和且kill掉梯度。<br />
Sigmoids函数收敛缓慢。</p>
</blockquote>
<h3 id="tanh"><a class="markdownIt-Anchor" href="#tanh"></a> tanh</h3>
<blockquote>
<p>也称为双切正切函数，取值范围为[-1,1]。<br />
tanh在特征相差明显时的效果会很好，在循环过程中会不断扩大特征效果。<br />
与 sigmoid 的区别是，tanh 是 0 均值的，比Sigmoid函数收敛速度更快，因此实际应用中 tanh 会比 sigmoid 更好，但是没有改变Sigmoid函数的最大问题——由于饱和性产生的梯度消失</p>
</blockquote>
<h3 id="relu"><a class="markdownIt-Anchor" href="#relu"></a> relu</h3>
<blockquote>
<p>整流线性单元<br />
使用 ReLU 得到的 SGD 的收敛速度会比 sigmoid/tanh 快很多</p>
<p>ReLU 的缺点：<br />
训练的时候很”脆弱”，很容易就”die”了<br />
例如，一个非常大的梯度流过一个 ReLU 神经元，更新过参数之后，这个神经元再也不会对任何数据有激活现象了，那么这个神经元的梯度就永远都会是 0.<br />
如果 learning rate 很大，那么很有可能网络中的 40% 的神经元都”dead”了。</p>
</blockquote>
<h3 id="leaky-relu-p-relu-r-relu"><a class="markdownIt-Anchor" href="#leaky-relu-p-relu-r-relu"></a> Leaky-ReLU、P-ReLU、R-ReLU</h3>
<blockquote>
<p>Leaky ReLU 的概念是：当 x &lt; 0 时，它得到 0.1 的正梯度。该函数一定程度上缓解了 dead ReLU 问题，但是使用该函数的结果并不连贯。尽管它具备 ReLU 激活函数的所有特征，如计算高效、快速收敛、在正区域内不会饱和。</p>
<p>Leaky ReLU 可以得到更多扩展。不让 x 乘常数项，而是让 x 乘超参数，这看起来比 Leaky ReLU 效果要好。该扩展就是 Parametric ReLU。</p>
<p>Randomized ReLU，在测试阶段，把训练过程中所有的 αij 取个平均值。</p>
<p>总之，最好使用 ReLU，但是你可以使用 Leaky ReLU 或 Parametric ReLU 实验一下，看看它们是否更适合你的问题。</p>
</blockquote>
<h3 id="maxout"><a class="markdownIt-Anchor" href="#maxout"></a> Maxout</h3>
<blockquote>
<p>Maxout 是对 ReLU 和 Leaky ReLU 的一般化归纳。<br />
这样 Maxout 神经元就拥有 ReLU 单元的所有优点（线性和不饱和），而没有它的缺点（死亡的 ReLU 单元）。然而和 ReLU 对比，它每个神经元的参数数量增加了一倍，这就导致整体参数的数量激增。</p>
</blockquote>
<h3 id="softplus"><a class="markdownIt-Anchor" href="#softplus"></a> Softplus</h3>
<blockquote>
<p>softplus可以看作是ReLu的平滑。根据神经科学家的相关研究，softplus和ReLu与脑神经元激活频率函数有神似的地方。也就是说，相比于早期的激活函数，softplus和ReLu更加接近脑神经元的激活模型，而神经网络正是基于脑神经科学发展而来，这两个激活函数的应用促成了神经网络研究的新浪潮。ReLU是目前深度学习模型中应用最火热的激活函数之一。</p>
</blockquote>
<h3 id="softmax"><a class="markdownIt-Anchor" href="#softmax"></a> softmax</h3>
<blockquote>
<p>Softmax - 用于多分类神经网络输出</p>
</blockquote>
<h3 id="elu"><a class="markdownIt-Anchor" href="#elu"></a> ELU</h3>
<blockquote>
<p>指数化线性单元<br />
优点：ELU具备Relu的优点，同时ELU也解决了Relu函数自身“死区”问题。不过ELU函数指数操作稍稍加大了工作量，实际计算中ELU中超参数λ一般设置为1。</p>
</blockquote>
<h3 id="selu"><a class="markdownIt-Anchor" href="#selu"></a> selu</h3>
<blockquote>
<p>可伸缩的指数线性单元</p>
</blockquote>
<h3 id="exponential"><a class="markdownIt-Anchor" href="#exponential"></a> exponential</h3>
<blockquote>
<p>自然数指数激活函数</p>
</blockquote>
<h2 id="激活函数选择"><a class="markdownIt-Anchor" href="#激活函数选择"></a> 激活函数选择</h2>
<blockquote>
<p>１．Sigmoid 和 ReLU 比较：sigmoid 的梯度消失问题，ReLU 的导数就不存在这样的问题<br />
２．Sigmoid 和 Softmax 区别：sigmoid将一个real value映射到（0,1）的区间，用来做二分类， softmax 把一个 k 维的real value向量映射成一个b维,其中 b维 是一个 0～1 的常数，输出神经元之和为 1.0，所以相当于概率值，然后可以根据 bi 的概率大小来进行多分类的任务。<br />
３．Sigmoid 和 tanh(x) 不建议使用；<br />
４．Relu最常用；<br />
５．为了进一步提高模型精度，Leaky Relu、参数化Relu、随机化Relu 和 ELU 均可尝试（但四者之间无绝对的高下之分）。<br />
６．在较深层的神经网络中，选用relu激活函数能使梯度更好地传播回去，但当使用softmax作为最后一层的激活函数时，其前一层最好不要使用relu进行激活，而是使用tanh作为替代，否则最终的loss很可能变成Nan；<br />
７．当选用高级激活函数时，建议的尝试顺序为ReLU-&gt;ELU-&gt;PReLU-&gt;MPELU，因为前两者没有超参数，而后两者需要自己调节参数使其更适应构建的网络结构。</p>
</blockquote>
<p>参考：<br />
<a href="https://www.cnblogs.com/lovychen/p/7561895.html">深度学习激活函数比较</a><br />
<a href="https://blog.csdn.net/hai008007/article/details/79749557">深度学习中激活函数的作用</a><br />
<a href="https://blog.csdn.net/qq_33221533/article/details/80973829">深度学习中的激活函数</a><br />
<a href="https://cloud.tencent.com/developer/article/1347786">深度学习: 激活函数 (Activation Functions)</a><br />
<a href="https://blog.csdn.net/cyh_24/article/details/50593400">神经网络之激活函数(Activation Function)</a><br />
<a href="https://www.jianshu.com/p/6158d88a4512">深度学习中的激活函数</a><br />
<a href="http://www.360doc.com/content/17/1102/21/1489589_700400500.shtml">深度学习中的主要激活函数有哪些？</a><br />
<a href="https://www.jianshu.com/p/916243941347">深度学习之激活函数详解</a><br />
<a href="https://blog.csdn.net/siyue0211/article/details/80480396">[深度学习] 激活函数</a><br />
<a href="https://www.cnblogs.com/liuyu124/p/7332471.html">浅谈深度学习中的激活函数 - The Activation Function in Deep Learning</a><br />
<a href="https://keras.io/zh/activations/">激活函数的用法</a></p>
]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>激活函数</tag>
      </tags>
  </entry>
  <entry>
    <title>对深度学习预训练的理解</title>
    <url>/2017/11/06/%E5%AF%B9%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9A%84%E7%90%86%E8%A7%A3/</url>
    <content><![CDATA[<p>本文从原理及使用方法，介绍深度学习中的预训练操作</p>
<a id="more"></a>
<h2 id="1什么使用预训练"><a class="markdownIt-Anchor" href="#1什么使用预训练"></a> 1.什么使用预训练？</h2>
<p>深度网络存在以下缺点：1. 网络越深，需要的训练样本数越多。若用监督则需大量标注样本，不然小规模样本容易造成过拟合。（深层网络意味着特征比较多，机器学习里面临多特征：a.多样本 b.规则化c.特征选择）2. 多层神经网络参数优化是个高阶非凸优化问题，常收敛较差的局部解3. 梯度扩散问题。BP算法计算出的梯度随着深度向前而显著下降，导致前面网络参数贡献很小，更新速度慢。</p>
<p>解决方法：逐层贪婪训练。无监督预训练（unsupervised pre-training）即训练网络的第一个隐藏层，再训练第二个，最后用这些训练好的网络参数值作为整个网络参数的初始值。  无监督学习—&gt;参数初始值；监督学习—&gt;fine-tuning，即训练有标注样本。经过预训练最终能得到比较好的局部最优解。简单来说，预训练模型(pre-trained model)是前人为了解决类似问题所创造出来的模型。你在解决问题的时候，不用从零开始训练一个新模型，可以从在类似问题中训练过的模型入手。</p>
<h2 id="2选择预训练模型"><a class="markdownIt-Anchor" href="#2选择预训练模型"></a> 2.选择预训练模型</h2>
<p>当在训练经网络的时候我们的目标是什么？我们希望网络能够在多次正向反向迭代的过程中，找到合适的权重。<br />
  通过使用之前在大数据集上经过训练的预训练模型，我们可以直接使用相应的结构和权重，将它们应用到我们正在面对的问题上。这被称作是“迁移学习”，即将预训练的模型“迁移”到我们正在应对的特定问题中。<br />
  在选择预训练模型的时候你需要非常仔细，如果你的问题与预训练模型训练情景下有很大的出入，那么模型所得到的预测结果将会非常不准确。<br />
  举例来说，如果把一个原本用于语音识别的模型用来做用户识别，那结果肯定是不理想的。<br />
  幸运的是，Keras库中有许多这类预训练的结构。<br />
  ImageNet数据集已经被广泛用作训练集，因为它规模足够大(包括120万张图片)，有助于训练普适模型。ImageNet的训练目标，是将所有的图片正确地划分到1000个分类条目下。这1000个分类基本上都来源于我们的日常生活，比如说猫猫狗狗的种类，各种家庭用品，日常通勤工具等等。<br />
  在迁移学习中，这些预训练的网络对于ImageNet数据集外的图片也表现出了很好的泛化性能。<br />
  既然预训练模型已经训练得很好，我们就不会在短时间内去修改过多的权重，在迁移学习中用到它的时候，往往只是进行微调(fine tune)。<br />
  在修改模型的过程中，我们通过会采用比一般训练模型更低的学习速率。</p>
<h2 id="3微调模型的方法"><a class="markdownIt-Anchor" href="#3微调模型的方法"></a> 3.微调模型的方法</h2>
<p>a.特征提取<br />
  我们可以将预训练模型当做特征提取装置来使用。具体的做法是，将输出层去掉，然后将剩下的整个网络当做一个固定的特征提取机，从而应用到新的数据集中。</p>
<p>b.采用预训练模型的结构<br />
  我们还可以采用预训练模型的结构，但先将所有的权重随机化，然后依据自己的数据集进行训练。</p>
<p>c.训练特定层，冻结其他层<br />
  另一种使用预训练模型的方法是对它进行部分的训练。具体的做法是，将模型起始的一些层的权重保持不变，重新训练后面的层，得到新的权重。在这个过程中，我们可以多次进行尝试，从而能够依据结果找到frozen layers和retrain layers之间的最佳搭配。<br />
  如何使用与训练模型，是由数据集大小和新旧数据集(预训练的数据集和我们要解决的数据集)之间数据的相似度来决定的。</p>
<p><strong>场景一：数据集小，数据相似度高(与pre-trained model的训练数据相比而言)</strong><br />
  在这种情况下，因为数据与预训练模型的训练数据相似度很高，因此我们不需要重新训练模型。我们只需要将输出层改制成符合问题情境下的结构就好。<br />
  我们使用预处理模型作为模式提取器。<br />
  比如说我们使用在ImageNet上训练的模型来辨认一组新照片中的小猫小狗。在这里，需要被辨认的图片与ImageNet库中的图片类似，但是我们的输出结果中只需要两项——猫或者狗。<br />
  在这个例子中，我们需要做的就是把dense layer和最终softmax layer的输出从1000个类别改为2个类别。</p>
<p><strong>场景二：数据集小，数据相似度不高</strong><br />
  在这种情况下，我们可以冻结预训练模型中的前k个层中的权重，然后重新训练后面的n-k个层，当然最后一层也需要根据相应的输出格式来进行修改。<br />
  因为数据的相似度不高，重新训练的过程就变得非常关键。而新数据集大小的不足，则是通过冻结预训练模型的前k层进行弥补。</p>
<p><strong>场景三：数据集大，数据相似度不高</strong><br />
  在这种情况下，因为我们有一个很大的数据集，所以神经网络的训练过程将会比较有效率。然而，因为实际数据与预训练模型的训练数据之间存在很大差异，采用预训练模型将不会是一种高效的方式。<br />
  因此最好的方法还是将预处理模型中的权重全都初始化后在新数据集的基础上重头开始训练。</p>
<p><strong>场景四：数据集大，数据相似度高</strong><br />
  这就是最理想的情况，采用预训练模型会变得非常高效。最好的运用方式是保持模型原有的结构和初始权重不变，随后在新数据集的基础上重新训练。</p>
<h2 id="4预训练的效果"><a class="markdownIt-Anchor" href="#4预训练的效果"></a> 4.预训练的效果</h2>
<p>a.测试误差即泛化能力更强<br />
b.fine-tuning对神经网络权值改变很小，似乎权值被困在某个局部区域。而且第一层改变最少，第二层次之…最后一层最大。这说明浅层的权值参数似乎是把参数整体限制在某个范围，即浅层权值对结果影响比较大，然而BP算法会出现梯度消失，即不容易改变浅层的权值参数。<br />
c.模型参数轨迹，无预训练不同初始值收敛到不同局部点，收敛点的扩散性；预训练会更偏向某些点，收敛点的收敛性。</p>
<h2 id="5注意事项"><a class="markdownIt-Anchor" href="#5注意事项"></a> 5.注意事项</h2>
<p>预训练类似于规则化权值,但是预训练规则化又不同于经典的规则化（L1/L2），训练数目越多，预训练结果越好,基于pre-training的深度学习网络，当满足大数据、深层次、多节点网络，效果更优。</p>
<p>参考：<br />
<a href="https://blog.csdn.net/u012509485/article/details/80507138">深度学习预训练</a><br />
<a href="https://www.jianshu.com/p/bdbd8f63afcb">深度学习中的预训练</a><br />
<a href="https://blog.csdn.net/weixin_39454351/article/details/86573753">深度学习中预训练和微调的个人理解</a><br />
<a href="https://blog.csdn.net/Hk_john/article/details/80495385">迁移学习：怎样用预训练模型搞定深度学习？</a></p>
]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>预训练</tag>
      </tags>
  </entry>
  <entry>
    <title>改变ubuntu终端显示语言（桌面系统是中文，终端提示是英文）</title>
    <url>/2018/04/10/%E6%94%B9%E5%8F%98ubuntu%E7%BB%88%E7%AB%AF%E6%98%BE%E7%A4%BA%E8%AF%AD%E8%A8%80%EF%BC%88%E6%A1%8C%E9%9D%A2%E7%B3%BB%E7%BB%9F%E6%98%AF%E4%B8%AD%E6%96%87%EF%BC%8C%E7%BB%88%E7%AB%AF%E6%8F%90%E7%A4%BA%E6%98%AF%E8%8B%B1%E6%96%87%EF%BC%89/</url>
    <content><![CDATA[<p>本文针对linux系统设置为中文后，终端也同步被改为中文，当出现错误提示时，不方便搜索答案，因此需要将终端语言改为英文的</p>
<a id="more"></a>
<p>1.打开终端：<br />
$ vi .bashrc</p>
<p>2.最后添加：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> [ <span class="string">&quot;<span class="variable">$TERM</span>&quot;</span>=<span class="string">&quot;linux&quot;</span> ] ;<span class="keyword">then</span></span><br><span class="line"><span class="built_in">export</span> LANGUAGE=en_US</span><br><span class="line"><span class="built_in">export</span> LANG=en_US.UTF-8</span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure>
<p>关闭当前终端，重新打开终端后命令中的提示就显示英文提示了。</p>
<p>注意对那些中文文件名，文件夹名会显示为乱码。<br />
实际是改变系统两个环境变量  $LANGUAGE 和 $LANG的值（可以用echo $LANG 来查看值）</p>
<p>注：此方法在bash和zsh上均有效</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>部署深度学习模型时的全流程加密方案探索</title>
    <url>/2021/03/11/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%83%A8%E7%BD%B2%E5%85%A8%E6%B5%81%E7%A8%8B%E5%8A%A0%E5%AF%86%E6%96%B9%E6%A1%88%E6%8E%A2%E7%B4%A2/</url>
    <content><![CDATA[<p>本文用于探索深度学习模型在部署全流程过程中的整体方案</p>
<a id="more"></a>
<h2 id="部署场景"><a class="markdownIt-Anchor" href="#部署场景"></a> 部署场景</h2>
<p><strong>涉及程序端及编程语言</strong>：界面端（C#）、服务端（C#）、训练端（Python）</p>
<p><strong>剥离加密之后的流程</strong>：</p>
<ol>
<li>界面端根据训练配置调用训练端</li>
<li>训练端训练结束后保存模型（结构、文件）</li>
<li>服务端加载模型</li>
</ol>
<h2 id="加密要求"><a class="markdownIt-Anchor" href="#加密要求"></a> 加密要求</h2>
<p>由C#编写的程序部署时会将其编译为二进制，无需加密保护，主要是针对训练端的Python及训练得到的模型，有以下要求：</p>
<ol>
<li>无法明文看到Python代码</li>
<li>无法获得模型（结构与权重）</li>
<li>windows上部署</li>
<li>加密方案不能大幅度增加部署成本</li>
</ol>
<h2 id="加密方案"><a class="markdownIt-Anchor" href="#加密方案"></a> 加密方案</h2>
<p>针对Python加密以及模型的加密，调查了主流的加密方案</p>
<h4 id="网络收集的python加密思路"><a class="markdownIt-Anchor" href="#网络收集的python加密思路"></a> 网络收集的Python加密思路</h4>
<table>
<thead>
<tr>
<th>序号</th>
<th>工具</th>
<th>方法描述</th>
<th>加密及解密</th>
<th>优缺点</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Nuitka<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup><sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup></td>
<td>.py 文件先被转成了 .c 文件，然后被编译成 .o 文件，最后合并成 .bin 可执行文件，从 bin 到 C 是不可逆的，从 C 到 Python 也是不可逆的，因此代码是安全的</td>
<td>编译为bin,<a href="http://xn--siqv1isvm2mbc8dr4c5s1fvtbv04cilu.so">或者编译为动态链接库.so</a> 文件</td>
<td>工作量小，安全性高，使用加密之后的Python便捷；编译时间长，过程复杂</td>
</tr>
<tr>
<td>2</td>
<td>发行.pyc文件<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup></td>
<td>通过compileall模块将.py文件转为.pyc文件，该文件是二进制，无法直接看源代码，而python解释器可以直接执行.pyc文件</td>
<td></td>
<td>台兼容性好，.py 能在哪里运行，.pyc 就能在哪里运行；解释器兼容性差，.pyc 只能在特定版本的解释器上运行。有现成的反编译工具，破解成本低</td>
</tr>
<tr>
<td>3</td>
<td>代码混淆（oxyry，pyobfuscate）<sup class="footnote-ref"><a href="#fn3" id="fnref3:1">[3:1]</a></sup></td>
<td>让人看不懂代码，移除注释和文档，改变缩进，在tokens中间加入一定空格，重命名函数、类、变量，在空白行插入无效代码</td>
<td></td>
<td>提高了一点源码破解门槛。兼容性好，只要源码逻辑能做到兼容，混淆代码亦能；只能对单个文件混淆，无法做到多个互相有联系的源码文件的联动混淆</td>
</tr>
<tr>
<td>4</td>
<td>py2exe<sup class="footnote-ref"><a href="#fn3" id="fnref3:2">[3:2]</a></sup></td>
<td>将源码编译为 .pyc 文件，加之必要的依赖文件，一起打包成一个可执行文件。最终 py2exe 打包出的是二进制文件。</td>
<td></td>
<td>直接打包成 exe，方便分发和执行。破解门槛比 .pyc 更高一些；兼容性差，只能运行在 Windows 系统上。生成的可执行文件内的布局是明确、公开的，可以找到源码对应的 .pyc 文件，进而反编译出源码。</td>
</tr>
<tr>
<td>5</td>
<td>Cython<sup class="footnote-ref"><a href="#fn3" id="fnref3:3">[3:3]</a></sup><sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup></td>
<td>将 .py/.pyx 编译为 .c 文件，再将 .c 文件编译为 .so(Unix) 或 .pyd(Windows)</td>
<td></td>
<td>生成的二进制 .so 或 .pyd 文件难以破解。同时带来了性能提升；兼容性稍差，对于不同版本的操作系统，可能需要重新编译。虽然支持大多数 Python 代码，但如果一旦发现部分代码不支持，完善成本较高。</td>
</tr>
<tr>
<td>6</td>
<td>Pyinstaller<sup class="footnote-ref"><a href="#fn5" id="fnref5">[5]</a></sup><sup class="footnote-ref"><a href="#fn6" id="fnref6">[6]</a></sup></td>
<td>打包为exe文件，</td>
<td></td>
<td>将Python文件转换为exe文件，以及dist文件夹和build文件夹，如果要移植到其他电脑上运行，也是只需要将这两个文件夹复制到对方电脑上，即使对方没有python环境，也可以运行程序，具有较好的兼容性；pyinstxtractor.py可以进行反编译</td>
</tr>
</tbody>
</table>
<p>注：py是源文件，pyc是源文件编译后的文件，pyo是源文件优化编译后的文件，pyd是其他语言写的python库<sup class="footnote-ref"><a href="#fn7" id="fnref7">[7]</a></sup></p>
<h4 id="网络收集的模型加密思路"><a class="markdownIt-Anchor" href="#网络收集的模型加密思路"></a> 网络收集的模型加密思路</h4>
<table>
<thead>
<tr>
<th>序号</th>
<th>方法描述</th>
<th>加密及解密</th>
<th>优缺点</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>将模型转换为二进制，直接打开看不见原始内容<sup class="footnote-ref"><a href="#fn8" id="fnref8">[8]</a></sup></td>
<td>ncnn2mem工具可以将ncnn模型转为二进制的：ncnn2mem resnet.param resnet.bin</td>
<td>使用netron可以查看文件，反编译成本很低</td>
</tr>
<tr>
<td>2</td>
<td>将模型打包为C code，并嵌入到程序中<sup class="footnote-ref"><a href="#fn8" id="fnref8:1">[8:1]</a></sup></td>
<td>ncnn2mem resnet.param resnet.id.h resnet.mem.h,把这个文件 include 进来，用内存加载接口，把模型当作代码直接嵌入编译进程序中</td>
<td>分发exe即可，虽然不能直接获得模型，但是能用 objdump 或者十六进制编辑器从 exe 静态区中把模型抠出来</td>
</tr>
<tr>
<td>3</td>
<td>使用专用加密库对模型加密<sup class="footnote-ref"><a href="#fn8" id="fnref8:2">[8:2]</a></sup></td>
<td>用 openssl，把 param.bin 和 bin 两个文件用 AES 加密成 param.bin.enc 和 bin.enc；程序实现以下三步，加载加密模型：读enc文件、解密到内存、从内存加载模型</td>
<td>可以从算法中xor pattern或获得密钥；堆内存上暴力查找 enc 大小左右的连续内存和关键字，把模型从内存里抠出来</td>
</tr>
<tr>
<td>4</td>
<td>自定义加密算法和数据读取<sup class="footnote-ref"><a href="#fn8" id="fnref8:3">[8:3]</a></sup></td>
<td>用普通 xor 混淆实现</td>
<td>任意时刻内存中都不会存在完整的模型内容，边解密边加载</td>
</tr>
<tr>
<td>5</td>
<td>给模型加些自定义 op<sup class="footnote-ref"><a href="#fn8" id="fnref8:4">[8:4]</a></sup></td>
<td>cnn 可以自定义 op，可以运行时注册自定义 op，可以直接改 param</td>
<td>即便看到了明文的 param，也容易被名字欺骗</td>
</tr>
<tr>
<td>6</td>
<td>将外部文件嵌入二进制文件(exe，dll)，并加壳保护该文件<sup class="footnote-ref"><a href="#fn9" id="fnref9">[9]</a></sup></td>
<td>直接程序之间调用</td>
<td>这种方法开发量小，仅需要将资源文件嵌入并在运行时加载。</td>
</tr>
<tr>
<td>7</td>
<td>自定义的外部文件加密方式<sup class="footnote-ref"><a href="#fn9" id="fnref9:1">[9:1]</a></sup></td>
<td></td>
<td>在加载模型文件前解密，考虑到安全性，防止解密后的模型文件暴露于内存被轻易dump，考虑使用流式加密的方法进行加解密，由此相对安全一点。</td>
</tr>
<tr>
<td>8</td>
<td>用protobuf自定义一种格式呀，没有协议文件<sup class="footnote-ref"><a href="#fn10" id="fnref10">[10]</a></sup></td>
<td></td>
<td>工程量比较大</td>
</tr>
<tr>
<td>9</td>
<td>部署到云端给客户api接口调用<sup class="footnote-ref"><a href="#fn10" id="fnref10:1">[10:1]</a></sup></td>
<td></td>
<td>特定场景不适合</td>
</tr>
</tbody>
</table>
<p><strong>参考资料：</strong></p>
<hr class="footnotes-sep" />
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p><a href="https://www.zhihu.com/question/299880517/answer/1719845490">如何防止商用的深度学习模型源码泄露？</a> <a href="#fnref1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn2" class="footnote-item"><p><a href="https://zhuanlan.zhihu.com/c_1245860717607686144">Nuitka-Python打包exe - 知乎</a> <a href="#fnref2" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn3" class="footnote-item"><p><a href="http://www.361way.com/python-encrypt/6159.html">现有Python 代码加密方案 - 运维之路</a> <a href="#fnref3" class="footnote-backref">↩︎</a> <a href="#fnref3:1" class="footnote-backref">↩︎</a> <a href="#fnref3:2" class="footnote-backref">↩︎</a> <a href="#fnref3:3" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn4" class="footnote-item"><p><a href="https://cloud.tencent.com/developer/article/1661136">用Cython加密打包python项目</a> <a href="#fnref4" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn5" class="footnote-item"><p><a href="https://www.cnblogs.com/hulk-1029/p/12106630.html">利用pyinstaller打包加密Python项目</a> <a href="#fnref5" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn6" class="footnote-item"><p><a href="https://blog.csdn.net/weixin_43652669/article/details/106401233">Pyinstaller 打包加密python项目</a> <a href="#fnref6" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn7" class="footnote-item"><p><a href="https://blog.csdn.net/willhuo/article/details/49886663">python py、pyc、pyo、pyd文件区别</a> <a href="#fnref7" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn8" class="footnote-item"><p><a href="https://zhuanlan.zhihu.com/p/268327784?utm_source=wechat_timeline">如何加密ncnn模型 - 知乎</a> <a href="#fnref8" class="footnote-backref">↩︎</a> <a href="#fnref8:1" class="footnote-backref">↩︎</a> <a href="#fnref8:2" class="footnote-backref">↩︎</a> <a href="#fnref8:3" class="footnote-backref">↩︎</a> <a href="#fnref8:4" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn9" class="footnote-item"><p><a href="https://blog.csdn.net/atp1992/article/details/87636173?utm_medium=distribute.pc_relevant_download.none-task-blog-searchFromBaidu-7.nonecase&amp;dist_request_id=&amp;depth_1-utm_source=distribute.pc_relevant_download.none-task-blog-searchFromBaidu-7.nonecas">浅谈深度学习模型如何保护–AES加密文件流的实现（带源码）</a> <a href="#fnref9" class="footnote-backref">↩︎</a> <a href="#fnref9:1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn10" class="footnote-item"><p><a href="https://www.zhihu.com/question/299880517">如何防止商用的深度学习模型源码泄露？ - 知乎</a> <a href="#fnref10" class="footnote-backref">↩︎</a> <a href="#fnref10:1" class="footnote-backref">↩︎</a></p>
</li>
</ol>
</section>
]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>部署</tag>
        <tag>加密</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习链式求导法则</title>
    <url>/2017/03/15/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%93%BE%E5%BC%8F%E6%B1%82%E5%AF%BC%E6%B3%95%E5%88%99/</url>
    <content><![CDATA[<p>本文使用一个两层的神经网络，推导深度学习中经典的过程：链式求导</p>
<a id="more"></a>
<p><strong>原始网络结构</strong><br />
<img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613531916405.png" alt="网络结构" /></p>
<p>链式求导法则，从网络的输出层将输入层逐层回传误差，并求得每个参数要下降的梯度。</p>
<h2 id="1输出层的前一层之间的参数更新"><a class="markdownIt-Anchor" href="#1输出层的前一层之间的参数更新"></a> 1.输出层的前一层之间的参数更新</h2>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613531916548.png" alt="倒数第二层参数更新示意图" /></p>
<p>对于一个神经元来说，其更新节点前的边权重过程需要求三个导数，分别是：<br />
(1)边上尾节点总的误差与输出之间的导数，即目标函数与输出之间的导数</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>D</mi><mi>e</mi><msub><mi>r</mi><mn>1</mn></msub><mo>=</mo><mfrac><mrow><mi>σ</mi><mo stretchy="false">(</mo><msub><mi>E</mi><mrow><mi>t</mi><mi>o</mi><mi>t</mi><mi>a</mi><mi>l</mi></mrow></msub><mo stretchy="false">)</mo></mrow><mrow><mi>σ</mi><mo stretchy="false">(</mo><mi>O</mi><mi>u</mi><msub><mi>t</mi><mrow><mi>o</mi><mn>1</mn></mrow></msub><mo stretchy="false">)</mo></mrow></mfrac><mo>=</mo><mfrac><mrow><mi>σ</mi><mo stretchy="false">(</mo><msub><mi>E</mi><mrow><mi>o</mi><mn>1</mn></mrow></msub><mo>+</mo><msub><mi>E</mi><mrow><mi>o</mi><mn>2</mn></mrow></msub><mo stretchy="false">)</mo></mrow><mrow><mi>σ</mi><mo stretchy="false">(</mo><mi>O</mi><mi>u</mi><msub><mi>t</mi><mrow><mi>o</mi><mn>1</mn></mrow></msub><mo stretchy="false">)</mo></mrow></mfrac><mspace linebreak="newline"></mspace><mo>=</mo><mfrac><mrow><mi>σ</mi><mo stretchy="false">(</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mo stretchy="false">(</mo><mo stretchy="false">(</mo><mi>t</mi><mi>r</mi><mi>a</mi><mi>g</mi><msub><mi>e</mi><mn>1</mn></msub><mo>−</mo><mi>O</mi><mi>u</mi><msub><mi>t</mi><mrow><mi>o</mi><mn>1</mn></mrow></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>+</mo><mo stretchy="false">(</mo><mi>t</mi><mi>r</mi><mi>a</mi><mi>g</mi><msub><mi>e</mi><mn>2</mn></msub><mo>−</mo><mi>O</mi><mi>u</mi><msub><mi>t</mi><mrow><mi>o</mi><mn>2</mn></mrow></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo stretchy="false">)</mo></mrow><mrow><mi>σ</mi><mo stretchy="false">(</mo><mi>O</mi><mi>u</mi><msub><mi>t</mi><mrow><mi>o</mi><mn>1</mn></mrow></msub><mo stretchy="false">)</mo></mrow></mfrac><mo>=</mo><mi>O</mi><mi>u</mi><msub><mi>t</mi><mrow><mi>o</mi><mn>1</mn></mrow></msub><mo>−</mo><mi>t</mi><mi>r</mi><mi>a</mi><mi>g</mi><msub><mi>e</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">Der_1=\frac{\sigma(E_{total})}{\sigma(Out_{o1})}=\frac{\sigma(E_{o1}+E_{o2})}{\sigma(Out_{o1})}\\=\frac{\sigma(\frac{1}{2}((trage_1-Out_{o1})^2+(trage_2-Out_{o2})^2 ) }{\sigma(Out_{o1})}=Out_{o1}-trage_1
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="mord mathdefault">e</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mord mathdefault">u</span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight">t</span><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mord mathdefault">u</span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.516108em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.580108em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mord mathdefault">u</span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.7350000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mopen">(</span><span class="mopen">(</span><span class="mord mathdefault">t</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord"><span class="mord mathdefault">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mord mathdefault">u</span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mopen">(</span><span class="mord mathdefault">t</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord"><span class="mord mathdefault">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mord mathdefault">u</span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mord mathdefault">u</span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.80952em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">t</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord"><span class="mord mathdefault">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></p>
<p>(2)边上尾节点输出和其激活函数的导数</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>D</mi><mi>e</mi><msub><mi>r</mi><mn>2</mn></msub><mo>=</mo><mfrac><mrow><mi>σ</mi><mo stretchy="false">(</mo><mi>O</mi><mi>u</mi><msub><mi>t</mi><mrow><mi>o</mi><mn>1</mn></mrow></msub><mo stretchy="false">)</mo></mrow><mrow><mi>σ</mi><mo stretchy="false">(</mo><mi>n</mi><mi>e</mi><msub><mi>t</mi><mrow><mi>o</mi><mn>1</mn></mrow></msub><mo stretchy="false">)</mo></mrow></mfrac><mo>=</mo><mfrac><mrow><mi>σ</mi><mo stretchy="false">(</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi><mrow><mo>−</mo><mi>n</mi><mi>e</mi><msub><mi>t</mi><mrow><mi>o</mi><mn>1</mn></mrow></msub></mrow></msup></mrow></mfrac><mo stretchy="false">)</mo></mrow><mrow><mi>σ</mi><mrow><mo stretchy="false">(</mo><mi>n</mi><mi>e</mi><msub><mi>t</mi><mrow><mi>o</mi><mn>1</mn></mrow></msub><mo stretchy="false">)</mo></mrow></mrow></mfrac><mo>=</mo><mi>o</mi><mi>u</mi><msub><mi>t</mi><mrow><mi>o</mi><mn>1</mn></mrow></msub><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>o</mi><mi>u</mi><msub><mi>t</mi><mrow><mi>o</mi><mn>1</mn></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Der_2=\frac{\sigma(Out_{o1})}{\sigma(net_{o1})}=\frac{\sigma(\frac{1}{1+e^{-net_{o1}}})}{\sigma{(net_{o1})}}=out_{o1}(1-out_{o1})
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="mord mathdefault">e</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord mathdefault">n</span><span class="mord mathdefault">e</span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mord mathdefault">u</span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.574439em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.638439em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mord"><span class="mopen">(</span><span class="mord mathdefault">n</span><span class="mord mathdefault">e</span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.7933310000000002em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">+</span><span class="mord mtight"><span class="mord mathdefault mtight">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7611214285714286em;"><span style="top:-2.8217785714285717em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mathdefault mtight">n</span><span class="mord mathdefault mtight">e</span><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3447999999999998em;margin-left:0em;margin-right:0.1em;"><span class="pstrut" style="height:2.64444em;"></span><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29964em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.403331em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">o</span><span class="mord mathdefault">u</span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">o</span><span class="mord mathdefault">u</span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p>
<p>(3)边上尾节点输入与该边的导数</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>D</mi><mi>e</mi><msub><mi>r</mi><mn>3</mn></msub><mo>=</mo><mfrac><mrow><mi>σ</mi><mo stretchy="false">(</mo><mi>n</mi><mi>e</mi><msub><mi>t</mi><mrow><mi>o</mi><mn>1</mn></mrow></msub><mo stretchy="false">)</mo></mrow><mrow><mi>σ</mi><mo stretchy="false">(</mo><msub><mi>w</mi><mn>5</mn></msub><mo stretchy="false">)</mo></mrow></mfrac><mo>=</mo><mfrac><mrow><mi>σ</mi><mo stretchy="false">(</mo><mi>O</mi><mi>u</mi><msub><mi>t</mi><mrow><mi>h</mi><mn>1</mn></mrow></msub><mo>∗</mo><msub><mi>w</mi><mn>5</mn></msub><mo>+</mo><mi>b</mi><mo stretchy="false">)</mo></mrow><mrow><mi>σ</mi><mo stretchy="false">(</mo><msub><mi>w</mi><mn>5</mn></msub><mo stretchy="false">)</mo></mrow></mfrac><mo>=</mo><mi>O</mi><mi>u</mi><msub><mi>t</mi><mrow><mi>h</mi><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">Der_3=\frac{\sigma(net_{o1})}{\sigma(w_5)}=\frac{\sigma(Out_{h1} * w_5+b)}{\sigma(w_5)}=Out_{h1}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="mord mathdefault">e</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">5</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord mathdefault">n</span><span class="mord mathdefault">e</span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">5</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mord mathdefault">u</span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">h</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">5</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault">b</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mord mathdefault">u</span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">h</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></p>
<p>边权重<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mn>5</mn></msub></mrow><annotation encoding="application/x-tex">w_5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">5</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>下降的梯度为以上三个导数的乘积。</p>
<h2 id="2其他层参数更新"><a class="markdownIt-Anchor" href="#2其他层参数更新"></a> 2.其他层参数更新</h2>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613531916549.png" alt="倒数第三层参数更新示意图" /></p>
<p>下面展示求目标函数对权重<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">w_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的梯度，<br />
总体公式：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mfrac><mrow><mi>σ</mi><mo stretchy="false">(</mo><msub><mi>E</mi><mrow><mi>t</mi><mi>o</mi><mi>t</mi><mi>a</mi><mi>l</mi></mrow></msub><mo stretchy="false">)</mo></mrow><mrow><mi>σ</mi><mo stretchy="false">(</mo><msub><mi>w</mi><mn>1</mn></msub><mo stretchy="false">)</mo></mrow></mfrac><mo>=</mo><mfrac><mrow><mi>σ</mi><mo stretchy="false">(</mo><msub><mi>E</mi><mrow><mi>t</mi><mi>o</mi><mi>t</mi><mi>a</mi><mi>l</mi></mrow></msub><mo stretchy="false">)</mo></mrow><mrow><mi>σ</mi><mo stretchy="false">(</mo><mi>O</mi><mi>u</mi><msub><mi>t</mi><msub><mi>h</mi><mn>1</mn></msub></msub><mo stretchy="false">)</mo></mrow></mfrac><mo>∗</mo><mfrac><mrow><mi>σ</mi><mo stretchy="false">(</mo><mi>O</mi><mi>u</mi><msub><mi>t</mi><msub><mi>h</mi><mn>1</mn></msub></msub><mo stretchy="false">)</mo></mrow><mrow><mi>σ</mi><mo stretchy="false">(</mo><mi>n</mi><mi>e</mi><msub><mi>t</mi><msub><mi>h</mi><mn>1</mn></msub></msub><mo stretchy="false">)</mo></mrow></mfrac><mo>∗</mo><mfrac><mrow><mi>σ</mi><mo stretchy="false">(</mo><mi>n</mi><mi>e</mi><msub><mi>t</mi><msub><mi>h</mi><mn>1</mn></msub></msub><mo stretchy="false">)</mo></mrow><mrow><mi>σ</mi><mo stretchy="false">(</mo><msub><mi>w</mi><mn>1</mn></msub><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\sigma(E_{total})}{\sigma(w_1)}=\frac{\sigma(E_{total})}{\sigma(Out_{h_1})}* \frac{\sigma(Out_{h_1})}{\sigma(net_{h_1})} * \frac{\sigma(net_{h_1})}{\sigma(w_1)}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.363em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight">t</span><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.3631em;vertical-align:-0.9361em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mord mathdefault">u</span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31731428571428577em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2501em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight">t</span><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9361em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.3631em;vertical-align:-0.9361em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord mathdefault">n</span><span class="mord mathdefault">e</span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31731428571428577em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2501em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.6769999999999996em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mord mathdefault">u</span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31731428571428577em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2501em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9361em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.6769999999999996em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord mathdefault">n</span><span class="mord mathdefault">e</span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31731428571428577em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2501em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<p>其中：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mfrac><mrow><mi>σ</mi><mo stretchy="false">(</mo><msub><mi>E</mi><mrow><mi>t</mi><mi>o</mi><mi>t</mi><mi>a</mi><mi>l</mi></mrow></msub><mo stretchy="false">)</mo></mrow><mrow><mi>σ</mi><mo stretchy="false">(</mo><mi>O</mi><mi>u</mi><msub><mi>t</mi><msub><mi>h</mi><mn>1</mn></msub></msub><mo stretchy="false">)</mo></mrow></mfrac><mi mathvariant="normal">＝</mi><mfrac><mrow><mi>σ</mi><mo stretchy="false">(</mo><msub><mi>E</mi><mrow><mi>o</mi><mn>1</mn></mrow></msub><mo stretchy="false">)</mo><mo>+</mo><mi>σ</mi><mo stretchy="false">(</mo><msub><mi>E</mi><mrow><mi>o</mi><mn>2</mn></mrow></msub><mo stretchy="false">)</mo></mrow><mrow><mi>σ</mi><mo stretchy="false">(</mo><mi>O</mi><mi>u</mi><msub><mi>t</mi><msub><mi>h</mi><mn>1</mn></msub></msub><mo stretchy="false">)</mo></mrow></mfrac><mo>=</mo><mfrac><mrow><mi>σ</mi><mo stretchy="false">(</mo><msub><mi>E</mi><mrow><mi>o</mi><mn>1</mn></mrow></msub><mo stretchy="false">)</mo></mrow><mrow><mi>σ</mi><mo stretchy="false">(</mo><mi>O</mi><mi>u</mi><msub><mi>t</mi><msub><mi>h</mi><mn>1</mn></msub></msub><mo stretchy="false">)</mo></mrow></mfrac><mo>+</mo><mfrac><mrow><mi>σ</mi><mo stretchy="false">(</mo><msub><mi>E</mi><mrow><mi>o</mi><mn>2</mn></mrow></msub><mo stretchy="false">)</mo></mrow><mrow><mi>σ</mi><mo stretchy="false">(</mo><mi>O</mi><mi>u</mi><msub><mi>t</mi><msub><mi>h</mi><mn>1</mn></msub></msub><mo stretchy="false">)</mo></mrow></mfrac><mi mathvariant="normal">≠</mi><mfrac><mrow><mi>σ</mi><mo stretchy="false">(</mo><msub><mi>E</mi><mrow><mi>o</mi><mn>1</mn></mrow></msub><mo>+</mo><msub><mi>E</mi><mrow><mi>o</mi><mn>2</mn></mrow></msub><mo stretchy="false">)</mo></mrow><mrow><mi>σ</mi><mo stretchy="false">(</mo><mi>O</mi><mi>u</mi><msub><mi>t</mi><msub><mi>h</mi><mn>1</mn></msub></msub><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\sigma(E_{total})}{\sigma(Out_{h_1})}＝ \frac{\sigma(E_{o1})+\sigma(E_{o2})}{\sigma(Out_{h_1})}= \frac{\sigma(E_{o1})}{\sigma(Out_{h_1})}+ \frac{\sigma(E_{o2})}{\sigma(Out_{h_1})} \neq   \frac{\sigma(E_{o1}+E_{o2})}{\sigma(Out_{h_1})}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.3631em;vertical-align:-0.9361em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mord mathdefault">u</span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31731428571428577em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2501em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight">t</span><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9361em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord cjk_fallback">＝</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mord mathdefault">u</span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31731428571428577em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2501em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9361em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.3631em;vertical-align:-0.9361em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mord mathdefault">u</span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31731428571428577em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2501em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9361em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.3631em;vertical-align:-0.9361em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mord mathdefault">u</span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31731428571428577em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2501em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9361em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel"><span class="mrel"><span class="mord"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="rlap"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="inner"><span class="mrel"></span></span><span class="fix"></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span></span><span class="mrel">=</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.3631em;vertical-align:-0.9361em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mord mathdefault">u</span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31731428571428577em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2501em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9361em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mfrac><mrow><mi>σ</mi><mo stretchy="false">(</mo><msub><mi>E</mi><mrow><mi>o</mi><mn>1</mn></mrow></msub><mo stretchy="false">)</mo></mrow><mrow><mi>σ</mi><mo stretchy="false">(</mo><mi>O</mi><mi>u</mi><msub><mi>t</mi><msub><mi>h</mi><mn>1</mn></msub></msub><mo stretchy="false">)</mo></mrow></mfrac><mo>=</mo><mfrac><mrow><mi>σ</mi><mo stretchy="false">(</mo><msub><mi>E</mi><mrow><mi>o</mi><mn>1</mn></mrow></msub><mo stretchy="false">)</mo></mrow><mrow><mi>σ</mi><mo stretchy="false">(</mo><mi>n</mi><mi>e</mi><msub><mi>t</mi><msub><mi>o</mi><mn>1</mn></msub></msub><mo stretchy="false">)</mo></mrow></mfrac><mo>∗</mo><mfrac><mrow><mi>σ</mi><mo stretchy="false">(</mo><mi>n</mi><mi>e</mi><msub><mi>t</mi><msub><mi>o</mi><mn>1</mn></msub></msub><mo stretchy="false">)</mo></mrow><mrow><mi>σ</mi><mo stretchy="false">(</mo><mi>O</mi><mi>u</mi><msub><mi>t</mi><msub><mi>h</mi><mn>1</mn></msub></msub><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex"> \frac{\sigma(E_{o1})}{\sigma(Out_{h_1})}=\frac{\sigma(E_{o1})}{\sigma(net_{o_1})}* \frac{\sigma(net_{o_1})}{\sigma(Out_{h_1})}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.3631em;vertical-align:-0.9361em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mord mathdefault">u</span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31731428571428577em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2501em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9361em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.3631em;vertical-align:-0.9361em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord mathdefault">n</span><span class="mord mathdefault">e</span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139199999999997em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31731428571428577em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2501em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9361em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.3631em;vertical-align:-0.9361em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mord mathdefault">u</span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31731428571428577em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2501em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.6769999999999996em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord mathdefault">n</span><span class="mord mathdefault">e</span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139199999999997em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31731428571428577em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2501em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9361em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mfrac><mrow><mi>σ</mi><mo stretchy="false">(</mo><msub><mi>E</mi><mrow><mi>o</mi><mn>1</mn></mrow></msub><mo stretchy="false">)</mo></mrow><mrow><mi>σ</mi><mo stretchy="false">(</mo><mi>n</mi><mi>e</mi><msub><mi>t</mi><msub><mi>o</mi><mn>1</mn></msub></msub><mo stretchy="false">)</mo></mrow></mfrac><mo>=</mo><mfrac><mrow><mi>σ</mi><mo stretchy="false">(</mo><msub><mi>E</mi><mrow><mi>o</mi><mn>1</mn></mrow></msub><mo stretchy="false">)</mo></mrow><mrow><mi>σ</mi><mo stretchy="false">(</mo><mi>O</mi><mi>u</mi><msub><mi>t</mi><mrow><mi>o</mi><mn>1</mn></mrow></msub><mo stretchy="false">)</mo></mrow></mfrac><mo>∗</mo><mfrac><mrow><mi>σ</mi><mo stretchy="false">(</mo><mi>O</mi><mi>u</mi><msub><mi>t</mi><mrow><mi>o</mi><mn>1</mn></mrow></msub><mo stretchy="false">)</mo></mrow><mrow><mi>σ</mi><mo stretchy="false">(</mo><mi>n</mi><mi>e</mi><msub><mi>t</mi><mrow><mi>o</mi><mn>1</mn></mrow></msub><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\sigma(E_{o1})}{\sigma(net_{o_1})}=\frac{\sigma(E_{o1})}{\sigma(Out_{o1})} * \frac{\sigma(Out_{o1})}{\sigma(net_{o1})}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.3631em;vertical-align:-0.9361em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord mathdefault">n</span><span class="mord mathdefault">e</span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139199999999997em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31731428571428577em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2501em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9361em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mord mathdefault">u</span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord mathdefault">n</span><span class="mord mathdefault">e</span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mord mathdefault">u</span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<p>通过以上公式可以计算出，目标函数对权重<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">w_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的梯度。</p>
<p>参考：<br />
<a href="https://blog.csdn.net/zhaomengszu/article/details/77834845">大白话讲解BP算法</a></p>
]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>链式求导</tag>
      </tags>
  </entry>
  <entry>
    <title>特征工程学习之sklearn单机特征工程</title>
    <url>/2017/03/25/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%E5%AD%A6%E4%B9%A0%E4%B9%8Bsklearn%E5%8D%95%E6%9C%BA%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/</url>
    <content><![CDATA[<p>本文基于sklearn进行数据的特征工作</p>
<a id="more"></a>
<h1 id="0数据的导入"><a class="markdownIt-Anchor" href="#0数据的导入"></a> 0.数据的导入</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"></span><br><span class="line"><span class="comment">#导入IRIS数据集</span></span><br><span class="line">iris=load_iris()</span><br><span class="line"></span><br><span class="line"><span class="comment">#特征矩阵</span></span><br><span class="line">print(iris.data[:<span class="number">5</span>],<span class="built_in">len</span>(iris.data))</span><br><span class="line"></span><br><span class="line"><span class="comment">#目标向量</span></span><br><span class="line">print(iris.target[:<span class="number">5</span>],<span class="built_in">len</span>(iris.target))</span><br></pre></td></tr></table></figure>
<pre><code>[[ 5.1  3.5  1.4  0.2]
 [ 4.9  3.   1.4  0.2]
 [ 4.7  3.2  1.3  0.2]
 [ 4.6  3.1  1.5  0.2]
 [ 5.   3.6  1.4  0.2]] 150
[0 0 0 0 0] 150
</code></pre>
<h1 id="1数据预处理"><a class="markdownIt-Anchor" href="#1数据预处理"></a> 1.数据预处理</h1>
<h2 id="11无量纲化"><a class="markdownIt-Anchor" href="#11无量纲化"></a> 1.1无量纲化</h2>
<h3 id="111标准化"><a class="markdownIt-Anchor" href="#111标准化"></a> 1.1.1标准化</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line"><span class="comment">#标准化，返回值为标准化后的值</span></span><br><span class="line">iris_standar=StandardScaler().fit_transform(iris.data)</span><br><span class="line">print(iris_standar[:<span class="number">5</span>])</span><br></pre></td></tr></table></figure>
<pre><code>[[-0.90068117  1.03205722 -1.3412724  -1.31297673]
 [-1.14301691 -0.1249576  -1.3412724  -1.31297673]
 [-1.38535265  0.33784833 -1.39813811 -1.31297673]
 [-1.50652052  0.10644536 -1.2844067  -1.31297673]
 [-1.02184904  1.26346019 -1.3412724  -1.31297673]]
</code></pre>
<h3 id="112区间缩放"><a class="markdownIt-Anchor" href="#112区间缩放"></a> 1.1.2区间缩放</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line"></span><br><span class="line"><span class="comment"># 区间缩放，返回值为已经缩放到[0,1]的值</span></span><br><span class="line">iris_minmax=MinMaxScaler().fit_transform(iris.data)</span><br><span class="line">print(iris_minmax[:<span class="number">5</span>])</span><br></pre></td></tr></table></figure>
<pre><code>[[ 0.22222222  0.625       0.06779661  0.04166667]
 [ 0.16666667  0.41666667  0.06779661  0.04166667]
 [ 0.11111111  0.5         0.05084746  0.04166667]
 [ 0.08333333  0.45833333  0.08474576  0.04166667]
 [ 0.19444444  0.66666667  0.06779661  0.04166667]]
</code></pre>
<h2 id="12对定量特征进行二值化"><a class="markdownIt-Anchor" href="#12对定量特征进行二值化"></a> 1.2对定量特征进行二值化</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> Binarizer</span><br><span class="line"></span><br><span class="line"><span class="comment">#二值化，分界线设置为3，返回二值化后的特征</span></span><br><span class="line">iris_binarizer=Binarizer(threshold=<span class="number">3</span>).fit_transform(iris.data)</span><br><span class="line">print(iris_binarizer[:<span class="number">5</span>])</span><br></pre></td></tr></table></figure>
<pre><code>[[ 1.  1.  0.  0.]
 [ 1.  0.  0.  0.]
 [ 1.  1.  0.  0.]
 [ 1.  1.  0.  0.]
 [ 1.  1.  0.  0.]]
</code></pre>
<h2 id="13对定性特征进行哑编码"><a class="markdownIt-Anchor" href="#13对定性特征进行哑编码"></a> 1.3对定性特征进行哑编码</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OneHotEncoder</span><br><span class="line"></span><br><span class="line"><span class="comment"># 哑编码，对iris的目标集进行哑编码，返回编码后的值</span></span><br><span class="line">iris_onehotencoder=OneHotEncoder().fit_transform(iris.target.reshape((-<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">print(iris.target[-<span class="number">5</span>:])</span><br><span class="line">print(iris.target.reshape((-<span class="number">1</span>,<span class="number">1</span>))[-<span class="number">5</span>:])</span><br><span class="line">print(iris_onehotencoder[-<span class="number">5</span>:])</span><br></pre></td></tr></table></figure>
<pre><code>[2 2 2 2 2]
[[2]
 [2]
 [2]
 [2]
 [2]]
  (0, 2)	1.0
  (1, 2)	1.0
  (2, 2)	1.0
  (3, 2)	1.0
  (4, 2)	1.0
</code></pre>
<h2 id="14缺失值计算"><a class="markdownIt-Anchor" href="#14缺失值计算"></a> 1.4缺失值计算</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> vstack, array, nan</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> Imputer</span><br><span class="line"></span><br><span class="line"><span class="comment">#缺失值计算，返回值为计算缺失值后的数据</span></span><br><span class="line"><span class="comment">#参数missing_value为缺失值的表示形式，默认为NaN</span></span><br><span class="line"><span class="comment">#参数strategy为缺失值填充方式，默认为mean（均值）</span></span><br><span class="line">iris_imputer=Imputer().fit_transform(vstack((array([nan, nan, nan, nan]), iris.data)))</span><br><span class="line">print(iris_imputer[:<span class="number">5</span>],<span class="built_in">len</span>(iris_imputer))</span><br></pre></td></tr></table></figure>
<pre><code>[[ 5.84333333  3.054       3.75866667  1.19866667]
 [ 5.1         3.5         1.4         0.2       ]
 [ 4.9         3.          1.4         0.2       ]
 [ 4.7         3.2         1.3         0.2       ]
 [ 4.6         3.1         1.5         0.2       ]] 151
</code></pre>
<h2 id="15数据变换"><a class="markdownIt-Anchor" href="#15数据变换"></a> 1.5数据变换</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures</span><br><span class="line"></span><br><span class="line"><span class="comment">#多项式转换</span></span><br><span class="line"><span class="comment">#参数degree为度，默认值为2</span></span><br><span class="line">iris_pol=PolynomialFeatures().fit_transform(iris.data)</span><br><span class="line">print(iris_pol[:<span class="number">5</span>])</span><br></pre></td></tr></table></figure>
<pre><code>[[  1.     5.1    3.5    1.4    0.2   26.01  17.85   7.14   1.02  12.25
    4.9    0.7    1.96   0.28   0.04]
 [  1.     4.9    3.     1.4    0.2   24.01  14.7    6.86   0.98   9.     4.2
    0.6    1.96   0.28   0.04]
 [  1.     4.7    3.2    1.3    0.2   22.09  15.04   6.11   0.94  10.24
    4.16   0.64   1.69   0.26   0.04]
 [  1.     4.6    3.1    1.5    0.2   21.16  14.26   6.9    0.92   9.61
    4.65   0.62   2.25   0.3    0.04]
 [  1.     5.     3.6    1.4    0.2   25.    18.     7.     1.    12.96
    5.04   0.72   1.96   0.28   0.04]]
</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> log1p</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> FunctionTransformer</span><br><span class="line"></span><br><span class="line"><span class="comment">#自定义转换函数为对数函数的数据变换</span></span><br><span class="line"><span class="comment">#第一个参数是单变元函数</span></span><br><span class="line">iris_ftf=FunctionTransformer(log1p).fit_transform(iris.data)</span><br><span class="line">print(iris_ftf[:<span class="number">5</span>])</span><br></pre></td></tr></table></figure>
<pre><code>[[ 1.80828877  1.5040774   0.87546874  0.18232156]
 [ 1.77495235  1.38629436  0.87546874  0.18232156]
 [ 1.74046617  1.43508453  0.83290912  0.18232156]
 [ 1.7227666   1.41098697  0.91629073  0.18232156]
 [ 1.79175947  1.5260563   0.87546874  0.18232156]]
</code></pre>
<h1 id="2特征选择"><a class="markdownIt-Anchor" href="#2特征选择"></a> 2.特征选择</h1>
<h2 id="21filter"><a class="markdownIt-Anchor" href="#21filter"></a> 2.1Filter</h2>
<h3 id="211方差选择法"><a class="markdownIt-Anchor" href="#211方差选择法"></a> 2.1.1方差选择法</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> VarianceThreshold</span><br><span class="line"></span><br><span class="line"><span class="comment">#方差选择法，返回值为特征选择后的数据</span></span><br><span class="line"><span class="comment">#参数threshold为方差的阈值</span></span><br><span class="line">iris_vt=VarianceThreshold(threshold=<span class="number">3</span>).fit_transform(iris.data)</span><br><span class="line">print(iris_vt,<span class="built_in">len</span>(iris_vt))</span><br></pre></td></tr></table></figure>
<pre><code>[[ 1.4]
 [ 1.4]
 [ 1.3]
 [ 1.5]
 [ 1.4]
 [ 1.7]
 [ 1.4]
 .......
</code></pre>
<h3 id="212相关系数法此处使用第二篇博客进行修改"><a class="markdownIt-Anchor" href="#212相关系数法此处使用第二篇博客进行修改"></a> 2.1.2相关系数法(此处使用第二篇博客进行修改)</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectKBest,chi2</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> pearsonr</span><br><span class="line"></span><br><span class="line"><span class="comment">#选择K个最好的特征，返回选择特征后的数据</span></span><br><span class="line"><span class="comment">#第一个参数为计算评估特征是否好的函数，该函数输入特征矩阵和目标向量，输出二元组（评分，P值）的数组，数组第i项为第i个特征的评分和P值。在此定义为计算相关系数</span></span><br><span class="line"><span class="comment">#参数k为选择的特征个数</span></span><br><span class="line">iris_pear=SelectKBest(chi2, k=<span class="number">2</span>).fit_transform(iris.data, iris.target)</span><br><span class="line">print(iris_pear,<span class="built_in">len</span>(iris_pear))</span><br></pre></td></tr></table></figure>
<pre><code>[[ 1.4  0.2]
 [ 1.4  0.2]
 [ 1.3  0.2]
 [ 1.5  0.2]
 [ 1.4  0.2]
 [ 1.7  0.4]
 [ 1.4  0.3]
 [ 1.5  0.2]
 [ 1.4  0.2]
  ..........
</code></pre>
<h3 id="213卡方检验"><a class="markdownIt-Anchor" href="#213卡方检验"></a> 2.1.3卡方检验</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectKBest</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> chi2</span><br><span class="line"></span><br><span class="line"><span class="comment">#选择K个最好的特征，返回选择特征后的数据</span></span><br><span class="line">iris_chi2=SelectKBest(chi2, k=<span class="number">2</span>).fit_transform(iris.data, iris.target)</span><br><span class="line">print(iris_chi2[:<span class="number">5</span>],<span class="built_in">len</span>(iris_chi2))</span><br></pre></td></tr></table></figure>
<pre><code>[[ 1.4  0.2]
 [ 1.4  0.2]
 [ 1.3  0.2]
 [ 1.5  0.2]
 [ 1.4  0.2]] 150
</code></pre>
<h3 id="214互信息法"><a class="markdownIt-Anchor" href="#214互信息法"></a> 2.1.4互信息法</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectKBest</span><br><span class="line"><span class="keyword">from</span> minepy <span class="keyword">import</span> MINE</span><br><span class="line"></span><br><span class="line"><span class="comment">#由于MINE的设计不是函数式的，定义mic方法将其为函数式的，返回一个二元组，二元组的第2项设置成固定的P值0.5</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mic</span>(<span class="params">x, y</span>):</span></span><br><span class="line">    m = MINE()</span><br><span class="line">    m.compute_score(x, y)</span><br><span class="line">    <span class="keyword">return</span> (m.mic(), <span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#选择K个最好的特征，返回特征选择后的数据</span></span><br><span class="line">SelectKBest(<span class="keyword">lambda</span> X, Y: array(<span class="built_in">map</span>(<span class="keyword">lambda</span> x:mic(x, Y), X.T)).T, k=<span class="number">2</span>).fit_transform(iris.data, iris.target)</span><br></pre></td></tr></table></figure>
<pre><code>---------------------------------------------------------------------------

ImportError                               Traceback (most recent call last)

&lt;ipython-input-47-807ad1fcacee&gt; in &lt;module&gt;()
      1 from sklearn.feature_selection import SelectKBest
----&gt; 2 from minepy import MINE
      3 
      4 #由于MINE的设计不是函数式的，定义mic方法将其为函数式的，返回一个二元组，二元组的第2项设置成固定的P值0.5
      5 def mic(x, y):


ImportError: No module named 'minepy'
</code></pre>
<h2 id="22wrapper"><a class="markdownIt-Anchor" href="#22wrapper"></a> 2.2Wrapper</h2>
<h3 id="321-递归特征消除法"><a class="markdownIt-Anchor" href="#321-递归特征消除法"></a> 3.2.1 递归特征消除法</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> RFE</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"></span><br><span class="line"><span class="comment">#递归特征消除法，返回特征选择后的数据</span></span><br><span class="line"><span class="comment">#参数estimator为基模型</span></span><br><span class="line"><span class="comment">#参数n_features_to_select为选择的特征个数</span></span><br><span class="line">iris_pfe=RFE(estimator=LogisticRegression(), n_features_to_select=<span class="number">2</span>).fit_transform(iris.data, iris.target)</span><br><span class="line">print(iris_pfe[:<span class="number">5</span>])</span><br></pre></td></tr></table></figure>
<pre><code>[[ 3.5  0.2]
 [ 3.   0.2]
 [ 3.2  0.2]
 [ 3.1  0.2]
 [ 3.6  0.2]]
</code></pre>
<h2 id="33-embedded"><a class="markdownIt-Anchor" href="#33-embedded"></a> 3.3 Embedded</h2>
<h3 id="331-基于惩罚项的特征选择法"><a class="markdownIt-Anchor" href="#331-基于惩罚项的特征选择法"></a> 3.3.1 基于惩罚项的特征选择法</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectFromModel</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"></span><br><span class="line"><span class="comment">#带L1惩罚项的逻辑回归作为基模型的特征选择</span></span><br><span class="line">iris_sfm=SelectFromModel(LogisticRegression(penalty=<span class="string">&quot;l1&quot;</span>, C=<span class="number">0.1</span>)).fit_transform(iris.data, iris.target)</span><br><span class="line">print(iris_sfm[:<span class="number">5</span>])</span><br></pre></td></tr></table></figure>
<pre><code>[[ 5.1  3.5  1.4]
 [ 4.9  3.   1.4]
 [ 4.7  3.2  1.3]
 [ 4.6  3.1  1.5]
 [ 5.   3.6  1.4]]
</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LR</span>(<span class="params">LogisticRegression</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, threshold=<span class="number">0.01</span>, dual=<span class="literal">False</span>, tol=<span class="number">1e-4</span>, C=<span class="number">1.0</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                 fit_intercept=<span class="literal">True</span>, intercept_scaling=<span class="number">1</span>, class_weight=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                 random_state=<span class="literal">None</span>, solver=<span class="string">&#x27;liblinear&#x27;</span>, max_iter=<span class="number">100</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                 multi_class=<span class="string">&#x27;ovr&#x27;</span>, verbose=<span class="number">0</span>, warm_start=<span class="literal">False</span>, n_jobs=<span class="number">1</span></span>):</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#权值相近的阈值</span></span><br><span class="line">        self.threshold = threshold</span><br><span class="line">        LogisticRegression.__init__(self, penalty=<span class="string">&#x27;l1&#x27;</span>, dual=dual, tol=tol, C=C,</span><br><span class="line">                 fit_intercept=fit_intercept, intercept_scaling=intercept_scaling, class_weight=class_weight,</span><br><span class="line">                 random_state=random_state, solver=solver, max_iter=max_iter,</span><br><span class="line">                 multi_class=multi_class, verbose=verbose, warm_start=warm_start, n_jobs=n_jobs)</span><br><span class="line">        <span class="comment">#使用同样的参数创建L2逻辑回归</span></span><br><span class="line">        self.l2 = LogisticRegression(penalty=<span class="string">&#x27;l2&#x27;</span>, dual=dual, tol=tol, C=C, fit_intercept=fit_intercept, intercept_scaling=intercept_scaling, class_weight = class_weight, random_state=random_state, solver=solver, max_iter=max_iter, multi_class=multi_class, verbose=verbose, warm_start=warm_start, n_jobs=n_jobs)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, X, y, sample_weight=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="comment">#训练L1逻辑回归</span></span><br><span class="line">        <span class="built_in">super</span>(LR, self).fit(X, y, sample_weight=sample_weight)</span><br><span class="line">        self.coef_old_ = self.coef_.copy()</span><br><span class="line">        <span class="comment">#训练L2逻辑回归</span></span><br><span class="line">        self.l2.fit(X, y, sample_weight=sample_weight)</span><br><span class="line"></span><br><span class="line">        cntOfRow, cntOfCol = self.coef_.shape</span><br><span class="line">        <span class="comment">#权值系数矩阵的行数对应目标值的种类数目</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(cntOfRow):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(cntOfCol):</span><br><span class="line">                coef = self.coef_[i][j]</span><br><span class="line">                <span class="comment">#L1逻辑回归的权值系数不为0</span></span><br><span class="line">                <span class="keyword">if</span> coef != <span class="number">0</span>:</span><br><span class="line">                    idx = [j]</span><br><span class="line">                    <span class="comment">#对应在L2逻辑回归中的权值系数</span></span><br><span class="line">                    coef1 = self.l2.coef_[i][j]</span><br><span class="line">                    <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(cntOfCol):</span><br><span class="line">                        coef2 = self.l2.coef_[i][k]</span><br><span class="line">                        <span class="comment">#在L2逻辑回归中，权值系数之差小于设定的阈值，且在L1中对应的权值为0</span></span><br><span class="line">                        <span class="keyword">if</span> <span class="built_in">abs</span>(coef1-coef2) &lt; self.threshold <span class="keyword">and</span> j != k <span class="keyword">and</span> self.coef_[i][k] == <span class="number">0</span>:</span><br><span class="line">                            idx.append(k)</span><br><span class="line">                    <span class="comment">#计算这一类特征的权值系数均值</span></span><br><span class="line">                    mean = coef / <span class="built_in">len</span>(idx)</span><br><span class="line">                    self.coef_[i][idx] = mean</span><br><span class="line">        <span class="keyword">return</span> self</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectFromModel</span><br><span class="line"> </span><br><span class="line"><span class="comment">#带L1和L2惩罚项的逻辑回归作为基模型的特征选择</span></span><br><span class="line"><span class="comment">#参数threshold为权值系数之差的阈值</span></span><br><span class="line">iris_sfm2=SelectFromModel(LR(threshold=<span class="number">0.5</span>, C=<span class="number">0.1</span>)).fit_transform(iris.data, iris.target)</span><br><span class="line">print(iris_sfm2[:<span class="number">5</span>])</span><br></pre></td></tr></table></figure>
<pre><code>[[ 5.1  3.5  1.4  0.2]
 [ 4.9  3.   1.4  0.2]
 [ 4.7  3.2  1.3  0.2]
 [ 4.6  3.1  1.5  0.2]
 [ 5.   3.6  1.4  0.2]]
</code></pre>
<h3 id="332-基于树模型的特征选择法"><a class="markdownIt-Anchor" href="#332-基于树模型的特征选择法"></a> 3.3.2 基于树模型的特征选择法</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectFromModel</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> GradientBoostingClassifier</span><br><span class="line"></span><br><span class="line"><span class="comment">#GBDT作为基模型的特征选择</span></span><br><span class="line">iris_sfm3=SelectFromModel(GradientBoostingClassifier()).fit_transform(iris.data, iris.target)</span><br><span class="line">print(iris_sfm3[:<span class="number">5</span>])</span><br></pre></td></tr></table></figure>
<pre><code>[[ 1.4  0.2]
 [ 1.4  0.2]
 [ 1.3  0.2]
 [ 1.5  0.2]
 [ 1.4  0.2]]
</code></pre>
<h1 id="4-降维"><a class="markdownIt-Anchor" href="#4-降维"></a> 4 降维</h1>
<h2 id="41-主成分分析法pca"><a class="markdownIt-Anchor" href="#41-主成分分析法pca"></a> 4.1 主成分分析法（PCA）</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"></span><br><span class="line"><span class="comment">#主成分分析法，返回降维后的数据</span></span><br><span class="line"><span class="comment">#参数n_components为主成分数目</span></span><br><span class="line">iris_pca=PCA(n_components=<span class="number">2</span>).fit_transform(iris.data)</span><br><span class="line">print(iris_pca[:<span class="number">5</span>])</span><br></pre></td></tr></table></figure>
<pre><code>[[-2.68420713  0.32660731]
 [-2.71539062 -0.16955685]
 [-2.88981954 -0.13734561]
 [-2.7464372  -0.31112432]
 [-2.72859298  0.33392456]]
</code></pre>
<h2 id="42-线性判别分析法lda"><a class="markdownIt-Anchor" href="#42-线性判别分析法lda"></a> 4.2 线性判别分析法（LDA）</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.lda <span class="keyword">import</span> LDA</span><br><span class="line"></span><br><span class="line"><span class="comment">#线性判别分析法，返回降维后的数据</span></span><br><span class="line"><span class="comment">#参数n_components为降维后的维数</span></span><br><span class="line">LDA(n_components=<span class="number">2</span>).fit_transform(iris.data, iris.target)</span><br></pre></td></tr></table></figure>
<pre><code>---------------------------------------------------------------------------

ImportError                               Traceback (most recent call last)

&lt;ipython-input-56-21fd5d727aec&gt; in &lt;module&gt;()
----&gt; 1 from sklearn.lda import LDA
      2 
      3 #线性判别分析法，返回降维后的数据
      4 #参数n_components为降维后的维数
      5 LDA(n_components=2).fit_transform(iris.data, iris.target)


ImportError: No module named 'sklearn.lda'
</code></pre>
<p><strong>参考文章</strong></p>
<p>1.<a href="http://www.cnblogs.com/jasonfreak/p/5448385.html">使用sklearn做单机特征工程</a></p>
<p>2.<a href="https://blog.csdn.net/lming_08/article/details/39210409">利用scikit-learn进行FeatureSelection</a></p>
]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>特征工程</tag>
        <tag>sklearn</tag>
      </tags>
  </entry>
  <entry>
    <title>给阅读的网页作标记</title>
    <url>/2016/06/01/%E7%BB%99%E9%98%85%E8%AF%BB%E7%9A%84%E7%BD%91%E9%A1%B5%E4%BD%9C%E6%A0%87%E8%AE%B0/</url>
    <content><![CDATA[<p><strong>需求</strong>：经常性的阅读一些文档，阅读过程中，想做些记录，但是现有的这方面工具很少，即是有也是需要使用账号登录，并进行收费的</p>
<a id="more"></a>
<p>现在FireFox下找到一款名为Textmarker的插件，该插件支持对文本进行高亮显示，并且可以自定义高亮的样式。</p>
<p>插件地址：<a href="https://addons.mozilla.org/zh-CN/firefox/addon/textmarkerpro/?src=api">https://addons.mozilla.org/zh-CN/firefox/addon/textmarkerpro/?src=api</a></p>
<p>插件使用效果：</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613525617346.jpg" alt="Textmarker使用效果" /></p>
<p>我的插件配置：<br />
<img src="./attachments/1613525617396.jpg" alt="Textmarker样式" /></p>
<p>导入配置数据：</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613525617407.jpg" alt="导入配置数据" /></p>
<p><font color="red"><strong>注：标注后刷新会消失高亮，所以建议标注后存储到第三方中，比如印象笔记等。</strong></font></p>
]]></content>
      <categories>
        <category>软件工具</category>
      </categories>
      <tags>
        <tag>Firefox</tag>
      </tags>
  </entry>
  <entry>
    <title>编程中的项目、文件、变量命名探究</title>
    <url>/2021/02/20/%E7%BC%96%E7%A0%81%E4%B8%AD%E5%90%84%E7%B1%BB%E5%91%BD%E5%90%8D%E6%96%B9%E5%BC%8F%E6%8E%A2%E7%B4%A2/</url>
    <content><![CDATA[<p>命名，可以说是编码的第一步，从一个项目如何命令，一个文件如何命名，到一个类的命名，一个函数的命名都需要规范</p>
<a id="more"></a>
<h1 id="1项目的命名方式"><a class="markdownIt-Anchor" href="#1项目的命名方式"></a> 1.项目的命名方式</h1>
<p>统计了github上Google与Nvidia两家公司的部分的开源项目，发现他们的命名规则分为以下几类</p>
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">Google</th>
<th style="text-align:center">Nvidia</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">全部小写</td>
<td style="text-align:center">tensorflow、tensorboard、tfjs</td>
<td style="text-align:center">deepops、aistore、libcudacxx</td>
</tr>
<tr>
<td style="text-align:center">小写+“-”</td>
<td style="text-align:center">model-card-toolkit、ngraph-bridge、tflite-support</td>
<td style="text-align:center">spark-rapids、framework-determinism、container-config、nvidia-gcp-samples</td>
</tr>
<tr>
<td style="text-align:center">首字母大写</td>
<td style="text-align:center">-</td>
<td style="text-align:center">TensorRT、TRTorch</td>
</tr>
<tr>
<td style="text-align:center">首字母大写+“-”</td>
<td style="text-align:center">-</td>
<td style="text-align:center">Reflex-Latency-Analyzer-Mouse-Database</td>
</tr>
<tr>
<td style="text-align:center">特殊含义的缩写（大写）</td>
<td style="text-align:center">-</td>
<td style="text-align:center">AMGX、DCGM、DALI</td>
</tr>
</tbody>
</table>
<blockquote>
<p>统计时间：2021.2.4</p>
</blockquote>
<p>从统计的数据来看，两家同时的开源项目命名以<code>全部小写</code>、<code>小写+“-”</code>为主，实际命名项目时，也建议使用这两种方式</p>
<h1 id="2python常见命名规"><a class="markdownIt-Anchor" href="#2python常见命名规"></a> 2.Python常见命名规</h1>
<blockquote>
<p>copy from <a href="https://zh-google-styleguide.readthedocs.io/en/latest/google-python-styleguide/python_style_rules/#id16">Google 开源项目风格指南-Python命名</a></p>
</blockquote>
<p><strong>Python之父Guido推荐的规范</strong></p>
<table>
<thead>
<tr>
<th style="text-align:left">Type</th>
<th style="text-align:left">Public</th>
<th style="text-align:left">Internal</th>
<th>note</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">Modules</td>
<td style="text-align:left">lower_with_under</td>
<td style="text-align:left">_lower_with_under</td>
<td>模块</td>
</tr>
<tr>
<td style="text-align:left">Packages</td>
<td style="text-align:left">lower_with_under</td>
<td style="text-align:left"></td>
<td>包</td>
</tr>
<tr>
<td style="text-align:left">Classes</td>
<td style="text-align:left">CapWords</td>
<td style="text-align:left">_CapWords</td>
<td>类</td>
</tr>
<tr>
<td style="text-align:left">Exceptions</td>
<td style="text-align:left">CapWords</td>
<td style="text-align:left"></td>
<td>异常</td>
</tr>
<tr>
<td style="text-align:left">Functions</td>
<td style="text-align:left">lower_with_under()</td>
<td style="text-align:left">_lower_with_under()</td>
<td>函数</td>
</tr>
<tr>
<td style="text-align:left">Global/Class Constants</td>
<td style="text-align:left">CAPS_WITH_UNDER</td>
<td style="text-align:left">_CAPS_WITH_UNDER</td>
<td>常量</td>
</tr>
<tr>
<td style="text-align:left">Global/Class Variables</td>
<td style="text-align:left">lower_with_under</td>
<td style="text-align:left">_lower_with_under</td>
<td>变量</td>
</tr>
<tr>
<td style="text-align:left">Instance Variables</td>
<td style="text-align:left">lower_with_under</td>
<td style="text-align:left">_lower_with_under (protected) or __lower_with_under (private)</td>
<td>实例变量</td>
</tr>
<tr>
<td style="text-align:left">Method Names</td>
<td style="text-align:left">lower_with_under()</td>
<td style="text-align:left">_lower_with_under() (protected) or __lower_with_under() (private)</td>
<td>方法名</td>
</tr>
</tbody>
</table>
<h1 id="c常见命名规范"><a class="markdownIt-Anchor" href="#c常见命名规范"></a> C++常见命名规范</h1>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">对于高质量的工程，一般会做到：</span><br><span class="line">	1.代码简洁精炼，美观，可读性好，高效率，高复用，可移植性好，高内聚，低耦合，没有冗余，不符合这些原则，必须特别说明。</span><br><span class="line">    2.规范性，代码有规可循。特殊排版、特殊语法、特殊指令，必须特别说明。</span><br></pre></td></tr></table></figure>
<blockquote>
<p>摘录自：<a href="https://www.cnblogs.com/winslam/p/11147396.html">C++命名规范</a></p>
</blockquote>
<p>1.什么是低耦合、高内聚？<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup></p>
<p><code>低耦合</code>:耦合指的是元素与元素之间的连接或依赖程度，这里的元素包括功能、对象、系统、子系统、模块。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">例如：现有元素A，B,A依赖B完成，如果B出现问题或者经过修改，A元素就不能正常工作，那么说元素A、B之间耦合</span><br></pre></td></tr></table></figure>
<p><code>高内聚</code>：或称为功能内聚，指系统中元素职责的相关性和集中程度，如果元素有高度的相关职责，而没有其他工作，这就是高内聚</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">例如：只需要元素A、B共同完成计算，就可以最终得到C，在元素A、B所在范围（函数、类、模块等）内，如果没有其他元素并且A、B不参与其他计算，则认为A、B元素所在范围高内聚。</span><br></pre></td></tr></table></figure>
<p><strong>通俗理解</strong></p>
<p>耦合越弱越好，内聚越强越好，最弱的模块就是通过一个主控模块协调N个模块进行协作，最终得到结果；最强的内聚体现在功能能不能拆分、就是是否原子化。</p>
<hr class="footnotes-sep" />
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p><a href="https://blog.csdn.net/liyuefeilong/article/details/50560564">个人总结的一些C/C++编码规范</a> <a href="#fnref1" class="footnote-backref">↩︎</a></p>
</li>
</ol>
</section>
]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>命名</tag>
      </tags>
  </entry>
  <entry>
    <title>读官方Git教程(1)~认识Git</title>
    <url>/2018/03/25/%E8%AF%BB%E5%AE%98%E6%96%B9Git%E6%95%99%E7%A8%8B(1)~%E8%AE%A4%E8%AF%86Git/</url>
    <content><![CDATA[<p>教程内容基本来自<a href="https://git-scm.com/book/zh/v2/%E8%B5%B7%E6%AD%A5-%E5%85%B3%E4%BA%8E%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6">git官方教程</a>,认真都了系列的文章,然后对一些重点的记录下来,做了简单的归纳并写上自己的思考.</p>
<a id="more"></a>
<h1 id="1git介绍"><a class="markdownIt-Anchor" href="#1git介绍"></a> 1.Git介绍</h1>
<p><strong>版本控制</strong>是一种记录一个或若干文件内容变化，以便将来查阅特定版本修订情况的系统。</p>
<p>采用版本控制系统（VCS）是个明智的选择。 有了它你就可以将某个文件回溯到之前的状态，甚至将整个项目都回退到过去某个时间点的状态;  你可以比较文件的变化细节，查出最后是谁修改了哪个地方，从而找出导致怪异问题出现的原因;  又是谁在何时报告了某个功能缺陷等等。 使用版本控制系统通常还意味着，就算你乱来一气把整个项目中的文件改的改删的删，你也照样可以轻松恢复到原先的样子。 但额外增加的工作量却微乎其微。</p>
<h1 id="2git版本控制原理"><a class="markdownIt-Anchor" href="#2git版本控制原理"></a> 2.Git版本控制原理</h1>
<p>Git 和其它版本控制系统（包括 Subversion 和近似工具）的主要差别在于 Git 对待数据的方法。概念上来区分，其它大部分系统以文件变更列表的方式存储信息。下图是一般CSV的设计原理:</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613546181169.png" alt="其他版本控制的原理" /></p>
<p>存储的是每个文件与初始版本的差异,即每个版本相当于以增量的方式存储当前版本与初始版本的差异.</p>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613546181170.png" alt="Git版本控制原理" /></p>
<p>Git不采用这种方式,而是是把数据看作是对小型文件系统的一组快照。 每次你提交更新，或在 Git 中保存项目状态时，它主要对当时的全部文件制作一个快照并保存这个快照的索引。Git 对待数据更像是一个 <strong>快照流</strong>。</p>
<h1 id="3git特点"><a class="markdownIt-Anchor" href="#3git特点"></a> 3.Git特点</h1>
<p><strong>3.1本地操作</strong><br />
在 Git 中的绝大多数操作都只需要访问本地文件和资源，一般不需要来自网络上其它计算机的信息。</p>
<p>举个例子，要浏览项目的历史，Git 不需外连到服务器去获取历史，然后再显示出来——它只需直接从本地数据库中读取。 你能立即看到项目历史。 如果你想查看当前版本与一个月前的版本之间引入的修改，Git 会查找到一个月前的文件做一次本地的差异计算，而不是由远程服务器处理或从远程服务器拉回旧版本文件再来本地处理。</p>
<p><strong>3.2数据完整性</strong><br />
Git 数据库中保存的信息都是以文件内容的哈希值来索引，而不是文件名。这意味着不可能在 Git 不知情时更改任何文件内容或目录内容。同时, 若你在传送过程中丢失信息或损坏文件，Git 就能发现。</p>
<p><strong>3.3一般只添加数据</strong><br />
你执行的 Git 操作，几乎只往 Git 数据库中增加数据。 很难让 Git 执行任何不可逆操作，或者让它以任何方式清除数据。</p>
<h1 id="4git中文件的三种状态"><a class="markdownIt-Anchor" href="#4git中文件的三种状态"></a> 4.Git中文件的三种状态</h1>
<p>Git 有三种状态，你的文件可能处于其中之一：</p>
<blockquote>
<p>a.已提交（committed)   已提交表示数据已经安全的保存在本地数据库中。<br />
b.已修改（modified）  已修改表示修改了文件，但还没保存到数据库中。<br />
c.已暂存（staged)   已暂存表示对一个已修改文件的当前版本做了标记，使之包含在下次提交的快照中。</p>
</blockquote>
<p><img src="https://gitee.com/savecoding/imagesbed/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1613546181176.png" alt="工作目录、暂存区域以及 Git 仓库" /></p>
<p>Git 仓库目录是 Git 用来保存项目的元数据和对象数据库的地方。 这是 Git 中最重要的部分，从其它计算机克隆仓库时，拷贝的就是这里的数据。</p>
<p>工作目录是对项目的某个版本独立提取出来的内容。 这些从 Git 仓库的压缩数据库中提取出来的文件，放在磁盘上供你使用或修改。</p>
<p>暂存区域是一个文件，保存了下次将提交的文件列表信息，一般在 Git 仓库目录中。 有时候也被称作<code>索引</code>，不过一般说法还是叫暂存区域。</p>
<p>基本的 Git 工作流程如下：</p>
<blockquote>
<p>在工作目录中修改文件。<br />
暂存文件，将文件的快照放入暂存区域。<br />
提交更新，找到暂存区域的文件，将快照永久性存储到 Git 仓库目录。</p>
</blockquote>
<p>如果 Git 目录中保存着的特定版本文件，就属于已提交状态。 如果作了修改并已放入暂存区域，就属于已暂存状态。 如果自上次取出后，作了修改但还没有放到暂存区域，就是已修改状态。</p>
]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>版本管理</tag>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>读官方Git教程(2)~安装与配置</title>
    <url>/2018/03/25/%E8%AF%BB%E5%AE%98%E6%96%B9Git%E6%95%99%E7%A8%8B(2)~%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<p>教程内容基本来自<a href="https://git-scm.com/book/zh/v2/%E8%B5%B7%E6%AD%A5-%E5%85%B3%E4%BA%8E%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6">git官方教程</a>,认真都了系列的文章,然后对一些重点的记录下来,做了简单的归纳并写上自己的思考.</p>
<a id="more"></a>
<h1 id="1安装"><a class="markdownIt-Anchor" href="#1安装"></a> 1.安装</h1>
<p>在基于 Debian 的发行版上，使用 apt-get安装:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo apt-get install git</span><br></pre></td></tr></table></figure>
<h1 id="2配置"><a class="markdownIt-Anchor" href="#2配置"></a> 2.配置</h1>
<p>Git 自带一个 git config 的工具来帮助设置控制 Git 外观和行为的配置变量。 这些变量存储在三个不同的位置：</p>
<blockquote>
<p>(1)/etc/gitconfig 文件: 包含系统上每一个用户及他们仓库的通用配置。 如果使用带有 --system 选项的 git config 时，它会从此文件读写配置变量。<br />
(2)~/.gitconfig 或 ~/.config/git/config 文件：只针对当前用户。 可以传递 --global 选项让 Git 读写此文件。<br />
(3)当前使用仓库的 Git 目录中的 config 文件（就是 .git/config）：针对该仓库。</p>
</blockquote>
<p>每一个级别覆盖上一级别的配置，所以 .git/config 的配置变量会覆盖 /etc/gitconfig 中的配置变量。</p>
<p><strong>配置用户信息</strong><br />
当安装完 Git 应该做的第一件事就是设置你的用户名称与邮件地址。 使用以下命令配置:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git config --global user.name <span class="string">&quot;xxxx&quot;</span></span><br><span class="line">git config --global user.email xx@example.com</span><br></pre></td></tr></table></figure>
<p>当你想针对特定项目使用不同的用户名称与邮件地址时，可以在那个项目目录下运行没有 --global 选项的命令来配置。</p>
<p><strong>配置文本编辑器</strong><br />
Git 会使用操作系统默认的文本编辑器，通常是 Vim。 如果你想使用不同的文本编辑器，例如 Emacs，使用以下命令配置:</p>
 <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git config --global core.editor emacs</span><br></pre></td></tr></table></figure>
<p><strong>检测配置信息</strong><br />
如果想要检查你的配置，可以使用 git config --list 命令来列出所有 Git 当时能找到的配置。</p>
<p>注:你可能会看到重复的变量名，因为 Git 会从不同的文件中读取同一个配置</p>
<p>你可以通过输入 git config <key>来检查 Git 的某一项配置,如查看用户名:</p>
 <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git config user.name</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>版本管理</tag>
        <tag>git</tag>
      </tags>
  </entry>
</search>
